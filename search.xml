<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>红黑树原理</title>
      <link href="/2022/04/16/collection/%E7%BA%A2%E9%BB%91%E6%A0%91%E5%8E%9F%E7%90%86/"/>
      <url>/2022/04/16/collection/%E7%BA%A2%E9%BB%91%E6%A0%91%E5%8E%9F%E7%90%86/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="二叉搜索树"><a href="#二叉搜索树" class="headerlink" title="二叉搜索树"></a>二叉搜索树</h1><h2 id="二叉搜索树的定义"><a href="#二叉搜索树的定义" class="headerlink" title="二叉搜索树的定义"></a>二叉搜索树的定义</h2><p>二叉搜索树（Binary Search Tree），它或者是一棵空树，或者是具有下列性质的二叉树：</p><ul><li>若它的左子树不空，则左子树上所有结点的值均小于它的根结点的值；</li><li>若它的右子树不空，则右子树上所有结点的值均大于它的根结点的值；</li><li>它的左、右子树也分别为二叉排序树。</li></ul><p><img src="https://cdn.jsdelivr.net/gh/junian455/pic@master/img/image-20210604212421939.png"></p><ol><li>二叉搜索树：通俗地讲，以当前节点为根，其左右子树的特点：<strong>左小右大</strong>。当前节点为 50 时，其左子树所有节点均小于 50，右子树所有节点均大于 50：</li></ol><p><img src="https://cdn.jsdelivr.net/gh/junian455/pic@master/img/image-20210604212537415.png"><br>2. 节点 50 的左右子树也同样符合这种特点，以左子树为例（以 30 为根的树）：<br><img src="https://cdn.jsdelivr.net/gh/junian455/pic@master/img/image-20210604212624535.png"></p><ol start="3"><li>同样的，其他的子树、子树的子树等均符合该规律（类似递归）。</li></ol><h2 id="二叉搜索树的查找"><a href="#二叉搜索树的查找" class="headerlink" title="二叉搜索树的查找"></a>二叉搜索树的查找</h2><p>根据左小右大的特点，查找一个元素时，从根节点出发：</p><ol><li>如果查找的元素比当前节点小，则到左子树找；</li><li>如果查找的元素比当前节点大，则到右子树找；</li><li>如果查找的元素等于当前节点，说明找到了；</li><li>如果直至叶子节点都找不到对应的，说明该元素不存在该树中。</li></ol><p><img src="https://cdn.jsdelivr.net/gh/junian455/pic@master/img/image-20210604213153624.png"></p><p><img src="https://cdn.jsdelivr.net/gh/junian455/pic@master/img/image-20210604213236420.png"></p><h2 id="二叉搜索树的插入"><a href="#二叉搜索树的插入" class="headerlink" title="二叉搜索树的插入"></a>二叉搜索树的插入</h2><p>插入元素时，主要是找到合适的位置进行插入（类似查找）：</p><ol><li>插入的树为空树（无节点），直接创建节点即可；</li><li>插入的树非空树：<ul><li>如果插入的元素比当前节点小，则到左子树插入；如果左子树 / 节点为 null，插入该处；</li><li>如果插入的元素比当前节点大，则到右子树插入；如果右子树 / 节点为 null，插入该处；</li><li>如果插入的元素和当前节点相等，说明该元素已经存在了，直接返回。</li></ul></li></ol><p><img src="https://cdn.jsdelivr.net/gh/junian455/pic@master/img/image-20210604213438652.png"></p><h2 id="二叉搜索树的删除"><a href="#二叉搜索树的删除" class="headerlink" title="二叉搜索树的删除"></a>二叉搜索树的删除</h2><p><strong>前继节点和后继节点</strong></p><blockquote><p>二叉搜索树因为自身的特性（左小右大），中序遍历的结果必然是有序的。比如以下这棵树，其遍历的结果为：【20, 30, 35, 40, 45, 50, 55, 60, 65 70, 80】</p></blockquote><p><img src="https://cdn.jsdelivr.net/gh/junian455/pic@master/img/image-20210604213631098.png"></p><blockquote><p>在二叉搜索树中，前继节点表示比当前节点小的最大值，后继节点表示比当前节点大的最小值，看例子就很容易明白：比如上面【20, 30, 35, 40, 45, 50, 55, 60, 65 70, 80】中，节点 50 的前继节点为 45，后继节点为 55。在二叉搜索树中，寻找前后继节点很简单：</p></blockquote><ol><li>寻找前继节点，当前节点左转一下，然后右转一直走到底（右子节点为 null 时终止）：</li></ol><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210604213827013.png"></p><ol start="2"><li>寻找后继节点，当前节点右转一下，然后左转一直走到底（左子节点为 null 时终止）：</li></ol><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210604213936309.png"></p><h3 id="根据子节点数量进行删除处理"><a href="#根据子节点数量进行删除处理" class="headerlink" title="根据子节点数量进行删除处理"></a>根据子节点数量进行删除处理</h3><p>删除前首先要找到该节点，如果找不到，直接结束即可。找到后，可以分为以下三种情景：</p><ol><li><p>无子节点，即叶子节点，直接删除即可；</p></li><li><p>只有一个子节点，用该子节点接到删除节点的父节点即可；</p></li><li><p>有两个子节点，使用前或后继节点作为替换节点，对删除节点进行数据替换，然后转移至删除替换节点即可。而此时删除后继节点时，必然是情景 1 或 2 了。如下图：</p></li></ol><p><img src="https://cdn.jsdelivr.net/gh/junian455/pic@master/img/image-20210604215052103.png"></p><p><strong>情景 1：</strong></p><p><img src="https://cdn.jsdelivr.net/gh/junian455/pic@master/img/image-20210604215126921.png"><br><strong>情景 2：</strong></p><p><img src="https://cdn.jsdelivr.net/gh/junian455/pic@master/img/image-20210604215316458.png"><br><strong>情景 3 ：</strong></p><p><img src="https://cdn.jsdelivr.net/gh/junian455/pic@master/img/image-20210604215342745.png"></p><blockquote><p>关于情景 3，无论使用前继节点还是后继节点，均可以达到同样的目的，选其一即可。</p></blockquote><h2 id="二叉搜索树的问题"><a href="#二叉搜索树的问题" class="headerlink" title="二叉搜索树的问题"></a>二叉搜索树的问题</h2><ol><li>极端时，搜索的时间复杂度将会降低到 O (n)，比如以下这个例子，连续插入 10,20,30,40,50：</li></ol><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210604214218409.png"></p><ol start="2"><li>而平衡二叉搜索树（AVL 树、红黑树等）就是为了解决这个问题：平衡二叉树在进行插入、删除后，会进行自平衡，从而保证其查询的时间复杂度接近于 O (log2n)。如红黑树连续插入 10,20,30,40,50：</li></ol><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210604214241912.png"></p><h1 id="红黑树"><a href="#红黑树" class="headerlink" title="红黑树"></a>红黑树</h1><h2 id="红黑树的定义"><a href="#红黑树的定义" class="headerlink" title="红黑树的定义"></a>红黑树的定义</h2><p>红黑树在二叉搜索树的基础上，还要求有以下性质：</p><ol><li>节点是红色或黑色；</li><li>根节点是黑色；</li><li>不能有连续的两个红色节点。</li><li>从任一节点到其每个叶子的简单路径都包含相同数目的黑色节点。</li></ol><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210621213429942.png"></p><ul><li><p>性质 3 表明：红色节点的父、左子、右子只能是黑色节点，红色和红色不能直接连一起；而黑色无论红黑都可以连一起。（红色暴脾气互不相容，黑色和蔼可亲谁来都行）</p></li><li><p>性质 4 表明：随便选一个节点，不论从怎么走，走到最后叶子节点时，其经过路径的黑色节点数量都是相等的（所谓完全黑平衡）。</p></li><li><p>性质 3 和 4 共同决定了：最长路径的节点总数量不会超过最短路径的两倍。因为黑色节点数量要一样，红色不能连着来，从而路径全黑时最短，红黑交替时最长。</p></li><li><p>因为路径长度 / 高度差有了一定限制，所以称红黑树是有一定平衡性的，不会出现极端倾斜的情况。</p></li><li><p>有一些红黑树定义（比如维基百科），还有一个性质：“叶子是黑色的 NULL 节点”。如下所示：</p></li></ul><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210621214018831.png"></p><blockquote><p>引入黑色的 NULL 节点并不会对之前的定义产生影响（各路径都增加一个黑色节点，黑色数量依然相等），其目的更多是为了简化平衡操作的情况，平衡时可以认为：null 就是黑色节点。此时只需要考虑红和黑这两种情况就行，而不用考虑非红非黑的 null。</p></blockquote><h2 id="旋转"><a href="#旋转" class="headerlink" title="旋转"></a>旋转</h2><p>说插入之前，先来看看旋转：</p><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210621214159638.png"></p><ul><li><p>旋转后，原来 “左小右大” 的特点不会受到影响，影响的是左右子树的高度，右旋左子树高度 - 1，右子树 + 1；左旋右子树高度 - 1，左子树 + 1。</p></li><li><p>比如某棵树的左子树高度已经达到 3，而右子树只有 1，只需要右旋一下，左右子树高度都将调整为 2。整棵树来看，高度就相当于降低了 1（3 -&gt; 2），这就是高度的 “平衡”。</p></li><li><p>旋转前首先要确定旋转的节点（姑且叫支点）是哪个，这个非常重要。比如上图右旋前，要以 X 为支点才能转成右侧那样，如果选择 Y 作为支点，则要往下一层看了（X 节点将以 P 的角色出现）。</p></li><li><p>另外留意一下 b：</p><ul><li>右旋前，b 是挂在 Y 的右子，而右旋后，挂到了 X 的左子了；</li><li>左旋前，b 是挂在 X 的左子，而左旋后，挂到了 Y 的右子了。</li></ul></li></ul><h2 id="插入平衡"><a href="#插入平衡" class="headerlink" title="插入平衡"></a>插入平衡</h2><ol><li>开始之前，我们先约定一下名称：</li></ol><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210621214521836.png"></p><ol start="2"><li><p>红黑树属于二叉搜索树，插入动作也与二叉搜索树一致，只不过红黑树在插入之后，多了平衡动作（旋转与涂色）。</p></li><li><p>新插入的节点均为红色节点，因为红色不会影响路径上黑色节点的数量，保持性质 4。如果父节点为黑色，就直接结束了；如果父节点为红色，则需要另外处理了。</p></li><li><p>以新插入的节点为当前平衡节点 N，插入平衡大体上分为以下情形：</p></li></ol><p><img src="https://cdn.jsdelivr.net/gh/junian455/pic@master/img/image-20210621214712328.png"></p><h2 id="情形-1-N-为根节点（父节点为-NULL）"><a href="#情形-1-N-为根节点（父节点为-NULL）" class="headerlink" title="情形 1. N 为根节点（父节点为 NULL）"></a>情形 1. N 为根节点（父节点为 NULL）</h2><p>当前平衡节点 N 为根节点时，直接涂黑根节点即可。</p><p><img src="https://cdn.jsdelivr.net/gh/junian455/pic@master/img/image-20210621214829285.png"></p><h2 id="情形-2-父黑"><a href="#情形-2-父黑" class="headerlink" title="情形 2. 父黑"></a>情形 2. 父黑</h2><p>父节点为黑色时，无需其他操作，已然平衡。</p><p><img src="https://cdn.jsdelivr.net/gh/junian455/pic@master/img/image-20210621214904348.png"></p><h2 id="情形-3-父红-叔红"><a href="#情形-3-父红-叔红" class="headerlink" title="情形 3. 父红 - 叔红"></a>情形 3. 父红 - 叔红</h2><p>父红 - 叔红时，将父 / 叔节 (P/U) 点涂黑，祖父节点 (GP) 涂红；而后以祖父节点 (GP) 作为新的平衡节点 N，递归执行平衡操作。</p><p><img src="https://cdn.jsdelivr.net/gh/junian455/pic@master/img/image-20210621214954969.png"></p><h2 id="情形-4-父红-叔黑"><a href="#情形-4-父红-叔黑" class="headerlink" title="情形 4. 父红 - 叔黑"></a>情形 4. 父红 - 叔黑</h2><p><strong>情形 4.1 父节点和 N 同一边</strong><br><strong>情形 4.1.1 父 N 同左</strong></p><p>“父 N 同左” 指的是：<strong>父节点为祖父节点的左子，N 为父节点的左子</strong>。此时以<strong>祖父节点 (GP) 为支点进行右旋；</strong>然后将 P 涂黑，将 GP 涂红。</p><p><img src="https://cdn.jsdelivr.net/gh/junian455/pic@master/img/image-20210621215515564.png"></p><blockquote><p>旋转后，P 涂黑是因为要涂为原 GP 的黑色（往上兼容 GP 的父节点）；而 GP 涂红则是因为右旋后，经过 U 的路径的黑色节点数量 + 1，涂红进行数量平衡；下同。</p></blockquote><p><strong>情形 4.1.2 父 N 同右</strong></p><p>“父 N 同右” 指的是：<strong>父节点是祖父节点的右子，N 为父节点的右子</strong>。此时以<strong>祖父节点 (GP) 为支点进行左旋</strong>；将 P 涂黑，将 GP 涂红。</p><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210621215640141.png"></p><h3 id="情形-4-2-父节点和-N-不在同一边"><a href="#情形-4-2-父节点和-N-不在同一边" class="headerlink" title="情形 4.2 父节点和 N 不在同一边"></a>情形 4.2 父节点和 N 不在同一边</h3><p><strong>情形 4.2.1 父左 N 右</strong></p><p>“父左 N 右” 指的是：<strong>父节点是祖父节点的左子，N 为父节点的右子。此时，以父节点 (P) 进行左旋</strong>，旋转后，以 P 作为新的平衡节点 N，转至 [情形 4.1.1 父 N 同左] 处理。</p><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210621215721671.png"></p><p><strong>情形 4.2.2 父右 N 左</strong></p><p>“父右 N 左” 指的是：<strong>父节点是祖父节点的右子，N 为父节点的左子</strong>。 此时，以<strong>父节点 (P) 进行右旋</strong>，旋转后，以 P 作为新的平衡节点，此时再进行【情形 4.1.2 父 N 同右】处理。</p><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210621215751709.png"></p><h2 id="插入总结与实例"><a href="#插入总结与实例" class="headerlink" title="插入总结与实例"></a>插入总结与实例</h2><blockquote><p>首先是将节点先插入再说，插入后，以刚插入的节点作为当前平衡节点 N，进行平衡操作。现在回头看插入平衡的这几种情形，其实并不复杂：</p></blockquote><ol><li>N 为根：涂黑完事；</li><li>父黑：啥事不用管；</li><li>父红叔红：父 / 叔涂黑，祖父涂红，然后把祖父当成新的平衡节点递归处理（我们下面平衡了，让他老人家和上面沟通吧）；</li><li>父红叔黑：父节点和新插入节点同一边的话，扭一下就完事了（同左右旋，同右左旋，顺便涂色）；不在同一边的话，先扭到同一边吧。</li></ol><p>实例说明：为了简化，图中没有画出 null 的黑色节点。插入 10、20、15、30、5、8：</p><p><img src="https://cdn.jsdelivr.net/gh/junian455/pic@master/img/image-20210621220104464.png"></p><h2 id="红黑树删除动作"><a href="#红黑树删除动作" class="headerlink" title="红黑树删除动作"></a>红黑树删除动作</h2><p>红黑树和二叉搜索树的删除类似，只不过加上颜色属性（这里的子节点均指非 NULL 节点）：</p><ol><li><p>无子节点时，删除节点可能为红色或者黑色：</p><ul><li>如果为红色，直接删除即可，不会影响黑色节点的数量；</li><li>如果为黑色，则需要进行删除平衡的操作了。</li></ul></li><li><p>只有一个子节点时，删除节点只能是黑色，其子节点为红色，无法满足红黑树的性质了。 此时用删除节点的子节点接到父节点，且将子节点颜色涂黑，保证黑色数量。</p></li><li><p>有两个子节点时，与二叉搜索树一样，使用后继节点作为替换的删除节点，情形转至为 1 或 2 处理。</p></li></ol><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210623183154785.png"></p><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210623183306766.png"></p><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210623183338156.png"></p><p>我们发现，删除情形 3 总是会转换为情形 1 和 2，而情形 1.1 和情形 2 处理平衡非常简单，本文主要讨论的是情形 1.2：删除<strong>黑色的叶子节点</strong>。因为一旦该节点被拿掉，红黑树中通过该节点的路径黑色节点数量将会减 1，而且无法像情形 2 那样将子节点涂黑来达到平衡。此时只能自底向上进行平衡操作。</p><blockquote><p>这里的图特意将黑色的 NULL 节点给加上，这是因为删除节点被摘掉后，我们可以用一个黑色的节点接上，从而进行统一处理。</p></blockquote><h2 id="删除后的平衡"><a href="#删除后的平衡" class="headerlink" title="删除后的平衡"></a>删除后的平衡</h2><p>我们先约定一下节点名称：</p><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210623183553595.png"></p><p>h (A-&gt;B-&gt; 叶子) 表示从 A 走到 B 再走到某一个叶子路径的黑色节点数量（A 与 B，B 与叶子之间可能间隔了多个节点）</p><hr><p>本文余下内容均指的是删除黑色的叶子节点后引发的一系列平衡操作。比如 P-&gt;D-&gt;N，删除 D（黑色）后，N 接至父节点：P-&gt;N。</p><p>因为删除了一个黑色节点（N 的父节点 D），经过 N 的路径的黑色数量减 1，即 h (P-&gt;N-&gt; 叶子) 比 h (P-&gt;S-&gt; 叶子) 少 1。平衡的方式有：</p><ol><li><p>h (P-&gt;N-&gt; 叶子) 不变，h (P-&gt;S-&gt; 叶子) 减 1，此时已经子平衡，然而 h (GP-&gt;P-&gt; 叶子) 还是会比 h (GP -&gt; U -&gt; 叶子) 少 1，此时需要将 P 当作新的 N，向上递归处理；</p></li><li><p>h (P-&gt;N-&gt; 叶子) 加 1，h (P-&gt;S-&gt; 叶子) 不变，也就是恢复了原来的状态，此时已经平衡，因为 h (GP-&gt;P-&gt; 叶子)=h (GP -&gt; U -&gt; 叶子)。<br>本文下面平衡的思路主要就是基于以上两种方式，另外要注意的是，红色和红色不能连一起的约束也不能违反。理解这个比较重要。</p></li></ol><blockquote><p>GP-&gt;P-&gt; 叶子 的路径，要么经过 N，要么经过 S，如果 h (P-&gt;N-&gt; 叶子) 和 h (P-&gt;S-&gt; 叶子) 均少 1 了，自然 h (GP-&gt;P-&gt; 叶子) 会少 1。</p></blockquote><p>删除平衡情形，主要根据 [兄节点的位置 / 颜色]、[兄的子节点的颜色]、[父节点颜色] 进行分类：</p><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210623184415756.png"></p><p>N 节点的位置知道后，S 的位置自然也就知道了，相反亦可；这里以 S 位置作为分类，主要是为了便于理解和记忆。</p><h2 id="情形-1-当前节点为根节点（父节点为-NULL）"><a href="#情形-1-当前节点为根节点（父节点为-NULL）" class="headerlink" title="情形 1 当前节点为根节点（父节点为 NULL）"></a>情形 1 当前节点为根节点（父节点为 NULL）</h2><p>比较特殊的情况，无需平衡操作。因为经过根节点的黑色数量少一个，意味着所有路径都少一个，已然平衡。</p><h2 id="情形-2-兄弟节点为黑色（S-黑）"><a href="#情形-2-兄弟节点为黑色（S-黑）" class="headerlink" title="情形 2 兄弟节点为黑色（S = 黑）"></a>情形 2 兄弟节点为黑色（S = 黑）</h2><h3 id="情形-2-1-兄弟的子节点全黑"><a href="#情形-2-1-兄弟的子节点全黑" class="headerlink" title="情形 2.1 兄弟的子节点全黑"></a>情形 2.1 兄弟的子节点全黑</h3><p>兄弟节点的子节点全为黑色（SL/SR = 黑），也就意味着兄弟节点（S）可以涂红而不会和子冲突。S 涂红后，也就实现了子平衡， 这时候我们看父节点是红是黑，再做处理。</p><p><strong>情形 2.1.1 父节点为黑色（P = 黑）</strong></p><p>此时将 S 涂红，父节点作为新的平衡节点 N，递归上去处理。这个也就是之前提到的 h (P-&gt;N-&gt; 叶子) 不变，h (P-&gt;S-&gt; 叶子) 减 1，而 h (GP-&gt;P-&gt; 叶子)，依然会比 h (GP -&gt; U -&gt; 叶子) 少 1，所以要递归上去处理。</p><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210623190829319.png"></p><p><strong>情形 2.1.2 父节点为红色（P = 红）</strong></p><p>此时将 S 涂红，P 涂黑，平衡结束。S 涂红后，h (P-&gt;N-&gt; 叶子) 不变，h (P-&gt;S-&gt; 叶子)-1，实现子平衡，因为 P 节点是红色的，如果将它涂黑，h (P-&gt;N-&gt; 叶子) 和 h (P-&gt;S-&gt; 叶子) 均会 + 1，就可以恢复原来的状态了，而不用递归上去。</p><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210623190829319.png"></p><h3 id="情形-2-2-兄弟的子节点不全黑"><a href="#情形-2-2-兄弟的子节点不全黑" class="headerlink" title="情形 2.2 兄弟的子节点不全黑"></a>情形 2.2 兄弟的子节点不全黑</h3><p>所谓的不全黑包括：[SL 红，SR 红]、[SL 黑，SR 红]、[SL 红，SR 黑]。如果其中一个为黑，另外一个肯定是红。以全黑 / 非全黑作为分类，是因为全黑时无论 N 是在左子还是右子，其处理方式是一样的。而非全黑则要看 N 所处的位置（或者说** S 所处的位置**）进行特定方向的旋转。</p><p>为了方便理解和记忆，以 S 进行分组：</p><ul><li><p>S 为左子时（即 N 为右子），主要分两组 [SL = 红]、[SL = 黑]；</p></li><li><p>S 为右子时（即 N 为左子），主要分两组 [SR = 红]、[SR = 黑]。</p></li><li><p>【S 为左子，SL 红】与【S 为右子，SR 红】处理方式对称； 【S 为左子，SL 黑】与【S 为右子，SR 黑】处理方式对称。</p></li><li><p>【S 为左子，SL 黑】与【S 为右子，SR 黑】处理方式对称。</p></li></ul><p><strong>情形 2.2.1 S 为左子，SL 红；S 为右子，SR 红</strong></p><p>情形 (1) S 为黑色，S 为左子， SL 红时：以 P 为支点 右旋，交换 P 和 S 颜色， SL 涂黑；平衡结束。</p><p>这里的平衡思路其实就是：h (P-&gt;S-&gt; 叶子) 不变（因为 SL 涂黑补回来了），h (P-&gt;N-&gt; 叶子)+1（因为多了个黑色 P）。</p><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210623221308231.png"></p><blockquote><p>通常旋转后，新的 P 节点往往都会涂成原 P 的颜色：一是为了让 GP-P 不会颜色冲突；二是保持经过 P 的路径黑色数量不变。</p></blockquote><hr><p>对称的情形 (2)：S 为黑色，S 为右子， SR 红时：以 P 为支点 左旋；交换 P 和 S 颜色（S 涂为 P 原颜色，P 涂黑）， SR 涂黑；平衡结束。</p><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210623221406479.png"></p><p><strong>情形 2.2.2 S 为左子，SL 黑；S 为右子，SR 黑</strong></p><p>情形 (1) S 为黑色，S 为左子， SL 黑：以 S 为支点 左旋，交换 S 和 SR 颜色（SR 涂黑，S 涂红） ，此时转至情形 2.2.1-(1) S 左 - SL 红 进行处理。</p><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210623221450536.png"></p><blockquote><p>S 涂红是为了使 h (原 S-&gt;SR-&gt; 叶子) 不变。</p></blockquote><hr><p>对称的情形 (2) S 为黑色，S 为右子， SR 黑：以 S 为支点 右旋，交换 S 和 SL 颜色（SL 涂黑，S 涂红），此时转至 2.2.1-(1) S 右 - SR 红进行处理。</p><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210623221734614.png"></p><h2 id="情形-3-兄弟节点为红色（S-红）"><a href="#情形-3-兄弟节点为红色（S-红）" class="headerlink" title="情形 3 兄弟节点为红色（S = 红）"></a>情形 3 兄弟节点为红色（S = 红）</h2><ol><li><p>情形 (1) S 为左子时，以 P 进行右旋；</p></li><li><p>情形 (2) S 为右子时，以 P 进行左旋。</p></li><li><p>旋转后交换 P 和 S 的颜色（S 涂黑，P 涂红），N 兄弟节点变为黑色，进入情形 2 - 兄弟节点为黑色进行处理。</p></li></ol><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210623221954959.png"><br><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210623222010038.png"></p><h2 id="删除总结与实例"><a href="#删除总结与实例" class="headerlink" title="删除总结与实例"></a>删除总结与实例</h2><ol><li><p>删除动作（移除节点）之后，看看这个节点是不是黑色的叶子节点，如果不是，简单处理就可以达到平衡了；</p></li><li><p>先看 N 是不是根节点，是的话啥都不用管；不是的话看兄弟什么颜色：</p></li><li><p>兄弟是红色：进行旋转涂色，去到兄弟为黑色那里处理；</p></li><li><p>兄弟是黑色，看看兄弟子节点是不是全部都是黑。</p><ul><li>全黑的话，看父什么颜色进行对应处理；</li><li>不全黑，看兄在的位置，兄在左的话，看兄的左子是不是红色，进行对应处理；兄在右的话，看兄的右子是不是红色，进行对应处理。</li></ul></li></ol><p><strong>现在我们有一颗红黑树：</strong></p><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210623222138635.png"></p><ol><li>删除 50，删除动作 - 情形 3 –&gt; 删除动作 - 情形 2，简单处理即可：</li></ol><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210623222210858.png"><br>2. 删除 70，即黑色叶子节点，进行平衡：</p><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210623222321254.png"></p><ol start="3"><li>删除 60：</li></ol><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210623222358615.png"></p><ol start="4"><li>删除 10：</li></ol><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210623222421588.png"></p><ol start="5"><li>删除 20：</li></ol><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210623222442466.png"></p>]]></content>
      
      
      <categories>
          
          <category> 集合 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 二叉搜索树 </tag>
            
            <tag> 红黑树 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>设计模式-行为型设计模式</title>
      <link href="/2022/04/02/design/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E8%A1%8C%E4%B8%BA%E5%9E%8B%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
      <url>/2022/04/02/design/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E8%A1%8C%E4%B8%BA%E5%9E%8B%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="行为型模式"><a href="#行为型模式" class="headerlink" title="行为型模式"></a>行为型模式</h1><p>行为型模式是一类主要关注对象间相互通信（交互）的设计模式。这些对象之间的相互作用既能保证对象间能够交换数据，同时对象间仍然能够保持松耦合。</p><p>紧耦合一般会发生在一组紧密关联（相互依赖）的类之间。在面向对象的设计过程中，耦合引用的数量和设计过程中类与类之间的相互依赖是成正比的。用通俗的话讲，就是当一个类变化的时候，有多少可能需要同时修改其他类呢？而松耦合是软件架构设计的关键。在行为型模式中，功能实现与调用该实现的客户端之间应该是松耦合的，以避免硬编码和依赖性。</p><p>行为型模式处理不同的对象之间的通信关系，为其提供基本的通信方式，并提供实现这种通信方式的最常用、最灵活的解决方案。行为型模式描述的不仅是类或对象的模式，同时也包括了它们之间的通信模式。行为型模式能够用来避免硬编码和依赖性。</p><p><strong>行为型模式又分为以下子类别：</strong></p><ol><li>对象行为型模式：对象行为型模式使用对象组合而非继承。描述一组对象如何合作执行部分任务，而单个对象无法执行这些任务。</li><li>类行为型模式：类行为型模式使用继承而不是对象组合来描述算法和流程控制。</li></ol><p><strong>具体包括：</strong></p><ul><li>职责链模式（COR）：在一系列对象链之间传递请求的方法。</li><li>命令模式：命令模式主要用于在需要向对象发出请求的情况，发出请求的对象无须了解请求的操作内容，也无须了解请求的实际接收对象。</li><li>解释器模式：解释器提供了在代码中使用特定语言的一种方法。解释器模式就是一种用于在程序中解析特定语言的设计模式。</li><li>迭代器模式：迭代器用于顺序访问集合（组合）对象中的元素，而无须了解其内部结构。</li><li>中介者模式：定义简单的类间通信。</li><li>备忘录模式：捕获和恢复对象的内部状态。</li><li>观察者模式：一种通知多个类进行改变的方式。</li><li>状态模式：当一个对象状态改变时改变其功能。</li><li>策略模式：在类中进行算法封装。</li><li>模板方法模式：将算法中的部分步骤延迟到子类中进行计算。</li><li>访问者模式：在不改变类的条件下为该类定义一个新的操作。</li></ul><table><thead><tr><th>对象行为型模式</th><th align="right">类行为型模式</th></tr></thead><tbody><tr><td>职责链模式</td><td align="right"></td></tr><tr><td>解释器模式</td><td align="right"></td></tr><tr><td>命令模式</td><td align="right">模板方法模式</td></tr><tr><td>迭代器模式</td><td align="right"></td></tr><tr><td>中介者模式</td><td align="right"></td></tr><tr><td>备忘录模式</td><td align="right"></td></tr><tr><td>观察者模式</td><td align="right"></td></tr><tr><td>状态模式</td><td align="right"></td></tr><tr><td>策略模式</td><td align="right"></td></tr><tr><td>访问者模式</td><td align="right"></td></tr></tbody></table><h2 id="职责链设计模式"><a href="#职责链设计模式" class="headerlink" title="职责链设计模式"></a>职责链设计模式</h2><ol><li><p>在职责链模式中，由发送端发送一个请求到一个对象链中，链中的对象自行处理请求。如果链中的对象决定不响应请求，它会将请求转发给链中的下一个对象。</p></li><li><p>职责链的目的是通过特定设计对请求的发送者和接收者之间进行解耦。解耦是软件设计中很重要的一个方面。通过该设计模式能够使我们彻底地将发送者和接收者之间完全解耦。发送者是用于调用操作的对象，接收者是接收请求并执行相关操作的对象。通过解耦，发送者不需要关心接收者的接口。</p></li><li><p>在职责链模式中，职责是前后传递的。对于链中的对象，决定谁来响应请求的责任由整个链中左侧的对象来承担。这就像问答测验的时候传递问题一样。当提问者向一个人提问，如果他不知道答案，他就把问题传给下一个人，以此类推。当一个人回答了问题，问题就会停止向下传递。有时，也可能到达最后一个人时，还是没有人能回答问题。</p></li><li><p>我们能举出若干个职责链模式的例子：硬币分拣机、ATM 取款机、Servlet 过滤器和 Java 的异常处理机制。在 Java 中，我们可以在 catch 语句中列出的异常序列时就抛出一个异常，catch 列表从上到下逐条扫描。如果赶上第一个进行异常处理就可以立刻完成任务，否则责任转移到下一行，直到最后一行。</p></li></ol><h3 id="模式中包括的类"><a href="#模式中包括的类" class="headerlink" title="模式中包括的类"></a>模式中包括的类</h3><ul><li>抽象处理者（Handler）：定义用于处理请求的接口。</li><li>具体处理者（ Concrete Handler）：它负责处理请求。如果它能够处理这样的要求就会自行处理，否则会将请求发送到下一个处理者。</li><li>客户端（Client）：将命令发送到职责链中第一个能够处理该请求的对象。</li></ul><p><strong>UML 图</strong></p><p><img src="https://cdn.jsdelivr.net/gh/junian455/pic@master/img/image-20210630194840468.png"></p><h3 id="功能及应用场景"><a href="#功能及应用场景" class="headerlink" title="功能及应用场景"></a>功能及应用场景</h3><ul><li>发送者并不知道在链中的哪个对象会响应请求。</li><li>职责链中的每一个对象都有责任决定是否对请求进行响应，如果这些对象有能力响应请求就会响应请求。</li><li>如果对象（或节点）决定向后传递请求它需要具有选择下一个节点和继续传递的能力。</li><li>也有可能没有任何一个节点能够响应请求（有些请求可能无法得到处理）</li><li>会在运行时确定哪些对象能够响应请求。</li></ul><h2 id="命令设计模式"><a href="#命令设计模式" class="headerlink" title="命令设计模式"></a>命令设计模式</h2><p>命令模式（也称为行动模式、业务模式）是一个对象行为型模式。</p><p>这使我们能够实现发送者和接收者之间完全解耦。通过解耦，发送者无须了解接收者的接口。在这里，请求的含义是需要被执行的命令。</p><h3 id="模式中包括的类-1"><a href="#模式中包括的类-1" class="headerlink" title="模式中包括的类"></a>模式中包括的类</h3><ul><li>抽象命令类（Command）：在类中对需要执行的命令接口进行声明。</li><li>具体命令类（ ConcreteCommand）：将接收者对象和行为之间进行绑定。它通过调用接收者中相应的操作实现 execute 方法。</li><li>客户端（ Client）：客户端完成对命令对象的实例化并提供随后需要调用的方法的信息。</li><li>调用者（Invoker）：调用者决定合适的调用方法。</li><li>接收者（Receiver）：接收者是包含方法代码的类的一个实例。这意味着它知道如何处理一个请求并执行相应的操作。任何一个类都可以作为接收者。</li></ul><h3 id="UML-图"><a href="#UML-图" class="headerlink" title="UML 图"></a>UML 图</h3><p><img src="https://cdn.jsdelivr.net/gh/junian455/pic@master/img/image-20210630195039276.png"></p><h3 id="功能及应用场景-1"><a href="#功能及应用场景-1" class="headerlink" title="功能及应用场景"></a>功能及应用场景</h3><ul><li><p>通过参数化对象实现功能执行。命令是面向对象式的，而不是回调函数式的。</p></li><li><p>指定消息队列并在不同的时间执行请求一个命令对象可以有独立于原始请求的生命周期。如果一个请求的接收者可以由一个独立地址空间的方式来表示，那么你可以将请求对应的命令对象转换到不同的进程并在其中完成请求。<br>支持撤销。命令的执行操作可以作为状态进行存储，并在需要时实现命令撤销。命令接口必须增加一个 unexecute 操作，支持撤销之前命令调用的执行效果。执行的命令存储在命令的历史列表中。无限次数的撤销和重做是通过遍历这个列表并分别调<br>用 unexecute 和 execute 来实现的。</p></li><li><p>支持日志记录变化，在系统崩溃的情况下使命令可以重新应用。通过增加 load 和 store 操作命令接口参数，你可以保存一个持续变化的日志。从系统崩溃中恢复需要从磁盘重新加载日志命令和使用 Execute 作重新执行这些命令。</p></li><li><p>通过在原生操作基础上的高层操作构建系统。这样的结构在支持交易操作的信息系统中很常见。一个交易事务封装一组变化的数据。命令模式提供了一种交易模型。命令都有一个共同的接口，允许你使用相同的方式调用所有的交易。这种模式也使得它很容易与新的交易系统进行交互扩展。</p></li></ul><p><strong>注意事项：</strong></p><ul><li><p>目的：将请求封装为一个对象，从而使客户端可以将不同的请求、队列、日志请求及其他支持撤销的操作进行参数化。</p></li><li><p>发出请求的对象无须知道请求对应的操作或请求接收者的任何信息。</p></li><li><p>后果：</p><ul><li>将调用操作的对象和执行操作的对象之间对命令进行解耦。即调用者和接收者之间解耦。</li><li>命令转换为一类对象。使其可以像其他对象那样进行操作和扩展。</li><li>我们可以将命令组合成一个组合命令。一般来说，组合命令是一个组合模式的实例。</li><li>很容易添加新的命令，因为我们无须改变现有的类。</li></ul></li></ul><h2 id="解释器设计模式"><a href="#解释器设计模式" class="headerlink" title="解释器设计模式"></a>解释器设计模式</h2><blockquote><p>解释器模式是一种用于在程序中解析特定语法的设计模式。解释器模式是组合模式的一种应用。对于特定的某种语言，解释器模式能够定义针对其语法表示形式的解释器，并实现对该语言语句的翻译和解释。</p></blockquote><h3 id="模式中包括的类-2"><a href="#模式中包括的类-2" class="headerlink" title="模式中包括的类"></a>模式中包括的类</h3><ul><li>内容类（Context）：包含解释器的全局信息。</li><li>表达式（AbstractExpression）：带有名叫 interpret 抽象方法的抽象类。它会声明执行操作的接口。</li><li>终结符表达式（TerminalExpression）：就是带有终结符的表达式。</li><li>非终结符表达式（ NonterminalExpression）：在两个终结符表达式或非终结符表达式之间实现逻辑运算（与或运算）的表达式。</li><li>客户端（Client）：建立抽象树，并调用抽象树中的 interpret 方法。</li></ul><h3 id="UML-图-1"><a href="#UML-图-1" class="headerlink" title="UML 图"></a>UML 图</h3><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210630195428888.png"></p><h3 id="功能及应用场景-2"><a href="#功能及应用场景-2" class="headerlink" title="功能及应用场景"></a>功能及应用场景</h3><blockquote><p>解释器模式的适用范围非常有限。我们可以说解释器模式仅仅用于需要进行正式语法解释的地方，但这些领域往往已经有了更好的标准的解决方法，因此，在实际使用中，并不会经常使用该模式。该模式可以用于解释使用了特定语法的表达式或者建立某个简单的规则引擎的时候。</p></blockquote><h2 id="迭代器设计模式"><a href="#迭代器设计模式" class="headerlink" title="迭代器设计模式"></a>迭代器设计模式</h2><p>迭代器模式也是一种行为型模式。迭代器模式允许对一组对象元素的遍历（也叫收集）以完成功能实现。</p><h3 id="模式中包括的类-3"><a href="#模式中包括的类-3" class="headerlink" title="模式中包括的类"></a>模式中包括的类</h3><ul><li>迭代器（Iterator）：它会实现一个用于定义迭代器的抽象迭代器接口。</li><li>具体迭代器（Concretel）：这是迭代器的实现（实现迭代器接口）。</li><li>抽象容器（Container）：这是用于定义聚合关系的接口。</li><li>具体容器（ConcreteContainer）：一个聚合关系的实现。</li></ul><h3 id="UML-图-2"><a href="#UML-图-2" class="headerlink" title="UML 图"></a>UML 图</h3><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210630195535105.png"></p><h3 id="功能及应用场景-3"><a href="#功能及应用场景-3" class="headerlink" title="功能及应用场景"></a>功能及应用场景</h3><ul><li>需要访问一个聚合（也称为容器）对象的内容，而无须了解其内部表示。</li><li>支持对聚合对象的多种遍历方式。</li><li>为遍历不同的聚合结构提供统一的接口（即支持多态迭代）。</li><li>迭代器模式允许我们访问集合对象中的内容，而无须暴露其内部数据结构。</li><li>支持多个迭代器同时遍历集合对象。这意味着我们可以对相同的集合创建多个独立的迭代器。</li><li>为遍历不同的集合提供统一的接口。</li></ul><h2 id="中介者设计模式"><a href="#中介者设计模式" class="headerlink" title="中介者设计模式"></a>中介者设计模式</h2><blockquote><p><strong>中介者模式</strong>主要是关于数据交互的设计模式。中介者设计模式很容易理解，却难以实现。该模式的核心是一个中介者对象，负责协调一系列对象之间一系列不同的数据请求。这一系列对象称为同事类。同事类会让中介者知道它们会发生变化，这样中介者负责处理变化对不同对象之间交互的影响。</p></blockquote><h3 id="模式中包括的类-4"><a href="#模式中包括的类-4" class="headerlink" title="模式中包括的类"></a>模式中包括的类</h3><ul><li>中介者接口（Mediator）：它定义了一个接口来实现同事类对象之间的沟通。</li><li>具体中介者（ ConcreteMediator）：它知道各个同事类，并和这些同事类保持相互引用。它实现了与同事类之间的通信和消息传递。</li><li>同事类（ Colleague）：这些类保存了对中介者的引用。无论它们想和任何其他同事类进行交互，都必须通过与中介类通信来实现。</li></ul><h3 id="UML-图-3"><a href="#UML-图-3" class="headerlink" title="UML 图"></a>UML 图</h3><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210630195910287.png"></p><h3 id="功能及应用场景-4"><a href="#功能及应用场景-4" class="headerlink" title="功能及应用场景"></a>功能及应用场景</h3><ul><li>一组对象使用了标准的通信方式，但整体通信的连接都非常复杂，由此产生的相互依赖的结果导致系统难以结构化，也很难理解。</li><li>由于对象之间的通信和相互引用，导致对象难以重用。</li><li>分布在多个类中的行为能够被统一定制化，而无须创建过多的子类。</li></ul><p><strong>需要注意的问题：</strong></p><p>实际使用中介者模式的时候，反而会让问题变得越来越复杂。所以最佳的实践是仅让中介者类负责对象之间的通信部分。</p><ul><li>定义一个对象来负责一系列对象之间的交互。</li><li>同事类发送和接收请求都需要通过中介者。</li></ul><p><strong>功能：</strong></p><ul><li><p>它对同事类进行解耦。中介类实现了同事类之间的松耦合。你可以相互独立地对不同的同事类进行修改和重用。</p></li><li><p>它简化了对象协议。中介者取代了许多交互作用，而实现了与多个同事类之间一对多的通信方式。一对多关系更容易理解、维护和扩展。</p></li><li><p>它集中了控制。中介者模式在中介者中集成了系统交互的复杂性。因此通过中介封装协议之后，它会比任何单一的同事类都更为复杂。这会使中介者作为一个整体也很难维护。</p></li><li><p>门面模式不同于中介者模式的是，它抽象了对象的子系统以提供一个更方便的接口。该种抽象是单向的。也就是说，门面对象会向子系统中的各个类发出请求，反之则不会。相比之下，中介者模式更像是同事类对象之间通过中介者的合作行为，系统的交互都是多向的。</p></li><li><p>当各个同事类只和一个中介者对象交互时，没有必要再去定义一个抽象的中介者类。抽象中介者只用于多个同事类通过多个抽象中介者的子类进行交互的情况，反之则不同。</p></li></ul><h2 id="备忘录设计模式"><a href="#备忘录设计模式" class="headerlink" title="备忘录设计模式"></a>备忘录设计模式</h2><blockquote><p>我们每天至少会使用一次这种模式。备忘录模式提供了一种使对象恢复到其以前状态的能力（通过回滚撤销）。备忘录模式是通过两个对象实现的：<strong>发起者和管理者</strong>。<strong>发起者</strong>是具有内部状态的某个对象。<strong>管理者</strong>则会对<strong>发起者</strong>执行一些操作，并实现撤销更改。</p></blockquote><h3 id="模式中包括的类-5"><a href="#模式中包括的类-5" class="headerlink" title="模式中包括的类"></a>模式中包括的类</h3><ul><li>发起者（Originator）：发起者知道如何保存自己。这是我们想要保存状态的类。</li><li>管理者（ Caretaker）：管理者是用于管理发起者进行状态保存的对象，具体处理发起者何时、如何、为何对状态进行存储。管理员应能够对发起者进行修改，同时也能够撤销这些修改。</li><li>备忘录（Memento）：备忘录会保存发起人的状态信息，而这些状态不能由管理者修改。</li></ul><h3 id="UML-图-4"><a href="#UML-图-4" class="headerlink" title="UML 图"></a>UML 图</h3><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210630200134183.png"></p><h3 id="功能及应用场景-5"><a href="#功能及应用场景-5" class="headerlink" title="功能及应用场景"></a>功能及应用场景</h3><p>当我们在实际应用中需要提供撤销机制，当一个对象有可能需要在后续操作中恢复其内部状态时，就需要使用备忘录模式。结合本设计模式实现对象状态序列化，能够使其易于保存对象的状态并进行状态回滚。</p><p>当一个对象状态的快照必须被存储，且在后续操作过程中需要被恢复时，就可以使用备忘录模式。</p><h2 id="观察者设计模式"><a href="#观察者设计模式" class="headerlink" title="观察者设计模式"></a>观察者设计模式</h2><blockquote><p>在观察者模式中，一种叫作被观察者的对象维护了观察者对象的集合。当被观察者对象变化时，它会通知观察者。在被观察者对象所维护的观察者集合中能够添加或删除观察者。被观察者的<strong>状态变化</strong>能够传递给观察者。这样观察者能够根据被观察者的<strong>状态变化</strong>做出相应的改变。</p></blockquote><h3 id="模式中包括的类-6"><a href="#模式中包括的类-6" class="headerlink" title="模式中包括的类"></a>模式中包括的类</h3><ul><li><p>被观察者（Listener）：定义了向客户端添加和移除观察者操作的接口或抽象类。</p></li><li><p>具体被观察者（ ConcreteListener）：具体被观察者类。它维护了对象的状态，并在当其状态改变时通知各个观察者。</p></li><li><p>观察者（Observer）：定义了用于通知对象的接口或抽象类。</p></li><li><p>具体观察者（ ConcreteObserver）：具体实现了观察者。</p></li></ul><h3 id="UML-图-5"><a href="#UML-图-5" class="headerlink" title="UML 图"></a>UML 图</h3><p><img src="https://cdn.jsdelivr.net/gh/junian455/pic@master/img/image-20210630200319987.png"></p><h3 id="功能及应用场景-6"><a href="#功能及应用场景-6" class="headerlink" title="功能及应用场景"></a>功能及应用场景</h3><ul><li>当一个对象的改变需要其他对象同时改变，而我们并不知道需要有多少个对象一起改变时。</li><li>当一个对象必须通知其他对象，而无须了解这些对象是谁时。</li><li>当一个抽象包含有两个方面，其中一个依赖于另一个。将这些方面封装成独立的对象，以便我们独立改变和重复使用它们时。</li></ul><h2 id="状态设计模式"><a href="#状态设计模式" class="headerlink" title="状态设计模式"></a>状态设计模式</h2><blockquote><p>状态模式是一种行为型模式。状态模式背后的理念是根据其状态变化来改变对象的行为。状态模式允许对象根据内部状态（内容类）实现不同的行为。内容类可以具有大量的内部状态，每当对内容类调用 request 方法时，消息就被委托给状态类进行处理。</p></blockquote><p>状态类接口定义了一个对所有具体状态类都有效的通用接口，并在其中封装了与特定状态相关的所有操作。具体状态类对请求提供各自具体的实现。当内容类的状态变化时，那么与之关联的具体状态类也会发生一定相应的改变。</p><h3 id="模式中包括的类-7"><a href="#模式中包括的类-7" class="headerlink" title="模式中包括的类"></a>模式中包括的类</h3><ul><li><p><strong>内容类（ Context）</strong>：内容类主要用于状态模式的客户端。客户端并不直接访问对象的状态。内容类拥有一个具体的状态对象并根据其当前状态提供所需实现的行为。</p></li><li><p><strong>抽象状态类（ State）</strong>：这个抽象类是所有具体状态类的基类。状态类定义了一个通用接口。内容类对象能够通过使用该接口实现对不同功能的改变。在状态类及其子类的各个条目或属性中，本身并没有任何的状态。</p></li><li><p><strong>具体状态类（ ConcreteState）</strong>：具体状态类根据内容类所提供的状态实现真正的功能改变。每个状态类所提供的行为都适用于内容类对象的某一个状态。它们也包含着由内容类状态变化所下发的指令。</p></li></ul><h3 id="UML-图-6"><a href="#UML-图-6" class="headerlink" title="UML 图"></a>UML 图</h3><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210630200511439.png"></p><h3 id="功能及应用场景-7"><a href="#功能及应用场景-7" class="headerlink" title="功能及应用场景"></a>功能及应用场景</h3><ul><li>状态模式为对象提供了一个清晰的状态表示。</li><li>它允许一个对象在运行时部分清晰明了地改变其类型。</li></ul><h2 id="策略设计模式"><a href="#策略设计模式" class="headerlink" title="策略设计模式"></a>策略设计模式</h2><p>策略模式主要用于需要使用不同的算法来处理不同的数据（对象）时。这意味着策略模式定义了一系列算法，并且使其可以替换使用。策略模式是一种可以在运行时选择算法的设计模式。</p><p>本模式可以使算法独立于调用算法的客户端。策略模式也称为政策模式，在使用多种不同的算法（每种算法都可以对应一个单独的类，而每个类的功能又各不相同）时可以运用策略模式。</p><h3 id="模式中包括的类-8"><a href="#模式中包括的类-8" class="headerlink" title="模式中包括的类"></a>模式中包括的类</h3><ul><li><p>抽象策略类（Strategy）：定义一个所有算法都支持的通用接口。内容类会使用这个接口来调用由具体策略类定义的各个算法。</p></li><li><p>具体策略类（ ContreteStrategy）：每个具体策略类都会实现一个相应的算法。</p></li><li><p>内容类（ Context）：包含一个对策略对象的引用，它可以定义一个用于策略类访问内容类数据的接口。内容类对象包含了对将要使用的具体策略对象的引用。当需要进行特定操作时，会从对应的策略类对象中运行相应的算法。内容类本身觉察不到策略类的执行。如果有必要的话，还可以定义专用的对象来传递从内容类对象到策略类的数据。内容类对象接收来自客户端的请求，并将其委托给策略类对象。通常具体策略类是由客户端创建，并传递给内容类。从这一点来讲，客户端仅与内容类进行交互。</p></li></ul><h3 id="UML-图-7"><a href="#UML-图-7" class="headerlink" title="UML 图"></a>UML 图</h3><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210630200732554.png"></p><h3 id="功能及应用场景-8"><a href="#功能及应用场景-8" class="headerlink" title="功能及应用场景"></a>功能及应用场景</h3><p>当我们有多种不同的算法可供选择（每种算法都可以对应一个单独的类，而每个类的功能又各不相同）时，可以应用策略模式。策略模式会定义一组算法并能够使其相互替代使用。</p><h2 id="模板方法设计模式"><a href="#模板方法设计模式" class="headerlink" title="模板方法设计模式"></a>模板方法设计模式</h2><blockquote><p>模板方法会定义算法的各个执行步骤。算法的一个或多个步骤可以由子类通过重写来实现，同时保证算法的完整性并能够实现多种不同的功能。</p></blockquote><p>类行为型模式使用继承来实现模式的功能。在模板方法模式中，会有一个方法（ Template method 方法）来定义算法的各个步骤，这些步骤（即方法）的具体实现会放到子类中，也就是说，在模板方法中定义了特定算法，但该算法的具体步骤仍然需要通过子类来定义。模板方法会由一个抽象类来实现在这个抽象类中还会声明该算法的各个步骤（方法），最后将其具体实现的方法声明实现为抽象类的子类。</p><h3 id="模式中包括的类-9"><a href="#模式中包括的类-9" class="headerlink" title="模式中包括的类"></a>模式中包括的类</h3><ul><li><p>抽象类（ AbstractClass）：定义了算法的抽象操作，并交由具体的子类完成这些操作的具体实现。它实现了一个模板方法，它该方法包含了算法的各个步骤。该模板方法还会在抽象类中定义各个相应步骤的基本操作。</p></li><li><p>具体类（ ConcreteClass）：他们通过执行基本操作来实现算法类的具体步骤。当调用一个具体类时，模板方法代码会从基类执行，而模板方法所使用的各个方法由派生类实现和调用。</p></li></ul><h3 id="UML-图-8"><a href="#UML-图-8" class="headerlink" title="UML 图"></a>UML 图</h3><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210630200958473.png"></p><h3 id="功能及应用场景-9"><a href="#功能及应用场景-9" class="headerlink" title="功能及应用场景"></a>功能及应用场景</h3><ul><li><p>当一个算法的功能需要能够改变，并通过在子类中对功能重写来实现这种改变。</p></li><li><p>当我们要避免代码重复时，能够在子类中实现算法不同的变化。</p></li><li><p>在一开始，模板方法可能不是一个显而易见的选择。最明显的现象会是当我们发现几乎完全一样的类在执行某些类似的逻辑。这时，我们就应该考虑使用模板方法模式来清理现有代码。</p></li></ul><h2 id="访问者设计模式"><a href="#访问者设计模式" class="headerlink" title="访问者设计模式"></a>访问者设计模式</h2><blockquote><p>访问者模式用来简化对象相关操作的分组。这些操作是由访问者来执行的，而不是把这些代码放在被访问的类中。由于访问的操作是由访问者执行的，而不是由被访问的类，这样执行操作的代码会集中在访问者中，而不是分散在对象分组中。这为代码提供了更好的可维护性。访问者模式也避免了使用 instanceof 运算符对相似的类执行计算。</p></blockquote><h3 id="模式中包括的类-10"><a href="#模式中包括的类-10" class="headerlink" title="模式中包括的类"></a>模式中包括的类</h3><ul><li>访问者（ Visitor）：包括一个接口或抽象类，用于声明在所有类型的可访问对象中访问哪些操作。通常操作的名称是相同的，而是由该方法的参数来区分不同的操作。由输入对象类型来决定访问该方法中的哪一个。</li><li>具体访问者（ Concrete Visitor）：用于实现各个类型的访问者和各个类型的访问方法。它在抽象访问者中进行声明，并各自独立实现。每一个具体访问者会负责实现不同的功能。当定义一个新的访问者时，只需要将其传递给对象结构即可。</li><li>元素类（Element）：一个抽象对象用于声明所接受的操作。它是一个入口点，能够允许哪一类访问者对象访问。在集合中的每个对象都需要实现该抽象对象，以便相应访问者能够实现对其进行访问。</li><li>具体元素类（ Concrete Element）：这些类实现了抽象元素类的接口或类，并定义了所接受的操作。通过其可接受的操作，能够将访问者对象传递给该对象。</li><li>结构对象（ ObjectStruture）：这是一个包含了所有可访问对象的类。它提供了一种机制来遍历所有元素。这种结构不一定是一个集合，也可以是一个极其复杂的结构，如组合对象。</li></ul><h3 id="UML-图-9"><a href="#UML-图-9" class="headerlink" title="UML 图"></a>UML 图</h3><p><img src="https://cdn.jsdelivr.net/gh/junian455/pic@master/img/image-20210630201115297.png"></p><h3 id="功能及应用场景-10"><a href="#功能及应用场景-10" class="headerlink" title="功能及应用场景"></a>功能及应用场景</h3><ol><li><p>在 visitCollection () 方法中，我们调用 Visitable.accept (this) 来实现对正确的访问者方法进行调用。这叫作双重分派。访问者调用元素类中的方法，又会回到对访问者类中进行调用。</p></li><li><p><strong>访问者模式更适用于对象结构非常稳定，而对象的操作却需要经常变化的情况下</strong>。访问者模式只提供处理每种数据类型的方法，并且让数据对象确定调用哪个方法。由于数据对象本质上都知道其自身的类型，所以在访问者模式中算法决定所调用的方法所起到的作用是微不足道的。</p></li><li><p>因此，数据的整体处理包括对数据对象的分发以及通过对适当的访问者处理方法的二次分发。这就叫作双重分派。使用访问者模式的一个主要优点是，对于在我们的数据结构中添加需要执行的新的操作来说，是非常容易的。我们所要做的就是创建一个新的访问者，并定义相应的操作。</p></li><li><p>但访问者模式的主要问题是，因为每个访问者需要有相应的方法来处理每一种可能的具体数据，那么一旦实现了访问者模式，其具体类的数量和类型就不能被轻易改变。</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 设计模式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
            <tag> UML图 </tag>
            
            <tag> 单例设计模式 </tag>
            
            <tag> 工厂方法设计模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>怎么利用Redis实现数据的去重？</title>
      <link href="/2022/03/14/redis/%E6%80%8E%E4%B9%88%E5%88%A9%E7%94%A8Redis%E5%AE%9E%E7%8E%B0%E6%95%B0%E6%8D%AE%E7%9A%84%E5%8E%BB%E9%87%8D%EF%BC%9F/"/>
      <url>/2022/03/14/redis/%E6%80%8E%E4%B9%88%E5%88%A9%E7%94%A8Redis%E5%AE%9E%E7%8E%B0%E6%95%B0%E6%8D%AE%E7%9A%84%E5%8E%BB%E9%87%8D%EF%BC%9F/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="怎么利用Redis实现数据的去重？"><a href="#怎么利用Redis实现数据的去重？" class="headerlink" title="怎么利用Redis实现数据的去重？"></a>怎么利用Redis实现数据的去重？</h1><ol><li><p>Redis的set：它可以去除重复元素，也可以快速判断某一个元素是否存在于集合中，如果元素很多（比如上亿的计数），占用内存很大。</p></li><li><p>Redis的bit：它可以用来实现比set内存高度压缩的计数，它通过一个bit设置为1或者0，表示存储某个元素是否存在信息。例如网站唯一访客计数，可以把user_id作为 bit 的偏移量 offset，如设置为1表示有访问，使用1 MB的空间就可以存放800多万用户的一天访问计数情况。</p></li></ol><h2 id="Bitmap-位图（DAU：日活跃用户）"><a href="#Bitmap-位图（DAU：日活跃用户）" class="headerlink" title="Bitmap 位图（DAU：日活跃用户）"></a>Bitmap 位图（DAU：日活跃用户）</h2><ol><li><p>位图不是特殊的数据结构，它其实就是普通的字符串，也就是 byte 数组，用 getbit 和 setbit 来操作，能够统计精确的值。</p></li><li><p>可以用于布尔型数据的存取，比如用户一年的签到记录，签到了是1，没签到是0，记录365天，通过 bitcount 指令来统计用户一共签到了多少天，每个签到记录只占用一位，365位大约是46个字节大小，用户上亿时，大大节约了内存空间。</p></li><li><p>Redis 的位数组是自动扩展，如果设置了某个偏移位置超出了现有的内容范围，就会自动将位数组进行零扩充。（也就是进行扩充，初始值为0）</p></li></ol><ol start="3"><li>HyperLogLog：实现超大数据量精确的唯一计数都是比较困难的，HyperLogLog可以仅仅使用 12 k左右的内存，实现上亿的唯一计数，而且误差控制在百分之一左右。</li></ol><h2 id="HyperLogLog"><a href="#HyperLogLog" class="headerlink" title="HyperLogLog"></a>HyperLogLog</h2><ul><li><p>采用基数算法实现，它设有 16384 个桶进行独立计数，也就是 2 的 14 次方，每个桶占 6 位，1字节等于8位，所以2 的 14 次方乘以 6 再除以 8，就等于 12k 字节了。它根据输入元素来计算基数，而不是存储元素本身。</p></li><li><p>占用空间小，无论统计多少个数据，最多占用12K的内存。（redis 设有 16384个桶，每个桶里的数据最多需要6位进行存储，16384 x 6 / 8 约等于 12k 字节）</p></li><li><p>它统计值时存在误差，标准误差为0.81%</p></li><li><p>缺点：HyperLogLog 只会根据输入元素来计算基数，而不会储存输入元素本身，所以 HyperLogLog 不能像集合那样返回输入的各个元素。</p></li></ul><h2 id="HyperLogLog-使用场景（UV：网站的独立访客）"><a href="#HyperLogLog-使用场景（UV：网站的独立访客）" class="headerlink" title="HyperLogLog 使用场景（UV：网站的独立访客）"></a>HyperLogLog 使用场景（UV：网站的独立访客）</h2><ol><li><p>根据用户的IP来统计访问量，需要去重，同一个用户一天之内的多次访问请求只能计数一次，所以每个网页请求都需要带上用户的ID，无论是登录用户还是未登录的游客，都需要一个唯一ID来标识。</p></li><li><p>最开始容易想到的是为每一个页面设置一个独立的 set 集合来存储当天访问该页面的所有用户ID，但如果页面访问量非常大，比如几千万的 UV，这样 set 集合就会非常大，浪费了空间，而且对于这个 UV 值，一般情况下并不需要多么的精确，比如 100 万和 101 万，对于这个场景，并没什么大的区别。所以想到了采用 redis 的 HyperLogLog 数据结构来实现。</p></li><li><p>HyperLogLog 提供不精确的去重计数方案，标准误差为 0.81%，这个精确度已经可以满足 UV 的统计需求了，而且占用的内存不超过12k。</p></li></ol><ol start="4"><li>bloomfilter布隆过滤器：布隆过滤器是一种占用空间很小的数据结构，它由一个很长的二进制向量和一组Hash映射函数组成，它用于检索一个元素是否在一个集合中</li></ol><ul><li>对于布隆过滤器，大家有兴趣可以看下这篇文章哈，<a href="https://mp.weixin.qq.com/s?__biz=Mzg3NzU5NTIwNg==&mid=2247493887&idx=2&sn=a18d3a5726d04c245d6f05bbeb024c4f&chksm=cf2237d6f855bec031c444f026ccb6e08923b720503d605a327f4308ef5c79638eff3784f9ac&token=1967970286&lang=zh_CN&scene=21#wechat_redirect">面试必备：布隆过滤器是什么？有什么用？</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Redis缓存 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis </tag>
            
            <tag> HyperLogLog </tag>
            
            <tag> Bitmap </tag>
            
            <tag> 布隆过滤器 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SEATA</title>
      <link href="/2022/01/20/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/SEATA/"/>
      <url>/2022/01/20/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/SEATA/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="What-is-seata？"><a href="#What-is-seata？" class="headerlink" title="What is seata？"></a>What is seata？</h1><p><strong>Seata</strong>是一款开源的分布式事务解决方案，致力于在微服务架构下提供高性能和简单易用的<strong>分布式事务服务</strong>；</p><p>Seata为用户提供了<strong>AT、TCC、SAGA和XA</strong>事务模式，为用户打造一站式的分布式解决方案；</p><p>四种事务模式中，XA模式正在开发中…，其他事务模式已经实现；</p><blockquote><p>目前使用的流行度情况是：<code>AT > TCC > Saga；</code></p></blockquote><p>我们可以参看seata各公司使用列表：</p><p>大部分公司都采用的AT事务模式；<a href="https://github.com/seata/seata/issues/1246"></a></p><p>Seata已经在国内很多团队开始落地，其中不乏有大公司；</p><ul><li>Github：<a href="https://github.com/seata/seata">https://github.com/seata/seata</a></li><li>官网：<a href="http://seata.io/">http://seata.io/</a> </li><li>当前最新版本：1.3.0</li></ul><h1 id="Seata架构中角色"><a href="#Seata架构中角色" class="headerlink" title="Seata架构中角色"></a>Seata架构中角色</h1><ol><li>TC (Transaction Coordinator) - 事务协调者</li></ol><blockquote><p>维护全局和分支事务的状态，驱动全局事务提交或回滚；</p></blockquote><ol start="2"><li>TM (Transaction Manager) - 事务管理器</li></ol><blockquote><p>定义全局事务的范围：开始全局事务、提交或回滚全局事务；</p></blockquote><ol start="3"><li>RM (Resource Manager) - 资源管理器</li></ol><blockquote><p>管理分支事务处理的资源，与TC交互以注册分支事务和报告分支事务的状态，并驱动分支事务提交或回滚；</p></blockquote><p><img src="https://cdn.jsdelivr.net/gh/junian455/pic@master/20210326165758916.png"></p><p>其中<strong>TC为单独部署的 Server 服务端</strong>，TM和RM为嵌入到应用中的 Client 客户端；</p><h1 id="Seata里分布式事务的生命周期"><a href="#Seata里分布式事务的生命周期" class="headerlink" title="Seata里分布式事务的生命周期"></a>Seata里分布式事务的生命周期</h1><p><img src="https://cdn.jsdelivr.net/gh/junian455/pic@master/20210326165804706.png"></p><ul><li><p>TM请求TC开启一个全局事务，TC会生成一个XID作为该全局事务的编号，XID会在微服务的调用链路中传播，保证将多个微服务的子事务关联在一起；</p></li><li><p>RM请求TC将本地事务注册为全局事务的分支事务，通过全局事务的XID进行关联；</p></li><li><p>TM请求TC告诉XID对应的全局事务是进行提交还是回滚；</p></li><li><p>TC驱动RM将XID对应的自己的本地事务进行提交还是回滚；</p></li></ul><h1 id="TC-Server运行环境部署"><a href="#TC-Server运行环境部署" class="headerlink" title="TC Server运行环境部署"></a>TC Server运行环境部署</h1><ol><li><p>我们先部署单机环境的 Seata TC Server，用于学习或测试，在生产环境中要部署集群环境；</p></li><li><p>因为TC需要进行全局事务和分支事务的记录，所以需要对应的存储，目前，TC有<strong>三种存储模式</strong>( store.mode )：</p></li></ol><ul><li><p>file模式：适合单机模式，全局事务会话信息在内存中读写，并持久化本地文件 root.data，性能较高；</p></li><li><p>db模式：适合集群模式，全局事务会话信息通过 db 共享，相对性能差点；</p></li><li><p>redis模式：解决db存储的性能问题；</p></li></ul><h2 id="file模式部署单机TC-Server"><a href="#file模式部署单机TC-Server" class="headerlink" title="file模式部署单机TC Server"></a>file模式部署单机TC Server</h2><p><img src="https://cdn.jsdelivr.net/gh/junian455/pic@master/20210326165812407.png"></p><blockquote><p>Seata运行环境部署</p></blockquote><ol><li><p>下载Seata：<a href="http://seata.io/zh-cn/blog/download.html">http://seata.io/zh-cn/blog/download.html</a></p></li><li><p>解压：tar -zxvf seata-server-1.3.0.tar.gz</p></li><li><p>切换cd seata</p></li></ol><p><img src="https://cdn.jsdelivr.net/gh/junian455/pic@master/20210326165823647.png"></p><ol start="4"><li>默认seata-server.sh脚本设置的jvm内存参数2G，我们再虚拟机里面做实验，可以改小一点；</li></ol><p><img src="https://cdn.jsdelivr.net/gh/junian455/pic@master/20210326165829730.png"></p><ol start="5"><li><p>在bin目录下启动：./seata-server.sh</p></li><li><p>默认配置下，Seata TC Server 启动在 8091 端口；</p></li></ol><p>因为我们没有修改任何配置文件，默认情况seata使用的是file模式进行数据持久化，所以可以看到用于持久化的本地文件 root.data；</p><h1 id="AT模式事务案例"><a href="#AT模式事务案例" class="headerlink" title="AT模式事务案例"></a>AT模式事务案例</h1><h2 id="单体应用多数据源分布式事务"><a href="#单体应用多数据源分布式事务" class="headerlink" title="单体应用多数据源分布式事务"></a>单体应用多数据源分布式事务</h2><p><img src="https://cdn.jsdelivr.net/gh/junian455/pic@master/20210326165849181.png"></p><blockquote><p>在Spring Boot单体项目中，如果使用了多数据源，就需要考虑多个数据源的数据一致性，即产生了分布式事务的问题，我们采用Seata的AT事务模式来解决该分布式事务问题；</p></blockquote><p>以电商购物下单为例：</p><p><img src="https://cdn.jsdelivr.net/gh/junian455/pic@master/20210326165907656.png"></p><ol><li><p>准备数据库表和数据；其中每个库中的undo_log表，是 <strong>Seata AT模式</strong>必须创建的表，主要用于分支事务的回滚；</p></li><li><p>开发一个SpringBoot单体应用；</p></li></ol><p><img src="https://cdn.jsdelivr.net/gh/junian455/pic@master/img/20210326165913986.png"> </p><ol start="3"><li>测试：<a href="http://localhost:8080/order?userId=1&amp;productId=1">http://localhost:8080/order?userId=1&amp;productId=1</a></li></ol><h2 id="微服务的分布式事务"><a href="#微服务的分布式事务" class="headerlink" title="微服务的分布式事务"></a>微服务的分布式事务</h2><p><img src="20210326165921342.png"></p><h2 id="AT事务模式分布式事务工作机制"><a href="#AT事务模式分布式事务工作机制" class="headerlink" title="AT事务模式分布式事务工作机制"></a>AT事务模式分布式事务工作机制</h2><p><strong>前提</strong></p><p>基于支持本地 ACID 事务的关系型数据库；（mysql、oracle）</p><p>Java 应用，通过JDBC访问数据库；</p><p><strong>整体机制</strong></p><p>就是两阶段提交协议的演变：</p><ul><li><p>一阶段：</p><ul><li>“业务数据“和“回滚日志记录“在同一个本地事务中提交，释放本地锁和连接资源；</li></ul></li><li><p>二阶段：</p><ul><li><p>如果没有异常异步化提交，非常快速地完成；</p></li><li><p>如果有异常回滚通过一阶段的回滚日志进行反向补偿；</p></li><li><p>具体举例说明整个AT分支的工作过程：</p></li></ul></li></ul><pre><code class="bash">业务表：product Field Type     Key id     bigint(20) PRI name varchar(100) since varchar(100)</code></pre><h2 id="AT分支事务的业务逻辑："><a href="#AT分支事务的业务逻辑：" class="headerlink" title="AT分支事务的业务逻辑："></a>AT分支事务的业务逻辑：</h2><pre><code>update product set name = &#39;GTS&#39; where name = &#39;TXC&#39;;</code></pre><ul><li>一阶段过程：</li></ul><ol><li><p>解析SQL，得到SQL的类型（UPDATE），表（product），条件（where name = ‘TXC’）等相关的信息；</p></li><li><p>查询前镜像：根据解析得到的条件信息，生成查询语句，定位数据；</p></li></ol><pre><code>select id, name, since from product where name = &#39;TXC&#39;;</code></pre><blockquote><p>得到前镜像：</p></blockquote><pre><code>id name since1 TXC     2014</code></pre><ol start="3"><li><p>执行业务 SQL：更新这条记录的 name 为 ‘GTS’；</p></li><li><p>查询后镜像：根据前镜像的结果，通过 主键 定位数据；</p></li></ol><pre><code>select id, name, since from product where id = 1;</code></pre><blockquote><p>得到后镜像：</p></blockquote><pre><code>id name since1 GTS     2014</code></pre><ol start="5"><li><p>插入回滚日志：把前后镜像数据以及业务SQL相关的信息组成一条回滚日志记录，插入到 UNDO_LOG 表中；</p></li><li><p>分支事务提交前，向TC注册分支，申请product表中，主键值等于1的记录的全局锁（在当前的同一个全局事务id范围内是可以申请到全局锁的，不同的全局事务id才会排斥）；</p></li><li><p>本地事务提交：业务数据的更新和前面步骤中生成的 UNDO LOG 一并提交；</p></li><li><p>将本地事务提交的结果上报给TC；</p></li></ol><ul><li>二阶段-回滚</li></ul><ol><li><p>收到 TC 的分支回滚请求，开启一个本地事务，执行如下操作；</p></li><li><p>通过 XID 和 Branch ID 查找到相应的 UNDO LOG 记录；</p></li><li><p>数据校验：拿 UNDO LOG 中的后镜像与当前数据进行比较，如果有不同，说明数据被当前全局事务之外的动作做了修改，这种情况，需要人工来处理；</p></li><li><p>根据 UNDO LOG 中的前镜像和业务 SQL 的相关信息生成并执行回滚的语句：</p></li></ol><p>update product set name = ‘TXC’ where id = 1;</p><ol start="5"><li>提交本地事务，并把本地事务的执行结果（即分支事务回滚的结果）上报给 TC；</li></ol><ul><li>二阶段-提交</li></ul><ol><li><p>收到TC的分支提交请求，把请求放入一个异步任务的队列中，马上返回提交成功的结果给TC；</p></li><li><p>异步任务阶段的分支提交请求将异步和批量地删除相应UNDO LOG记录；</p></li></ol><pre><code class="bash">回滚日志表：Field         Type branch_id     bigint       PK xid             varchar(100) context         varchar(128) rollback_info longblob log_status     tinyint log_created     datetime log_modified datetimeSQL建表语句： CREATE TABLE `undo_log` (   `id` bigint NOT NULL AUTO_INCREMENT,   `branch_id` bigint NOT NULL,   `xid` varchar(100) NOT NULL,   `context` varchar(128) NOT NULL,   `rollback_info` longblob NOT NULL,   `log_status` int NOT NULL,   `log_created` datetime NOT NULL,   `log_modified` datetime NOT NULL,   PRIMARY KEY (`id`),   UNIQUE KEY `ux_undo_log` (`xid`,`branch_id`) ) ENGINE=InnoDB AUTO_INCREMENT=4 DEFAULT CHARSET=utf8;</code></pre><h2 id="AT事务模式运行机制解读"><a href="#AT事务模式运行机制解读" class="headerlink" title="AT事务模式运行机制解读"></a>AT事务模式运行机制解读</h2><blockquote><p>AT 模式的前提：</p></blockquote><ol><li><p>基于支持本地 ACID 事务的关系型数据库；</p></li><li><p>Java 应用，通过 JDBC 访问数据库；</p></li></ol><p>整体机制是两阶段提交协议的演变：</p><ol><li><p>一阶段：业务数据和回滚日志记录在同一个本地事务中提交，释放本地锁和连接资源；（本地事务，就已经在数据库持久化了）</p></li><li><p>二阶段：</p></li></ol><p>如果没有异常提交异步化，非常快速地完成；（正常情况，那就提交了，同步一下TC Server的状态，删除回滚日志）</p><p>如果有异常回滚通过一阶段的回滚日志进行反向补偿；（比如订单删除，库存加回去，余额加回去）；</p><p><strong>写隔离</strong></p><p>一阶段本地事务提交前，需要确保先拿到<code>全局锁</code>；</p><p>拿不到 <code>全局锁</code> ，不能提交本地事务；</p><p>拿 <code>全局锁</code> 的尝试被限制在一定范围内，超出范围将放弃，并回滚本地事务，释放本地锁；</p><p>以一个示例来说明： </p><p><strong>两个</strong>或者多个全局事务 tx1 和 tx2，分别并发对 a 表的 m 字段进行更新操作，m 的初始值 1000；</p><p>假设tx1 先开始，开启本地事务，拿到本地锁，更新操作 m = 1000 - 100 = 900,本地事务提交前，先拿到该记录的 <code>全局锁</code> ，拿到了全局锁，本地提交并释放本地锁；</p><p>tx2后开始，开启本地事务，拿到本地锁，更新操作 m = 900 - 100 = 800，本地事务提交前，尝试拿该记录的 全局锁 ，tx1全局提交前，该记录的全局锁一直会被 tx1 持有，tx2 需要重试等待 <code>全局锁</code> ；</p><p><img src="https://cdn.jsdelivr.net/gh/junian455/pic@master/img/20210326170405492.png"> </p><p>tx1 二阶段全局提交，释放 全局锁 ，tx2 拿到<code> 全局锁</code> 提交本地事务；</p><p><img src="https://cdn.jsdelivr.net/gh/junian455/pic@master/img/20210326170411747.png"> </p><p>如果 tx1 的二阶段全局回滚，则 tx1 需要重新获取该数据的本地锁，进行反向补偿的更新操作，实现分支的回滚；</p><p>此时，如果 tx2 仍在等待该数据的 全局锁，同时持有本地锁，则 tx1 的分支回滚会失败。分支的回滚会一直重试，直到 tx2 的 全局锁 等锁超时，放弃 全局锁 并回滚本地事务释放本地锁，tx1 的分支回滚最终成功；</p><p>因为整个过程 全局锁 在 tx1 结束前一直是被 tx1 持有的，所以不会发生 脏写 的问题；</p><p><strong>读隔离</strong></p><p>在数据库本地事务隔离级别 读已提交（Read Committed） 或以上的基础上，<code>Seata</code>（AT 模式）的默认全局隔离级别是 读未提交（Read Uncommitted）；</p><p>如果应用在特定场景下，必需要求全局的 读已提交 ，目前 Seata 的方式是通过 SELECT FOR UPDATE 语句的代理；</p><p><img src="https://cdn.jsdelivr.net/gh/junian455/pic@master/img/20210326170420496.png"> </p><p>SELECT FOR UPDATE 语句的执行会申请 全局锁 ，如果 全局锁 被其他事务持有，则释放本地锁（回滚 SELECT FOR UPDATE 语句的本地执行）并重试，这个过程中，查询是被 block 住的，直到 全局锁 拿到，即读取的相关数据是 已提交 的，才返回；</p><p>出于总体性能上的考虑，Seata目前的方案并没有对所有SELECT语句都进行代理，仅针对 FOR UPDATE 的 SELECT 语句；</p><h3 id="Seata-TC-Server集群部署"><a href="#Seata-TC-Server集群部署" class="headerlink" title="Seata TC Server集群部署"></a>Seata TC Server集群部署</h3><p>生产环境下，需要部署集群 Seata TC Server，实现高可用，在集群时，多个 Seata TC Server 通过 db 数据库或者redis实现全局事务会话信息的共享；</p><p>每个Seata TC Server注册自己到注册中心上，应用从注册中心获得Seata TC Server实例，这就是Seata TC Server的集群；</p><p><img src="https://cdn.jsdelivr.net/gh/junian455/pic@master/img/20210326170425973.png"> </p><p>Seata TC Server 对主流的注册中心都提供了集成，Naco作为注册中心越来越流行，这里我们就采用Nacos；</p><p>Seata TC Server集群搭建具体步骤：</p><ol><li><p>下载并解压两个seata-server-1.3.0.tar.gz；</p></li><li><p>初始化 Seata TC Server 的 db 数据库，在 MySQL 中，创建 seata 数据库，并在该库下执行如下SQL脚本：</p></li></ol><p>使用seata-1.3.0\script\server\db脚本（网盘有共享）</p><ol start="3"><li>修改 seata/conf/file.conf 配置文件，修改使用 db 数据库，实现 Seata TC Server 的全局事务会话信息的共享；</li></ol><pre><code class="bash"> 1）mode = &quot;db&quot;（2）数据库的连接信息 driverClassName = &quot;com.mysql.cj.jdbc.Driver&quot;url = &quot;jdbc:mysql://39.99.163.122:3306/seata&quot; user = &quot;mysql&quot;password = &quot;UoT1R8[09/VsfXoO5&gt;6YteB&quot;</code></pre><ol start="4"><li>设置使用 Nacos 注册中心；</li></ol><ul><li>修改 seata/conf/registry.conf 配置文件，设置使用 Nacos 注册中心；</li></ul><pre><code class="bash">、type = &quot;nacos&quot;Nacos连接信息：nacos &#123;    application = &quot;seata-server&quot;    serverAddr = &quot;127.0.0.1:8848&quot;    group = &quot;SEATA_GROUP&quot;    namespace = &quot;&quot;    cluster = &quot;default&quot;    username = &quot;&quot;    password = &quot;&quot;&#125;</code></pre><p>5、启动数据库和nacos；</p><p>6、启动两个 TC Server (虚拟机的话指定-h 否则默认是本地ip)</p><p>执行</p><p>nohup ./seata-server.sh -h 192.168.247.129  -p 8091 -m db  -n 1 &gt;/usr/local/seata/bin/seata.log 2&gt;&amp;1 &amp;</p><p>命令，启动第一个TC Server;</p><p>-p：Seata TC Server 监听的端口；</p><p>-n：Server node，在多个 TC Server 时，需区分各自节点，用于生成不同区间的 transactionId 事务编号，以免冲突；</p><p>执行  </p><p>nohup ./seata-server.sh -h 192.168.247.130  -p 8092 -m db  -n 2&gt;/usr/local/seata/bin/seata.log 2&gt;&amp;1 &amp;  </p><p>命令，启动第二个TC Server；</p><ol start="7"><li>打开Nacos注册中心控制台，可以看到有两个Seata TC Server 实例；</li></ol><p><img src="https://cdn.jsdelivr.net/gh/junian455/pic@master/img/20210326170452179.png"><br>8. 应用测试；</p><p><strong>对于SpringBoot单体应用：</strong></p><ol><li>添加nacos客户端依赖；</li></ol><pre><code class="bash">&lt;!-- nacos-client --&gt;&lt;dependency&gt;    &lt;groupId&gt;com.alibaba.nacos&lt;/groupId&gt;    &lt;artifactId&gt;nacos-client&lt;/artifactId&gt;    &lt;version&gt;1.3.1&lt;/version&gt;&lt;/dependency&gt;</code></pre><ol start="2"><li>配置application.properties文件</li></ol><pre><code class="bash">#----------------------------------------------------------# Seata应用编号，默认为$&#123;spring.application.name&#125;seata.application-id=springcloud-order-seata# Seata事务组编号，用于TC集群名seata.tx-service-group=springcloud-order-seata-group# 虚拟组和分组的映射seata.service.vgroup-mapping.springcloud-order-seata-group=default#seata-spring-boot-starter 1.1版本少一些配置项seata.enabled=trueseata.registry.type=nacosseata.registry.nacos.cluster=defaultseata.registry.nacos.server-addr=192.168.172.128:8848seata.registry.nacos.group=SEATA_GROUPseata.registry.nacos.application=seata-server</code></pre><p><strong>对于Spring Cloud Alibaba微服务应用</strong>：</p><p>则不需要加nacos的jar包依赖，application.properties文件配置完全一样；</p><h3 id="TCC事务模式执行机制"><a href="#TCC事务模式执行机制" class="headerlink" title="TCC事务模式执行机制"></a>TCC事务模式执行机制</h3><blockquote><p>AT模式基本上能满足我们使用分布式事务大部分需求，但涉及非关系型数据库与中间件的操作、跨公司服务的调用、跨语言的应用调用就需要结合TCC模式；</p></blockquote><p><img src="https://cdn.jsdelivr.net/gh/junian455/pic@master/img/2021032617051976.png"></p><p>一个分布式的全局事务，整体是两阶段提交（<code>Try - [Comfirm/Cancel]</code>）的模型，在Seata中，AT模式与TCC模式事实上都是基于两阶段提交，它们的区别在于：</p><blockquote><p>AT模式基于支持本地ACID事务的关系型数据库：</p></blockquote><ol><li><p>一阶段prepare行为：在本地事务中，一并提交“业务数据更新“和”相应回滚日志记录”；</p></li><li><p>二阶段 commit 行为：马上成功结束，自动异步批量清理回滚日志；</p></li><li><p>二阶段 rollback 行为：通过回滚日志，自动生成补偿操作，完成数据回滚；</p></li></ol><blockquote><p>而TCC 模式，需要我们人为编写代码实现提交和回滚：</p></blockquote><ol><li><p>一阶段 prepare 行为：调用自定义的 prepare 逻辑；(真正要做的事情，比如插入订单，更新库存，更新余额)</p></li><li><p>二阶段 commit 行为：调用自定义的 commit 逻辑；（自己写代码实现）</p></li><li><p>二阶段 rollback 行为：调用自定义的 rollback 逻辑；（自己写代码实现）</p></li></ol><p>所以TCC模式，就是把自定义的分支事务的提交和回滚并纳入到全局事务管理中；</p><p>通俗来说，Seata的TCC模式就是手工版本的AT模式，它允许你自定义两阶段的处理逻辑而不需要依赖AT模式的undo_log回滚表；</p><h2 id="TCC事务模式应用实践"><a href="#TCC事务模式应用实践" class="headerlink" title="TCC事务模式应用实践"></a>TCC事务模式应用实践</h2><ol><li>基于SpringBoot单体应用的TCC事务</li></ol><p><img src="https://cdn.jsdelivr.net/gh/junian455/pic@master/img/2021032617051976.png"></p><pre><code class="bash">@LocalTCCpublic interface AccountService &#123;    /**     * 扣除余额     * 定义两阶段提交     * name = reduceStock为一阶段try方法     * commitMethod = commitTcc 为二阶段确认方法     * rollbackMethod = cancel 为二阶段取消方法     * BusinessActionContextParameter注解 可传递参数到二阶段方法     *     * @param userId 用户ID     * @param money  扣减金额     * @throws Exception 失败时抛出异常     */    @TwoPhaseBusinessAction(name = &quot;reduceBalance&quot;, commitMethod = &quot;commitTcc&quot;, rollbackMethod = &quot;cancelTcc&quot;)    void reduceBalance(@BusinessActionContextParameter(paramName = &quot;userId&quot;) Integer userId,                       @BusinessActionContextParameter(paramName = &quot;money&quot;) BigDecimal money);    /**     * 确认方法、可以另命名，但要保证与commitMethod一致     * context可以传递try方法的参数     *     * @param context 上下文     * @return boolean     */    boolean commitTcc(BusinessActionContext context);    /**     * 二阶段取消方法     *     * @param context 上下文     * @return boolean     */    boolean cancelTcc(BusinessActionContext context);&#125;</code></pre><p><code>@LocalTCC</code>注解标识此TCC为本地模式，即该事务是本地调用，非RPC调用，<code>@LocalTCC</code>一定需要注解在接口上，此接口可以是寻常的业务接口，只要实现了TCC的两阶段提交对应方法即可；</p><p><code>@TwoPhaseBusinessAction</code>，该注解标识为TCC模式，注解try方法，其中name为当前tcc方法的bean名称，写方法名便可（全局唯一），commitMethod指提交方法，rollbackMethod指事务回滚方法，指定好三个方法之后，Seata会根据事务的成功或失败，通过动态代理去帮我们自动调用提交或者回滚；</p><p><code>@BusinessActionContextParameter</code> 注解可以将参数传递到二阶段（commitMethod/rollbackMethod）的方法；</p><p><code>BusinessActionContext</code> 是指TCC事务上下文，携带了业务方法的参数；</p><blockquote><ol><li>基于Spring Cloud Alibaba的TCC分布式事务</li><li>具体代码实现和springboot单体应用的代码实现几乎没有区别，具体参考Git上提交的代码；</li><li>由于Seata出现时间并不长，也在不断的改进中，在实际面试中应该不会问大家比较底层的实现，同学们如果感兴趣的话，基于我们已有的源码阅读经验，可以看一下Seata的源码，它如何进行事务隔离保证数据一致性，官方提供的文档并不详细；</li></ol></blockquote><h1 id="Seata总结："><a href="#Seata总结：" class="headerlink" title="Seata总结："></a>Seata总结：</h1><ol><li>Seata 三种角色<ul><li>TM事务管理器：相当于业务中台,向TC发起全局事务的开始触发,让其生成全局事务ID, 向TC发起全局事务的提交或者回滚信号</li><li>TC事务协调器: 生成全局事务ID XID,协调每个RM资源管理器，触发子事务的事务提交和事务回滚</li><li>RM资源管理器：程序已启动就向TC注册自己的信息,负责自己子事务的本地事务提交和本地事务回滚</li></ul></li><li>Seata 流程</li></ol><ul><li><p>一阶段：</p><ul><li>TM向TC发起一个全局事务请求操作，TC生成一个全局事务XID，XID会在微服务的调用链路中传播</li><li>RM准备执行本地事务请求，申请本地事务锁和申请全局事务锁，拿全局事务锁的尝试被限制在一定范围内，超出范围将放弃，并回滚本地事务，释放本地锁。</li><li>如果全局事务锁被其他资源占据，需要等待并尝试获取全局事务锁，本地事务和UndoLog日志文件一起完成提交，释放本地事<br>务锁，</li></ul></li><li><p>二阶段-回滚：</p><ul><li>如果其中一个RM本地事务提交失败,抛出异常,TM捕捉到异常信息,向TC发起全局事务回滚信号，TC协调每个RM逐步发起本地事务回滚</li><li>回滚的时候会对比UndoLog日志的afterImage后快照和当前数据做对比，如果不一致，则出现了“脏写”需要人工介入操作，如果一致，更新的数据需要更新回原来数据，新增的数据需要删除</li></ul></li><li><p>二阶段-提交：</p><ul><li>如果每一个RM本地事务提交都成功，TM向TC发起全局事务提交信号，TC异步协调让所有RM本地事务快速提交</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> 分布式事务 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式事务 </tag>
            
            <tag> SEATA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分布式事务</title>
      <link href="/2022/01/10/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/"/>
      <url>/2022/01/10/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="分布式事务"><a href="#分布式事务" class="headerlink" title="分布式事务"></a>分布式事务</h1><h2 id="分布式事务的概念"><a href="#分布式事务的概念" class="headerlink" title="分布式事务的概念"></a>分布式事务的概念</h2><p>分布式事务指的是一个请求在<strong>多个系统的调用链当中如何确保数据一致。</strong></p><h2 id="分布式事务协议"><a href="#分布式事务协议" class="headerlink" title="分布式事务协议"></a>分布式事务协议</h2><p><strong>分布式事务协议：</strong></p><ul><li>2PC</li><li>3PC</li><li>TCC</li></ul><h2 id="2PC-两阶段提交协议"><a href="#2PC-两阶段提交协议" class="headerlink" title="2PC 两阶段提交协议"></a>2PC 两阶段提交协议</h2><p>2PC 是非常经典的<strong>强一致、中心化的原子提交协议</strong>，协议中定义了两类节点：一个中心化协调者节点和多个参与者节点。2PC 分为两个阶段：</p><ul><li><p>准备阶段：</p><ul><li>协调者向所有参与者发送事务内容，询问是否可以提交事务，并等待所有参与者答复；</li><li>各参与者执行事务操作，将 Undo 和 Redo 信息记入事务日志中（但不提交事务）；</li><li>如参与者执行成功，给协调者反馈 YES，即可以提交；如执行失败，给协调者反馈 NO，即不可提交。</li></ul></li><li><p><strong>提交阶段</strong>（所有参与者均反馈 YES）：</p><ul><li>协调者向所有参与者发出正式提交事务的请求（即 Commit 请求）；</li><li>参与者执行 Commit 请求，并释放整个事务期间占用的资源；</li><li>各参与者向协调者反馈 Ack 完成的消息；</li><li>协调者收到所有参与者反馈的 Ack 消息后，即完成事务提交。</li></ul></li><li><p><strong>提交阶段</strong>（任何一个参与者反馈 NO）：</p><ul><li>协调者向所有参与者发出回滚请求（即 Rollback 请求）；</li><li>参与者使用阶段 1 中的 Undo 信息执行回滚操作，并释放整个事务期间占用的资源；</li><li>各参与者向协调者反馈 Ack 完成的消息；</li><li>协调者收到所有参与者反馈的 Ack 消息后，即完成事务中断。</li></ul></li></ul><p><strong>2PC 两阶段提交过程中会遇到一些问题：</strong></p><ol><li><p><strong>性能问题</strong>：从流程上可以看出，其最大缺点就在于它的执行过程中间，<strong>节点都处于阻塞状态</strong>。各个操作数据库的节点此时都占用着数据库资源，只有当所有节点准备完毕，事务协调者才会通知进行全局提交，参与者进行本地事务提交后才会释放资源。</p></li><li><p><strong>协调者单点故障问题：</strong>事务协调者是整个 XA 模型的核心，一旦事务协调者节点挂掉，会导致参与者收不到提交或回滚的通知，从而导致参与者节点始终处于事务无法完成的中间状态。</p></li><li><p><strong>丢失消息导致的数据不一致问题：</strong>在第二个阶段，如果发生局部网络问题，一部分事务参与者收到了提交消息，另一部分事务参与者没收到提交消息，那么就会导致节点间数据的不一致问题。</p></li></ol><h2 id="3PC-三阶段提交协议"><a href="#3PC-三阶段提交协议" class="headerlink" title="3PC 三阶段提交协议"></a>3PC 三阶段提交协议</h2><blockquote><p>2PC 的改进版本，其在两阶段提交的基础上增加了 CanCommit 阶段，并引入了超时机制。一旦事务参与者迟迟没有收到协调者的 Commit 请求，就会自动进行本地 commit，这样相对有效地解决了协调者单点故障的问题。</p></blockquote><ul><li><p><strong>阶段 1：CanCommit</strong></p><ul><li>协调者向所有参与者发出包含事务内容的 CanCommit 请求，询问是否可以提交事务，并等待所有参与者答复；</li><li>参与者收到 CanCommit 请求后，如果认为可以执行事务操作，则反馈 YES 并进入预备状态，否则反馈 NO。</li></ul></li><li><p><strong>阶段 2：PreCommit 事务预提交：</strong>（所有参与者均反馈 YES 时）</p><ul><li>协调者向所有参与者发出 PreCommit 请求，进入准备阶段；</li><li>参与者收到 PreCommit 请求后，执行事务操作，将 Undo 和 Redo 信息记入事务日志中（但不提交事务）；</li><li>各参与者向协调者反馈 Ack 响应或 No 响应，并等待最终指令。</li></ul></li><li><p><strong>阶段 2：PreCommit ：</strong> 中断事务（任何一个参与者反馈 NO，或者等待超时后协调者尚无法收到所有参与者的反馈时）</p><ul><li>协调者向所有参与者发出 abort 请求；</li><li>无论收到协调者发出的 abort 请求，或在等待协调者请求过程中出现超时，参与者均会中断事务。</li></ul></li><li><p><strong>阶段 3：do Commit 提交事务：</strong>（所有参与者均反馈 Ack 响应时）</p><ul><li>如果协调者处于工作状态，则向所有参与者发出 do Commit 请求；</li><li>参与者收到 do Commit 请求后，会正式执行事务提交，并释放整个事务期间占用的资源；</li><li>各参与者向协调者反馈 Ack 完成的消息；</li><li>协调者收到所有参与者反馈的 Ack 消息后，即完成事务提交。</li></ul></li><li><p><strong>阶段 3：do Commit 中断事务：</strong>（任何一个参与者反馈 NO，或者等待超时后协调者尚无法收到所有参与者的反馈时）　　</p><ul><li>如果协调者处于工作状态，向所有参与者发出 abort 请求；　　</li><li>参与者使用阶段 1 中的 Undo 信息执行回滚操作，并释放整个事务期间占用的资源；　　</li><li>各参与者向协调者反馈 Ack 完成的消息；　　</li><li>协调者收到所有参与者反馈的 Ack 消息后，即完成事务中断。</li></ul></li></ul><h2 id="TCC-补偿事务协议"><a href="#TCC-补偿事务协议" class="headerlink" title="TCC 补偿事务协议"></a>TCC 补偿事务协议</h2><blockquote><p>TCC 将事务提交分为 Try - Confirm - Cancel 3 个操作：</p></blockquote><ul><li>Try：预留业务资源 / 数据效验</li><li>Confirm：确认执行业务操作</li><li>Cancel：取消执行业务操作</li></ul><blockquote><p>TCC 事务处理流程和 2PC 二阶段提交类似，不过 2PC 通常都是在跨库的 DB 层面，而 <strong>TCC 本质就是一个应用层面的 2PC。</strong></p></blockquote><h2 id="CAP-原则"><a href="#CAP-原则" class="headerlink" title="CAP 原则"></a>CAP 原则</h2><p><strong>概念</strong></p><p>CAP 原则又称 <strong>CAP 定理</strong>，指的是在一个分布式系统中，<code>一致性（Consistency）、可用性（Availability）、分区容错性（Partition tolerance）</code>。CAP 原则指的是，这三个要素最多只能同时实现两点，不可能三者兼顾。</p><ul><li><strong>一致性（C）：</strong> 在分布式系统中的所有数据备份，在同一时刻是否同样的值。（等同于所有节点访问同一份最新的数据副本）</li><li><strong>可用性（A）：</strong> 保证每个请求不管成功或者失败都有响应。</li><li><strong>分区容忍性（P）：</strong> 系统中任意信息的丢失或失败不会影响系统的继续运作。</li></ul><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210807155418846.png"></p><blockquote><p>CAP 特性的取舍</p></blockquote><ol><li><p>满足 CA 舍弃 P，也就是满足一致性和可用性，舍弃容错性。但是这也就意味着你的系统不是分布式的了，因为涉及分布式的想法就是把功能分开，部署到不同的机器上。</p></li><li><p>满足 CP 舍弃 A，也就是满足一致性和容错性，舍弃可用性。如果你的系统允许有段时间的访问失效等问题，这个是可以满足的。就好比多个人并发买票，后台网络出现故障，你买的时候系统就崩溃了。</p></li><li><p>满足 AP 舍弃 C，也就是满足可用性和容错性，舍弃一致性。这也就是意味着你的系统在并发访问的时候可能会出现数据不一致的情况。</p></li></ol><blockquote><p>实时证明，大多数都是牺牲了一致性。像 12306 还有淘宝网，就好比是你买火车票，本来你看到的是还有一张票，其实在这个时刻已经被买走了，你填好了信息准备买的时候发现系统提示你没票了。这就是牺牲了一致性。</p></blockquote><p>但是不是说牺牲一致性一定是最好的。就好比 mysql 中的事务机制，张三给李四转了 100 块钱，这时候必须保证张三的账户上少了 100，李四的账户多了 100。因此需要数据的一致性，而且什么时候转钱都可以，也需要可用性。但是可以转钱失败是可以允许的。</p>]]></content>
      
      
      <categories>
          
          <category> 分布式事务 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 2PC </tag>
            
            <tag> 3PC </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分布式缓存</title>
      <link href="/2021/12/04/redis/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98/"/>
      <url>/2021/12/04/redis/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="分布式缓存"><a href="#分布式缓存" class="headerlink" title="分布式缓存"></a>分布式缓存</h1><h2 id="在项目中缓存是如何使用的？缓存如果使用不当会造成什么后果？"><a href="#在项目中缓存是如何使用的？缓存如果使用不当会造成什么后果？" class="headerlink" title="在项目中缓存是如何使用的？缓存如果使用不当会造成什么后果？"></a>在项目中缓存是如何使用的？缓存如果使用不当会造成什么后果？</h2><h3 id="项目中缓存是如何使用的？"><a href="#项目中缓存是如何使用的？" class="headerlink" title="项目中缓存是如何使用的？"></a>项目中缓存是如何使用的？</h3><p>这个，需要结合自己项目的业务来。</p><h3 id="为什么要用缓存？"><a href="#为什么要用缓存？" class="headerlink" title="为什么要用缓存？"></a>为什么要用缓存？</h3><p>用缓存，主要有两个用途：高性能、高并发。</p><h3 id="用了缓存之后会有什么不良后果？"><a href="#用了缓存之后会有什么不良后果？" class="headerlink" title="用了缓存之后会有什么不良后果？"></a>用了缓存之后会有什么不良后果？</h3><p>常见的缓存问题有以下几个：</p><ul><li>缓存与数据库双写不一致</li><li>缓存雪崩、缓存穿透</li><li>缓存并发竞争</li></ul><h3 id="缓存数据的处理流程是怎样的？"><a href="#缓存数据的处理流程是怎样的？" class="headerlink" title="缓存数据的处理流程是怎样的？"></a>缓存数据的处理流程是怎样的？</h3><p>简单来说就是:</p><ol><li>如果用户请求的数据在缓存中就直接返回；</li><li>缓存中不存在的话就看数据库中是否存在；</li><li>数据库中存在的话就更新缓存中的数据；</li><li>数据库中不存在的话就返回空数据。</li></ol><h3 id="Redis-和-Memcached-有什么区别？Redis-的线程模型是什么？为什么单线程的-Redis-比多线程的-Memcached-效率要高得多？"><a href="#Redis-和-Memcached-有什么区别？Redis-的线程模型是什么？为什么单线程的-Redis-比多线程的-Memcached-效率要高得多？" class="headerlink" title="Redis 和 Memcached 有什么区别？Redis 的线程模型是什么？为什么单线程的 Redis 比多线程的 Memcached 效率要高得多？"></a>Redis 和 Memcached 有什么区别？Redis 的线程模型是什么？为什么单线程的 Redis 比多线程的 Memcached 效率要高得多？</h3><h3 id="redis-和-memcached-有啥区别？"><a href="#redis-和-memcached-有啥区别？" class="headerlink" title="redis 和 memcached 有啥区别？"></a>redis 和 memcached 有啥区别？</h3><p>共同点 ：</p><ol><li>都是基于内存的数据库，一般都用来当做缓存使用。</li><li>都有过期策略。</li><li>两者的性能都非常高。</li></ol><p>区别 ：</p><ol><li>Redis 支持更丰富的数据类型（支持更复杂的应用场景）。Redis 不仅仅支持简单的 k/v 类型的数据，同时还提供 list，set，zset，hash 等数据结构的存储。Memcached 只支持最简单的 k/v 数据类型。</li><li>Redis 支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用，而 Memecache 把数据全部存在内存之中。</li><li>Redis 有灾难恢复机制。 因为可以把缓存中的数据持久化到磁盘上。</li><li>Redis 在服务器内存使用完之后，可以将不用的数据放到磁盘上。但是，Memcached 在服务器内存使用完之后，就会直接报异常。</li><li>Memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；但是 Redis 目前是原生支持 cluster 模式的.</li><li>Memcached 是多线程，非阻塞 IO 复用的网络模型；Redis 使用单线程的多路 IO 复用模型。 （Redis 6.0 引入了多线程 IO ）</li><li>Redis 支持发布订阅模型、Lua 脚本、事务等功能，而 Memcached 不支持。并且，Redis 支持更多的编程语言。</li><li>Memcached 过期数据的删除策略只用了惰性删除，而 Redis 同时使用了惰性删除与定期删除。</li><li><h3 id="redis-的线程模型"><a href="#redis-的线程模型" class="headerlink" title="redis 的线程模型"></a>redis 的线程模型</h3>redis 内部使用文件事件处理器 file event handler，这个文件事件处理器是单线程的，所以 redis 才叫做单线程的模型。它采用 IO 多路复用机制同时监听多个 socket，将产生事件的 socket 压入内存队列中，事件分派器根据 socket 上的事件类型来选择对应的事件处理器进行处理。</li></ol><p>文件事件处理器的结构包含 4 个部分：</p><ul><li>多个 socket</li><li>IO 多路复用程序</li><li>文件事件分派器</li><li>事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）</li></ul><p>多个 socket 可能会并发产生不同的操作，每个操作对应不同的文件事件，但是 IO 多路复用程序会监听多个 socket，会将产生事件的 socket 放入队列中排队，事件分派器每次从队列中取出一个 socket，根据 socket 的事件类型交给对应的事件处理器进行处理。</p><p>来看客户端与 redis 的一次通信过程：</p><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210806161320423.png" alt="redis通信过程" title="redis通信过程"></p><ul><li><p>首先，redis 服务端进程初始化的时候，会将 server socket 的 AE_READABLE 事件与连接应答处理器关联。</p></li><li><p>客户端 socket01 向 redis 进程的 server socket 请求建立连接，此时 server socket 会产生一个 AE_READABLE 事件，IO 多路复用程序监听到 server socket 产生的事件后，将该 socket 压入队列中。文件事件分派器从队列中获取 socket，交给连接应答处理器。连接应答处理器会创建一个能与客户端通信的 socket01，并将该 socket01 的 AE_READABLE 事件与命令请求处理器关联。</p></li></ul><ul><li><p>假设此时客户端发送了一个<font color=red>set key value</font>请求，此时 redis 中的 socket01 会产生 AE_READABLE 事件，IO 多路复用程序将 socket01 压入队列，此时事件分派器从队列中获取到 socket01 产生的 AE_READABLE 事件，由于前面 socket01 的 AE_READABLE 事件已经与命令请求处理器关联，因此事件分派器将事件交给命令请求处理器来处理。命令请求处理器读取 socket01 的 key value 并在自己内存中完成 key value 的设置。操作完成后，它会将 socket01 的 AE_WRITABLE 事件与命令回复处理器关联。</p></li><li><p>如果此时客户端准备好接收返回结果了，那么 redis 中的 socket01 会产生一个 AE_WRITABLE 事件，同样压入队列中，事件分派器找到相关联的命令回复处理器，由命令回复处理器对 socket01 输入本次操作的一个结果，比如 ok，之后解除 socket01 的 AE_WRITABLE 事件与命令回复处理器的关联。</p></li><li><p>这样便完成了一次通信。关于 Redis 的一次通信过程。</p></li></ul><h3 id="为啥-redis-单线程模型也能效率这么高？"><a href="#为啥-redis-单线程模型也能效率这么高？" class="headerlink" title="为啥 redis 单线程模型也能效率这么高？"></a>为啥 redis 单线程模型也能效率这么高？</h3><ul><li>纯内存操作；</li><li>核心是基于非阻塞的 IO 多路复用机制；</li><li>C 语言实现，一般来说，C 语言实现的程序 “距离” 操作系统更近，执行速度相对会更快；</li><li>单线程反而避免了多线程的频繁上下文切换问题，预防了多线程可能产生的竞争问题。</li></ul><h3 id="Redis-没有使用多线程？为什么不使用多线程？Redis6-0-之后为何引入了多线程？"><a href="#Redis-没有使用多线程？为什么不使用多线程？Redis6-0-之后为何引入了多线程？" class="headerlink" title="Redis 没有使用多线程？为什么不使用多线程？Redis6.0 之后为何引入了多线程？"></a>Redis 没有使用多线程？为什么不使用多线程？Redis6.0 之后为何引入了多线程？</h3><p>虽然说 Redis 是单线程模型，但是， 实际上，Redis 在 4.0 之后的版本中就已经加入了对多线程的支持。不过，Redis 4.0 增加的多线程主要是针对一些大键值对的删除操作的命令，使用这些命令就会使用主处理之外的其他线程来 “异步处理”。</p><p>大体上来说，Redis 6.0 之前主要还是单线程处理。</p><h2 id="Redis6-0-之前为什么不使用多线程？"><a href="#Redis6-0-之前为什么不使用多线程？" class="headerlink" title="Redis6.0 之前为什么不使用多线程？"></a>Redis6.0 之前为什么不使用多线程？</h2><p>我觉得主要原因有下面 3 个：</p><ol><li>单线程编程容易并且更容易维护；</li><li>Redis 的性能瓶颈不再 CPU ，主要在内存和网络；</li><li>多线程就会存在死锁、线程上下文切换等问题，甚至会影响性能。</li></ol><h3 id="Redis6-0-之后为何引入了多线程？"><a href="#Redis6-0-之后为何引入了多线程？" class="headerlink" title="Redis6.0 之后为何引入了多线程？"></a>Redis6.0 之后为何引入了多线程？</h3><p><strong>Redis6.0 引入多线程主要是为了提高网络 IO 读写性能</strong>，因为这个算是 Redis 中的一个性能瓶颈（Redis 的瓶颈主要受限于内存和网络）。虽然，Redis6.0 引入了多线程，但是 Redis 的多线程只是在网络数据的读写这类耗时操作上使用了， 执行命令仍然是单线程顺序执行。因此，你也不需要担心线程安全问题。</p><p>Redis6.0 的多线程默认是禁用的，只使用主线程。如需开启需要修改 redis 配置文件 <strong>redis.conf</strong> ：</p><pre><code class="bash">io-threads-do-reads yes</code></pre><p>开启多线程后，还需要设置线程数，否则是不生效的。同样需要修改 redis 配置文件 <font color=red>redis.conf</font> :</p><pre><code class="bash">io-threads 4 #官网建议4核的机器建议设置为2或3个线程，8核的建议设置为6个线程</code></pre><h2 id="Redis-都有哪些数据类型？分别在哪些场景下使用比较合适？"><a href="#Redis-都有哪些数据类型？分别在哪些场景下使用比较合适？" class="headerlink" title="Redis 都有哪些数据类型？分别在哪些场景下使用比较合适？"></a>Redis 都有哪些数据类型？分别在哪些场景下使用比较合适？</h2><p>redis 主要有以下几种数据类型：</p><ul><li>string：普通的 set 和 get，做简单的 KV 缓存，一般常用在需要计数的场景，比如用户的访问次数、热点文章的点赞转发数量等等。</li><li>hash：类似 map 的一种结构，这个一般就是可以将结构化的数据（系统中对象数据的存储），比如一个对象（前提是这个对象没嵌套其他的对象）给缓存在 redis 里，然后每次读写缓存的时候，可以就操作 hash 里的某个字段。</li><li>list：有序列表，可以通过 list 存储一些列表型的数据结构，类似粉丝列表、文章的评论列表之类的东西，</li><li>set：set 是无序集合，自动去重。可以基于 set 玩儿交集、并集、差集的操作，比如交集吧，可以把两个人的粉丝列表整一个交集，看看俩人的共同好友是谁？对吧。</li><li>sorted set：是排序的 set，去重但可以排序，写进去的时候给一个分数，自动根据分数排序。场景：需要对数据根据某个权重进行排序的场景。比如在直播系统中，实时排行信息包含直播间在线用户列表，各种礼物排行榜，弹幕消息（可以理解为按消息维度的消息排行榜）等信息。</li></ul><h3 id="Redis-是如何判断数据是否过期的呢？Redis-的过期策略都有哪些？手写一下-LRU-代码实现？"><a href="#Redis-是如何判断数据是否过期的呢？Redis-的过期策略都有哪些？手写一下-LRU-代码实现？" class="headerlink" title="Redis 是如何判断数据是否过期的呢？Redis 的过期策略都有哪些？手写一下 LRU 代码实现？"></a>Redis 是如何判断数据是否过期的呢？Redis 的过期策略都有哪些？手写一下 LRU 代码实现？</h3><h3 id="数据过期判断"><a href="#数据过期判断" class="headerlink" title="数据过期判断"></a>数据过期判断</h3><p>Redis 通过一个叫做过期字典（可以看作是 hash 表）来保存数据过期的时间。过期字典的键指向 Redis 数据库中的某个 key (键)，过期字典的值是一个 long long 类型的整数，这个整数保存了 key 所指向的数据库键的过期时间（毫秒精度的 UNIX 时间戳）。</p><h3 id="redis-过期策略"><a href="#redis-过期策略" class="headerlink" title="redis 过期策略"></a>redis 过期策略</h3><p>redis 过期策略是：<strong>定期删除 + 惰性删除</strong>。</p><p>所谓<strong>定期删除</strong>，指的是 redis 默认是每隔 100ms 就随机抽取一些设置了过期时间的 key，检查其是否过期，如果过期就删除。假设 redis 里放了 10w 个 key，都设置了过期时间，你每隔几百毫秒，就检查 10w 个 key，那 redis 基本上就死了，cpu 负载会很高的，消耗在你的检查过期 key 上了。注意，这里可不是每隔 100ms 就遍历所有的设置过期时间的 key，那样就是一场性能上的灾难。实际上 redis 是每隔 100ms <strong>随机抽取</strong>一些 key 来检查和删除的。</p><p>但是问题是，定期删除可能会导致很多过期 key 到了时间并没有被删除掉，那咋整呢？所以就是惰性删除了。这就是说，在你获取某个 key 的时候，redis 会检查一下 ，这个 key 如果设置了过期时间那么是否过期了？如果过期了此时就会删除，不会给你返回任何东西。</p><blockquote><p>获取 key 的时候，如果此时 key 已经过期，就删除，不会返回任何东西。</p></blockquote><p>但是实际上这还是有问题的，如果定期删除漏掉了很多过期 key，然后你也没及时去查，也就没走惰性删除，此时会怎么样？如果大量过期 key 堆积在内存里，导致 redis 内存块耗尽了，咋整？</p><p>答案是：<strong>走内存淘汰机制</strong>。</p><h3 id="内存淘汰机制"><a href="#内存淘汰机制" class="headerlink" title="内存淘汰机制"></a>内存淘汰机制</h3><p>redis 内存淘汰机制有以下几个：</p><ul><li>noeviction: 当内存不足以容纳新写入数据时，新写入操作会报错，这个一般没人用吧，实在是太恶心了。</li><li>allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 key（这个是最常用的）。</li><li><ul><li>volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的 key（这个一般不太合适）。</li></ul></li><li>allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个 key，这个一般没人用吧，为啥要随机，肯定是把最近最少使用的 key 给干掉啊。</li><li>volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个 key。</li><li>volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的 key 优先移除。</li></ul><h3 id="手写一个-LRU-算法"><a href="#手写一个-LRU-算法" class="headerlink" title="手写一个 LRU 算法"></a>手写一个 LRU 算法</h3><pre><code class="bash">class LRUCache&lt;K, V&gt; extends LinkedHashMap&lt;K, V&gt; &#123;    private final int CACHE_SIZE;    /**     * 传递进来最多能缓存多少数据     *     * @param cacheSize 缓存大小     */    public LRUCache(int cacheSize) &#123;        // true 表示让 linkedHashMap 按照访问顺序来进行排序，最近访问的放在头部，最老访问的放在尾部。        super((int) Math.ceil(cacheSize / 0.75) + 1, 0.75f, true);        CACHE_SIZE = cacheSize;    &#125;    @Override    protected boolean removeEldestEntry(Map.Entry&lt;K, V&gt; eldest) &#123;        // 当 map中的数据量大于指定的缓存个数的时候，就自动删除最老的数据。        return size() &gt; CACHE_SIZE;    &#125;&#125;</code></pre><h2 id="Redis-事务？"><a href="#Redis-事务？" class="headerlink" title="Redis 事务？"></a>Redis 事务？</h2><p>Redis 可以通过 <strong>MULTI，EXEC，DISCARD 和 WATCH</strong> 等命令来实现事务 (transaction) 功能。使用 MULTI 命令后可以输入多个命令。Redis 不会立即执行这些命令，而是将它们放到队列，当调用了 EXEC] 命令将执行所有命令。</p><p><strong>Redis 是不支持 roll back 的，因而不满足原子性的（而且不满足持久性）。</strong></p><p>Redis 官网也解释了自己为啥不支持回滚。简单来说就是 Redis 开发者们觉得没必要支持回滚，这样更简单便捷并且性能更好。Redis 开发者觉得即使命令执行错误也应该在开发过程中就被发现而不是生产过程中。</p><h3 id="如何保证-Redis-高并发、高可用？Redis-的主从复制原理能介绍一下么？Redis-的哨兵原理能介绍一下么？"><a href="#如何保证-Redis-高并发、高可用？Redis-的主从复制原理能介绍一下么？Redis-的哨兵原理能介绍一下么？" class="headerlink" title="如何保证 Redis 高并发、高可用？Redis 的主从复制原理能介绍一下么？Redis 的哨兵原理能介绍一下么？"></a>如何保证 Redis 高并发、高可用？Redis 的主从复制原理能介绍一下么？Redis 的哨兵原理能介绍一下么？</h3><p><a href="https://www.baidu.com/">Redis 的哨兵原理</a></p><h2 id="Redis-的持久化有哪几种方式？不同的持久化机制都有什么优缺点？持久化机制具体底层是如何实现的？"><a href="#Redis-的持久化有哪几种方式？不同的持久化机制都有什么优缺点？持久化机制具体底层是如何实现的？" class="headerlink" title="Redis 的持久化有哪几种方式？不同的持久化机制都有什么优缺点？持久化机制具体底层是如何实现的？"></a>Redis 的持久化有哪几种方式？不同的持久化机制都有什么优缺点？持久化机制具体底层是如何实现的？</h2><h3 id="redis-持久化的两种方式"><a href="#redis-持久化的两种方式" class="headerlink" title="redis 持久化的两种方式"></a>redis 持久化的两种方式</h3><ul><li>RDB：RDB 持久化机制，是对 redis 中的数据执行周期性的持久化。</li><li>AOF：AOF 机制对每条写入命令作为日志，以 append-only 的模式写入一个日志文件中，在 redis 重启的时候，可以通过回放 AOF 日志中的写入指令来重新构建整个数据集。<br>如果 redis 挂了，服务器上的内存和磁盘上的数据都丢了，可以从云服务上拷贝回来之前的数据，放到指定的目录中，然后重新启动 redis，redis 就会自动根据持久化数据文件中的数据，去恢复内存中的数据，继续对外提供服务。</li></ul><p>如果同时使用 RDB 和 AOF 两种持久化机制，那么在 redis 重启的时候，会使用 AOF 来重新构建数据，因为 AOF 中的数据更加完整。</p><h3 id="RDB-优缺点"><a href="#RDB-优缺点" class="headerlink" title="RDB 优缺点"></a>RDB 优缺点</h3><ul><li><p>RDB 会生成多个数据文件，每个数据文件都代表了某一个时刻中 redis 的数据，这种多个数据文件的方式，非常适合做冷备，可以将这种完整的数据文件发送到一些远程的安全存储上去，比如说 Amazon 的 S3 云服务上去，在国内可以是阿里云的 ODPS 分布式存储上，以预定好的备份策略来定期备份 redis 中的数据。</p></li><li><p>RDB 对 redis 对外提供的读写服务，影响非常小，可以让 redis 保持高性能，因为 redis 主进程只需要 fork 一个子进程，让子进程执行磁盘 IO 操作来进行 RDB 持久化即可。<br>相对于 AOF 持久化机制来说，直接基于 RDB 数据文件来重启和恢复 redis 进程，更加快速。<br>如果想要在 redis 故障时，尽可能少的丢失数据，那么 RDB 没有 AOF 好。一般来说，RDB 数据快照文件，都是每隔 5 分钟，或者更长时间生成一次，这个时候就得接受一旦 redis 进程宕机，那么会丢失最近 5 分钟的数据。</p></li><li><p>RDB 每次在 fork 子进程来执行 RDB 快照数据文件生成的时候，如果数据文件特别大，可能会导致对客户端提供的服务暂停数毫秒，或者甚至数秒。</p></li></ul><h3 id="AOF-优缺点"><a href="#AOF-优缺点" class="headerlink" title="AOF 优缺点"></a>AOF 优缺点</h3><ul><li><p>AOF 可以更好的保护数据不丢失，一般 AOF 会每隔 1 秒，通过一个后台线程执行一次 fsync 操作，最多丢失 1 秒钟的数据。</p></li><li><p>AOF 日志文件以 append-only 模式写入，所以没有任何磁盘寻址的开销，写入性能非常高，而且文件不容易破损，即使文件尾部破损，也很容易修复。</p></li><li><p>AOF 日志文件即使过大的时候，出现后台重写操作，也不会影响客户端的读写。因为在 rewrite log 的时候，会对其中的指令进行压缩，创建出一份需要恢复数据的最小日志出来。在创建新日志文件的时候，老的日志文件还是照常写入。当新的 merge 后的日志文件 ready 的时候，再交换新老日志文件即可。</p></li><li><p>AOF 日志文件的命令通过非常可读的方式进行记录，这个特性非常适合做灾难性的误删除的紧急恢复。比如某人不小心用 flushall 命令清空了所有数据，只要这个时候后台 rewrite 还没有发生，那么就可以立即拷贝 AOF 文件，将最后一条 flushall 命令给删了，然后再将该 AOF 文件放回去，就可以通过恢复机制，自动恢复所有数据。<br>对于同一份数据来说，AOF 日志文件通常比 RDB 数据快照文件更大。</p></li><li><p>AOF 开启后，支持的写 QPS 会比 RDB 支持的写 QPS 低，因为 AOF 一般会配置成每秒 fsync 一次日志文件，当然，每秒一次 fsync，性能也还是很高的。（如果实时写入，那么 QPS 会大降，redis 性能会大大降低）<br>以前 AOF 发生过 bug，就是通过 AOF 记录的日志，进行数据恢复的时候，没有恢复一模一样的数据出来。所以说，类似 AOF 这种较为复杂的基于命令日志 /merge/ 回放的方式，比基于 RDB 每次持久化一份完整的数据快照文件的方式，更加脆弱一些，容易有 bug。不过 AOF 就是为了避免 rewrite 过程导致的 bug，因此每次 rewrite 并不是基于旧的指令日志进行 merge 的，而是基于当时内存中的数据进行指令的重新构建，这样健壮性会好很多。</p></li></ul><h3 id="RDB-和-AOF-到底该如何选择"><a href="#RDB-和-AOF-到底该如何选择" class="headerlink" title="RDB 和 AOF 到底该如何选择"></a>RDB 和 AOF 到底该如何选择</h3><ul><li><p>不要仅仅使用 RDB，因为那样会导致你丢失很多数据；</p></li><li><p>也不要仅仅使用 AOF，因为那样有两个问题：第一，你通过 AOF 做冷备，没有 RDB 做冷备来的恢复速度更快；第二，RDB 每次简单粗暴生成数据快照，更加健壮，可以避免 AOF 这种复杂的备份和恢复机制的 bug；</p></li><li><p>redis 支持同时开启开启两种持久化方式，我们可以综合使用 AOF 和 RDB 两种持久化机制，用 AOF 来保证数据不丢失，作为数据恢复的第一选择；用 RDB 来做不同程度的冷备，在 AOF 文件都丢失或损坏不可用的时候，还可以使用 RDB 来进行快速的数据恢复。</p></li></ul><h2 id="Redis-集群模式的工作原理能说一下么？在集群模式下，Redis-的-key-是如何寻址的？分布式寻址都有哪些算法？了解一致性-hash-算法吗？如何动态增加和删除一个节点？"><a href="#Redis-集群模式的工作原理能说一下么？在集群模式下，Redis-的-key-是如何寻址的？分布式寻址都有哪些算法？了解一致性-hash-算法吗？如何动态增加和删除一个节点？" class="headerlink" title="Redis 集群模式的工作原理能说一下么？在集群模式下，Redis 的 key 是如何寻址的？分布式寻址都有哪些算法？了解一致性 hash 算法吗？如何动态增加和删除一个节点？"></a>Redis 集群模式的工作原理能说一下么？在集群模式下，Redis 的 key 是如何寻址的？分布式寻址都有哪些算法？了解一致性 hash 算法吗？如何动态增加和删除一个节点？</h2><h3 id="redis-cluster-介绍"><a href="#redis-cluster-介绍" class="headerlink" title="redis cluster 介绍"></a>redis cluster 介绍</h3><ul><li><p>自动将数据进行分片，每个 master 上放一部分数据</p></li><li><p>提供内置的高可用支持，部分 master 不可用时，还是可以继续工作的</p></li></ul><p>在 redis cluster 架构下，每个 redis 要放开两个端口号，比如一个是 6379，另外一个就是 加 1w 的端口号，比如 16379。16379 端口号是用来进行节点间通信的，也就是 cluster bus 的东西，cluster bus 的通信，用来进行故障检测、配置更新、故障转移授权。cluster bus 用了另外一种二进制的协议，gossip 协议，用于节点间进行高效的数据交换，占用更少的网络带宽和处理时间。</p><h3 id="节点间的内部通信机制"><a href="#节点间的内部通信机制" class="headerlink" title="节点间的内部通信机制"></a>节点间的内部通信机制</h3><p><strong>基本通信原理</strong></p><p>集群元数据的维护有两种方式：集中式、Gossip 协议。redis cluster 节点间采用 gossip 协议进行通信。</p><p><strong>集中式</strong>是将集群元数据（节点信息、故障等等）几种存储在某个节点上。集中式元数据集中存储的一个典型代表，就是大数据领域的 storm。它是分布式的大数据实时计算引擎，是集中式的元数据存储的结构，底层基于 zookeeper（分布式协调的中间件）对所有元数据进行存储维护。</p><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210806164328350.png" alt="集中式通信" title="集中式通信"></p><p>redis 维护集群元数据采用另一个方式， <font color=red>gossip 协议</font>，所有节点都持有一份元数据，不同的节点如果出现了元数据的变更，就不断将元数据发送给其它的节点，让其它节点也进行元数据的变更。</p><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210806164415142.png" alt="gossip 协议" title="gossip 协议"></p><p><strong>集中式的好处</strong>在于，元数据的读取和更新，时效性非常好，一旦元数据出现了变更，就立即更新到集中式的存储中，其它节点读取的时候就可以感知到；不好在于，所有的元数据的更新压力全部集中在一个地方，可能会导致元数据的存储有压力。</p><p><strong>gossip 好处</strong>在于，元数据的更新比较分散，不是集中在一个地方，更新请求会陆陆续续打到所有节点上去更新，降低了压力；不好在于，元数据的更新有延时，可能导致集群中的一些操作会有一些滞后。</p><ul><li>10000 端口：每个节点都有一个专门用于节点间通信的端口，就是自己提供服务的端口号 + 10000，比如 7001，那么用于节点间通信的就是 17001 端口。每个节点每隔一段时间都会往另外几个节点发送 ping 消息，同时其它几个节点接收到 ping 之后返回 pong。</li><li>交换的信息：信息包括故障信息，节点的增加和删除，hash slot 信息等等。</li></ul><p><strong>gossip 协议</strong></p><p>gossip 协议包含多种消息，包含 <font color=red>ping,pong,meet,fail</font> 等等。</p><ul><li>meet：某个节点发送 meet 给新加入的节点，让新节点加入集群中，然后新节点就会开始与其它节点进行通信。</li></ul><pre><code class="bash">redis-trib.rb add-node</code></pre><p>其实内部就是发送了一个 gossip meet 消息给新加入的节点，通知那个节点去加入我们的集群。</p><ul><li>ping：每个节点都会频繁给其它节点发送 ping，其中包含自己的状态还有自己维护的集群元数据，互相通过 ping 交换元数据。</li><li>pong：返回 ping 和 meet，包含自己的状态和其它信息，也用于信息广播和更新。</li><li>fail：某个节点判断另一个节点 fail 之后，就发送 fail 给其它节点，通知其它节点说，某个节点宕机啦。</li></ul><h3 id="ping-消息深入"><a href="#ping-消息深入" class="headerlink" title="ping 消息深入"></a>ping 消息深入</h3><p>ping 时要携带一些元数据，如果很频繁，可能会加重网络负担。</p><p>每个节点每秒会执行 10 次 ping，每次会选择 5 个最久没有通信的其它节点。当然如果发现某个节点通信延时达到了 cluster_node_timeout / 2，那么立即发送 ping，避免数据交换延时过长，落后的时间太长了。比如说，两个节点之间都 10 分钟没有交换数据了，那么整个集群处于严重的元数据不一致的情况，就会有问题。所以 cluster_node_timeout 可以调节，如果调得比较大，那么会降低 ping 的频率。</p><p>每次 ping，会带上自己节点的信息，还有就是带上 1/10 其它节点的信息，发送出去，进行交换。至少包含 3 个其它节点的信息，最多包含 总节点数减 2 个其它节点的信息。</p><h3 id="分布式寻址算法"><a href="#分布式寻址算法" class="headerlink" title="分布式寻址算法"></a>分布式寻址算法</h3><ul><li>hash 算法（大量缓存重建）</li><li>一致性 hash 算法（自动缓存迁移）+ 虚拟节点（自动负载均衡）</li><li>redis cluster 的 hash slot 算法</li></ul><p><strong>hash 算法</strong></p><p>来了一个 key，首先计算 hash 值，然后对节点数取模。然后打在不同的 master 节点上。一旦某一个 master 节点宕机，所有请求过来，都会基于最新的剩余 master 节点数去取模，尝试去取数据。这会导致大部分的请求过来，全部无法拿到有效的缓存，导致大量的流量涌入数据库。</p><p><img src="https://cdn.jsdelivr.net/gh/junian455/pic@master/img/image-20210806165256905.png" alt="hash 算法" title="hash 算法"></p><p><strong>一致性 hash 算法</strong><br>一致性 hash 算法将整个 hash 值空间组织成一个虚拟的圆环，整个空间按顺时针方向组织，下一步将各个 master 节点（使用服务器的 ip 或主机名）进行 hash。这样就能确定每个节点在其哈希环上的位置。</p><p>来了一个 key，首先计算 hash 值，并确定此数据在环上的位置，从此位置沿环顺时针 “行走”，遇到的第一个 master 节点就是 key 所在位置。</p><p>在一致性哈希算法中，如果一个节点挂了，受影响的数据仅仅是此节点到环空间前一个节点（沿着逆时针方向行走遇到的第一个节点）之间的数据，其它不受影响。增加一个节点也同理。</p><p>然而，一致性哈希算法在节点太少时，容易因为节点分布不均匀而造成缓存热点的问题。为了解决这种热点问题，一致性 hash 算法引入了虚拟节点机制，即对每一个节点计算多个 hash，每个计算结果位置都放置一个虚拟节点，这样就实现了数据的均匀分布，负载均衡。</p><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210806165425055.png" alt="一致性哈希算法" title="一致性哈希算法"></p><p><strong>redis cluster 的 hash slot 算法</strong></p><p>redis cluster 有固定的 <font color=red>16384</font>  个 hash slot，对每个 key 计算 CRC16 值，然后对 16384 取模，可以获取 <font color=red>key</font> 对应的 <font color=red>hash slot</font>。</p><p>redis cluster 中每个 master 都会持有部分 slot，比如有 3 个 master，那么可能每个 master 持有 5000 多个 hash slot。hash slot 让 node 的增加和移除很简单，增加一个 master，就将其他 master 的 hash slot 移动部分过去，减少一个 master，就将它的 hash slot 移动到其他 master 上去。移动 hash slot 的成本是非常低的。客户端的 api，可以对指定的数据，让他们走同一个 hash slot，通过 <font color=red>hash tag</font> 来实现。</p><p>任何一台机器宕机，另外两个节点，不影响的。因为 key 找的是 hash slot，不是机器。</p><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210806171326766.png" alt="redis cluster 的 hash slot 算法" title="redis cluster 的 hash slot 算法"></p><h3 id="redis-cluster-的高可用与主备切换原理"><a href="#redis-cluster-的高可用与主备切换原理" class="headerlink" title="redis cluster 的高可用与主备切换原理"></a>redis cluster 的高可用与主备切换原理</h3><p>redis cluster 的高可用的原理，几乎跟哨兵是类似的。</p><p><strong>判断节点宕机</strong></p><ul><li><p>如果一个节点认为另外一个节点宕机，那么就是 pfail，主观宕机。如果多个节点都认为另外一个节点宕机了，那么就是 fail，客观宕机，跟哨兵的原理几乎一样，sdown，odown。在 cluster-node-timeout 内，某个节点一直没有返回 pong，那么就被认为 pfail。</p></li><li><p>如果一个节点认为某个节点 pfail 了，那么会在 gossip ping 消息中，ping 给其他节点，如果超过半数的节点都认为 pfail 了，那么就会变成 fail。</p></li></ul><p><strong>从节点过滤</strong></p><ul><li><p>对宕机的 master node，从其所有的 slave node 中，选择一个切换成 master node。</p></li><li><p>检查每个 slave node 与 master node 断开连接的时间，如果超过了 cluster-node-timeout * cluster-slave-validity-factor，那么就没有资格切换成 master。</p></li></ul><p><strong>从节点选举</strong></p><ul><li><p>每个从节点，都根据自己对 master 复制数据的 offset，来设置一个选举时间，offset 越大（复制数据越多）的从节点，选举时间越靠前，优先进行选举。</p></li><li><p>所有的 master node 开始 slave 选举投票，给要进行选举的 slave 进行投票，如果大部分 master node（N/2 + 1）都投票给了某个从节点，那么选举通过，那个从节点可以切换成 master。</p></li><li><p>从节点执行主备切换，从节点切换为主节点。</p></li></ul><p><strong>与哨兵比较</strong></p><p>整个流程跟哨兵相比，非常类似，所以说，redis cluster 功能强大，直接集成了 replication 和 sentinel 的功能。</p><h2 id="了解什么是-redis-的雪崩、穿透和击穿？Redis-崩溃之后会怎么样？系统该如何应对这种情况？如何处理-Redis-的穿透？"><a href="#了解什么是-redis-的雪崩、穿透和击穿？Redis-崩溃之后会怎么样？系统该如何应对这种情况？如何处理-Redis-的穿透？" class="headerlink" title="了解什么是 redis 的雪崩、穿透和击穿？Redis 崩溃之后会怎么样？系统该如何应对这种情况？如何处理 Redis 的穿透？"></a>了解什么是 redis 的雪崩、穿透和击穿？Redis 崩溃之后会怎么样？系统该如何应对这种情况？如何处理 Redis 的穿透？</h2><h3 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h3><p>对于系统 A，假设每天高峰期每秒 5000 个请求，本来缓存在高峰期可以扛住每秒 4000 个请求，但是缓存机器意外发生了全盘宕机。缓存挂了，此时 1 秒 5000 个请求全部落数据库，数据库必然扛不住，它会报一下警，然后就挂了。此时，如果没有采用什么特别的方案来处理这个故障，DBA 很着急，重启数据库，但是数据库立马又被新的流量给打死了，这就是缓存雪崩。</p><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210806165932347.png" alt="缓存雪崩" title="缓存雪崩"></p><p>缓存雪崩的事前事中事后的解决方案如下：</p><ul><li>事前：redis 高可用，主从 + 哨兵，redis cluster，避免全盘崩溃。</li><li>事中：本地 ehcache 缓存 + hystrix 限流 &amp; 降级，避免 MySQL 被打死。</li><li>事后：redis 持久化，一旦重启，自动从磁盘上加载数据，快速恢复缓存数据。</li></ul><p><img src="https://cdn.jsdelivr.net/gh/junian455/pic@master/img/image-20210806171411879.png" alt="缓存雪崩" title="缓存雪崩"></p><p>用户发送一个请求，系统 A 收到请求后，先查本地 ehcache 缓存，如果没查到再查 redis，如果 ehcache 和 redis 都没有，再查数据库，将数据库中的结果，写入 ehcache 和 redis 中。</p><p>限流组件，可以设置每秒的请求，有多少能通过组件，剩余的未通过的请求，怎么办？走降级！可以返回一些默认的值，或者友情提示，或者空白的值。</p><p><strong>针对 Redis 服务不可用的情况：</strong></p><ol><li>采用 Redis 集群，避免单机出现问题整个缓存服务都没办法使用。</li><li>限流，避免同时处理大量的请求。</li></ol><p><strong>针对热点缓存失效的情况：</strong></p><ol><li>设置不同的失效时间比如随机设置缓存的失效时间。</li><li>缓存永不失效。</li></ol><h3 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h3><p>对于系统 A，假设一秒 5000 个请求，结果其中 4000 个请求是黑客发出的恶意攻击。黑客发出的那 4000 个攻击，缓存中查不到，每次你去数据库里查，也查不到。</p><p>举个栗子。数据库 id 是从 1 开始的，结果黑客发过来的请求 id 全部都是负数。这样的话，缓存中不会有，请求每次都 <strong>“视缓存于无物”</strong>，直接查询数据库。这种恶意攻击场景的缓存穿透就会直接把数据库给打死。</p><p><strong>有哪些解决办法？</strong></p><p>最基本的就是首先做好参数校验，一些不合法的参数请求直接抛出异常信息返回给客户端。比如查询的数据库 id 不能小于 0、传入的邮箱格式不对的时候直接返回错误消息给客户端等等。</p><p><strong>缓存无效 key</strong></p><p>如果缓存和数据库都查不到某个 key 的数据就写一个到 Redis 中去并设置过期时间，具体命令如下： SET key value EX 10086 。这种方式可以解决请求的 key 变化不频繁的情况，如果黑客恶意攻击，每次构建不同的请求 key，会导致 Redis 中缓存大量无效的 key 。很明显，这种方案并不能从根本上解决此问题。如果非要用这种方式来解决穿透问题的话，尽量将无效的 key 的过期时间设置短一点比如 1 分钟。</p><p><strong>布隆过滤器</strong></p><p>布隆过滤器是一个非常神奇的数据结构，通过它我们可以非常方便地判断一个给定数据是否存在于海量数据中。我们需要的就是判断 key 是否合法，有没有感觉布隆过滤器就是我们想要找的那个 “人”。</p><p>具体是这样做的：把所有可能存在的请求的值都存放在布隆过滤器中，当用户请求过来，先判断用户发来的请求的值是否存在于布隆过滤器中。不存在的话，直接返回请求参数错误信息给客户端，存在的话才会走下面的流程。</p><p>加入布隆过滤器之后的缓存处理流程图如下：</p><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210807161444523.png" alt="缓存穿透" title="缓存穿透"></p><p>但是，需要注意的是布隆过滤器可能会存在误判的情况。总结来说就是： <strong>布隆过滤器说某个元素存在，小概率会误判。布隆过滤器说某个元素不在，那么这个元素一定不在。</strong></p><p>为什么会出现误判的情况呢？我们还要从布隆过滤器的原理来说！</p><p>我们先来看一下，当一个元素加入布隆过滤器中的时候，会进行哪些操作：</p><ol><li>使用布隆过滤器中的哈希函数对元素值进行计算，得到哈希值（有几个哈希函数得到几个哈希值）。</li><li>根据得到的哈希值，在位数组中把对应下标的值置为1。</li></ol><p>我们再来看一下，<strong>当我们需要判断一个元素是否存在于布隆过滤器</strong>的时候，会进行哪些操作：</p><ol><li>对给定元素再次进行相同的哈希计算；</li><li>得到值之后判断位数组中的每个元素是否都为 1，如果值都为 1，那么说明这个值在布隆过滤器中，如果存在一个值不为 1，说明该元素不在布隆过滤器中。然后，一定会出现这样一种情况：不同的字符串可能哈希出来的位置相同。 （可以适当增加位数组大小或者调整我们的哈希函数来降低概率）</li></ol><h3 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a>缓存击穿</h3><p>缓存击穿，就是说某个 key 非常热点，访问非常频繁，处于集中式高并发访问的情况，当这个 key 在失效的瞬间，大量的请求就击穿了缓存，直接请求数据库，就像是在一道屏障上凿开了一个洞。</p><p><strong>解决方式</strong></p><ul><li>可以将热点数据设置为永远不过期；</li><li>或者基于 redis or zookeeper 实现互斥锁，等待第一个请求构建完缓存之后，再释放锁，进而其它请求才能通过该 key 访问数据。</li></ul><h2 id="如何保证缓存与数据库的双写一致性？"><a href="#如何保证缓存与数据库的双写一致性？" class="headerlink" title="如何保证缓存与数据库的双写一致性？"></a>如何保证缓存与数据库的双写一致性？</h2><ul><li>缓存失效时间变短（不推荐，治标不治本） ：我们让缓存数据的过期时间变短，这样的话缓存就会从数据库中加载数据。另外，- 这种解决办法对于先操作缓存后操作数据库的场景不适用。<br>增加 cache 更新重试机制（常用）： 如果 cache 服务当前不可用导致缓存删除失败的话，我们就隔一段时间进行重试，重试次数可以自己定。如果多次重试还是失败的话，我们可以把当前更新失败的 key 存入队列中，等缓存服务可用之后，再将 缓存中对应的 key 删除即可。</li></ul><h2 id="Redis-的并发竞争问题是什么？如何解决这个问题？了解-Redis-事务的-CAS-方案吗？"><a href="#Redis-的并发竞争问题是什么？如何解决这个问题？了解-Redis-事务的-CAS-方案吗？" class="headerlink" title="Redis 的并发竞争问题是什么？如何解决这个问题？了解 Redis 事务的 CAS 方案吗？"></a>Redis 的并发竞争问题是什么？如何解决这个问题？了解 Redis 事务的 CAS 方案吗？</h2><p>多客户端同时并发写一个 key，可能本来应该先到的数据后到了，导致数据版本错了；或者是多客户端同时获取一个 key，修改值之后再写回去，只要顺序错了，数据就错了。 redis 自己就有天然解决这个问题的 CAS 类的乐观锁方案。</p>]]></content>
      
      
      <categories>
          
          <category> Redis缓存 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SpringCloud</title>
      <link href="/2021/10/10/spring/SpringCloud/"/>
      <url>/2021/10/10/spring/SpringCloud/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="什么是-Spring-Cloud"><a href="#什么是-Spring-Cloud" class="headerlink" title="什么是 Spring Cloud"></a>什么是 Spring Cloud</h1><p>Spring Cloud 是一系列框架的有序集合。它利用 Spring Boot 的开发便利性巧妙地简化了分布式系统基础设施的开发，如服务发现注册、配置中心、智能路由、消息总线、负载均衡、断路器、数据监控等，都可以用 Spring Boot 的开发风格做到一键启动和部署。Spring Cloud 并没有重复制造轮子，它只是将各家公司开发的比较成熟、经得起实际考验的服务框架组合起来，通过 Spring Boot 风格进行再封装屏蔽掉了复杂的配置和实现原理，最终给开发者留出了一套简单易懂、易部署和易维护的分布式系统开发工具包。</p><h1 id="设计目标与优缺点"><a href="#设计目标与优缺点" class="headerlink" title="设计目标与优缺点"></a>设计目标与优缺点</h1><h2 id="设计目标"><a href="#设计目标" class="headerlink" title="设计目标"></a>设计目标</h2><p>协调各个微服务，简化分布式系统开发。</p><h2 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h2><p><strong>优点：</strong></p><ul><li><p>产出于 Spring 大家族，Spring 在企业级开发框架中无人能敌，来头很大，可以保证后续的更新、完善；</p></li><li><p>组件丰富，功能齐全。Spring Cloud 为微服务架构提供了非常完整的支持。例如、配置管理、服务发现、断路器、微服务网关等；</p></li><li><p>Spring Cloud 社区活跃度很高，教程很丰富，遇到问题很容易找到解决方案；</p></li><li><p>服务拆分粒度更细，耦合度比较低，有利于资源重复利用，有利于提高开发效率；</p></li><li><p>可以更精准的制定优化服务方案，提高系统的可维护性；</p></li><li><p>减轻团队的成本，可以并行开发，不用关注其他人怎么开发，先关注自己的开发；</p></li><li><p>微服务可以是跨平台的，可以用任何一种语言开发；适于互联网时代，产品迭代周期更短。</p></li></ul><p><strong>缺点：</strong></p><ul><li><p>微服务过多，治理成本高，不利于维护系统；</p></li><li><p>分布式系统开发的成本高（容错，分布式事务等）对团队挑战大.</p></li></ul><blockquote><p>总的来说优点大过于缺点，目前看来 Spring Cloud 是一套非常完善的分布式框架，目前很多企业开始用微服务、Spring Cloud 的优势是显而易见的。</p></blockquote><h1 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a>整体架构</h1><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210903113038318.png"></p><h2 id="主要项目"><a href="#主要项目" class="headerlink" title="主要项目"></a>主要项目</h2><blockquote><p>Spring Cloud 的子项目，大致可分成两类，一类是对现有成熟框架”Spring Boot 化” 的封装和抽象，也是数量最多的项目；第二类是开发了一部分分布式系统的基础设施的实现，如 Spring Cloud Stream 扮演的就是 kafka, RabbitMQ 这样的角色。</p></blockquote><h2 id="Spring-Cloud-Config"><a href="#Spring-Cloud-Config" class="headerlink" title="Spring Cloud Config"></a>Spring Cloud Config</h2><blockquote><p>集中配置管理工具，分布式系统中统一的外部配置管理，默认使用 Git 来存储配置，可以支持客户端配置的刷新及加密、解密操作。</p></blockquote><h2 id="Spring-Cloud-Netflix"><a href="#Spring-Cloud-Netflix" class="headerlink" title="Spring Cloud Netflix"></a>Spring Cloud Netflix</h2><blockquote><p>Netflix OSS 开源组件集成，包括 Eureka、Hystrix、Ribbon、Feign、Zuul 等核心组件。</p></blockquote><ul><li>Eureka：服务治理组件，包括服务端的注册中心和客户端的服务发现机制；</li><li>Ribbon：负载均衡的服务调用组件，具有多种负载均衡调用策略；</li><li>Hystrix：服务容错组件，实现了断路器模式，为依赖服务的出错和延迟提供了容错能力；</li><li>Feign：基于 Ribbon 和 Hystrix 的声明式服务调用组件；</li><li>Zuul：API 网关组件，对请求提供路由及过滤功能。</li></ul><h2 id="Spring-Cloud-Bus"><a href="#Spring-Cloud-Bus" class="headerlink" title="Spring Cloud Bus"></a>Spring Cloud Bus</h2><blockquote><p>用于传播集群状态变化的消息总线，使用轻量级消息代理链接分布式系统中的节点，可以用来动态刷新集群中的服务配置。</p></blockquote><h2 id="Spring-Cloud-Consul"><a href="#Spring-Cloud-Consul" class="headerlink" title="Spring Cloud Consul"></a>Spring Cloud Consul</h2><blockquote><p>基于 Hashicorp Consul 的服务治理组件。</p></blockquote><h1 id="Spring-Cloud-Security"><a href="#Spring-Cloud-Security" class="headerlink" title="Spring Cloud Security"></a>Spring Cloud Security</h1><blockquote><p>安全工具包，对 Zuul 代理中的负载均衡 OAuth2 客户端及登录认证进行支持。</p></blockquote><h1 id="Spring-Cloud-Sleuth"><a href="#Spring-Cloud-Sleuth" class="headerlink" title="Spring Cloud Sleuth"></a>Spring Cloud Sleuth</h1><blockquote><p>Spring Cloud 应用程序的分布式请求链路跟踪，支持使用 Zipkin、HTrace 和基于日志（例如 ELK）的跟踪。</p></blockquote><h1 id="Spring-Cloud-Stream"><a href="#Spring-Cloud-Stream" class="headerlink" title="Spring Cloud Stream"></a>Spring Cloud Stream</h1><blockquote><p>轻量级事件驱动微服务框架，可以使用简单的声明式模型来发送及接收消息，主要实现为 Apache Kafka 及 RabbitMQ。</p></blockquote><p>Spring Cloud Task<br>用于快速构建短暂、有限数据处理任务的微服务框架，用于向应用中添加功能性和非功能性的特性。</p><p>Spring Cloud Zookeeper<br>基于 Apache Zookeeper 的服务治理组件。</p><p>Spring Cloud Gateway<br>API 网关组件，对请求提供路由及过滤功能。</p><p>Spring Cloud OpenFeign<br>基于 Ribbon 和 Hystrix 的声明式服务调用组件，可以动态创建基于 Spring MVC 注解的接口实现用于服务调用，在 Spring Cloud 2.0 中已经取代 Feign 成为了一等公民。</p><p>SpringBoot 和 SpringCloud 的区别？<br>SpringBoot 专注于快速方便的开发单个个体微服务。</p><p>SpringCloud 是关注全局的微服务协调整理治理框架，它将 SpringBoot 开发的一个个单体微服务整合并管理起来，为各个微服务之间提供，配置管理、服务发现、断路器、路由、微代理、事件总线、全局锁、决策竞选、分布式会话等等集成服务。</p><p>SpringBoot 可以离开 SpringCloud 独立使用开发项目， 但是 SpringCloud 离不开 SpringBoot ，属于依赖的关系。</p><p>服务注册和发现是什么意思？Spring Cloud 如何实现？<br>当我们开始一个项目时，我们通常在属性文件中进行所有的配置。随着越来越多的服务开发和部署，添加和修改这些属性变得更加复杂。有些服务可能会下降，而某些位置可能会发生变化。手动更改属性可能会产生问题。 Eureka 服务注册和发现可以在这种情况下提供帮助。由于所有服务都在 Eureka 服务器上注册并通过调用 Eureka 服务器完成查找，因此无需处理服务地点的任何更改和处理。</p><p>Spring Cloud 和 dubbo 区别？<br>服务调用方式 ，dubbo 是 RPC，springcloud Rest Api；<br>注册中心，dubbo 是 zookeeper，springcloud 是 eureka，也可以是 zookeeper；<br>服务网关，dubbo 本身没有实现，只能通过其他第三方技术整合，springcloud 有 Zuul 路由网关，作为路由服务器，进行消费者的请求分发，springcloud 支持断路器，与 git 完美集成配置文件支持版本控制，事物总线实现配置文件的更新与服务自动装配等等一系列的微服务架构要素。<br>负载平衡的意义什么？<br>在计算中，负载平衡可以改善跨计算机，计算机集群，网络链接，中央处理单元或磁盘驱动器等多种计算资源的工作负载分布。负载平衡旨在优化资源使用，最大化吞吐量，最小化响应时间并避免任何单一资源的过载。使用多个组件进行负载平衡而不是单个组件可能会通过冗余来提高可靠性和可用性。负载平衡通常涉及专用软件或硬件，例如多层交换机或域名系统服务器进程。</p><p>什么是 Hystrix？它如何实现容错？<br>Hystrix 是一个延迟和容错库，旨在隔离远程系统，服务和第三方库的访问点，当出现故障是不可避免的故障时，停止级联故障并在复杂的分布式系统中实现弹性。通常对于使用微服务架构开发的系统，涉及到许多微服务。这些微服务彼此协作。</p><p>假设如果上图中的微服务 9 失败了，那么使用传统方法我们将传播一个异常，但这仍然会导致整个系统崩溃。随着微服务数量的增加，这个问题变得更加复杂。微服务的数量可以高达 1000，这是 hystrix 出现的地方，我们将使用 Hystrix 在这种情况下的 Fallback 方法功能。</p><p>现在假设由于某种原因，employee-producer 公开的服务会抛出异常，我们在这种情况下使用 Hystrix 定义了一个回退方法。这种后备方法应该具有与公开服务相同的返回类型。如果暴露服务中出现异常，则回退方法将返回一些值。</p><p>什么是 Hystrix 断路器？需要它吗？<br>由于某些原因，employee-consumer 公开服务会引发异常。在这种情况下使用 Hystrix 我们定义了一个回退方法，如果在公开服务中发生异常，则回退方法返回一些默认值。</p><p>image-20210903114939660<br>如果 firstPage method () 中的异常继续发生，则 Hystrix 电路将中断，并且员工使用者将一起跳过 firtsPage 方法，并直接调用回退方法。 断路器的目的是给第一页方法或第一页方法可能调用的其他方法留出时间，并导致异常恢复。可能发生的情况是，在负载较小的情况下，导致异常的问题有更好的恢复机会 。</p><h1 id="什么是-Spring-Cloud-Bus？"><a href="#什么是-Spring-Cloud-Bus？" class="headerlink" title="什么是 Spring Cloud Bus？"></a>什么是 Spring Cloud Bus？</h1><p>Spring Cloud Bus 提供了跨多个实例刷新配置的功能。因此，如果我们刷新一个模块，则会自动刷新所有其他必需的模块。如果我们有多个微服务启动并运行，这特别有用。这是通过将所有微服务连接到单个消息代理来实现的。无论何时刷新实例，此事件都会订阅到侦听此代理的所有微服务，并且它们也会刷新。可以通过使用端点 / 总线 / 刷新来实现对任何单个实例的刷新。</p><h1 id="Spring-Cloud-断路器的作用"><a href="#Spring-Cloud-断路器的作用" class="headerlink" title="Spring Cloud 断路器的作用"></a>Spring Cloud 断路器的作用</h1><p>当一个服务调用另一个服务由于网络原因或自身原因出现问题，调用者就会等待被调用者的响应。当更多的服务请求到这些资源导致更多的请求等待，发生连锁效应（雪崩效应）。</p><p>断路器有完全打开状态：一段时间内，达到一定的次数无法调用，并且多次监测没有恢复的迹象，断路器完全打开。那么下次请求就不会请求到该服务。</p><p>半开：短时间内有恢复迹象，断路器会发送部分（一次）请求发给该服务（试探），正常调用时，断路器关闭。</p><p>关闭：当服务一直处于正常状态能正常调用。</p><h1 id="什么是-Spring-Cloud-Config"><a href="#什么是-Spring-Cloud-Config" class="headerlink" title="什么是 Spring Cloud Config?"></a>什么是 Spring Cloud Config?</h1><p>在分布式系统中，由于服务数量巨多，为了方便服务配置文件统一管理，实时更新，所以需要分布式配置中心组件。在 Spring Cloud 中，有分布式配置中心组件 spring cloud config ，它支持配置服务放在配置服务的内存中（即本地），也支持放在远程 Git 仓库中。在 spring cloud config 组件中，分两个角色，一是 config server，二是 config client。</p><h1 id="什么是-Spring-Cloud-Gateway"><a href="#什么是-Spring-Cloud-Gateway" class="headerlink" title="什么是 Spring Cloud Gateway?"></a>什么是 Spring Cloud Gateway?</h1><p>Spring Cloud Gateway 是 Spring Cloud 官方推出的第二代网关框架，取代 Zuul 网关。网关作为流量的，在微服务系统中有着非常作用，网关常见的功能有路由转发、权限校验、限流控制等作用。</p><p>使用了一个 RouteLocatorBuilder 的 bean 去创建路由，除了创建路由 RouteLocatorBuilder 可以让你添加各种 predicates 和 filters，predicates 断言的意思，顾名思义就是根据具体的请求的规则，由具体的 route 去处理，filters 是各种过滤器，用来对请求做各种判断和修改。</p>]]></content>
      
      
      <categories>
          
          <category> SpringCloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringCloud Config </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>设计模式-结构型设计模式</title>
      <link href="/2021/09/16/design/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E7%BB%93%E6%9E%84%E5%9E%8B%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
      <url>/2021/09/16/design/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E7%BB%93%E6%9E%84%E5%9E%8B%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="结构型设计模式"><a href="#结构型设计模式" class="headerlink" title="结构型设计模式"></a>结构型设计模式</h1><p>结构型模式主要描述如何将对象和类组合在一起以组成更复杂的结构。在软件工程中结构型模式是用于帮助设计人员通过简单的方式来识别和实现对象之间关系的设计模式。结构型模式会以组的形式组织程序。这种划分形式使代码更加清晰，维护更加简便。结构型模式用于代码和对象的结构组织。结构型模式会以组的形式组织程序。这种划分形式使代码更加清晰，维护更加简便。</p><p><strong>结构型模式又分为以下子类别：</strong></p><ol><li>对象结构型模式：用于对象之间相互关联与组织，以便形成更大、更复杂的结构。</li><li>类结构型模式：用于实现基于继承的代码抽象，并且会介绍如何通过该模式提供更有用的程序接口。</li></ol><p><strong>具体包括：</strong></p><table><thead><tr><th>对象结构型模式</th><th align="right">类结构型模式</th></tr></thead><tbody><tr><td>桥接模式</td><td align="right">类适配器模式</td></tr><tr><td>组合模式</td><td align="right"></td></tr><tr><td>装饰模式</td><td align="right"></td></tr><tr><td>门面模式</td><td align="right"></td></tr><tr><td>享元模式</td><td align="right"></td></tr><tr><td>对象适配器模式</td><td align="right"></td></tr><tr><td>代理模式</td><td align="right"></td></tr></tbody></table><ol><li><p>组合模式：它能够为客户端处理各种复杂和灵活的树状结构。这些树结构可以由各种不同类型的容器和叶节点组成，其深度或组合形式能够在运行时调整或确定。</p></li><li><p>装饰模式：允许我们通过附加新的功能或修改现有功能，在运行时动态地修改对象。</p></li><li><p>门面模式：允许我们为客户端创建一个统一的接口以访问不同子系统的不同接口，从而简化客户端。</p></li><li><p>享元模式：客户端调用类时会在运行时创建大量对象，该模式会重新设计类以优化内存开销。</p></li><li><p>代理模式：为其他对象提供一种代理以控制对这个对象的访问。这种模式的目的是一个对象不适合或者不能直接引用另一个对象，简化客户端并实现对象访问，同时避免任何副作用。</p></li><li><p>适配器模式：允许我们为一个已有的类提供一个新的接口，并在客户端请求不同接口时实现类的重用。</p></li><li><p>桥接模式：允许我们将类与其接口相互解耦。允许类及其接口随着时间相互独立变化，增加类重用的次数，提高后续可扩展性。它也允许运行时对接口的不同实现方式动态切换，使代码更加灵活。</p></li></ol><h2 id="适配器设计模式"><a href="#适配器设计模式" class="headerlink" title="适配器设计模式"></a>适配器设计模式</h2><p>软件适配器的工作原理也和插座适配器完全一样。我们也经常需要在程序中使用到不同的类或模块。假设有一段代码写得很烂，如果我们直接将这些代码集成到程序中，会将现有的代码搞乱。但是我们又不得不调用这段代码，因为我们需要实现相关的功能，而从头写起会耽误很多宝贵的时间。这时的最佳实践就是编写适配器，并将所需要的代码包装进去。这样我们就能够使用自定义的接口，从而降低对外部代码的依赖。</p><p>适配器模式会将现有接口转换为新的接口，已实现对应用程序中不相关的类的兼容性和可重用性的目标。适配器模式也被称为包装模式。适配器模式能够帮助那些因为接口不兼容而无法一起工作的类，以便它们能够一同工作。</p><p>适配器模式也负责将数据转换成适当的形式。当客户端在接口中指定了其对数据格式的要求时，我们通常可以创建新的类以实现现有类的接口和子类。这种实现方式也会通过创建类适配器，实现对客户端调用命和现有类中被调用方法之间接口的转换。</p><h3 id="模式中包括的类"><a href="#模式中包括的类" class="headerlink" title="模式中包括的类"></a>模式中包括的类</h3><ul><li>客户端（Client）调用目标类的类或程序。</li><li>目标类（Target）客户端想要使用的接口。</li><li>适配对象类（Adapetee）需要进行适配的类或对象。</li><li>适配器类（ Adapter）按照目标类接口的要求对适配对象接口实现接口形式的适配转换。</li><li>request 方法：客户端想要执行的操作。</li><li>specificRequest 方法：适配对象中能够完成 request 方法功能的实现。</li></ul><h3 id="UML-图"><a href="#UML-图" class="headerlink" title="UML 图"></a>UML 图</h3><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210630163942385.png"></p><h3 id="功能及应用场景"><a href="#功能及应用场景" class="headerlink" title="功能及应用场景"></a>功能及应用场景</h3><p>在具体实践上，有两种实际应用适配器模式的方法：</p><ol><li>使用继承［类适配器］</li><li>使用关联［对象适配器］</li></ol><p><strong>应用场景：</strong></p><ul><li>我们想要使用现有的类，但它的接口不符合我们的需要。</li><li>我们想要创建一个可重用的类，能够与一些无关的类或不可预见的类进行协作，同时这个类无须具有兼容的接口。<br>（仅适用于对象适配器）我们需要使用多个已经存在的子类，而我们为每一个子类都做接口适配显然是不切实际的。使用对象适配器可以直- 接适配其父类的接口。</li></ul><h2 id="桥接设计模式"><a href="#桥接设计模式" class="headerlink" title="桥接设计模式"></a>桥接设计模式</h2><blockquote><p>桥接模式是结构型模式中的另一个典型模式。桥接模式用于将类的接口与接口的实现相互解耦。这样做提高了系统的灵活性使得接口和实现两者均可独立变化。<br>举一个例子，让我们想一下家用电器及其开关。例如，风扇的开关。开关是电器的控制接口，而一旦闭合开关，实际让风扇运转的是风扇电机。<br>所以，在这个示例中，开关和风扇之间是彼此独立的。如果我们将开关接到电灯泡的供电线路上，那么我们还可以选用其他开关来控制风扇。</p></blockquote><h3 id="模式中包括的类-1"><a href="#模式中包括的类-1" class="headerlink" title="模式中包括的类"></a>模式中包括的类</h3><ul><li>抽象化对象（Abstraction）桥接设计模式的核心，并定义了关键症结所在，包含对实现化对象的引用。</li><li>扩充抽象化对象（RefinedAbstraction）扩展抽象化对象，并将抽象化对象细化到新的层次。对实现化对象隐藏细节元素。</li><li>实现化对象（Implementor）该接口比抽象化对象的层次更高。只对基本操作进行定义。</li><li>具体实现化对象（Concretelmplementor）通过提供具体实现来执行实现化对象的具体功能。</li></ul><h3 id="UML-图-1"><a href="#UML-图-1" class="headerlink" title="UML 图"></a>UML 图</h3><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210630164156773.png"></p><h3 id="功能及应用场景-1"><a href="#功能及应用场景-1" class="headerlink" title="功能及应用场景"></a>功能及应用场景</h3><blockquote><p>桥接模式主要适用于系统的多个维度上都经常发生变化的情况。桥接模式能够将不同的抽象维度进行衔接。通过桥接模式，抽象化对象和实现化对象不会在编译时进行绑定，而能够在各自的类被调用时独立扩展。当你经常需要在运行时在多个实现之间进行切换时，桥接模式也非常有用。</p></blockquote><h2 id="组合设计模式"><a href="#组合设计模式" class="headerlink" title="组合设计模式"></a>组合设计模式</h2><p>在大部分系统开发过程中，程序员都会遇到某个组件既可以是独立的个体对象，也能够作为对象集合的情况。组合模式就用于此类情况的设计。简单来说，组合模式是一组对象的集合，而这组对象中的每一个对象本身也是一个组合模式构成的对象，或者只是一个原始对象。</p><p>组合模式中存在着一个树形结构，并且在该结构中的分支节点和叶节点上都能够执行相同的操作。树形结构中每一个分支节点都包含子节点的类（能继承出叶节点和分支节点），这样的分支节点本身就是一个组合模式构成的节点。树形结构中的叶子节点仅是一个原始对象，其没有子节点（不能继承出叶节点和分支节点）。组合模式的子类（下一级节点）可以是叶子节点或其他组合模式。</p><h3 id="模式中包括的类-2"><a href="#模式中包括的类-2" class="headerlink" title="模式中包括的类"></a>模式中包括的类</h3><ul><li><p>组件对象：（Component，结构）</p><ul><li>组件对象在整个继承结构的最顶端。它是对组合模式的抽象。</li><li>它声明了组合模式中的对象接口。</li><li>可以选择性地定义一个接口，以便对递归结构中组件的父类进行访问，并在需要的时候实现该接口。</li></ul></li><li><p>叶子节点：（Leaf，原始对象）</p><ul><li>树形结构的末端且不会再有子节点。</li><li>定义了组合结构中单个对象的行为。</li></ul></li><li><p>分支节点类：（Composite，组）</p><ul><li>包含了子组件并为它们定义行为。</li><li>实现子节点的相关操作。</li></ul></li></ul><h3 id="UML-图-2"><a href="#UML-图-2" class="headerlink" title="UML 图"></a>UML 图</h3><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210630164419373.png"></p><h3 id="功能及应用场景-2"><a href="#功能及应用场景-2" class="headerlink" title="功能及应用场景"></a>功能及应用场景</h3><ul><li><p>当对象的集合需要采用与单个对象相同的处理方式时。</p></li><li><p>操纵单个对象的方式与操纵一组对象的方式类似时。</p></li><li><p>注意存在能够组合的递归结构或树形结构。</p></li><li><p>客户端能够通过组件对象访问整个继承结构，而它们却不会知道自己所处理的是叶子节点还是分支节点。</p></li></ul><blockquote><p>组合模式的目的是能够使独立对象（单个分支节点或叶子节点）和对象集合（子树）都能够以同样的方式组织起来。组合模式中所有的对象都来自于其本身（成为一种嵌套结构）。组合模式允许我们使用递归的方式将类似的对象组合成一种树形结构，来实现复杂结构对象的构建。</p></blockquote><h2 id="装饰者设计模式"><a href="#装饰者设计模式" class="headerlink" title="装饰者设计模式"></a>装饰者设计模式</h2><p>装饰设计模式用来在运行时扩展或修改一个实例的功能。一般来说，继承可以扩展类的功能（用于类的所有实例）。但与继承不同的是，通过装饰模式，我们可以选择一个类的某个对象，并对其进行修改，而不会影响这个类中其他的实例。继承会直接为类增加功能，而装饰模式则会通过将对象与其他对象进行包装的方式将功能添加到类。</p><h3 id="模式中包括的类-3"><a href="#模式中包括的类-3" class="headerlink" title="模式中包括的类"></a>模式中包括的类</h3><ul><li>抽象组件（Component）给出一个抽象接口，用于能够动态添加功能的对象。</li><li>具体组件（Concrete Component）定义一个实现组件接口的对象。这是实际需要加以装饰的对象，但其对装饰的过程一无所知。</li></ul><h3 id="UML-图-3"><a href="#UML-图-3" class="headerlink" title="UML 图"></a>UML 图</h3><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210630164820760.png"></p><h3 id="功能及应用场景-3"><a href="#功能及应用场景-3" class="headerlink" title="功能及应用场景"></a>功能及应用场景</h3><p>装饰设计模式用来在运行时扩展或修改一个实例的功能。一般来说，继承可以扩展类的功能（用于类的所有实例）。但与继承不同的是，通过装饰模式，我们可以选择一个类的某个对象，并对其进行修改，而不会影响这个类中其他的实例。</p><h2 id="门面设计模式"><a href="#门面设计模式" class="headerlink" title="门面设计模式"></a>门面设计模式</h2><p>许多业务流程都会涉及复杂的业务类操作。由于流程很复杂，所以其涉及了多个业务对象，这往往会导致各个类之间的紧密耦合，从而降低系统的灵活性和设计的清晰度。底层业务组件间的复杂关系会使客户端的代码编写变得很困难。</p><p>门面模式简化了到复杂系统的外部接口，为此它会对所有的类进行整合，并构建一个复杂系统的子系统。</p><p>门面模式能够将用户与系统内部复杂的细节相互屏蔽，并只为用户提供简化后的更容易使用的外部接口。同时它也将系统内部代码与接口子系统的代码相互解耦，以便修改和升级系统代码。</p><p>相比于其他设计模式，门面模式更注重实现代码的解耦。它所强调的是代码设计中很重要的一点，即代码抽象。通过提供一个简单的接口并隐藏其后的复杂性，从而实现抽象。</p><p>在这种方式下，代码的实现完全交由门面层处理。客户端只会与一个接口交互，同时也只有和这个接口交互的权限。这样就能隐藏全部系统的复杂性。总而言之，门面模式通过提供一个简单的接口为客户端简化了与复杂系统的交互。从另一方面看，门面模式也保证了能够在不修改客户端代码的情况下对具体实现方法进行修改。</p><h3 id="模式中包括的类-4"><a href="#模式中包括的类-4" class="headerlink" title="模式中包括的类"></a>模式中包括的类</h3><ul><li><p>门面层（ Facade）：它知道子系统内各个类的具体功能，并将客户端请求转换成对系统内部对象的调用。</p></li><li><p>系统内部类（ ComplicatedClass）：这些类会实现系统功能，处理门面层对象分配的各项工作任务。它们本身并不知道门面层的存在，也没有对其进行任何的引用。</p></li></ul><h3 id="UML-图-4"><a href="#UML-图-4" class="headerlink" title="UML 图"></a>UML 图</h3><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210630165235034.png"></p><h3 id="功能及应用场景-4"><a href="#功能及应用场景-4" class="headerlink" title="功能及应用场景"></a>功能及应用场景</h3><ul><li><p>想要为一个复杂的子系统提供一个简单接口。子系统随着其自身的发展往往变得越来越复杂。它们应用的大多数的设计模式会导致类的数量更多、代码段更小。这使得该子系统可重用更好，也更容易进行自定义。而对于某些无法自定义的客户端来说，它也变得难以使用，门面层可以提供对大多数客户端来说足够好的简化的调用接口，只有极少数高度定制化的客户端需要直接调用门面层之后的底层代码。</p></li><li><p>在客户端和抽象层的实现类之间存在大量的依赖关系。引入一个门面层能够将客户端的子系统与其他子系统进行解耦，从而促进子系统的独立性和可移植性。</p></li><li><p>你想要为你的子系统增加层级。使用一个门面层对每个子系统级别分别定义一个入口点。如果子系统之间存在依赖关系，那么你可以通过令这些子系统之间的交互全部需要经由门面层来简化彼此的依赖关系。</p></li></ul><h2 id="代理设计模式"><a href="#代理设计模式" class="headerlink" title="代理设计模式"></a>代理设计模式</h2><p>根据目的不同，有各种<strong>不同类型的代理</strong>。例如，有保护性代理，控制对某个对象的访问权限；有虚拟代理，处理开销过大而难以创建的对象，并通过远程访问控制来访问远程对象。</p><h3 id="UML-图-5"><a href="#UML-图-5" class="headerlink" title="UML 图"></a>UML 图</h3><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210630165416954.png"></p><h3 id="功能及应用场景-5"><a href="#功能及应用场景-5" class="headerlink" title="功能及应用场景"></a>功能及应用场景</h3><blockquote><p>代理模式主要用于当我们需要用一个简单对象来表示一个复杂对象的情形。如果创建对象的开销很大，那么可以推迟其创建，并使用一个简单对象来代理其功能直到必须立即创建的时候。这个简单对象就可以称为复杂对象的代理。</p></blockquote><h2 id="享元设计模式"><a href="#享元设计模式" class="headerlink" title="享元设计模式"></a>享元设计模式</h2><p><strong>享元模式</strong>能够减少用于创建和操作大量相似的细碎对象所花费的成本。享元模式主要用在需要创建大量类似性质的对象时。大量的对象会消耗高内存，享元模式给出了一个解决方案，即通过共享对象来减少内存负载它的具体实现则是根据对象属性将对象分成两种类型：内蕴状态和外蕴状态。共享是享元模式的关键。</p><h3 id="模式中包括的类-5"><a href="#模式中包括的类-5" class="headerlink" title="模式中包括的类"></a>模式中包括的类</h3><ul><li><p>抽象享元角色（ Flyweight）声明一个为具体享元角色规定了必须实现的接口，而外蕴状态就是以参数的形式通过此方法传入。</p></li><li><p>具体享元角色（ Concrete Flyweight）实现享元模式接口，并存储内蕴状态。具体享元角色必须是共享的。具体享元角色必须保持其内蕴状态不变，并且能够操纵外蕴状态。</p></li><li><p>享元工厂角色（FlyweightFactory）负责创建和管理享元角色。此外，该工厂确保了享元角色的共享。工厂维护了不同的享元对象池，并负责在对象创建完成时从对象池返回对象，以及向对象池添加对象。</p></li><li><p>客户端（Client）维护对所有享元对象的引用，而且需要存储和计算对应的外蕴状态。</p></li></ul><h3 id="UML-图-6"><a href="#UML-图-6" class="headerlink" title="UML 图"></a>UML 图</h3><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210630165644153.png"></p><h3 id="功能及应用场景-6"><a href="#功能及应用场景-6" class="headerlink" title="功能及应用场景"></a>功能及应用场景</h3><p>当我们选择享元模式的时候，需要考虑以下因素：</p><ul><li>需要创建大量的对象时。</li><li>由于对象众多，内存的开销是一个制约因素。</li><li>大多数对象属性可以分为内蕴状态和外蕴状态。</li><li>应用程序需要使用多种对象，且创建对象后需要多次重复使用。</li><li>外蕴状态最好是通过计算得到的，而不需要进行存储。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 设计模式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
            <tag> UML图 </tag>
            
            <tag> 装饰模式 </tag>
            
            <tag> 享元模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>设计模式-创造型设计模式</title>
      <link href="/2021/09/11/design/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%88%9B%E9%80%A0%E5%9E%8B%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
      <url>/2021/09/11/design/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%88%9B%E9%80%A0%E5%9E%8B%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="创造型设计模式"><a href="#创造型设计模式" class="headerlink" title="创造型设计模式"></a>创造型设计模式</h1><ul><li>创造型设计模式主要关注的是类的实例化，也就是说体现的是对象的创建方法，利用这些模式，我们可以在适当的情况下以适当的形式创建对象，创造型设计模式通过控制对象的创建来解决设计中的问题。</li></ul><blockquote><p><strong>创造型设计模式主要包含以下子类别：</strong></p><ol><li>对象创造型设计模式：主要完成对象创建，并将对象中部分内容放到其他对象中创建。</li><li>类创造型设计模式：主要完成类的实例化，并将类中的部分对象放到子类中创建，此类模式在实例化过程中高效地利用了继承机制</li></ol></blockquote><p><strong>创造型设计模式主要包含以下 5 种具体的设计模式：</strong></p><ul><li>抽象工厂设计模式：提供一个用于创建相关对象或相互依赖对象的接口，无需指定对象的具体类。</li><li>生成器设计模式：将复杂对象的构建与其表示相互分离，使得同样的构建过程可以创建不同的表示。</li><li>工厂方法设计模式：允许在子类中实现本类的实例化类。</li><li>原型设计模式：使用一个原型实例来指定创建对象的种类，然后通过拷贝这些原型实现新对象的创建。</li><li>单例模式：确保某个类在系统中仅有一个实例，并提供一个访问它的全局访问点。</li></ul><table><thead><tr><th>对象创造型设计模式</th><th align="left">类创造型设计模式</th></tr></thead><tbody><tr><td>抽象工厂设计模式</td><td align="left">工厂方法设计模式</td></tr><tr><td>生成器设计模式</td><td align="left"></td></tr><tr><td>原型设计模式</td><td align="left"></td></tr><tr><td>单例设计模式</td><td align="left"></td></tr></tbody></table><h2 id="工厂方法设计模式"><a href="#工厂方法设计模式" class="headerlink" title="工厂方法设计模式"></a>工厂方法设计模式</h2><blockquote><p>工厂方法的作用是创建对象，用来从一组实现特定逻辑的类中实例化某个对象。</p></blockquote><h3 id="模式中包括的类"><a href="#模式中包括的类" class="headerlink" title="模式中包括的类"></a>模式中包括的类</h3><ul><li><p>产品类（Product）中定义了工厂方法创建的对象接口。</p></li><li><p>具体产品类（ Concrete Product）实现产品类接口。</p></li><li><p>工厂类（ Creator，因为由它来创建产品类，所以叫作工厂类）声明工厂方法，返回一个产品类对象。可用于调用创建产品类对象的生成方法。</p></li><li><p>具体工厂类（ Concrete Creator）重写用于创建具体产品类对象的方法。</p></li></ul><h3 id="UML-图"><a href="#UML-图" class="headerlink" title="UML 图"></a>UML 图</h3><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210630141241582.png"></p><h3 id="功能及应用场景"><a href="#功能及应用场景" class="headerlink" title="功能及应用场景"></a>功能及应用场景</h3><ul><li><p>当需要创建一个类，而在编程时不能确定这个类的类型时（需要运行时确定）。</p></li><li><p>当一个类希望由其子类来指定所创建对象的具体类型时。</p></li><li><p>当我们想要定位被创建类，并获取相关信息时。</p></li></ul><h2 id="抽象工厂设计模式"><a href="#抽象工厂设计模式" class="headerlink" title="抽象工厂设计模式"></a>抽象工厂设计模式</h2><p>抽象工厂模式相比于工厂方法模式的抽象层次更高。这意味着抽象工厂返回的是一组类的工厂。与工厂方法模式类似（返回多个子类中的一个），此方法会返回一个工厂，而这个工厂会返回多个子类中的一个。简单来说，抽象工厂是一个工厂对象，该对象又会返回若干工厂中的一个。</p><p>工厂模式是创造型模式的典型示例。抽象工厂设计模式是工厂方法模式的扩展，从而使我们无须担心所创建对象的实际类就能够创建对象。抽象工厂模式扩展了工厂方法模式，允许创建更多类型的对象。</p><h3 id="模式中包括的类-1"><a href="#模式中包括的类-1" class="headerlink" title="模式中包括的类"></a>模式中包括的类</h3><ul><li>抽象工厂（AbstractFactory）声明一个用于完成抽象产品对象创建操作的接口。</li><li>具体工厂（ConcreteFactory）实现创建具体产品对象的操作。</li><li>抽象产品（AbstractProduct）声明一个用于一类产品对象的接口。</li><li>具体产品（ConcreteProduct）定义由相应的具体工厂来创建的产品对象。</li><li>客户端（Client）使用由抽象工厂和抽象产品类声明的唯一接口。</li></ul><h3 id="UML-图-1"><a href="#UML-图-1" class="headerlink" title="UML 图"></a>UML 图</h3><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210630141413150.png"></p><h3 id="功能及应用场景-1"><a href="#功能及应用场景-1" class="headerlink" title="功能及应用场景"></a>功能及应用场景</h3><blockquote><p>抽象工厂模式的主要优点之一是它屏蔽了这些具体类的创建方法。实际应用的类名称不需要再让客户端（将客户端与具体类解耦）知道。由于具体类是屏蔽的，因此我们可以在不同的工厂（实现方法）之间进行切换。</p></blockquote><h2 id="生成器设计模式"><a href="#生成器设计模式" class="headerlink" title="生成器设计模式"></a>生成器设计模式</h2><ul><li><p>生成器模式，能够从简单的对象一步一步生成复杂的对象。生成器模式是一种用来逐步构建复杂对象并在最后一步返回对象的创造型模式。</p></li><li><p>构造一个对象的过程是通过泛型实现的，以便它能够用于对同一对象创建不同的表示形式。</p></li></ul><h3 id="模式中包括的类-2"><a href="#模式中包括的类-2" class="headerlink" title="模式中包括的类"></a>模式中包括的类</h3><ul><li><p>生成器类（ Builder）提供一个接口用于创建产品的各个组成部件。具体生成器（Concrete Builder）提供此接口的实现。</p></li><li><p>具体生成器（ ConcreteBuilder）会跟踪其所创建对象的表现形式，并在创建对象的同时提供一个接口获取产品（Product）。</p></li><li><p>导演类（ Director）通过生成器提供的接口构造对象。产品类用于表示被构造的复杂对象。这包括对我们构建的所有类进行定义。</p></li></ul><h3 id="UML-图-2"><a href="#UML-图-2" class="headerlink" title="UML 图"></a>UML 图</h3><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210630142835827.png"></p><h3 id="功能及应用场景-2"><a href="#功能及应用场景-2" class="headerlink" title="功能及应用场景"></a>功能及应用场景</h3><p>生成器模式隐藏了产品构建过程中的内部细节。各个生成器之间都是相互独立的。这提高了代码的模块化，并使其他的生成器更方便地创建对象。因为每个生成器都能够逐步创建对象，这让我们能够很好地对最终产品进行掌控。</p><h2 id="单例设计模式"><a href="#单例设计模式" class="headerlink" title="单例设计模式"></a>单例设计模式</h2><blockquote><p>在应用程序的整个生命周期中，对象只有一个实例的时候，就会使用单例设计模式。单例类总是在第一次被访问时完成实例化，直至应用程序退出之前，都只会使用同一个实例。单一实例创建策略：我们通过限制构造函数（通过设置其为私有）从而限制单例类的实例化。之后在定义类时包含一个该类的静态私有对象，以便创建单例类的实例。在单例模式中，最棘手的部分是对单一实例的实现和管理。在单例模式的定义过程中，有两点需要注意的地方：</p></blockquote><ul><li>该类仅允许存在一个实例。</li><li>需要为该单一实例提供一个全局访问点。</li></ul><blockquote><p>单例模式中的主动实例化和被动实例化（饿汉、懒汉），线程安全的单例：双重同步锁、静态变量、枚举。</p></blockquote><h3 id="UML-图-3"><a href="#UML-图-3" class="headerlink" title="UML 图"></a>UML 图</h3><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210630201404401.png"></p><h3 id="功能及应用场景-3"><a href="#功能及应用场景-3" class="headerlink" title="功能及应用场景"></a>功能及应用场景</h3><p>在应用程序的整个生命周期中，对象只有一个实例的时候，就会使用单例设计模式。</p><h2 id="原型设计模式"><a href="#原型设计模式" class="headerlink" title="原型设计模式"></a>原型设计模式</h2><blockquote><p>相比于以往创建一个复杂对象总是费时费力，原型模式只需要复制现有的相似对象，并根据需要做适当修改。原型意味着使用克隆方法。克隆方法是一种复制对象的操作。克隆出的对象副本被初始化为调用克隆方法时原始对象的当前状态。这意味着对象的克隆避免了创建新对象。如果创建一个新对象的开销很大，而且有可能引起资源紧张时，我们就克隆对象。</p></blockquote><ul><li><p>浅层复制：当原始对象变化时，新对象也跟着改变。这主要是因为浅层复制并没有实际复制新的对象，而只是对原有对象的一个引用。</p></li><li><p>深层复制：当原始对象变化时，新对象不受影响，因为原始对象所包含的所有参数、对象和引用在复制新对象的过程中都建立了新的拷贝。</p></li></ul><p>使用克隆方法来复制对象时，具体是使用浅层复制还是深层复制是由业务需求来决定的。在使用原型模式时，使用克隆方法来复制对象仅仅是一个设计上的决策。克隆方法对于原型模式来说并不是强制性的最佳选择。</p><h3 id="模式中包括的类-3"><a href="#模式中包括的类-3" class="headerlink" title="模式中包括的类"></a>模式中包括的类</h3><ul><li>客户端（Client）：通过调用原型类的克隆操作创建一个新对象。</li><li>原型类（ Prototype）：声明一个接口用于克隆自己。</li><li>具体原型类（ Concrete Prototype）：实现克隆自己的操作。</li></ul><h3 id="UML图"><a href="#UML图" class="headerlink" title="UML图"></a>UML图</h3><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210630143348935.png"></p><h3 id="功能及应用场景-4"><a href="#功能及应用场景-4" class="headerlink" title="功能及应用场景"></a>功能及应用场景</h3><ol><li><p>当一个系统应该独立于其产品的创建、组合和表示。</p></li><li><p>当需要实例化的类是在运行时定义的，例如动态加载，或避免建立一个平行于产品类继承层次的工厂类继承层次时。</p></li><li><p>当一个类的实例仅可以拥有若干不同的状态组合中的一个时。使用原型模式建立相应数量的原型和克隆方法，会比每次都手动实例化类并配置相应状态更加方便。</p></li></ol><p><strong>主要难点：</strong></p><ul><li><p>每个原型类的子类都必须实现克隆操作。这实现起来可能有难度。例如，当类已经存在的时候添加克隆方法可能比较困难。</p></li><li><p>对象内部包含其他不支持克隆的对象或具有循环引用的对象时，实现克隆方法会比较困难。</p></li></ul><p><strong>优点：</strong></p><ul><li><p>原型模式意味着使用克隆方法。克隆方法是一种复制对象的操作。相比于耗时的复制对象创建过程，原型模式仅复制类似的现有对象，再根据需要对复制出的副本进行修改。</p></li><li><p>客户端可以在运行时添加或移除原型对象。</p></li><li><p>通过各种参数来定义新对象：高度动态的系统允许我们通过使用对象组合来定义新的特征，例如为对象变量指定相应的参数值，而不是重新定义一个类。我们通过实例化现有类可以有效地定义新类型的对象，并为客户端对象注册原型实例。客户端可以通过向原型类委派某个责任而使其具有新的特征。这种设计允许用户无须大量编程就能轻松定义新的类。事实上，克隆一个原型本质上是类似于类的实例化的。但原型模式能够大大降低系统所需的类的数量。</p></li></ul><p><strong>副作用：</strong></p><ul><li><p>使用原型模式，我们可以根据需要通过对象克隆来实现运行时对象的添加和删除。我们可以根据程序运行情况在运行时修改类的内部数据表示形式。</p></li><li><p>在 Java 中实现原型模式的一大困难是如果这些类已经存在，我们未必能够通过添加所需要的克隆方法或深层克隆方法对类进行修改。此外，那些与其他类具有循环引用关系的类并不能真正实现克隆。</p></li><li><p>需要在这些类中具有足够的数据访问权限或方法，以便在克隆完成后对相应的数据进行修改。这可能需要在这些原型类中添加相应的数据访问方法，以便我们对类完成克隆之后可以修改数据。</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 设计模式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
            <tag> UML图 </tag>
            
            <tag> 单例设计模式 </tag>
            
            <tag> 工厂方法设计模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>设计模式</title>
      <link href="/2021/09/05/design/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
      <url>/2021/09/05/design/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="设计模式"><a href="#设计模式" class="headerlink" title="设计模式"></a>设计模式</h1><h2 id="设计模式是什么"><a href="#设计模式是什么" class="headerlink" title="设计模式是什么"></a>设计模式是什么</h2><ul><li><p>设计模式是一个通过定义、使用、测试去解决特定问题的方法，是针对软件设计中在给定条件下会重复性发生的问题而提出的一种通用性的可重用解决方案，设计模式不是可以直接转化为代码的完整设计，它是用于描述在不同情况下解决问题的通用方案。</p></li><li><p>设计模式，是一套被反复使用、多数人知晓的、经过分类编目的、代码设计经验的总结。使用设计模式是为了可重用代码、让代码更容易被他人理解、保证代码可靠性、程序的重用性。</p></li></ul><h2 id="设计模式的作用"><a href="#设计模式的作用" class="headerlink" title="设计模式的作用"></a>设计模式的作用</h2><blockquote><p>设计模式通过提供经过验证的行之有效的开发范式加快开发过程，预防重大的隐患问题，提高代码可读性。</p></blockquote><h2 id="设计模式的分类"><a href="#设计模式的分类" class="headerlink" title="设计模式的分类"></a>设计模式的分类</h2><blockquote><p>这里主要讨论 GoF 所提出的 23 种设计模式，可将其分为三种类型：</p></blockquote><ol><li><p>创造型设计模式</p></li><li><p>结构型设计模式</p></li><li><p>行为型设计模式</p></li></ol><h3 id="创造型设计模式"><a href="#创造型设计模式" class="headerlink" title="创造型设计模式"></a>创造型设计模式</h3><blockquote><p>注重完成对象的实例化，相比于直接实例化对象，根据实际情况选择合适的设计模式完成对象的实例化，可以为复杂的业务场景带来更高的灵活性。创造型设计模式主要包括以下几种：</p></blockquote><ol><li><p>抽象工厂设计模式</p></li><li><p>生成器设计模式</p></li><li><p>工厂方法设计模式</p></li><li><p>原型设计模式</p></li><li><p>单例设计模式</p></li></ol><h3 id="结构型设计模式"><a href="#结构型设计模式" class="headerlink" title="结构型设计模式"></a>结构型设计模式</h3><blockquote><p>结构型设计模式用于指导我们完成对代码的结构划分，如此，代码结构会更加清晰，更易理解，也提高了软件的可维护性。结构型设计模式主要包括以下几种：</p></blockquote><ol><li><p>适配器设计模式</p></li><li><p>桥接设计模式</p></li><li><p>组合设计模式</p></li><li><p>装饰设计模式</p></li><li><p>门面设计模式</p></li><li><p>享元设计模式</p></li><li><p>代理设计模式</p></li></ol><h3 id="行为型设计模式"><a href="#行为型设计模式" class="headerlink" title="行为型设计模式"></a>行为型设计模式</h3><blockquote><p>行为型设计模式主要用于定义对象之间的通信与流程控制，主要的设计模式都非常注重优化对象之间的数据交互方式。行为型设计模式主要包括以下几种：</p></blockquote><ol><li><p>职责链设计模式</p></li><li><p>命令设计模式</p></li><li><p>解释器设计模式</p></li><li><p>迭代器设计模式</p></li><li><p>中介者设计模式</p></li><li><p>备忘录设计模式</p></li><li><p>观察者设计模式</p></li><li><p>策略设计模式</p></li><li><p>状态设计模式</p></li><li><p>模板方法设计模式</p></li><li><p>访问者设计模式</p></li></ol><h3 id="如何学习设计模式"><a href="#如何学习设计模式" class="headerlink" title="如何学习设计模式"></a>如何学习设计模式</h3><blockquote><ul><li>模式名称是什么？</li><li>模式类型是什么？是创造型，结构型，还是行为型？</li><li>模式的目的是什么？（作用是什么？解决了什么问题？）</li><li>模式的别名是什么？</li><li>什么情况下使用该模式？</li><li>该模式的基本示例</li><li>该模式的 UML 图是什么样的？是类图还是交互图？</li><li>都有哪些对象在模式中参与活动？列出设计模式中使用的类和对象，并说明他们各自的角色</li><li>模式中的类和对象是怎么进行交互的？</li><li>通过应用设计模式能获取什么好处，有哪些坏处？如何权衡？</li><li>如何实现该模式</li><li>与该模式相近的设计模式是什么？这几种相近的模式有哪些异同点？</li></ul></blockquote><h2 id="正确看待设计模式"><a href="#正确看待设计模式" class="headerlink" title="正确看待设计模式"></a>正确看待设计模式</h2><ol><li><p>恰当使用设计模式能够提高代码的复用性，但是由于复用性往往会引入封装与间接调用，这些会降低系统性能，增加代码复杂程度。因此，除非设计模式能够帮助我们完成代码的实现或者后续的维护工作，否则没有必要去引入设计模式。</p></li><li><p>学习设计模式的关键并不在于学习设计模式本身，而是在于识别应用场景与潜在的风险，并将设计模式用之有道，这般，设计模式才能算作得心应手的工具。</p></li><li><p>在没有必要的情况大可不必去使用设计模式，因为设计模式有可能会牺牲代码的简洁性，而且滥用设计模式多会引入新的问题却没有解决原来的问题。</p></li><li><p><strong>保持代码的整洁，模块化和可读性，同时不要让各类之间过度耦合。</strong></p></li></ol><blockquote><p><a href="">创造型设计模式</a><br><a href="">结构型设计模式</a><br><a href="">行为型设计模式</a></p></blockquote><h2 id="Java-中的设计模式应用"><a href="#Java-中的设计模式应用" class="headerlink" title="Java 中的设计模式应用"></a>Java 中的设计模式应用</h2><h3 id="工厂模式"><a href="#工厂模式" class="headerlink" title="工厂模式"></a>工厂模式</h3><p>java.text.DateFormat 工具类，它用于格式化一个本地日期或者时间。</p><pre><code class="bash">public final static DateFormat getDateInstance();public final static DateFormat getDateInstance(int style);public final static DateFormat getDateInstance(int style,Locale locale);</code></pre><h3 id="适配器模式"><a href="#适配器模式" class="headerlink" title="适配器模式"></a>适配器模式</h3><blockquote><p>把其他类适配为集合类。</p></blockquote><pre><code class="bash">List&lt;Integer&gt; arrayList = java.util.Arrays.asList(new Integer[]&#123;1,2,3&#125;);List&lt;Integer&gt; arrayList = java.util.Arrays.asList(1,2,3);</code></pre><h3 id="代理模式"><a href="#代理模式" class="headerlink" title="代理模式"></a>代理模式</h3><blockquote><p>如 JDK （Proxy）本身的动态代理。<br>还有 Spring AOP、日志打印、异常处理、事务控制、权限控制等。</p></blockquote><p><strong>代理的分类</strong></p><ul><li>静态代理 (静态定义代理类)</li><li>动态代理 (动态生成代理类，也称为 Jdk 自带动态代理)</li><li>Cglib 、javaassist（字节码操作库）</li></ul><p><strong>三种代理的区别</strong></p><ol><li>静态代理：简单代理模式，是动态代理的理论基础。常见使用在代理模式。</li><li>jdk 动态代理：使用反射完成代理。需要有顶层接口才能使用，常见是 mybatis 的 mapper 文件是代理。</li><li>cglib 动态代理：也是使用反射完成代理，可以直接代理类（jdk 动态代理不行），使用字节码技术，不能对 final 类进行继承。（需要导入 jar 包）</li></ol><h3 id="单例模式"><a href="#单例模式" class="headerlink" title="单例模式"></a>单例模式</h3><blockquote><p>全局只允许有一个实例，比如：</p></blockquote><pre><code class="bash">Runtime.getRuntime();</code></pre><h3 id="装饰器"><a href="#装饰器" class="headerlink" title="装饰器"></a>装饰器</h3><p>为一个对象动态的加上一系列的动作，而不需要因为这些动作的不同而产生大量的继承类。</p><pre><code class="bash">java.io.BufferedInputStream(InputStream);  java.io.DataInputStream(InputStream);  java.io.BufferedOutputStream(OutputStream);  java.util.zip.ZipOutputStream(OutputStream);  java.util.Collections.checkedList(List list, Class type) ;</code></pre><h3 id="模板方法模式"><a href="#模板方法模式" class="headerlink" title="模板方法模式"></a>模板方法模式</h3><blockquote><p>定义一个操作中算法的骨架，将一些步骤的执行延迟到其子类中。比如，Arrays.sort () 方法，它要求对象实现 Comparable 接口。</p></blockquote><h3 id="IO-使用了什么设计模式？"><a href="#IO-使用了什么设计模式？" class="headerlink" title="IO 使用了什么设计模式？"></a>IO 使用了什么设计模式？</h3><ul><li>适配器模式：由于 InputStream 是字节流不能享受到字符流读取字符那么便捷的功能，借助 InputStreamReader 将其转为 Reader 子类，因而可以拥有便捷操作文本文件方法；</li><li>装饰器模式：将 InputStream 字节流包装为其他流的过程就是装饰器模式，比如，包装为 FileInputStream、<br>ByteArrayInputStream、PipedInputStream 等。</li></ul><h2 id="Spring-中都使用了哪些设计模式？"><a href="#Spring-中都使用了哪些设计模式？" class="headerlink" title="Spring 中都使用了哪些设计模式？"></a>Spring 中都使用了哪些设计模式？</h2><ul><li>代理模式：在 AOP 中有使用。</li><li>单例模式：bean 默认是单例模式。</li><li>模板方法模式：jdbcTemplate。</li><li>工厂模式：BeanFactory。</li><li>观察者模式：Spring 事件驱动模型就是观察者模式很经典的一个应用，比如，ContextStartedEvent 就是 - ApplicationContext 启动后触发的事件。</li><li>适配器模式：Spring MVC 中也是用到了适配器模式适配 Controller。</li></ul><p><strong>Spring IOC</strong></p><ul><li>看过 Spring 源码就知道，在 Spring IOC 容器创建 bean 的过程是使用了工厂设计模式</li><li>Spring 中无论是通过 xml 配置，还是通过配置类还是注解进行创建 bean，大部分都是通过简单工厂来进行创建的。</li><li>当容器拿到了 beanName 和 class 类型后，动态的通过反射创建具体的某个对象，最后将创建的对象放到 Map 中。</li></ul><p><strong>为什么 Spring IOC 要使用工厂设计模式创建 Bean 呢</strong></p><ul><li>在实际开发中，如果我们 A 对象调用 B，B 调用 C，C 调用 D 的话我们程序的耦合性就会变高。（耦合大致分为类与类之间的依赖，方法与方法之间的依赖。）</li><li>在很久以前的三层架构编程时，都是控制层调用业务层，业务层调用数据访问层时，都是是直接 new 对象，耦合性大大提升，代码重复量很高，对象满天飞</li><li>为了避免这种情况，Spring 使用工厂模式编程，写一个工厂，由工厂创建 Bean，以后我们如果要对象就直接管工厂要就可以，剩下的事情不归我们管了。Spring IOC 容器的工厂中有个静态的 Map 集合，是为了让工厂符合单例设计模式，即每个对象只生产一次，生产出对象后就存入到 Map 集合中，保证了实例不会重复影响程序效率。</li></ul><h2 id="哪些地方用到了单例模式"><a href="#哪些地方用到了单例模式" class="headerlink" title="哪些地方用到了单例模式"></a>哪些地方用到了单例模式</h2><ol><li>网站的计数器，一般也是采用单例模式实现，否则难以同步。</li><li>应用程序的日志应用，一般都是单例模式实现，只有一个实例去操作才好，否则内容不好追加显示。</li><li>多线程的线程池的设计一般也是采用单例模式，因为线程池要方便对池中的线程进行控制</li><li>Windows 的（任务管理器）就是很典型的单例模式，他不能打开俩个</li><li>windows 的（回收站）也是典型的单例应用。在整个系统运行过程中，回收站只维护一个实例。</li></ol><h2 id="单例优缺点"><a href="#单例优缺点" class="headerlink" title="单例优缺点"></a>单例优缺点</h2><p><strong>优点：</strong></p><ol><li>在单例模式中，活动的单例只有一个实例，对单例类的所有实例化得到的都是相同的一个实例。这样就防止其它对象对自己的实例化，确保所有的对象都访问一个实例</li><li>单例模式具有一定的伸缩性，类自己来控制实例化进程，类就在改变实例化进程上有相应的伸缩性。</li><li>提供了对唯一实例的受控访问。</li><li>由于在系统内存中只存在一个对象，因此可以节约系统资源，当需要频繁创建和销毁的对象时单例模式无疑可以提高系统的性能。</li><li>允许可变数目的实例。</li><li>避免对共享资源的多重占用。</li></ol><p><strong>缺点：</strong></p><ol><li>不适用于变化的对象，如果同一类型的对象总是要在不同的用例场景发生变化，单例就会引起数据的错误，不能保存彼此的状态。</li><li>由于单利模式中没有抽象层，因此单例类的扩展有很大的困难。</li><li>单例类的职责过重，在一定程度上违背了 “单一职责原则”。</li><li>滥用单例将带来一些负面问题，如为了节省资源将数据库连接池对象设计为的单例类，可能会导致共享连接池对象的程序过多而出现连接池溢出；如果实例化的对象长时间不被利用，系统会认为是垃圾而被回收，这将导致对象状态的丢失。</li></ol><h2 id="单例模式使用注意事项"><a href="#单例模式使用注意事项" class="headerlink" title="单例模式使用注意事项"></a>单例模式使用注意事项</h2><ol><li><p>使用时不能用反射模式创建单例，否则会实例化一个新的对象。</p></li><li><p>使用懒单例模式时注意线程安全问题。</p></li><li><p>饿单例模式和懒单例模式构造方法都是私有的，因而是不能被继承的，有些单例模式可以被继承（如登记式模式）。</p></li></ol><h2 id="如何选择单例创建方式"><a href="#如何选择单例创建方式" class="headerlink" title="如何选择单例创建方式"></a>如何选择单例创建方式</h2><ul><li>如果不需要延迟加载单例，可以使用枚举或者饿汉式，相对来说枚举性好于饿汉式。 如果需要延迟加载，可以使用静态内部类或者懒汉式，相对来说静态内部类好于懒韩式。 最好使用饿汉式。</li></ul><h2 id="单例创建方式"><a href="#单例创建方式" class="headerlink" title="单例创建方式"></a>单例创建方式</h2><p><strong>（主要使用饿汉和懒汉式）</strong></p><ol><li>饿汉式：类初始化时，会立即加载该对象，线程天生安全，调用效率高。</li><li>懒汉式：类初始化时，不会初始化该对象，真正需要使用的时候才会创建该对象，具备懒加载功能。</li><li>静态内部方式：结合了懒汉式和饿汉式各自的优点，真正需要对象的时候才会加载，加载类是线程安全的。</li><li>枚举单例：使用枚举实现单例模式优点：实现简单、调用效率高，枚举本身就是单例，由 jvm 从根本上提供保障！避免通过反射和反序列化的漏洞， 缺点没有延迟加载。</li><li>双重检测锁方式 (因为 JVM 本质重排序的原因，可能会初始化多次，不推荐使用)。</li></ol><h2 id="懒汉式的单例模式如何实现单例？"><a href="#懒汉式的单例模式如何实现单例？" class="headerlink" title="懒汉式的单例模式如何实现单例？"></a>懒汉式的单例模式如何实现单例？</h2><blockquote><p>通过双重检测以及 synchronized,volatile 关键字实现。</p></blockquote><h2 id="工厂模式好处"><a href="#工厂模式好处" class="headerlink" title="工厂模式好处"></a>工厂模式好处</h2><ul><li><p>工厂模式是我们最常用的实例化对象模式了，是用工厂方法代替 new 操作的一种模式。</p></li><li><p>利用工厂模式可以降低程序的耦合性，为后期的维护修改提供了很大的便利。</p></li><li><p>将选择实现类、创建对象统一管理和控制。从而将调用者跟我们的实现类解耦。</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 设计模式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>写接口时你有考虑过幂等性问题吗？</title>
      <link href="/2021/08/13/%E6%94%AF%E4%BB%98/%E5%86%99%E6%8E%A5%E5%8F%A3%E6%97%B6%E4%BD%A0%E6%9C%89%E8%80%83%E8%99%91%E8%BF%87%E5%B9%82%E7%AD%89%E6%80%A7%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F/"/>
      <url>/2021/08/13/%E6%94%AF%E4%BB%98/%E5%86%99%E6%8E%A5%E5%8F%A3%E6%97%B6%E4%BD%A0%E6%9C%89%E8%80%83%E8%99%91%E8%BF%87%E5%B9%82%E7%AD%89%E6%80%A7%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>自己最近负责的几个接口，都涉及到了幂等性的操作，抽空总结了一下。</p><h1 id="一、什么是幂等？"><a href="#一、什么是幂等？" class="headerlink" title="一、什么是幂等？"></a>一、什么是幂等？</h1><p>看一下维基百科怎么说的：</p><p><img src="https://cdn.jsdelivr.net/gh/junian455/pic@master/payment/%E5%B9%82%E7%AD%89%E7%BB%B4%E5%9F%BA%E7%99%BE%E7%A7%91.png"></p><p>幂等性：多次调用方法或者接口不会改变业务状态，可以保证重复调用的结果和单次调用的结果一致。</p><h1 id="二、使用幂等的场景"><a href="#二、使用幂等的场景" class="headerlink" title="二、使用幂等的场景"></a>二、使用幂等的场景</h1><h2 id="1、前端重复提交"><a href="#1、前端重复提交" class="headerlink" title="1、前端重复提交"></a>1、前端重复提交</h2><p>用户注册，用户创建商品等操作，前端都会提交一些数据给后台服务，后台需要根据用户提交的数据在数据库中创建记录。如果用户不小心多点了几次，后端收到了好几次提交，这时就会在数据库中重复创建了多条记录。这就是接口没有幂等性带来的 bug。</p><h2 id="2、接口超时重试"><a href="#2、接口超时重试" class="headerlink" title="2、接口超时重试"></a>2、接口超时重试</h2><p>对于给第三方调用的接口，有可能会因为网络原因而调用失败，这时，一般在设计的时候会对接口调用加上失败重试的机制。如果第一次调用已经执行了一半时，发生了网络异常。这时再次调用时就会因为脏数据的存在而出现调用异常。</p><h2 id="3、消息重复消费"><a href="#3、消息重复消费" class="headerlink" title="3、消息重复消费"></a>3、消息重复消费</h2><p>在使用消息中间件来处理消息队列，且手动 ack 确认消息被正常消费时。如果消费者突然断开连接，那么已经执行了一半的消息会重新放回队列。</p><p>当消息被其他消费者重新消费时，如果没有幂等性，就会导致消息重复消费时结果异常，如数据库重复数据，数据库数据冲突，资源重复等。</p><h1 id="三、解决方案"><a href="#三、解决方案" class="headerlink" title="三、解决方案"></a>三、解决方案</h1><h2 id="1、token-机制实现"><a href="#1、token-机制实现" class="headerlink" title="1、token 机制实现"></a>1、token 机制实现</h2><p>通过token 机制实现接口的幂等性,这是一种比较通用性的实现方法。</p><p>示意图如下：</p><p><img src="https://cdn.jsdelivr.net/gh/junian455/pic@master/payment/token%E6%9C%BA%E5%88%B6%E5%AE%9E%E7%8E%B0%E5%B9%82%E7%AD%89.png" alt="token机制实现幂等"><br>具体流程步骤：</p><p>客户端会先发送一个请求去获取 token，服务端会生成一个全局唯一的 ID 作为 token 保存在 redis 中，同时把这个 ID 返回给客户端<br>客户端第二次调用业务请求的时候必须携带这个 token<br>服务端会校验这个 token，如果校验成功，则执行业务，并删除 redis 中的 token<br>如果校验失败，说明 redis 中已经没有对应的 token，则表示重复操作，直接返回指定的结果给客户端<br>注意：</p><p>对 redis 中是否存在 token 以及删除的代码逻辑建议用 Lua 脚本实现，保证原子性<br>全局唯一 ID 可以用百度的 uid-generator、美团的 Leaf 去生成</p><h2 id="2、基于-mysql-实现"><a href="#2、基于-mysql-实现" class="headerlink" title="2、基于 mysql 实现"></a>2、基于 mysql 实现</h2><p>这种实现方式是利用 mysql 唯一索引的特性。</p><p>示意图如下：<br><img src="https://cdn.jsdelivr.net/gh/junian455/pic@master/payment/%E5%9F%BA%E4%BA%8Emysql%E5%AE%9E%E7%8E%B0%E5%B9%82%E7%AD%89.png" alt="基于mysql实现幂等"><br>具体流程步骤：</p><p>建立一张去重表，其中某个字段需要建立唯一索引<br>客户端去请求服务端，服务端会将这次请求的一些信息插入这张去重表中<br>因为表中某个字段带有唯一索引，如果插入成功，证明表中没有这次请求的信息，则执行后续的业务逻辑<br>如果插入失败，则代表已经执行过当前请求，直接返回</p><h2 id="3、基于-redis-实现"><a href="#3、基于-redis-实现" class="headerlink" title="3、基于 redis 实现"></a>3、基于 redis 实现</h2><p>这种实现方式是基于 SETNX 命令实现的</p><p>SETNX key value：将 key 的值设为 value ，当且仅当 key 不存在。若给定的 key 已经存在，则 SETNX 不做任何动作。</p><p>该命令在设置成功时返回 1，设置失败时返回 0。</p><p>示意图如下：</p><p><img src="https://cdn.jsdelivr.net/gh/junian455/pic@master/payment/redis%E5%AE%9E%E7%8E%B0%E5%B9%82%E7%AD%89.png" alt="redis实现幂等"></p><p>具体流程步骤：</p><p>客户端先请求服务端，会拿到一个能代表这次请求业务的唯一字段<br>将该字段以 SETNX 的方式存入 redis 中，并根据业务设置相应的超时时间<br>如果设置成功，证明这是第一次请求，则执行后续的业务逻辑<br>如果设置失败，则代表已经执行过当前请求，直接返回<br>总结<br>这几种实现幂等的方式其实都是大同小异的，类似的还有使用状态机、悲观锁、乐观锁的方式来实现，都是比较简单的。</p><p>总之，当你去设计一个接口的时候，幂等都是首要考虑的问题，特别是当你负责设计转账、支付这种涉及到 money 的接口，你要格外注意喽！</p>]]></content>
      
      
      <categories>
          
          <category> 支付 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 幂等 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>支付宝支付实战</title>
      <link href="/2021/08/05/%E6%94%AF%E4%BB%98/%E6%94%AF%E4%BB%98%E5%AE%9D%E6%94%AF%E4%BB%98%E5%AE%9E%E6%88%98/"/>
      <url>/2021/08/05/%E6%94%AF%E4%BB%98/%E6%94%AF%E4%BB%98%E5%AE%9D%E6%94%AF%E4%BB%98%E5%AE%9E%E6%88%98/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>]]></content>
      
      
      <categories>
          
          <category> 支付 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> jsapi支付 </tag>
            
            <tag> 签名解密 </tag>
            
            <tag> 回调通知 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>微信jsapi支付实战</title>
      <link href="/2021/07/22/%E6%94%AF%E4%BB%98/%E5%BE%AE%E4%BF%A1jsapi%E6%94%AF%E4%BB%98%E5%AE%9E%E6%88%98/"/>
      <url>/2021/07/22/%E6%94%AF%E4%BB%98/%E5%BE%AE%E4%BF%A1jsapi%E6%94%AF%E4%BB%98%E5%AE%9E%E6%88%98/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>]]></content>
      
      
      <categories>
          
          <category> 支付 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> jsapi支付 </tag>
            
            <tag> 签名解密 </tag>
            
            <tag> 回调通知 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>操作系统</title>
      <link href="/2021/06/19/os/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
      <url>/2021/06/19/os/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="进程和线程有什么区别？"><a href="#进程和线程有什么区别？" class="headerlink" title="进程和线程有什么区别？"></a>进程和线程有什么区别？</h1><ul><li>进程（Process）是系统进行资源分配和调度的基本单位，线程（Thread）是 CPU 调度和分派的基本单位；</li><li>线程依赖于进程而存在，一个进程至少有一个线程；</li><li>进程有自己的独立地址空间，线程共享所属进程的地址空间；</li><li>进程是拥有系统资源的一个独立单位，而线程自己基本上不拥有系统资源，只拥有一点在运行中必不可少的资源 (如程序计数器，一组寄存器和栈)，和其他线程共享本进程的相关资源如内存、I/O、cpu 等；</li><li>在进程切换时，涉及到整个当前进程 CPU 环境的保存、环境的设置以及新被调度运行的 CPU 环境的设置，而线程切换只需保存和设置少量的寄存器的内容，并不涉及存储器管理方面的操作，可见，进程切换的开销远大于线程切换的开销；</li><li>线程之间的通信更方便，同一进程下的线程共享全局变量等数据，而进程之间的通信需要以进程间通信 (IPC) 的方式进行；</li><li>多线程程序只要有一个线程崩溃，整个程序就崩溃了，但多进程程序中一个进程崩溃并不会对其它进程造成影响，因为进程有自己的独立地址空间，因此多进程更加健壮。</li></ul><blockquote><p>进程操作代码实现，可以参考：<a href="https://www.liaoxuefeng.com/wiki/1016959663602400/1017628290184064">多进程 - 廖雪峰的官方网站</a></p></blockquote><h2 id="同一进程中的线程可以共享哪些数据？"><a href="#同一进程中的线程可以共享哪些数据？" class="headerlink" title="同一进程中的线程可以共享哪些数据？"></a>同一进程中的线程可以共享哪些数据？</h2><ul><li>进程代码段</li><li>进程的公有数据（全局变量、静态变量…）</li><li>进程打开的文件描述符</li><li>进程的当前目录</li><li>信号处理器 / 信号处理函数：对收到的信号的处理方式</li><li>进程 ID 与进程组 ID</li></ul><h2 id="线程独占哪些资源？"><a href="#线程独占哪些资源？" class="headerlink" title="线程独占哪些资源？"></a>线程独占哪些资源？</h2><ul><li>线程 ID</li><li>一组寄存器的值</li><li>线程自身的栈（堆是共享的）</li><li>错误返回码：线程可能会产生不同的错误返回码，一个线程的错误返回码不应该被其它线程修改</li><li>信号掩码 / 信号屏蔽字 (Signal mask)：表示是否屏蔽 / 阻塞相应的信号（SIGKILL,SIGSTOP 除外）</li></ul><h1 id="进程间通信有哪些方式？"><a href="#进程间通信有哪些方式？" class="headerlink" title="进程间通信有哪些方式？"></a>进程间通信有哪些方式？</h1><ol><li>管道 (Pipe)</li></ol><ul><li>管道是半双工的，数据只能向一个方向流动；需要双方通信时，需要建立起两个管道；</li><li>一个进程向管道中写的内容被管道另一端的进程读出。写入的内容每次都添加在管道缓冲区的末尾，并且每次都是从缓冲区的头部读出数据；</li><li>只能用于父子进程或者兄弟进程之间 (具有亲缘关系的进程)。</li></ul><ol start="2"><li><p>命名管道</p></li><li><p>消息队列</p></li><li><p>信号 (Signal)</p></li><li><p>共享内存</p></li><li><p>**信号量 (Semaphore)**：初始化操作、P 操作、V 操作；P 操作：信号量 - 1，检测是否小于 0，小于则进程进入阻塞状态；V 操作：信号量 + 1，若小于等于 0，则从队列中唤醒一个等待的进程进入就绪态。</p></li><li><p>套接字 (Socket)</p></li></ol><h1 id="进程同步问题"><a href="#进程同步问题" class="headerlink" title="进程同步问题"></a>进程同步问题</h1><p><strong>管程 Monitor</strong></p><blockquote><p>管程将共享变量以及对这些共享变量的操作封装起来，形成一个具有一定接口的功能模块，这样只能通过管程提供的某个过程才能访问管程中的资源。进程只能互斥地使用管程，使用完之后必须释放管程并唤醒入口等待队列中的进程。</p></blockquote><p>当一个进程试图进入管程时，在<strong>入口等待队列</strong>等待。若 P 进程唤醒了 Q 进程，则 Q 进程先执行，P 在<strong>紧急等待队列</strong>中等待。<strong>（ HOARE 管程）</strong></p><ol><li><p>wait 操作：执行 wait 操作的进程进入条件变量链末尾，唤醒紧急等待队列或者入口队列中的进程；</p></li><li><p>signal 操作：唤醒条件变量链中的进程，自己进入紧急等待队列，若条件变量链为空，则继续执行。<strong>（HOARE 管程）</strong></p></li></ol><p><strong>MESA 管程</strong>：将 HOARE 中的 signal 换成了 notify（或者 broadcast 通知所有满足条件的），进行通知而不是立马交换管程的使用权，在合适的时候，条件队列首位的进程可以进入，进入之前必须用 while 检查条件是否合适。优点：没有额外的进程切换。</p><p><strong>生产者 - 消费者问题</strong></p><blockquote><p>问题描述：使用一个缓冲区来存放数据，只有缓冲区没有满，生产者才可以写入数据；只有缓冲区不为空，消费者才可以读出数据。</p></blockquote><p>代码实现：</p><pre><code class="bash">// 伪代码描述 // 定义信号量 full记录缓冲区物品数量 empty代表缓冲区空位数量 mutex为互斥量semaphore full = 0, empty = n, mutex = 1;// 生产者进程void producer()&#123;    do&#123;         P(empty);      P(mutex);     // 生产者进行生产                V(mutex);         V(full);     &#125; while(1);&#125;void consumer()&#123;    do&#123;      P(full);      P(mutex);        // 消费者进行消费      V(mutex);      V(empty);     &#125; while(1);&#125;</code></pre><p><strong>哲学家就餐问题</strong></p><blockquote><p>问题描述：有五位哲学家围绕着餐桌坐，每一位哲学家要么思考，要么吃饭。为了吃饭，哲学家必须拿起两双筷子（分别放于左右两端）不幸的是，筷子的数量和哲学家相等，所以每只筷子必须由两位哲学家共享。</p></blockquote><p><strong>代码实现：</strong></p><pre><code class="bash">#define N 5  // number of philosopher#define LEFT (i + N - 1)%N // number of i&#39;s left neighbors#define RIGHT (i + 1)%N // number of i&#39;s right neighbors#define THINKING 0#define HUNGRY 1#define EATING 2typedef int semaphore;int state[N]; // array to keep track of everyone&#39;s statesemaphore mutex = 1; // mutual exclusion of critical regionsemaphore s[N]; void philosopher(int i) &#123;    while (TRUE) &#123;        think();        take_forks(i);        eat();        put_forks(i);    &#125;&#125;void take_forks(int i) &#123;    down(&amp;mutex); // enter critical region    state[i] = HUNGRY; // record that i is hungry    test_forks(i); // try to acquire two forks    up(&amp;mutex); // exit critical region    down(&amp;s[i]); // block if forks are not acquired&#125;void put_forks(int i) &#123;    down(&amp;mutex); // enter critical region    state[i] = THINKING; // record that has finished eating    test_forks(LEFT); // see if left neighbor can now eat    test_forks(RIGHT); // see if right neighbor can now eat    up(&amp;mutex); // exit critical region&#125;void test_forks(int i) &#123;    if (state[i] == HUNGRY &amp;&amp; state[LEFT] != EATING &amp;&amp; state[RIGHT] != EATING) &#123;        state[i] = EATING;        up(&amp;s[i]);    &#125;&#125;</code></pre><p><strong>读者 - 写者问题</strong></p><h2 id="临界区的概念？"><a href="#临界区的概念？" class="headerlink" title="临界区的概念？"></a>临界区的概念？</h2><p>各个进程中对临界资源（互斥资源 / 共享变量，一次只能给一个进程使用）进行操作的程序片段。</p><h2 id="同步与互斥的概念？"><a href="#同步与互斥的概念？" class="headerlink" title="同步与互斥的概念？"></a>同步与互斥的概念？</h2><ul><li>同步：多个进程因为合作而使得进程的执行有一定的先后顺序。比如某个进程需要另一个进程提供的消息，获得消息之前进入阻塞态。</li><li>互斥：多个进程在同一时刻只有一个进程能进入临界区。</li></ul><h2 id="并发、并行、异步的区别？"><a href="#并发、并行、异步的区别？" class="headerlink" title="并发、并行、异步的区别？"></a>并发、并行、异步的区别？</h2><ul><li>并发：在一个时间段中同时有多个程序在运行，但其实任一时刻，只有一个程序在 CPU 上运行，宏观上的并发是通过不断的切换实现的。</li><li>多线程：并发运行的一段代码。是实现异步的手段。</li><li>并行（和串行相比）：在多 CPU 系统中，多个程序无论宏观还是微观上都是同时执行的。</li><li>异步（和同步相比）：同步是顺序执行，异步是在等待某个资源的时候继续做自己的事。</li></ul><h1 id="进程有哪几种状态？"><a href="#进程有哪几种状态？" class="headerlink" title="进程有哪几种状态？"></a>进程有哪几种状态？</h1><p><img src="https://cdn.jsdelivr.net/gh/junian455/pic@master/img/20191202090217863_1873.png" alt="Process State"></p><ul><li>就绪状态：进程已获得除处理机以外的所需资源，等待分配处理机资源。</li><li>运行状态：占用处理机资源运行，处于此状态的进程数小于等于 CPU 数。</li><li>阻塞状态： 进程等待某种条件，在条件满足之前无法执行。</li></ul><h1 id="进程调度策略有哪些？"><a href="#进程调度策略有哪些？" class="headerlink" title="进程调度策略有哪些？"></a>进程调度策略有哪些？</h1><h2 id="批处理系统"><a href="#批处理系统" class="headerlink" title="批处理系统"></a>批处理系统</h2><ol><li>先来先服务 first-come first-serverd（FCFS）</li></ol><ul><li><p>按照请求的顺序进行调度。</p></li><li><p>非抢占式，开销小，无饥饿问题，响应时间不确定（可能很慢）。</p></li><li><p>对短进程不利，对 IO 密集型进程不利。</p></li></ul><ol start="2"><li>最短作业优先 shortest job first（SJF）</li></ol><ul><li><p>按估计运行时间最短的顺序进行调度。</p></li><li><p>非抢占式，吞吐量高，开销可能较大，可能导致饥饿问题。</p></li><li><p>对短进程提供好的响应时间，对长进程不利。</p></li></ul><ol start="3"><li>最短剩余时间优先 shortest remaining time next（SRTN）</li></ol><ul><li><p>按剩余运行时间的顺序进行调度。(最短作业优先的抢占式版本)。</p></li><li><p>吞吐量高，开销可能较大，提供好的响应时间。</p></li><li><p>可能导致饥饿问题，对长进程不利。</p></li></ul><ol start="4"><li>最高响应比优先 Highest Response Ratio Next（HRRN）</li></ol><ul><li>响应比 = 1+ 等待时间 / 处理时间。同时考虑了等待时间的长短和估计需要的执行时间长短，很好的平衡了长短进程。</li><li>非抢占，吞吐量高，开销可能较大，提供好的响应时间，无饥饿问题。</li></ul><h2 id="交互式系统"><a href="#交互式系统" class="headerlink" title="交互式系统"></a>交互式系统</h2><blockquote><p>交互式系统有大量的用户交互操作，在该系统中调度算法的目标是快速地进行响应。</p></blockquote><ol><li>时间片轮转 Round Robin</li></ol><ul><li>将所有就绪进程按 FCFS 的原则排成一个队列，用完时间片的进程排到队列最后。</li><li>抢占式（时间片用完时），开销小，无饥饿问题，为短进程提供好的响应时间。</li><li>若时间片小，进程切换频繁，吞吐量低；若时间片太长，实时性得不到保证。</li></ul><ol start="2"><li>优先级调度算法</li></ol><ul><li>为每个进程分配一个优先级，按优先级进行调度。为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。</li></ul><ol start="3"><li>多级反馈队列调度算法 Multilevel Feedback Queue</li></ol><ul><li><p>设置多个就绪队列 1、2、3…，优先级递减，时间片递增。只有等到优先级更高的队列为空时才会调度当前队列中的进程。如果进程用完了当前队列的时间片还未执行完，则会被移到下一队列。</p></li><li><p>抢占式（时间片用完时），开销可能较大，对 IO 型进程有利，可能会出现饥饿问题。</p></li></ul><h2 id="什么叫优先级反转？如何解决？"><a href="#什么叫优先级反转？如何解决？" class="headerlink" title="什么叫优先级反转？如何解决？"></a>什么叫优先级反转？如何解决？</h2><p><strong>高优先级的进程</strong>等待被一个低优先级进程占用的资源时，就会出现优先级反转，即优先级较低的进程比优先级较高的进程先执行。</p><blockquote><p>此处详细解释优先级反转带来的问题：如果有一个中等优先级的进程将低优先级的进程抢占，那么此时低优先级的进程无法正常进行并在后续释放被占用的资源，导致高优先级的任务一直被挂起，直到中等优先级的进程完成后，低优先级的进程才可以继续并在后续释放占用的资源，最后<strong>高优先级的进程</strong>才可以执行。导致的问题就是高优先级的进程在中等优先级的进程调度之后。</p></blockquote><p><strong>解决方法：</strong></p><ul><li><p>优先级天花板 (priority ceiling)：当任务申请某资源时，把该任务的优先级提升到可访问这个资源的所有任务中的最高优先级，这个优先级称为该资源的优先级天花板。简单易行。</p></li><li><p>优先级继承 (priority inheritance)：当任务 A 申请共享资源 S 时，如果 S 正在被任务 C 使用，通过比较任务 C 与自身的优先级，如发现任务 C 的优先级小于自身的优先级，则将任务 C 的优先级提升到自身的优先级，任务 C 释放资源 S 后，再恢复任务 C 的原优先级。</p></li></ul><h1 id="什么是僵尸进程？"><a href="#什么是僵尸进程？" class="headerlink" title="什么是僵尸进程？"></a>什么是僵尸进程？</h1><blockquote><p>一个子进程结束后，它的父进程并没有等待它（调用 wait 或者 waitpid），那么这个子进程将成为一个僵尸进程。</p></blockquote><p><strong>僵尸进程</strong>是一个已经死亡的进程，但是并没有真正被销毁。它已经放弃了几乎所有内存空间，没有任何可执行代码，也不能被调度，仅仅在进程表中保留一个位置，记载该进程的进程 ID、终止状态以及资源利用信息 (CPU 时间，内存使用量等等) 供父进程收集，除此之外，<strong>僵尸进程</strong>不再占有任何内存空间。这个<strong>僵尸进程</strong>可能会一直留在系统中直到系统重启。</p><blockquote><p>危害：占用进程号，而系统所能使用的进程号是有限的；占用内存。</p></blockquote><h2 id="以下情况不会产生僵尸进程："><a href="#以下情况不会产生僵尸进程：" class="headerlink" title="以下情况不会产生僵尸进程："></a>以下情况不会产生僵尸进程：</h2><ol><li><p>该进程的父进程先结束了。每个进程结束的时候，系统都会扫描是否存在子进程，如果有则用 Init 进程接管，成为该进程的父进程，并且会调用 wait 等待其结束。</p></li><li><p>父进程调用 wait 或者 waitpid 等待子进程结束（需要每隔一段时间查询子进程是否结束）。wait 系统调用会使父进程暂停执行，直到它的一个子进程结束为止。waitpid 则可以加入 WNOHANG(wait-no-hang) 选项，如果没有发现结束的子进程，就会立即返回，不会将调用 waitpid 的进程阻塞。同时，waitpid 还可以选择是等待任一子进程（同 wait），还是等待指定 pid 的子进程，还是等待同一进程组下的任一子进程，还是等待组 ID 等于 pid 的任一子进程。</p></li><li><p>子进程结束时，系统会产生 SIGCHLD(signal-child) 信号，可以注册一个信号处理函数，在该函数中调用 waitpid，等待所有结束的子进程（注意：一般都需要循环调用 waitpid，因为在信号处理函数开始执行之前，可能已经有多个子进程结束了，而信号处理函数只<br>执行一次，所以要循环调用将所有结束的子进程回收）。</p></li><li><p>也可以用 signal(SIGCLD, SIG_IGN)(signal-ignore) 通知内核，表示忽略 SIGCHLD 信号，那么子进程结束后，内核会进行回收。</p></li></ol><h2 id="什么是孤儿进程？"><a href="#什么是孤儿进程？" class="headerlink" title="什么是孤儿进程？"></a>什么是孤儿进程？</h2><blockquote><p>一个父进程已经结束了，但是它的子进程还在运行，那么这些子进程将成为孤儿进程。孤儿进程会被 Init（进程 ID 为 1）接管，当这些孤儿进程结束时由 Init 完成状态收集工作。</p></blockquote><h1 id="线程同步有哪些方式？"><a href="#线程同步有哪些方式？" class="headerlink" title="线程同步有哪些方式？"></a>线程同步有哪些方式？</h1><blockquote><p>为什么需要线程同步：线程有时候会和其他线程共享一些资源，比如内存、数据库等。当多个线程同时读写同一份共享资源的时候，可能会发生冲突。因此需要线程的同步，多个线程按顺序访问资源。</p></blockquote><ul><li><p><strong>互斥量 Mutex</strong>：互斥量是内核对象，只有拥有互斥对象的线程才有访问互斥资源的权限。因为互斥对象只有一个，所以可以保证互斥资源不会被多个线程同时访问；当前拥有互斥对象的线程处理完任务后必须将互斥对象交出，以便其他线程访问该资源。</p></li><li><p><strong>信号量 Semaphore</strong>：信号量是内核对象，它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量。信号量对象保存了最大资源计数和当前可用资源计数，每增加一个线程对共享资源的访问，当前可用资源计数就减 1，只要当前可用资源计数大于 0，就可以发出信号量信号，如果为 0，则将线程放入一个队列中等待。线程处理完共享资源后，应在离开的同时通过 ReleaseSemaphore 函数将当前可用资源数加 1。如果信号量的取值只能为 0 或 1，那么信号量就成为了互斥量。</p></li><li><p><strong>事件 Event</strong>：允许一个线程在处理完一个任务后，主动唤醒另外一个线程执行任务。事件分为手动重置事件和自动重置事件。手动重置事件被设置为激发状态后，会唤醒所有等待的线程，而且一直保持为激发状态，直到程序重新把它设置为未激发状态。自动重置事件被设置为激发状态后，会唤醒一个等待中的线程，然后自动恢复为未激发状态。</p></li><li><p><strong>临界区 Critical Section</strong>：任意时刻只允许一个线程对临界资源进行访问。拥有临界区对象的线程可以访问该临界资源，其它试图访问该资源的线程将被挂起，直到临界区对象被释放。</p></li></ul><h2 id="互斥量和临界区有什么区别？"><a href="#互斥量和临界区有什么区别？" class="headerlink" title="互斥量和临界区有什么区别？"></a>互斥量和临界区有什么区别？</h2><p>互斥量是可以命名的，可以用于不同进程之间的同步；而临界区只能用于同一进程中线程的同步。创建互斥量需要的资源更多，因此临界区的优势是速度快，节省资源。</p><h1 id="什么是协程？"><a href="#什么是协程？" class="headerlink" title="什么是协程？"></a>什么是协程？</h1><blockquote><p>协程是一种<strong>用户态的轻量级线程</strong>，协程的调度完全由用户控制。协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈，直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快。</p></blockquote><h2 id="协程多与线程进行比较？"><a href="#协程多与线程进行比较？" class="headerlink" title="协程多与线程进行比较？"></a>协程多与线程进行比较？</h2><ol><li><p>一个线程可以拥有多个协程，一个进程也可以单独拥有多个协程，这样 python 中则能使用多核 CPU。</p></li><li><p>线程进程都是同步机制，而协程则是异步</p></li><li><p>协程能保留上一次调用时的状态，每次过程重入时，就相当于进入上一次调用的状态</p></li></ol><h1 id="进程的异常控制流：陷阱、中断、异常和信号"><a href="#进程的异常控制流：陷阱、中断、异常和信号" class="headerlink" title="进程的异常控制流：陷阱、中断、异常和信号"></a>进程的异常控制流：陷阱、中断、异常和信号</h1><ol><li><p>陷阱是<strong>有意</strong>造成的 “异常”，是执行一条指令的结果。陷阱是同步的。陷阱的主要作用是实现系统调用。比如，进程可以执行 <code>syscall n</code> 指令向内核请求服务。当进程执行这条指令后，会中断当前的控制流，陷入到内核态，执行相应的系统调用。内核的处理程序在执行结束后，会将结果返回给进程，同时退回到用户态。进程此时继续执行<strong>下一条指令</strong>。</p></li><li><p>中断由处理器外部的硬件产生，不是执行某条指令的结果，也无法预测发生时机。由于中断独立于当前执行的程序，因此中断是异步事件。中断包括 I/O 设备发出的 I/O 中断、各种定时器引起的时钟中断、调试程序中设置的断点等引起的调试中断等。</p></li><li><p>异常是一种错误情况，是执行当前指令的结果，可能被错误处理程序修正，也可能直接终止应用程序。异常是同步的。这里特指因为执行当前指令而产生的<strong>错误情况</strong>，比如除法异常、缺页异常等。有些书上为了区分，也将这类 “异常” 称为 <strong>“故障”</strong>。</p></li><li><p>信号是一种更高层的软件形式的异常，同样会中断进程的控制流，可以由进程进行处理。一个信号代表了一个消息。信号的作用是用来<strong>通知进程</strong>发生了某种系统事件。</p></li></ol><blockquote><p>更详细的可以参考：<a href="https://imageslr.github.io/2020/07/09/trap-interrupt-exception.html"></a></p></blockquote><h1 id="什么是-IO-多路复用？怎么实现？"><a href="#什么是-IO-多路复用？怎么实现？" class="headerlink" title="什么是 IO 多路复用？怎么实现？"></a>什么是 IO 多路复用？怎么实现？</h1><p>IO 多路复用（IO Multiplexing）是指单个进程 / 线程就可以同时处理多个 IO 请求。</p><p><strong>实现原理</strong>：用户将想要监视的文件描述符（File Descriptor）添加到 select/poll/epoll 函数中，由内核监视，函数阻塞。一旦有文件描述符就绪（读就绪或写就绪），或者超时（设置 timeout），函数就会返回，然后该进程可以进行相应的读 / 写操作。</p><h2 id="select-poll-epoll-三者的区别？"><a href="#select-poll-epoll-三者的区别？" class="headerlink" title="select/poll/epoll 三者的区别？"></a>select/poll/epoll 三者的区别？</h2><ul><li><p><code>select</code>：将文件描述符放入一个集合中，调用 select 时，将这个集合从用户空间拷贝到内核空间（缺点 1：每次都要复制，开销大），由内核根据就绪状态修改该集合的内容。（缺点 2）集合大小有限制，32 位机默认是 1024（64 位：2048）；采用水平触发机制。select 函数返回后，需要通过遍历这个集合，找到就绪的文件描述符（缺点 3：轮询的方式效率较低），当文件描述符的数量增加时，效率会线性下降；</p></li><li><p><code>poll</code>：和 select 几乎没有区别，区别在于文件描述符的存储方式不同，poll 采用链表的方式存储，没有最大存储数量的限制。</p></li><li><p><code>epoll</code>：通过内核和用户空间共享内存，避免了不断复制的问题；支持的同时连接数上限很高（1G 左右的内存支持 10W 左右的连接数）；文件描述符就绪时，采用回调机制，避免了轮询（回调函数将就绪的描述符添加到一个链表中，执行 epoll_wait 时，返回这个链表）；支持水平触发和边缘触发，采用边缘触发机制时，只有活跃的描述符才会触发回调函数。</p></li></ul><p><strong>总结，区别主要在于：</strong></p><ul><li><p>一个线程 / 进程所能打开的最大连接数</p></li><li><p>文件描述符传递方式（是否复制）</p></li><li><p>水平触发 or 边缘触发</p></li><li><p>查询就绪的描述符时的效率（是否轮询）</p></li></ul><h2 id="什么时候使用-select-poll，什么时候使用-epoll？"><a href="#什么时候使用-select-poll，什么时候使用-epoll？" class="headerlink" title="什么时候使用 select/poll，什么时候使用 epoll？"></a>什么时候使用 select/poll，什么时候使用 epoll？</h2><p>当连接数较多并且有很多的不活跃连接时，epoll 的效率比其它两者高很多；但是当连接数较少并且都十分活跃的情况下，由于 epoll 需要很多回调，因此性能可能低于其它两者。</p><h2 id="什么是文件描述符？"><a href="#什么是文件描述符？" class="headerlink" title="什么是文件描述符？"></a>什么是文件描述符？</h2><p>文件描述符在形式上是一个非负整数。实际上，它是一个索引值，指向内核为每一个进程所维护的该进程打开文件的记录表。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。</p><p>内核通过文件描述符来访问文件。文件描述符指向一个文件。</p><h2 id="什么是水平触发？什么是边缘触发？"><a href="#什么是水平触发？什么是边缘触发？" class="headerlink" title="什么是水平触发？什么是边缘触发？"></a>什么是水平触发？什么是边缘触发？</h2><ul><li><p>水平触发（LT，Level Trigger）模式下，只要一个文件描述符就绪，就会触发通知，如果用户程序没有一次性把数据读写完，下次还会通知。</p></li><li><p>边缘触发（ET，Edge Trigger）模式下，当描述符从未就绪变为就绪时通知一次，之后不会再通知，直到再次从未就绪变为就绪（缓冲区从不可读 / 写变为可读 / 写）。</p></li><li><p>区别：边缘触发效率更高，减少了被重复触发的次数，函数不会返回大量用户程序可能不需要的文件描述符。</p></li><li><p>为什么边缘触发一定要用非阻塞（non-block）IO：避免由于一个描述符的阻塞读 / 阻塞写操作让处理其它描述符的任务出现饥饿状态。</p></li></ul><h2 id="有哪些常见的-IO-模型？"><a href="#有哪些常见的-IO-模型？" class="headerlink" title="有哪些常见的 IO 模型？"></a>有哪些常见的 IO 模型？</h2><ul><li>同步阻塞 IO（Blocking IO）：用户线程发起 IO 读 / 写操作之后，线程阻塞，直到可以开始处理数据；对 CPU 资源的利用率不够。</li><li>同步非阻塞 IO（Non-blocking IO）：发起 IO 请求之后可以立即返回，如果没有就绪的数据，需要不断地发起 IO 请求直到数据就绪；不断重复请求消耗了大量的 CPU 资源。</li><li>IO 多路复用</li><li>异步 IO（Asynchronous IO）：用户线程发出 IO 请求之后，继续执行，由内核进行数据的读取并放在用户指定的缓冲区内，在 IO 完成之后通知用户线程直接使用。</li></ul><h1 id="什么是用户态和内核态？"><a href="#什么是用户态和内核态？" class="headerlink" title="什么是用户态和内核态？"></a>什么是用户态和内核态？</h1><blockquote><p>为了限制不同程序的访问能力，防止一些程序访问其它程序的内存数据，CPU 划分了用户态和内核态两个权限等级。</p></blockquote><ul><li><p>用户态只能受限地访问内存，且不允许访问外围设备，没有占用 CPU 的能力，CPU 资源可以被其它程序获取；</p></li><li><p>内核态可以访问内存所有数据以及外围设备，也可以进行程序的切换。所有用户程序都运行在用户态，但有时需要进行一些内核态的操作，比如从硬盘或者键盘读数据，这时就需要进行系统调用，使用<strong>陷阱指令</strong>，CPU 切换到内核态，执行相应的服务，再切换为用户态并返回系统调用的结果。</p></li></ul><h2 id="为什么要分用户态和内核态？"><a href="#为什么要分用户态和内核态？" class="headerlink" title="为什么要分用户态和内核态？"></a>为什么要分用户态和内核态？</h2><p>（我自己的见解：）</p><ul><li>安全性：防止用户程序恶意或者不小心破坏系统 / 内存 / 硬件资源；</li><li>封装性：用户程序不需要实现更加底层的代码；</li><li>利于调度：如果多个用户程序都在等待键盘输入，这时就需要进行调度，统一交给操作系统调度更加方便。</li></ul><h2 id="如何从用户态切换到内核态？"><a href="#如何从用户态切换到内核态？" class="headerlink" title="如何从用户态切换到内核态？"></a>如何从用户态切换到内核态？</h2><ul><li>系统调用：比如读取命令行输入。本质上还是通过中断实现。</li><li>用户程序发生异常时：比如缺页异常。</li><li>外围设备的中断：外围设备完成用户请求的操作之后，会向 CPU 发出中断信号，这时 CPU 会转去处理对应的中断处理程序。</li></ul><h1 id="什么是死锁？"><a href="#什么是死锁？" class="headerlink" title="什么是死锁？"></a>什么是死锁？</h1><p>在两个或者多个并发进程中，每个进程持有某种资源而又等待其它进程释放它们现在保持着的资源，在未改变这种状态之前都不能向前推进，称这一组进程产生了死锁 (deadlock)。</p><h2 id="死锁产生的必要条件？"><a href="#死锁产生的必要条件？" class="headerlink" title="死锁产生的必要条件？"></a>死锁产生的必要条件？</h2><ul><li>互斥：一个资源一次只能被一个进程使用；</li><li>占有并等待：一个进程至少占有一个资源，并在等待另一个被其它进程占用的资源；</li><li>非抢占：已经分配给一个进程的资源不能被强制性抢占，只能由进程完成任务之后自愿释放；</li><li>循环等待：若干进程之间形成一种头尾相接的环形等待资源关系，该环路中的每个进程都在等待下一个进程所占有的资源。</li></ul><h2 id="死锁有哪些处理方法？"><a href="#死锁有哪些处理方法？" class="headerlink" title="死锁有哪些处理方法？"></a>死锁有哪些处理方法？</h2><p><strong>鸵鸟策略</strong></p><p>直接忽略死锁。因为解决死锁问题的代价很高，因此鸵鸟策略这种不采取任务措施的方案会获得更高的性能。当发生死锁时不会对用户造成多大影响，或发生死锁的概率很低，可以采用鸵鸟策略。</p><p><strong>死锁预防</strong></p><p>基本思想是破坏形成死锁的四个必要条件：</p><ul><li><p>破坏互斥条件：允许某些资源同时被多个进程访问。但是有些资源本身并不具有这种属性，因此这种方案实用性有限；</p></li><li><p>破坏占有并等待条件：</p><ul><li>实行资源预先分配策略（当一个进程开始运行之前，必须一次性向系统申请它所需要的全部资源，否则不运行）；</li><li>或者只允许进程在没有占用资源的时候才能申请资源（申请资源前先释放占有的资源）；</li><li>缺点：很多时候无法预知一个进程所需的全部资源；同时，会降低资源利用率，降低系统的并发性。</li></ul></li><li><p>破坏非抢占条件：允许进程强行抢占被其它进程占有的资源。会降低系统性能；</p></li><li><p>破坏循环等待条件：对所有资源统一编号，所有进程对资源的请求必须按照序号递增的顺序提出，即只有占有了编号较小的资源才能申请编号较大的资源。这样避免了占有大号资源的进程去申请小号资源。</p></li></ul><h2 id="死锁避免"><a href="#死锁避免" class="headerlink" title="死锁避免"></a>死锁避免</h2><blockquote><p>动态地检测资源分配状态，以确保系统处于安全状态，只有处于安全状态时才会进行资源的分配。所谓安全状态是指：即使所有进程突然请求需要的所有资源，也能存在某种对进程的资源分配顺序，使得每一个进程运行完毕。</p></blockquote><h2 id="死锁解除"><a href="#死锁解除" class="headerlink" title="死锁解除"></a>死锁解除</h2><blockquote><p>如何检测死锁：检测有向图是否存在环；或者使用类似死锁避免的检测算法。死锁解除的方法：</p></blockquote><ol><li>利用抢占：挂起某些进程，并抢占它的资源。但应防止某些进程被长时间挂起而处于饥饿状态；</li><li>利用回滚：让某些进程回退到足以解除死锁的地步，进程回退时自愿释放资源。要求系统保持进程的历史信息，设置还原点；</li><li>利用杀死进程：强制杀死某些进程直到死锁解除为止，可以按照优先级进行。</li></ol><h2 id="银行家算法"><a href="#银行家算法" class="headerlink" title="银行家算法"></a>银行家算法</h2><p><strong>概念</strong></p><p>银行家算法（ banker’s algorithm ）由 Dijkstra 于 1965 提出，关键是将死锁的问题演示为一个银行家贷款的模型，由于能用于银行系统的现金贷款而出名。一个银行家向一群客户发放信用卡，每个客户有不同的信用额度。每个客户可以提出信用额度内的任意额度的请求，直到额度用完后再一次性还款。银行家承诺每个客户最终都能获得自己需要的额度。所谓 “最终”，是说银行家可以先挂起某个额度请求较大的客户的请求，优先满足小额度的请求，等小额度的请求还款后，再处理挂起的请求。这样，资金能够永远流通。所以银行家算法其核心是：保证银行家系统的资源数至少不小于一个客户的所需要的资源数。</p><p><strong>算法原理</strong></p><p>银行家算法的基本思想是分配资源之前，判断系统是否是安全的；若是，才分配。每分配一次资源就测试一次是否安全，不是资源全部就位后才测试，注意理解 checkError 函数的循环顺序。</p><p>​ 我们可以把操作系统看作是银行家，操作系统管理的资源相当于银行家管理的资金，进程向操作系统请求分配资源相当于用户向银行家贷款。 为保证资金的安全，银行家规定：</p><ol><li>当一个顾客对资金的最大需求量不超过银行家现有的资金时就可接纳该顾客 (试探性分配)；</li><li>顾客可以分期贷款，但贷款的总数不能超过最大需求量 (可能一次并不能满足所需要的全部资源)；</li><li>当银行家现有的资金不能满足顾客尚需的贷款数额时，对顾客的贷款可推迟支付，但总能使顾客在有限的时间里得到贷款 (不存在死锁)</li><li>当顾客得到所需的全部资金后，一定能在有限的时间里归还所有的资金 (运行后释放)。</li></ol><blockquote><p>操作系统按照银行家制定的规则为进程分配资源，当进程首次申请资源时，要测试该进程对资源的最大需求量，如果系统现存的资源可以满足它的最大需求量则按当前的申请量分配资源，否则就推迟分配。当进程在执行中继续申请资源时，先测试该进程本次申请的资源数是否超过了该资源所剩余的总量。若超过则拒绝分配资源，若能存在安全状态，则按当前的申请量分配资源，否则也要推迟分配。</p></blockquote><pre><code class="bash">  import java.util.Arrays;   import javax.swing.JOptionPane;      public class Banker &#123;       /*     * 资源向量必须全部设置成static，因为可能     * 同一个线程多次输入才满足条件     */    //每个线程需要的资源数   static int max[][] = &#123; &#123; 7, 5, 3 &#125;, &#123; 3, 2, 2 &#125;, &#123; 9, 0, 2 &#125;,     &#123; 2, 2, 2 &#125;, &#123; 4, 3, 3 &#125; &#125;;   //系统可用资源数   static int avaliable[] = &#123;10,5,7&#125;;   //已经分配资源   static int allocation[][] = &#123; &#123; 0, 0, 0 &#125;, &#123; 0, 0, 0 &#125;, &#123; 0, 0, 0 &#125;,      &#123; 0, 0, 0 &#125;, &#123; 0, 0, 0 &#125; &#125;;    //每个进程还需要的资源数,初试一个资源也没分配；实际上应该等于max-avaliable    static int need[][] = Arrays.copyOf(max,max.length);    //每次申请的资源数    static int request[] = &#123; 0, 0, 0 &#125;;    //NUM个线程，N种资源   static final int NUM = 5, N = 3;    static Function function = new Function();       public static void main(String[] args) &#123;      JOptionPane jpane = new JOptionPane();         //是否进行模拟标志，没有布尔，因为从JOpotionpane输入     int flag = 1;            while(1==flag) &#123;        /*         * 用与判断线程号是否合法         * 需要放在while内部，防止下次继续模拟时i还是上次输入的        */        int i = -1;        while(i&lt;0||i&gt;=NUM) &#123;          String str = jpane.showInputDialog(&quot;输入申请资源的线程号(0到4)：&quot;);          i = Integer.parseInt(str);          if(i&lt;0||i&gt;=NUM) &#123;            JOptionPane.showMessageDialog(jpane, &quot;输入的线程号不合法！！！&quot;);          &#125;       &#125;        //资源输入有效性标志       boolean tag = true;         for(int j=0; j&lt;N; j++) &#123;          String str = jpane.showInputDialog(&quot;输入线程&quot;+i+&quot;所申请的资源&quot;+j+&quot;数目：&quot;);          request[j] = Integer.parseInt(str);         //有效性检查        if(request[j]&gt;need[i][j]) &#123;           JOptionPane.showMessageDialog(jpane, &quot;输入的资源数大于需要资源数！！！&quot;);           tag = false;          break;         &#125;else &#123;          if(request[j]&gt;avaliable[j]) &#123;            JOptionPane.showMessageDialog(jpane, &quot;输入的资源数大于可用资源数！！！&quot;);            tag = false;              break;          &#125;         &#125;       &#125;       //是否存在安全序列       boolean vis = true;        if(tag) &#123;          function.allocateK(i);         vis = function.checkError(i);        if(false==vis) &#123;            //上面调用了allocateK，所以不仅需要释放，还需要恢复            function.freeKAndRestore(i);          &#125;else &#123;           //测试是否全部资源到位            boolean f = function.checkRun(i);           if(true==f) &#123;            JOptionPane.showMessageDialog(jpane                 ,&quot;进程&quot;+i+&quot;全部资源到位！！！&quot;+&quot;\n&quot;+&quot;即将释放所占用资源&quot;);             function.freeKNotRestore(i);          &#125;        &#125;      &#125;else &#123;         //实际上没必要清空，因为该数组是输入的，只为了展示一种良好习惯        Arrays.fill(request,0);        &#125;        String str = JOptionPane.showInputDialog(&quot;是否继续模拟(1表示是，0退出)？&quot;);       flag = Integer.parseInt(str);     &#125;  &#125; &#125;   class Function &#123;    /*   * 实际上完全是静态的，没必要新new一个Banker     */  Banker banker = new Banker();    //为线程k分配资源   public void allocateK(int k) &#123;    for(int i=0; i&lt;banker.N; i++) &#123;       banker.avaliable[i] -= banker.request[i];      banker.need[k][i] -= banker.request[i];      banker.allocation[k][i] += banker.request[i];    &#125;   &#125;   public boolean checkError(int i) &#123;     int work = 0;     //存储所有线程是否安全    boolean[] finish = new boolean[banker.NUM];    Arrays.fill(finish,false);    //存储一个安全序列     int temp[] = new int[banker.NUM];    Arrays.fill(temp,0);    //temp数组下标     int t = 0;          //线程号参数是i     for(int j=0; j&lt;banker.N; j++) &#123;       work = banker.avaliable[j];      int k = i;             while(k&lt;banker.NUM) &#123;         if(finish[k]==false&amp;&amp;work&gt;=banker.need[k][j]) &#123;          /*           *  注意不是max数组，因为此时线程k           *  所需资源不一定完全就位           *  加的是allocation，因为进行此项检查前先试探性地            *  分配给线程k资源了           */           //满足该线程，回收该项资源，看是否满足其它线程          work += banker.allocation[k][j];          finish[k] = true;           temp[t++] = k;          k = 0;                   &#125;else &#123;           k++;       &#125;      &#125;       //和while平级       for(int p=0; p&lt;banker.NUM; p++) &#123;         if(finish[p]==false) &#123;          return false;         &#125;      &#125;     &#125;     return true;   &#125;  //释放线程k所占用资源并恢复   public void freeKAndRestore(int k) &#123;    for(int i=0; i&lt;banker.N; i++) &#123;      banker.avaliable[i] += banker.request[i];     banker.need[k][i] += banker.request[i];       banker.allocation[k][i] -= banker.request[i];     &#125;   &#125;   //仅仅释放线程k所占用资源，仅在某线程全部得到资源运行后才调用   public void freeKNotRestore(int k) &#123;    for(int i=0; i&lt;banker.N; i++) &#123;       banker.avaliable[i] = banker.avaliable[i] + banker.allocation[k][i];    &#125;   &#125;   //三种资源是否全部到位   public boolean checkRun(int k) &#123;     int n = 0;     for(int i=0; i&lt;banker.N; i++) &#123;       if (banker.need[k][i] == 0)         n++;     &#125;     if (n == 3)       return true;     else       return false;   &#125;&#125;</code></pre><h2 id="分页和分段有什么区别？"><a href="#分页和分段有什么区别？" class="headerlink" title="分页和分段有什么区别？"></a>分页和分段有什么区别？</h2><ul><li><p>页式存储：用户空间划分为大小相等的部分称为页（page），内存空间划分为同样大小的区域称为页框，分配时以页为单位，按进程需要的页数分配，逻辑上相邻的页物理上不一定相邻。</p></li><li><p>段式存储：用户进程地址空间按照自身逻辑关系划分为若干个段（segment）（如代码段，数据段，堆栈段），内存空间被动态划分为长度不同的区域，分配时以段为单位，每段在内存中占据连续空间，各段可以不相邻。</p></li><li><p>段页式存储：用户进程先按段划分，段内再按页划分，内存划分和分配按页。</p></li></ul><p><strong>区别：</strong></p><ul><li><p>目的不同：分页的目的是管理内存，用于虚拟内存以获得更大的地址空间；分段的目的是满足用户的需要，使程序和数据可以被划分为逻辑上独立的地址空间；</p></li><li><p>大小不同：段的大小不固定，由其所完成的功能决定；页的大小固定，由系统决定；</p></li><li><p>地址空间维度不同：分段是二维地址空间（段号 + 段内偏移），分页是一维地址空间（每个进程一个页表 / 多级页表，通过一个逻辑地址就能找到对应的物理地址）；</p></li><li><p>分段便于信息的保护和共享；分页的共享受到限制；</p></li><li><p>碎片：分段没有内碎片，但会产生外碎片；分页没有外碎片，但会产生内碎片（一个页填不满）。</p></li></ul><h1 id="什么是虚拟内存？"><a href="#什么是虚拟内存？" class="headerlink" title="什么是虚拟内存？"></a>什么是虚拟内存？</h1><p>每个程序都拥有自己的地址空间，这个地址空间被分成大小相等的页，这些页被映射到物理内存，但不需要所有的页都在物理内存中，当程序引用到不在物理内存中的页时，由操作系统将缺失的部分装入物理内存。这样，对于程序来说，逻辑上似乎有很大的内存空间，只是实际上有一部分是存储在磁盘上，因此叫做虚拟内存。</p><p>虚拟内存的优点是让程序可以获得更多的可用内存。</p><p>虚拟内存的实现方式、页表 / 多级页表、缺页中断、不同的页面淘汰算法：答案。</p><h2 id="如何进行地址空间到物理内存的映射？"><a href="#如何进行地址空间到物理内存的映射？" class="headerlink" title="如何进行地址空间到物理内存的映射？"></a>如何进行地址空间到物理内存的映射？</h2><p><strong>内存管理单元（MMU）</strong>管理着逻辑地址和物理地址的转换，其中的页表（Page table）存储着页（逻辑地址）和页框（物理内存空间）的映射表，页表中还包含包含有效位（是在内存还是磁盘）、访问位（是否被访问过）、修改位（内存中是否被修改过）、保护位（只读还是可读写）。逻辑地址：页号 + 页内地址（偏移）。每个进程一个页表，放在内存，页表起始地址在 PCB / 寄存器中。</p><h2 id="有哪些页面置换算法？"><a href="#有哪些页面置换算法？" class="headerlink" title="有哪些页面置换算法？"></a>有哪些页面置换算法？</h2><p>在程序运行过程中，如果要访问的页面不在内存中，就发生缺页中断从而将该页调入内存中。此时如果内存已无空闲空间，系统必须从内存中调出一个页面到磁盘中来腾出空间。页面置换算法的主要目标是使页面置换频率最低（也可以说缺页率最低）。</p><ul><li><p><strong>最佳页面置换算法</strong> OPT（Optimal replacement algorithm）：置换以后不需要或者最远的将来才需要的页面，是一种理论上的算法，是最优策略。</p></li><li><p><strong>先进先出</strong> FIFO：置换在内存中驻留时间最长的页面。缺点：有可能将那些经常被访问的页面也被换出，从而使缺页率升高。</p></li><li><p><strong>第二次机会算法</strong> SCR：按 FIFO 选择某一页面，若其访问位为 1，给第二次机会，并将访问位置 0。</p></li><li><p><strong>时钟算法</strong> Clock：SCR 中需要将页面在链表中移动（第二次机会的时候要将这个页面从链表头移到链表尾），时钟算法使用环形链表，再使用一个指针指向最老的页面，避免了移动页面的开销。</p></li><li><p><strong>最近未使用算法</strong> NRU（Not Recently Used）：检查访问位 R、修改位 M，优先置换 R=M=0，其次是（R=0, M=1）。</p></li><li><p><strong>最近最少使用算法</strong> LRU（Least Recently Used）：置换出未使用时间最长的一页；实现方式：维护时间戳，或者维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。</p></li><li><p>最不经常使用算法 NFU：置换出访问次数最少的页面。</p></li></ul><p><strong>局部性原理</strong></p><ul><li>时间上：最近被访问的页在不久的将来还会被访问；</li><li>空间上：内存中被访问的页周围的页也很可能被访问。</li></ul><p><strong>什么是颠簸现象</strong></p><blockquote><p>颠簸本质上是指频繁的页调度行为。进程发生缺页中断时必须置换某一页。然而，其他所有的页都在使用，它置换一个页，但又立刻再次需要这个页。因此会不断产生缺页中断，导致整个系统的效率急剧下降，这种现象称为颠簸。内存颠簸的解决策略包括：</p></blockquote><ul><li>修改页面置换算法；</li><li>降低同时运行的程序的数量；</li><li>终止该进程或增加物理内存容量。</li></ul><h1 id="缓冲区溢出问题"><a href="#缓冲区溢出问题" class="headerlink" title="缓冲区溢出问题"></a>缓冲区溢出问题</h1><h2 id="什么是缓冲区溢出？"><a href="#什么是缓冲区溢出？" class="headerlink" title="什么是缓冲区溢出？"></a>什么是缓冲区溢出？</h2><p>C 语言使用运行时栈来存储过程信息。每个函数的信息存储在一个栈帧中，包括寄存器、局部变量、参数、返回地址等。C 对于数组引用不进行任何边界检查，因此<strong>对越界的数组元素的写操作会破坏存储在栈中的状态信息</strong>，这种现象称为缓冲区溢出。缓冲区溢出会破坏程序运行，也可以被用来进行攻击计算机，如使用一个指向攻击代码的指针覆盖返回地址。</p><h2 id="缓冲区溢出的防范方式"><a href="#缓冲区溢出的防范方式" class="headerlink" title="缓冲区溢出的防范方式"></a>缓冲区溢出的防范方式</h2><p>防范缓冲区溢出攻击的机制有三种：随机化、栈保护和限制可执行代码区域。</p><ul><li><p>随机化：包括栈随机化（程序开始时在栈上分配一段随机大小的空间）和地址空间布局随机化（Address-Space Layout Randomization，ASLR，即每次运行时程序的不同部分，包括代码段、数据段、栈、堆等都会被加载到内存空间的不同区域），但只能增加攻击一个系统的难度，不能完全保证安全。</p></li><li><p>栈保护：在每个函数的栈帧的局部变量和栈状态之间存储一个随机产生的特殊的值，称为金丝雀值（canary）。在恢复寄存器状态和函数返回之前，程序检测这个金丝雀值是否被改变了，如果是，那么程序异常终止。</p></li><li><p>限制可执行代码区域：内存页的访问形式有三种：可读、可写、可执行，只有编译器产生的那部分代码所处的内存才是可执行的，其他页限制为只允许读和写。</p></li></ul><blockquote><p>更详细的可以参考：<a href="https://imageslr.github.io/2020/07/08/tech-interview.html#stackoverflow"></a></p></blockquote><h1 id="磁盘调度"><a href="#磁盘调度" class="headerlink" title="磁盘调度"></a>磁盘调度</h1><p>过程：磁头（找到对应的盘面）；磁道（一个盘面上的同心圆环，寻道时间）；扇区（旋转时间）。为减小寻道时间的调度算法：</p><ul><li>先来先服务</li><li>最短寻道时间优先</li><li>电梯算法：电梯总是保持一个方向运行，直到该方向没有请求为止，然后改变运行方向。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 操作系统 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 操作系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>工作上常用的linux命令</title>
      <link href="/2021/06/11/os/linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"/>
      <url>/2021/06/11/os/linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="生产服务器变慢，谈谈诊断思路和性能评估？"><a href="#生产服务器变慢，谈谈诊断思路和性能评估？" class="headerlink" title="生产服务器变慢，谈谈诊断思路和性能评估？"></a>生产服务器变慢，谈谈诊断思路和性能评估？</h1><blockquote><p>整机</p></blockquote><pre><code class="bash">//查看整机的系统性能top</code></pre><p><img src="https://cdn.jsdelivr.net/gh/junian455/pic@master/img/73af65c3c2ff47fbbf9a449ed3dc77ef.png"></p><pre><code class="bash">[root@izwz94gb5cfw913042mfyxz ~]# uptime 13:57:06 up 90 days, 17:54,  1 user,  load average: 0.10, 0.31, 0.310.10, 0.31, 0.31。三个值分别代表一分钟，五分钟，十五分钟系统的平均负载值。如果三个值相加除以3乘以100%，大于60%，系统的负担压力中。</code></pre><blockquote><p>CPU </p></blockquote><pre><code class="bash">//每两秒采样一次，攻击采样三次。[root@izwz94gb5cfw913042mfyxz ~]# vmstat -n 2 3procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st 2  0      0 106312   5772 322900    0    0    37    11    0    1  2  1 97  0  0 0  0      0 106328   5772 322932    0    0     0     0 2604 4965  1  1 98  0  0 0  0      0 106204   5796 322932    0    0     0    88 3171 6018  3  2 95  0  0</code></pre><blockquote><p>一般vmstat工具的使用是通过两个数字参数来完成的，第一个参数是采样的时间间隔，间隔单位是秒，第二个参数是采样的次数。</p></blockquote><p><strong>procs</strong></p><blockquote><p>r:运行和等待CPU时间片的进程数，原则上一核的CPU的运行队列不要超过2，整个系统的运行队列不能超过总核数的两倍，否责代表系统压力过大。<br>b:等待资源的进程数。比如正在等待磁盘IO，网络IO等。</p></blockquote><p> <strong>——cpu—–</strong></p><ul><li>us：用户进程消耗CPU时间百分比，us值高，用户进程消耗CPU时间多，如果长期大于50%，优化程序。</li><li>sy：内核进程消耗CPU时间百分比。</li><li>us+sy：参考值80%，如果 us+sy大于80%，说明可能存在CPU不足。</li><li>id:处于空闲的CPU百分比。</li><li>wa:系统等待IO的CPU时间百分比。</li><li>st：来自于一个虚拟机偷取的CPU时间百分比。</li></ul><pre><code class="bash">//查看所有CPU核程信息[root@izwz94gb5cfw913042mfyxz ~]# mpstat -P ALL 2Linux 3.10.0-514.26.2.el7.x86_64 (izwz94gb5cfw913042mfyxz)      10/26/2021      _x86_64_        (2 CPU)02:16:33 PM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle02:16:35 PM  all    1.02    0.00    0.77    0.00    0.00    0.00    0.00    0.00    0.00   98.2102:16:35 PM    0    1.02    0.00    1.02    0.00    0.00    0.00    0.00    0.00    0.00   97.9602:16:35 PM    1    1.53    0.00    0.51    0.00    0.00    0.00    0.00    0.00    0.00   97.96</code></pre><pre><code class="bash">//每个进程使用CPU的用量分解信息[root@izwz94gb5cfw913042mfyxz ~]# pidstat -u 1 -p 1000Linux 3.10.0-514.26.2.el7.x86_64 (izwz94gb5cfw913042mfyxz)      10/26/2021      _x86_64_        (2 CPU)02:19:03 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command</code></pre><blockquote><p>内存</p></blockquote><pre><code class="bash">//free 查看内存，-g单位是g，-m单位是m[root@izwz94gb5cfw913042mfyxz ~]# free              total        used        free      shared  buff/cache   availableMem:        1777920     1345096      103748      130532      329076      131808Swap:             0           0           0[root@izwz94gb5cfw913042mfyxz ~]# free -g              total        used        free      shared  buff/cache   availableMem:              1           1           0           0           0           0Swap:             0           0           0[root@izwz94gb5cfw913042mfyxz ~]# free -m              total        used        free      shared  buff/cache   availableMem:           1736        1313          94         127         327         128Swap:             0           0           0应用程序可用内存/系统物理内存小于20%需要加内存。//5101 进程号，2。每两秒采样一次  。  查看额外[root@izwz94gb5cfw913042mfyxz ~]# pidstat -p 5101 -r 2Linux 3.10.0-514.26.2.el7.x86_64 (izwz94gb5cfw913042mfyxz)      10/26/2021      _x86_64_        (2 CPU)02:25:05 PM   UID       PID  minflt/s  majflt/s     VSZ    RSS   %MEM  Command</code></pre><blockquote><p>硬盘</p></blockquote><pre><code class="bash">//查看磁盘剩余空间数[root@izwz94gb5cfw913042mfyxz ~]#  df -hFilesystem      Size  Used Avail Use% Mounted on/dev/vda1        59G   11G   46G  19% /devtmpfs        859M     0  859M   0% /devtmpfs           869M     0  869M   0% /dev/shmtmpfs           869M   89M  780M  11% /runtmpfs           869M     0  869M   0% /sys/fs/cgrouptmpfs           174M     0  174M   0% /run/user/0tmpfs           174M     0  174M   0% /run/user/1002overlay          59G   11G   46G  19% /var/lib/docker/overlay2/2e1d41bb84f9fb99cd59fb8a23a1109a2bf5dbd0a75c77d47028411aa5c3df9c/mergedoverlay          59G   11G   46G  19% /var/lib/docker/overlay2/19d0ccd3a8704a753a8d25ef12a055b2947b072c3c4410ffb8ba4944fbec96f5/mergedoverlay          59G   11G   46G  19% /var/lib/docker/overlay2/a7c285fe5d2c560484b414c7fe3dd30e7c661152f1ddda05cba98e9b7f899b0a/mergedoverlay          59G   11G   46G  19% /var/lib/docker/overlay2/ab386309e81e650160b4f2367db497b1516e200d5e3b76f2720bd6907771407b/merged</code></pre><blockquote><p>磁盘IO</p></blockquote><pre><code class="bash">//参数 -d 表示，显示设备（磁盘）使用状态；-k某些使用block为单位的列强制使用Kilobytes为单位；1 10表示，数据显示每隔1秒刷新一次，共显示10次。使用-x参数表示获取更多统计信息。[root@izwz94gb5cfw913042mfyxz ~]# iostat -xdk 2 3Linux 3.10.0-514.26.2.el7.x86_64 (izwz94gb5cfw913042mfyxz)      10/26/2021      _x86_64_        (2 CPU)Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %utilvda               0.13     2.90    2.64    1.70    73.20    20.91    43.41     0.04    9.88   15.52    1.12   0.22   0.10Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %utilvda               0.00     0.00   18.50    0.00    82.00     0.00     8.86     0.02    1.22    1.22    0.00   0.05   0.10Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %utilvda               0.00     0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00    0.00    0.00   0.00   0.00util 长期高于 80%以上 磁盘数据过高，多半情况跟数据库读写有关，需要查看复杂的大 sqlrrqm/s: 每秒进行 merge 的读操作数目。即 delta(rmerge)/swrqm/s: 每秒进行 merge 的写操作数目。即 delta(wmerge)/sr/s: 每秒完成的读 I/O 设备次数。即 delta(rio)/sw/s: 每秒完成的写 I/O 设备次数。即 delta(wio)/srsec/s: 每秒读扇区数。即 delta(rsect)/swsec/s: 每秒写扇区数。即 delta(wsect)/srkB/s: 每秒读K字节数。是 rsect/s 的一半，因为每扇区大小为512字节。wkB/s: 每秒写K字节数。是 wsect/s 的一半。avgrq-sz: 平均每次设备I/O操作的数据大小 (扇区)。即 delta(rsect+wsect)/delta(rio+wio)avgqu-sz: 平均I/O队列长度。即 delta(aveq)/s/1000 (因为aveq的单位为毫秒)。await: 平均每次设备I/O操作的等待时间 (毫秒)。即 delta(ruse+wuse)/delta(rio+wio)svctm: 平均每次设备I/O操作的服务时间 (毫秒)。即 delta(use)/delta(rio+wio)%util: 一秒中有百分之多少的时间用于 I/O 操作，或者说一秒中有多少时间 I/O 队列是非空的。即 delta(use)/s/1000 (因为use的单位为毫秒)</code></pre><blockquote><p>网络IO</p></blockquote><pre><code class="bash">[root@izwz94gb5cfw913042mfyxz ~]# ifstat 1</code></pre><h1 id="假如生产环境出现CPU占用过高，谈谈分析思路以及定位"><a href="#假如生产环境出现CPU占用过高，谈谈分析思路以及定位" class="headerlink" title="假如生产环境出现CPU占用过高，谈谈分析思路以及定位"></a>假如生产环境出现CPU占用过高，谈谈分析思路以及定位</h1><ol><li>先用top命令找出cpu占用最高的</li><li>痛过ps -ef 或者jps 进一步定位，得知是一个怎样的后台程序给我们惹事。</li><li>定位到具体线程。 ps -mp 进程ID -o THREAD,tid,time</li><li>将线程ID转换为16进制格式（英文小写格式）(linux命令printf ‘0x%x’ tid)</li><li>jstack 进程ID|grep tid(16进制线程ID小写英文) -A60</li></ol><pre><code class="bash"> 1. 先用top命令找出cpu占用最高的   PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                                  4087 root      20   0   90524   3204   2348 S   0.3  0.1   0:52.84 rngd                                    28982 root      20   0 3266512 492616  24724 S   0.3 12.7  42:05.41 java  2. 痛过ps -ef 或者jps 进一步定位，得知是一个怎样的后台程序给我们惹事。 //定位到具体进程ID [root@fxiyun2_11_52 ~]# jps -l29106 xxl-job-admin-2.3.0.jar30706 sun.tools.jps.Jps28982 /home/jars/com.cncbox.catalog/com.cncbox.catalog.jar[root@fxiyun2_11_52 ~]# ps -ef|grep java|grep -v greproot     28982     1  0 10月21 ?      00:42:06 /bin/java -Dsun.misc.URLClassPath.disableJarChecking=true -server -Xms215m -Xmx512m -Djava.io.tmpdir=/home/jars/com.cncbox.catalog/logs/ -jar /home/jars/com.cncbox.catalog/com.cncbox.catalog.jar --spring.profiles.active=testroot     29106     1  0 10月21 ?      00:13:58 java -jar xxl-job-admin-2.3.0.jar 3. 定位到具体线程 -m 显示所有的线程 -p pid进程使用CPU的时间 -o 该参数后是用户自定义格式 [root@fxiyun2_11_52 ~]# ps -mp 28982 -o THREAD,tid,timeUSER     %CPU PRI SCNT WCHAN  USER SYSTEM   TID     TIMEroot      0.5   -    - -         -      -     - 00:42:07root      0.0  19    - futex_    -      - 28982 00:00:00root      0.0  19    - futex_    -      - 28984 00:00:15root      0.0  19    - futex_    -      - 28985 00:00:30root      0.0  19    - futex_    -      - 28986 00:00:00root      0.0  19    - futex_    -      - 28987 00:00:00root      0.0  19    - futex_    -      - 28988 00:00:00root      0.0  19    - futex_    -      - 28989 00:01:45root      0.0  19    - futex_    -      - 28990 00:00:39root      0.3  19    - futex_    -      - 29006 00:28:38[root@fxiyun2_11_52 ~]# jstack 28982|grep 714e -A60&quot;com.alibaba.nacos.client.Worker.fixed-10.12.1.162_8848-test&quot; #16 daemon prio=5 os_prio=0 cpu=1719405.56ms elapsed=451712.78s tid=0x00007fdf9438c000 nid=0x714e waiting on condition  [0x00007fdf41d14000]   java.lang.Thread.State: TIMED_WAITING (parking)        at jdk.internal.misc.Unsafe.park(java.base@11-ea/Native Method)        - parking to wait for  &lt;0x00000000e076c518&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)        at java.util.concurrent.locks.LockSupport.parkNanos(java.base@11-ea/LockSupport.java:234)        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(java.base@11-ea/AbstractQueuedSynchronizer.java:2123)        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(java.base@11-ea/ScheduledThreadPoolExecutor.java:1182)        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(java.base@11-ea/ScheduledThreadPoolExecutor.java:899)        at java.util.concurrent.ThreadPoolExecutor.getTask(java.base@11-ea/ThreadPoolExecutor.java:1054)        at java.util.concurrent.ThreadPoolExecutor.runWorker(java.base@11-ea/ThreadPoolExecutor.java:1114)        at java.util.concurrent.ThreadPoolExecutor$Worker.run(java.base@11-ea/ThreadPoolExecutor.java:628)        at java.lang.Thread.run(java.base@11-ea/Thread.java:834)</code></pre>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>RabbitMQ高级特性</title>
      <link href="/2021/05/22/mq/RabbitMQ%20%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7/"/>
      <url>/2021/05/22/mq/RabbitMQ%20%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="RabbitMQ-是什么？"><a href="#RabbitMQ-是什么？" class="headerlink" title="RabbitMQ 是什么？"></a>RabbitMQ 是什么？</h1><p>RabbitMQ 是实现了高级消息队列协议（<font color="red">AMQP</font>）的开源消息代理软件（亦称面向消息的中间件）。RabbitMQ 服务器是用 Erlang 语言编写的，而群集和故障转移是构建在开放电信平台框架上的。所有主要的编程语言均有与代理接口通讯的客户端库。</p><p>PS: 也可能直接问什么是消息队列？消息队列就是一个使用队列来通信的组件。</p><h1 id="RabbitMQ-特点？"><a href="#RabbitMQ-特点？" class="headerlink" title="RabbitMQ 特点？"></a>RabbitMQ 特点？</h1><p>1.可靠性: RabbitMQ 使用一些机制来保证可靠性， 如持久化、传输确认及发布确认等。</p><ol start="2"><li><p>灵活的路由 : 在消息进入队列之前，通过交换器来路由消息。对于典型的路由功能， RabbitMQ 己经提供了一些内置的交换器来实现。针对更复杂的路由功能，可以将多个 交换器绑定在一起， 也可以通过插件机制来实现自己的交换器。</p></li><li><p>扩展性: 多个 RabbitMQ 节点可以组成一个集群，也可以根据实际业务情况动态地扩展 集群中节点。</p></li><li><p>高可用性 : 队列可以在集群中的机器上设置镜像，使得在部分节点出现问题的情况下队 列仍然可用。</p></li><li><p>多种协议: RabbitMQ 除了原生支持 AMQP 协议，还支持 STOMP， MQTT 等多种消息 中间件协议。</p></li><li><p>多语言客户端 :RabbitMQ 几乎支持所有常用语言，比如 Java、 Python、 Ruby、 PHP、 C#、 JavaScript 等。</p></li><li><p>管理界面 : RabbitMQ 提供了一个易用的用户界面，使得用户可以监控和管理消息、集 群中的节点等。</p></li><li><p>插件机制 : RabbitMQ 提供了许多插件 ， 以实现从多方面进行扩展，当然也可以编写自 己的插件。</p></li></ol><h1 id="AMQP-是什么？"><a href="#AMQP-是什么？" class="headerlink" title="AMQP 是什么？"></a>AMQP 是什么？</h1><p>RabbitMQ 就是 AMQP 协议的 Erlang 的实现 (当然 RabbitMQ 还支持 STOMP2、 MQTT3 等协议 ) AMQP 的模型架构 和 RabbitMQ 的模型架构是一样的，生产者将消息发送给交换器，交换器和队列绑定 。</p><p>RabbitMQ 中的交换器、交换器类型、队列、绑定、路由键等都是遵循的 AMQP 协议中相 应的概念。目前 RabbitMQ 最新版本默认支持的是 AMQP 0-9-1。</p><h1 id="AMQP-协议-3-层？"><a href="#AMQP-协议-3-层？" class="headerlink" title="AMQP 协议 3 层？"></a>AMQP 协议 3 层？</h1><p>Module Layer: 协议最高层，主要定义了一些客户端调用的命令，客户端可以用这些命令实现自己的业务逻辑。</p><p>Session Layer: 中间层，主要负责客户端命令发送给服务器，再将服务端应答返回客户端，提供可靠性同步机制和错误处理。</p><p>TransportLayer: 最底层，主要传输二进制数据流，提供帧的处理、信道服用、错误检测和数据表示等。</p><h1 id="AMQP-模型的几大组件？"><a href="#AMQP-模型的几大组件？" class="headerlink" title="AMQP 模型的几大组件？"></a>AMQP 模型的几大组件？</h1><p>交换器 (Exchange)：消息代理服务器中用于把消息路由到队列的组件。<br>队列 (Queue)：用来存储消息的数据结构，位于硬盘或内存中。<br>绑定 (Binding)：一套规则，告知交换器消息应该将消息投递给哪个队列。</p><h1 id="说说生产者-Producer-和消费者-Consumer"><a href="#说说生产者-Producer-和消费者-Consumer" class="headerlink" title="说说生产者 Producer 和消费者 Consumer?"></a>说说生产者 Producer 和消费者 Consumer?</h1><p>生产者</p><ul><li>消息生产者，就是投递消息的一方。</li><li>消息一般包含两个部分：消息体（payload) 和标签 (Label)。</li></ul><p>消费者</p><ul><li>消费消息，也就是接收消息的一方。</li><li>消费者连接到 RabbitMQ 服务器，并订阅到队列上。消费消息时只消费消息体，丢弃标签。</li></ul><h1 id="为什么需要消息队列？"><a href="#为什么需要消息队列？" class="headerlink" title="为什么需要消息队列？"></a>为什么需要消息队列？</h1><p>从本质上来说是因为互联网的快速发展，业务不断扩张，促使技术架构需要不断的演进。</p><p>从以前的单体架构到现在的微服务架构，成百上千的服务之间相互调用和依赖。从互联网初期一个服务器上有 100 个在线用户已经很了不得，到现在坐拥 10 亿日活的微信。此时，我们需要有一个「工具」来解耦服务之间的关系、控制资源合理合时的使用以及缓冲流量洪峰等等。因此，消息队列就应运而生了。</p><p>它常用来实现：<font color="red">异步处理、服务解耦、流量控制（削峰）</font>。</p><h1 id="说说-Broker-服务节点、Queue-队列、Exchange-交换器？"><a href="#说说-Broker-服务节点、Queue-队列、Exchange-交换器？" class="headerlink" title="说说 Broker 服务节点、Queue 队列、Exchange 交换器？"></a>说说 Broker 服务节点、Queue 队列、Exchange 交换器？</h1><ul><li>Broker 可以看做 RabbitMQ 的服务节点。一般请下一个 Broker 可以看做一个 RabbitMQ 服务器。</li><li>Queue:RabbitMQ 的内部对象，用于存储消息。多个消费者可以订阅同一队列，这时队列中的消息会被平摊（轮询）给多个消费者进行处理。</li><li>Exchange: 生产者将消息发送到交换器，由交换器将消息路由到一个或者多个队列中。当路由不到时，或返回给生产者或直接丢弃。</li></ul><h1 id="消息队列有什么优缺点"><a href="#消息队列有什么优缺点" class="headerlink" title="消息队列有什么优缺点"></a>消息队列有什么优缺点</h1><p>优点上面已经说了，就是在特殊场景下有其对应的好处，解耦、异步、削峰。缺点有以下几个：</p><ul><li>系统可用性降低 系统引入的外部依赖越多，越容易挂掉。万一 MQ 挂了，MQ 一挂，整套系统崩 溃，你不就完了？</li><li>系统复杂度提高 硬生生加个 MQ 进来，你怎么保证消息没有重复消费？怎么处理消息丢失的情况？</li><li>怎么保证消息传递的顺序性？问题一大堆。</li><li>一致性问题 A 系统处理完了直接返回成功了，人都以为你这个请求就成功了；但是问题是，要是 BCD 三个系统那里，BD 两个系统写库成功了，结果 C 系统写库失败了，咋整？你这数据就不一致了。</li></ul><h1 id="如何保证消息的可靠性？"><a href="#如何保证消息的可靠性？" class="headerlink" title="如何保证消息的可靠性？"></a>如何保证消息的可靠性？</h1><p>消息到 MQ 的过程中搞丢，MQ 自己搞丢，MQ 到消费过程中搞丢。</p><p><font color="red">生产者到RabbitMQ</font>：事务机制和 Confirm 机制，注意：事务机制和 Confirm 机制是互斥的，两者不能共存，会导致 RabbitMQ 报错。</p><p><font color="red">RabbitMQ自身</font>：持久化、集群、普通模式、镜像模式。</p><p><font color="red">RabbitMQ到消费者</font>：basicAck 机制、死信队列、消息补偿机制。</p><h1 id="什么是-RoutingKey-路由键？"><a href="#什么是-RoutingKey-路由键？" class="headerlink" title="什么是 RoutingKey 路由键？"></a>什么是 RoutingKey 路由键？</h1><p>生产者将消息发送给交换器的时候，会指定一个 RoutingKey, 用来指定这个消息的路由规则，这个 RoutingKey 需要与交换器类型和绑定键 (BindingKey) 联合使用才能最终生效。</p><h1 id="Binding-绑定？"><a href="#Binding-绑定？" class="headerlink" title="Binding 绑定？"></a>Binding 绑定？</h1><p>通过绑定将交换器和队列关联起来，一般会指定一个 BindingKey, 这样 RabbitMq 就知道如何正确路由消息到队列了。</p><h1 id="交换器-4-种类型？"><a href="#交换器-4-种类型？" class="headerlink" title="交换器 4 种类型？"></a>交换器 4 种类型？</h1><p>主要有以下 4 种。</p><ul><li>fanout: 把所有发送到该交换器的消息路由到所有与该交换器绑定的队列中。</li><li>direct: 把消息路由到 BindingKey 和 RoutingKey 完全匹配的队列中。</li><li>topic:</li><li>匹配规则：</li></ul><pre><code class="bash">RoutingKey` 为一个 点号&#39;.&#39;: 分隔的字符串。比如: `java.xiaoka.show</code></pre><p>BindingKey 和 RoutingKey 一样也是点号 “.“分隔的字符串。</p><p>BindingKey 可使用 * 和 # 用于做模糊匹配，* 匹配一个单词，# 匹配多个或者 0 个</p><p>headers: 不依赖路由键匹配规则路由消息。是根据发送消息内容中的 headers 属性进行匹配。性能差，基本用不到。</p><h1 id="生产者消息运转？"><a href="#生产者消息运转？" class="headerlink" title="生产者消息运转？"></a>生产者消息运转？</h1><ol><li><p>Producer 先连接到 Broker, 建立连接 Connection, 开启一个信道 (Channel)。</p></li><li><p>Producer 声明一个交换器并设置好相关属性。</p></li><li><p>Producer 声明一个队列并设置好相关属性。</p></li><li><p>Producer 通过路由键将交换器和队列绑定起来。</p></li><li><p>Producer 发送消息到 Broker, 其中包含路由键、交换器等信息。</p></li><li><p>相应的交换器根据接收到的路由键查找匹配的队列。</p></li><li><p>如果找到，将消息存入对应的队列，如果没有找到，会根据生产者的配置丢弃或者退回给生产者。</p></li><li><p>关闭信道。</p></li><li><p>管理连接。</p></li></ol><h1 id="消费者接收消息过程？"><a href="#消费者接收消息过程？" class="headerlink" title="消费者接收消息过程？"></a>消费者接收消息过程？</h1><ol><li><p>Producer 先连接到 Broker, 建立连接 Connection, 开启一个信道 (Channel)。</p></li><li><p>向 Broker 请求消费响应的队列中消息，可能会设置响应的回调函数。</p></li><li><p>待 Broker 回应并投递相应队列中的消息，接收消息。</p></li><li><p>消费者确认收到的消息，ack。</p></li><li><p>RabbitMq 从队列中删除已经确定的消息。</p></li><li><p>关闭信道。</p></li><li><p>关闭连接。</p></li></ol><h1 id="交换器无法根据自身类型和路由键找到符合条件队列时，有哪些处理？"><a href="#交换器无法根据自身类型和路由键找到符合条件队列时，有哪些处理？" class="headerlink" title="交换器无法根据自身类型和路由键找到符合条件队列时，有哪些处理？"></a>交换器无法根据自身类型和路由键找到符合条件队列时，有哪些处理？</h1><ul><li>mandatory ：true 返回消息给生产者。</li><li>mandatory: false 直接丢弃。</li></ul><h1 id="死信队列？"><a href="#死信队列？" class="headerlink" title="死信队列？"></a>死信队列？</h1><p>  DLX，全称为 Dead-Letter-Exchange，死信交换器，死信邮箱。当消息在一个队列中变成死信 (dead message) 之后，它能被重新被发送到另一个交换器中，这个交换器就是 DLX，绑定 DLX 的队列就称之为死信队列。</p><h1 id="导致的死信的几种原因？"><a href="#导致的死信的几种原因？" class="headerlink" title="导致的死信的几种原因？"></a>导致的死信的几种原因？</h1><ul><li>消息被拒（Basic.Reject /Basic.Nack) 且 requeue = false。</li><li>消息 TTL 过期。</li><li>队列满了，无法再添加。</li></ul><h1 id="延迟队列？"><a href="#延迟队列？" class="headerlink" title="延迟队列？"></a>延迟队列？</h1><p>存储对应的延迟消息，指当消息被发送以后，并不想让消费者立刻拿到消息，而是等待特定时间后，消费者才能拿到这个消息进行消费。</p><h1 id="优先级队列？"><a href="#优先级队列？" class="headerlink" title="优先级队列？"></a>优先级队列？</h1><p>优先级高的队列会先被消费。<br>可以通过 x-max-priority 参数来实现。<br>当消费速度大于生产速度且 Broker 没有堆积的情况下，优先级显得没有意义。</p><h1 id="事务机制？"><a href="#事务机制？" class="headerlink" title="事务机制？"></a>事务机制？</h1><p>RabbitMQ 客户端中与事务机制相关的方法有三个:</p><ol><li><p>channel.txSelect 用于将当前的信道设置成事务模式。</p></li><li><p>channel . txCommit 用于提交事务 。</p></li><li><p>channel . txRollback 用于事务回滚，如果在事务提交执行之前由于 RabbitMQ 异常崩溃或者其他原因抛出异常，通过 txRollback 来回滚。</p></li></ol><h1 id="发送确认机制？"><a href="#发送确认机制？" class="headerlink" title="发送确认机制？"></a>发送确认机制？</h1><p>生产者把信道设置为 confirm 确认模式，设置后，所有再改信道发布的消息都会被指定一个唯一的 ID，一旦消息被投递到所有匹配的队列之后，RabbitMQ 就会发送一个确认（Basic.Ack) 给生产者（包含消息的唯一 ID)，这样生产者就知道消息到达对应的目的地了。</p><h1 id="消费者获取消息的方式？"><a href="#消费者获取消息的方式？" class="headerlink" title="消费者获取消息的方式？"></a>消费者获取消息的方式？</h1><ul><li>推</li><li>拉<br>消费者某些原因无法处理当前接受的消息如何来拒绝？<br>channel .basicNack channel .basicReject</li></ul><h1 id="消息传输保证层级？"><a href="#消息传输保证层级？" class="headerlink" title="消息传输保证层级？"></a>消息传输保证层级？</h1><ul><li><p>At most once: 最多一次。消息可能会丢失，但不会重复传输。</p></li><li><p>At least once：最少一次。消息绝不会丢失，但可能会重复传输。</p></li><li><p>Exactly once: 恰好一次，每条消息肯定仅传输一次。</p></li></ul><h1 id="了解-Virtual-Host-吗？"><a href="#了解-Virtual-Host-吗？" class="headerlink" title="了解 Virtual Host 吗？"></a>了解 Virtual Host 吗？</h1><p>每一个 RabbitMQ 服务器都能创建虚拟的消息服务器，也叫虚拟主机 (virtual host)，简称 vhost。默认为 “/”。</p><h1 id="集群中的节点类型？"><a href="#集群中的节点类型？" class="headerlink" title="集群中的节点类型？"></a>集群中的节点类型？</h1><ul><li><p>内存节点：ram, 将变更写入内存。</p></li><li><p>磁盘节点：disc, 磁盘写入操作。</p></li><li><p>RabbitMQ 要求最少有一个磁盘节点。</p></li></ul><h1 id="队列结构？"><a href="#队列结构？" class="headerlink" title="队列结构？"></a>队列结构？</h1><p>通常由以下两部分组成？</p><ol><li><p>rabbit_amqqueue_process: 负责协议相关的消息处理，即接收生产者发布的消息、向消费者交付消息、处理消息的确认 (包括生产端的 confirm 和消费端的 ack) 等。</p></li><li><p>backing_queue: 是消息存储的具体形式和引擎，并向 rabbit amqqueue process 提供相关的接口以供调用。</p></li></ol><h1 id="RabbitMQ-中消息可能有的几种状态？"><a href="#RabbitMQ-中消息可能有的几种状态？" class="headerlink" title="RabbitMQ 中消息可能有的几种状态？"></a>RabbitMQ 中消息可能有的几种状态？</h1><ul><li><p>alpha: 消息内容 (包括消息体、属性和 headers) 和消息索引都存储在内存中 。</p></li><li><p>beta: 消息内容保存在磁盘中，消息索引保存在内存中。</p></li><li><p>gamma: 消息内容保存在磁盘中，消息索引在磁盘和内存中都有 。</p></li><li><p>delta: 消息内容和索引都在磁盘中 。</p></li></ul><h1 id="在何种场景下使用了消息中间件？"><a href="#在何种场景下使用了消息中间件？" class="headerlink" title="在何种场景下使用了消息中间件？"></a>在何种场景下使用了消息中间件？</h1><ul><li>接口之间耦合比较严重</li><li>面对大流量并发时，容易被冲垮</li><li>存在性能问题</li></ul><h1 id="生产者如何将消息可靠投递到-MQ？"><a href="#生产者如何将消息可靠投递到-MQ？" class="headerlink" title="生产者如何将消息可靠投递到 MQ？"></a>生产者如何将消息可靠投递到 MQ？</h1><ol><li><p>Client 发送消息给 MQ；</p></li><li><p>MQ 将消息持久化后，发送 Ack 消息给 Client，此处有可能因为网络问题导致 Ack 消息无法发送到 Client，那么 Client 在等待超时后，会重传消息；</p></li><li><p>Client 收到 Ack 消息后，认为消息已经投递成功。</p></li></ol><h1 id="MQ-如何将消息可靠投递到消费者？"><a href="#MQ-如何将消息可靠投递到消费者？" class="headerlink" title="MQ 如何将消息可靠投递到消费者？"></a>MQ 如何将消息可靠投递到消费者？</h1><ol><li><p>MQ 将消息 push 给 Client（或 Client 来 pull 消息）</p></li><li><p>Client 得到消息并做完业务逻辑</p></li><li><p>Client 发送 Ack 消息给 MQ，通知 MQ 删除该消息，此处有可能因为网络问题导致 Ack 失败，那么 Client 会重复消息，这里就引出消费幂等的问题；</p></li><li><p>MQ 将已消费的消息删除</p></li></ol><h1 id="如何保证-RabbitMQ-消息队列的高可用？"><a href="#如何保证-RabbitMQ-消息队列的高可用？" class="headerlink" title="如何保证 RabbitMQ 消息队列的高可用？"></a>如何保证 RabbitMQ 消息队列的高可用？</h1><p>RabbitMQ 有三种模式：<font color="red">单机模式，普通集群模式，镜像集群模式</font>。</p><ol><li><p>单机模式：就是 demo 级别的，一般就是你本地启动了玩玩儿的，没人生产用单机模式。</p></li><li><p>普通集群模式：意思就是在多台机器上启动多个 RabbitMQ 实例，每个机器启动一个。</p></li><li><p>镜像集群模式：这种模式，才是所谓的 RabbitMQ 的高可用模式，跟普通集群模式不一样的是，你创建的 queue，无论元数据 (元数据指 RabbitMQ 的配置数据) 还是 queue 里的消息都会存在于多个实例上，然后每次你写消息到 queue 的时候，都会自动把消息到多个实例的 queue 里进行消息同步。</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> MQ消息队列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 消息中间件 </tag>
            
            <tag> RabbitMQ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RabbitMQ</title>
      <link href="/2021/05/03/mq/RabbitMQ/"/>
      <url>/2021/05/03/mq/RabbitMQ/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="RabbitMQ"><a href="#RabbitMQ" class="headerlink" title="RabbitMQ"></a>RabbitMQ</h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>MQ 的相关概念<br>什么是 MQ<br>MQ (message queue)，从字面意思上看，本质是个队列，FIFO 先入先出，只不过队列中存放的内容是 message 而已，还是一种跨进程的通信机制，用于上下游传递消息。在互联网架构中，MQ 是一种非常常见的上下游 “逻辑解耦 + 物理解耦” 的消息通信服务。使用了 MQ 之后，消息发送上游只需要依赖 MQ，不 用依赖其他服务。</p><p>为什么要用 MQ<br>流量消峰</p><p>举个例子，如果订单系统最多能处理一万次订单，这个处理能力应付正常时段的下单时绰绰有余，正常时段我们下单一秒后就能返回结果。但是在高峰期，如果有两万次下单操作系统是处理不了的，只能限制订单超过一万后不允许用户下单。使用消息队列做缓冲，我们可以取消这个限制，把一秒内下的订单分散成一段时间来处理，这时有些用户可能在下单十几秒后才能收到下单成功的操作，但是比不能下单的体验要好。</p><p>应用解耦</p><p>以电商应用为例，应用中有订单系统、库存系统、物流系统、支付系统。用户创建订单后，如果耦合调用库存系统、物流系统、支付系统，任何一个子系统出了故障，都会造成下单操作异常。当转变成基于消息队列的方式后，系统间调用的问题会减少很多，比如物流系统因为发生故障，需要几分钟来修复。在 这几分钟的时间里，物流系统要处理的内存被缓存在消息队列中，用户的下单操作可以正常完成。当物流系统恢复后，继续处理订单信息即可，中单用户感受不到物流系统的故障，提升系统的可用性。</p><p>RabbitMQ-00000004</p><p>异步处理</p><p>有些服务间调用是异步的，例如 A 调用 B，B 需要花费很长时间执行，但是 A 需要知道 B 什么时候可以执行完。</p><p>以前一般有两种方式，A 过一段时间去调用 B 的查询 api 查询。或者 A 提供一个 callback api，B 执行完之后调用 api 通知 A 服务。这两种方式都不是很优雅。</p><p>使用消息总线，可以很方便解决这个问题， A 调用 B 服务后，只需要监听 B 处理完成的消息，当 B 处理完成后，会发送一条消息给 MQ，MQ 会将此消息转发给 A 服务。这样 A 服务既不用循环调用 B 的查询 api，也不用提供 callback api。同样 B 服务也不用做这些操作，A 服务还能及时的得到异步处理成功的消息。</p><p>RabbitMQ-00000005</p><p>MQ 的分类<br>ActiveMQ<br>优点：单机吞吐量万级，时效性 ms 级，可用性高，基于主从架构实现高可用性，较低的概率丢失数据。</p><p>缺点：官方社区现在对 ActiveMQ 5.x 维护越来越少，高吞吐量场景较少使用。</p><p>Kafka<br>大数据的杀手锏，谈到大数据领域内的消息传输，则绕不开 Kafka，这款为大数据而生的消息中间件，以其百万级 TPS 的吞吐量名声大噪，迅速成为大数据领域的宠儿，在数据采集、传输、存储的过程中发挥着举足轻重的作用。目前已经被 LinkedIn，Uber, Twitter, Netflix 等大公司所采纳。</p><p>优点：性能卓越，单机写入 TPS 约在百万条 / 秒，最大的优点，就是吞吐量高。时效性 ms 级，可用性非常高，kafka 是分布式的，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用，消费者采用 Pull 方式获取消息，消息有序，通过控制能够保证所有消息被消费且仅被消费一次；有优秀的第三方 Kafka Web 管理界面 Kafka-Manager；在日志领域比较成熟，被多家公司和多个开源项目使用；功能支持：功能较为简单，主要支持简单的 MQ 功能，在大数据领域的实时计算以及日志采集被大规模使用。</p><p>缺点：Kafka 单机超过 64 个队列 / 分区，Load 会发生明显的飙高现象，队列越多，load 越高，发送消息响应时间变长，使用短轮询方式，实时性取决于轮询间隔时间，消费失败不支持重试；支持消息顺序，但是一台代理宕机后，就会产生消息乱序，社区更新较慢。</p><p>RocketMQ<br>RocketMQ 出自阿里巴巴的开源产品，用 Java 语言实现，在设计时参考了 Kafka，并做出了自己的一 些改进。被阿里巴巴广泛应用在订单，交易，充值，流计算，消息推送，日志流式处理，binglog 分发等场景。</p><p>优点：单机吞吐量十万级，可用性非常高，分布式架构，消息可以做到 0 丢失，MQ 功能较为完善，还是分布式的，扩展性好，支持 10 亿级别的消息堆积，不会因为堆积导致性能下降。</p><p>缺点：支持的客户端语言不多，目前是 java 及 c++，其中 c++ 不成熟；社区活跃度一般，没有在 MQ 核心中去实现 JMS 等接口，有些系统要迁移需要修改大量代码。</p><p>RabbitMQ<br>2007 年发布，是一个在 AMQP (高级消息队列协议) 基础上完成的，可复用的企业消息系统，是当前最主流的消息中间件之一。</p><p>优点：由于 erlang 语言的高并发特性，性能较好；吞吐量到万级，MQ 功能比较完备，健壮、稳定、易用、跨平台、支持多种语言。如：Python、Ruby、.NET、Java、JMS、C、PHP、ActionScript、XMPP、STOMP 等，AJAX 文档齐全；开源提供的管理界面非常棒，用起来很好用，社区活跃度高；更新频率相当高。</p><p>缺点：商业版需要收费，学习成本较高。</p><p>MQ 的选择<br>Kafka</p><p>Kafka 主要特点是基于 Pull 的模式来处理消息消费，追求高吞吐量，一开始的目的就是用于日志收集和传输，适合产生大量数据的互联网服务的数据收集业务。大型公司建议可以选用，如果有日志采集功能，肯定是首选 kafka 了。</p><p>RocketMQ</p><p>天生为金融互联网领域而生，对于可靠性要求很高的场景，尤其是电商里面的订单扣款，以及业务削峰，在大量交易涌入时，后端可能无法及时处理的情况。RoketMQ 在稳定性上可能更值得信赖，这些业务场景在阿里双 11 已经经历了多次考验，如果你的业务有上述并发场景，建议可以选择 RocketMQ。</p><p>RabbitMQ</p><p>结合 erlang 语言本身的并发优势，性能好时效性微秒级，社区活跃度也比较高，管理界面用起来十分方便，如果你的数据量没有那么大，中小型公司优先选择功能比较完备的 RabbitMQ。</p><p>RabbitMQ<br>RabbitMQ 的概念<br>RabbitMQ 是一个消息中间件，它接受并转发消息。你可以把它当做一个快递站点，当你要发送一个包裹时，你把你的包裹放到快递站，快递员最终会把你的快递送到收件人那里，按照这种逻辑 RabbitMQ 是 一个快递站，一个快递员帮你传递快件。</p><p>RabbitMQ 与快递站的主要区别在于，它不处理快件而是接收，存储和转发消息数据。</p><p>image-20210625230930992</p><p>四大核心概念<br>生产者：产生数据发送消息的程序。</p><p>交换机：是 RabbitMQ 非常重要的一个部件，一方面它接收来自生产者的消息，另一方面它将消息推送到队列中。交换机必须确切知道如何处理它接收到的消息，是将这些消息推送到特定队列还是推送到多个队列，亦或者是把消息丢弃，这个得有交换机类型决定。</p><p>队列：队列是 RabbitMQ 内部使用的一种数据结构，尽管消息流经 RabbitMQ 和应用程序，但它们只能存储在队列中。队列仅受主机的内存和磁盘限制的约束，本质上是一个大的消息缓冲区。许多生产者可以将消息发送到一个队列，许多消费者可以尝试从一个队列接收数据。</p><p>消费者：大多时候是一个等待接收消息的程序。请注意生产者，消费者和消息中间件很多时候并不在同一机器上。同一个应用程序既可以是生产者又是可以是消费者。</p><p>各个名词介绍</p><p>RabbitMQ-00000007</p><p>Broker：接收和分发消息的应用，RabbitMQ Server 就是 Message Broker。</p><p>Virtual host：出于多用户和安全因素设计的，把 AMQP 的基本组件划分到一个虚拟的分组中，类似于网络中的 namespace 概念。当多个不同的用户使用同一个 RabbitMQ server 提供的服务时，可以划分出多个 vhost，每个用户在自己的 vhost 创建 exchange／queue 等。</p><p>Connection：publisher／consumer 和 broker 之间的 TCP 连接。</p><p>Channel：如果每一次访问 RabbitMQ 都建立一个 Connection，在消息量大的时候建立 TCP Connection 的开销将是巨大的，效率也较低。Channel 是在 connection 内部建立的逻辑连接，如果应用程序支持多线程，通常每个 thread 创建单独的 channel 进行通讯，AMQP method 包含了 channel id 帮助客户端和 message broker 识别 channel，所以 channel 之间是完全隔离的。Channel 作为轻量级的 Connection 极大减少了操作系统建立 TCP connection 的开销。</p><p>Exchange：message 到达 broker 的第一站，根据分发规则，匹配查询表中的 routing key，分发消息到 queue 中去。常用的类型有：direct (point-to-point), topic (publish-subscribe) and fanout (multicast)。</p><p>Queue：消息最终被送到这里等待 consumer 取走。</p><p>Binding：exchange 和 queue 之间的虚拟连接，binding 中可以包含 routing key，Binding 信息被保存到 exchange 中的查询表中，用于 message 的分发依据。</p><p>Linux 安装<br>安装 RabbitMQ<br>1、下载</p><p>官网下载地址：<a href="https://www.rabbitmq.com/download.html">https://www.rabbitmq.com/download.html</a></p><p>这里选择的版本号（注意这两版本要求）</p><p>rabbitmq-server-3.8.8-1.el7.noarch.rpm</p><p>GitHub：<a href="https://github.com/rabbitmq/rabbitmq-server/releases/tag/v3.8.8">https://github.com/rabbitmq/rabbitmq-server/releases/tag/v3.8.8</a></p><p>加载下载：<a href="https://packagecloud.io/rabbitmq/rabbitmq-server/packages/el/7/rabbitmq-server-3.8.8-1.el7.noarch.rpm">https://packagecloud.io/rabbitmq/rabbitmq-server/packages/el/7/rabbitmq-server-3.8.8-1.el7.noarch.rpm</a></p><p>erlang-21.3.8.21-1.el7.x86_64.rpm</p><p>官网：<a href="https://www.erlang-solutions.com/downloads/">https://www.erlang-solutions.com/downloads/</a></p><p>加速：<a href="https://packagecloud.io/rabbitmq/erlang/packages/el/7/erlang-21.3.8.21-1.el7.x86_64.rpm">https://packagecloud.io/rabbitmq/erlang/packages/el/7/erlang-21.3.8.21-1.el7.x86_64.rpm</a></p><p>2、安装</p><p>上传到 /usr/local/software 目录下 (如果没有 software 需要自己创建)</p><p>SH<br>1<br>2<br>3<br>rpm -ivh erlang-21.3.8.21-1.el7.x86_64.rpm<br>yum install socat -y<br>rpm -ivh rabbitmq-server-3.8.8-1.el7.noarch.rpm<br>3、启动</p><p>SH<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10</p><h1 id="启动服务"><a href="#启动服务" class="headerlink" title="启动服务"></a>启动服务</h1><p>systemctl start rabbitmq-server</p><h1 id="查看服务状态"><a href="#查看服务状态" class="headerlink" title="查看服务状态"></a>查看服务状态</h1><p>systemctl status rabbitmq-server</p><h1 id="开机自启动"><a href="#开机自启动" class="headerlink" title="开机自启动"></a>开机自启动</h1><p>systemctl enable rabbitmq-server</p><h1 id="停止服务"><a href="#停止服务" class="headerlink" title="停止服务"></a>停止服务</h1><p>systemctl stop rabbitmq-server</p><h1 id="重启服务"><a href="#重启服务" class="headerlink" title="重启服务"></a>重启服务</h1><p>systemctl restart rabbitmq-server<br>Web 管理界面及授权操作<br>1、安装</p><p>默认情况下，是没有安装 web 端的客户端插件，需要安装才可以生效：</p><p>SH<br>1<br>rabbitmq-plugins enable rabbitmq_management<br>安装完毕以后，重启服务即可：</p><p>SH<br>1<br>systemctl restart rabbitmq-server<br>访问 <a href="http://42.192.149.71:15672/">http://42.192.149.71:15672</a> ，用默认账号密码 (guest) 登录，出现权限问题。默认情况只能在 localhost 本机下访问，所以需要添加一个远程登录的用户</p><p>2、添加用户</p><p>SH<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10</p><h1 id="创建账号和密码"><a href="#创建账号和密码" class="headerlink" title="创建账号和密码"></a>创建账号和密码</h1><p>rabbitmqctl add_user admin 123456</p><h1 id="设置用户角色"><a href="#设置用户角色" class="headerlink" title="设置用户角色"></a>设置用户角色</h1><p>rabbitmqctl set_user_tags admin administrator</p><h1 id="为用户添加资源权限"><a href="#为用户添加资源权限" class="headerlink" title="为用户添加资源权限"></a>为用户添加资源权限</h1><h1 id="set-permissions-p"><a href="#set-permissions-p" class="headerlink" title="set_permissions [-p ]    "></a>set_permissions [-p <vhostpath>] <user> <conf> <write> <read></h1><p>rabbitmqctl set_permissions -p “/“ admin “.<em>“ “.</em>“ “.*”</p><h1 id="添加配置、写、读权限"><a href="#添加配置、写、读权限" class="headerlink" title="添加配置、写、读权限"></a>添加配置、写、读权限</h1><p>用户级别：</p><p>administrator：可以登录控制台、查看所有信息、可以对 rabbitmq 进行管理。<br>monitoring：监控者 登录控制台，查看所有信息。<br>policymaker：策略制定者 登录控制台，指定策略。<br>managment：普通管理员 登录控制台。<br>再次登录，用 admin 用户。</p><p>关闭应用的命令为：rabbitmqctl stop_app</p><p>清除的命令为：rabbitmqctl reset</p><p>重新启动命令为：rabbitmqctl start_app</p><p>Hello world<br>在下图中，“P” 是生产者，“ C” 是消费者。中间的框是一个队列 RabbitMQ 代表使用者保留的消息缓冲区。</p><p>RabbitMQ-00000012</p><p>连接的时候，需要开启 5672 端口。</p><p>image-20210626162052259</p><p>依赖</p><p>pom.xml：</p><pre><code class="bash">&lt;!--指定 jdk 编译版本--&gt;&lt;build&gt;    &lt;plugins&gt;        &lt;plugin&gt;            &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;            &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;            &lt;configuration&gt;                &lt;source&gt;8&lt;/source&gt;                &lt;target&gt;8&lt;/target&gt;            &lt;/configuration&gt;        &lt;/plugin&gt;    &lt;/plugins&gt;&lt;/build&gt;&lt;dependencies&gt;    &lt;!--rabbitmq 依赖客户端--&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.rabbitmq&lt;/groupId&gt;        &lt;artifactId&gt;amqp-client&lt;/artifactId&gt;        &lt;version&gt;5.8.0&lt;/version&gt;    &lt;/dependency&gt;    &lt;!--操作文件流的一个依赖--&gt;    &lt;dependency&gt;        &lt;groupId&gt;commons-io&lt;/groupId&gt;        &lt;artifactId&gt;commons-io&lt;/artifactId&gt;        &lt;version&gt;2.6&lt;/version&gt;    &lt;/dependency&gt;&lt;/dependencies&gt;</code></pre><p>消息生产者</p><p>发送消息：</p><pre><code class="bash">package com.oddfar.one;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;/** * @author zhiyuan */public class Producer &#123;    private final static String QUEUE_NAME = &quot;hello&quot;;    public static void main(String[] args) throws Exception &#123;        //创建一个连接工厂        ConnectionFactory factory = new ConnectionFactory();        factory.setHost(&quot;42.192.149.71&quot;);        factory.setUsername(&quot;admin&quot;);        factory.setPassword(&quot;123456&quot;);        //channel 实现了自动 close 接口 自动关闭 不需要显示关闭        //创建连接        Connection connection = factory.newConnection();        //获取信道        Channel channel = connection.createChannel();        /**         * 生成一个队列         * 1.队列名称         * 2.队列里面的消息是否持久化 也就是是否用完就删除         * 3.该队列是否只供一个消费者进行消费 是否进行共享 true 可以多个消费者消费         * 4.是否自动删除 最后一个消费者端开连接以后 该队列是否自动删除 true 自动删除         * 5.其他参数         */        channel.queueDeclare(QUEUE_NAME, false, false, false, null);        String message = &quot;hello world&quot;;        /**         * 发送一个消息         * 1.发送到那个交换机         * 2.路由的 key 是哪个         * 3.其他的参数信息         * 4.发送消息的消息体         */        channel.basicPublish(&quot;&quot;, QUEUE_NAME, null, message.getBytes());        System.out.println(&quot;消息发送完毕&quot;);    &#125;    &#125;消息消费者获取 “生产者” 发出的消息：```bashpackage com.oddfar.one;import com.rabbitmq.client.*;/** * @author zhiyuan */public class Consumer &#123;    private final static String QUEUE_NAME = &quot;hello&quot;;    public static void main(String[] args) throws Exception &#123;        ConnectionFactory factory = new ConnectionFactory();        factory.setHost(&quot;42.192.149.71&quot;);        factory.setUsername(&quot;admin&quot;);        factory.setPassword(&quot;123456&quot;);        Connection connection = factory.newConnection();        Channel channel = connection.createChannel();        System.out.println(&quot;等待接收消息.........&quot;);        //推送的消息如何进行消费的接口回调        DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; &#123;            String message = new String(delivery.getBody());            System.out.println(message);        &#125;;        //取消消费的一个回调接口 如在消费的时候队列被删除掉了        CancelCallback cancelCallback = (consumerTag) -&gt; &#123;            System.out.println(&quot;消息消费被中断&quot;);        &#125;;        /**         * 消费者消费消息 - 接受消息         * 1.消费哪个队列         * 2.消费成功之后是否要自动应答 true 代表自动应答 false 手动应答         * 3.消费者未成功消费的回调         * 4.消息被取消时的回调         */        channel.basicConsume(QUEUE_NAME, true, deliverCallback, cancelCallback);    &#125;&#125;</code></pre><h1 id="Work-Queues"><a href="#Work-Queues" class="headerlink" title="Work Queues"></a>Work Queues</h1><p>Work Queues— 工作队列 (又称任务队列) 的主要思想是避免立即执行资源密集型任务，而不得不等待它完成。我们把任务封装为消息并将其发送到队列，在后台运行的工作进程将弹出任务并最终执行作业。当有多个工作线程时，这些工作线程将一起处理这些任务。</p><p>轮训分发消息<br>在这个案例中我们会启动两个工作线程，一个消息发送线程，我们来看看他们两个工作线程是如何工作的。</p><ol><li>抽取工具类</li></ol><pre><code class="bash">package com.oddfar.utils;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;public class RabbitMqUtils &#123;    //得到一个连接的 channel    public static Channel getChannel() throws Exception &#123;        //创建一个连接工厂        ConnectionFactory factory = new ConnectionFactory();        factory.setHost(&quot;42.192.149.71&quot;);        factory.setUsername(&quot;admin&quot;);        factory.setPassword(&quot;123456&quot;);        Connection connection = factory.newConnection();        Channel channel = connection.createChannel();        return channel;    &#125;&#125;</code></pre><ol start="2"><li>启动两个工作线程来接受消息</li></ol><pre><code class="bash">package com.oddfar.two;import com.oddfar.utils.RabbitMqUtils;import com.rabbitmq.client.CancelCallback;import com.rabbitmq.client.Channel;import com.rabbitmq.client.DeliverCallback;/** * 这是一个工作线程，相当于之前的消费者 * * @author zhiyuan */public class Worker01 &#123;    private static final String QUEUE_NAME = &quot;hello&quot;;    public static void main(String[] args) throws Exception &#123;        Channel channel = RabbitMqUtils.getChannel();        //消息接受        DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; &#123;            String receivedMessage = new String(delivery.getBody());            System.out.println(&quot;接收到消息:&quot; + receivedMessage);        &#125;;        //消息被取消        CancelCallback cancelCallback = (consumerTag) -&gt; &#123;            System.out.println(consumerTag + &quot;消费者取消消费接口回调逻辑&quot;);        &#125;;        System.out.println(&quot;C1 消费者启动等待消费.................. &quot;);        channel.basicConsume(QUEUE_NAME, true, deliverCallback, cancelCallback);    &#125;&#125;</code></pre><p>选中 Allow multiple instances：</p><p>image-20210627125840217</p><p>启动后：</p><p>image-20210627130146584</p><p>3、启动一个发送消息线程</p><pre><code class="bash">public class Task01 &#123;    public static final String QUEUE_NAME = &quot;hello&quot;;    public static void main(String[] args) throws Exception &#123;        Channel channel = RabbitMqUtils.getChannel();        Scanner scanner = new Scanner(System.in);        while (scanner.hasNext()) &#123;            String message = scanner.next();            channel.basicPublish(&quot;&quot;, QUEUE_NAME, null, message.getBytes());            System.out.println(&quot;消息发送完成：&quot; + message);        &#125;    &#125;&#125;</code></pre><p>结果展示</p><p>通过程序执行发现生产者总共发送 4 个消息，消费者 1 和消费者 2 分别分得两个消息，并且是按照有序的一个接收一次消息。</p><p>RabbitMQ-00000016</p><p>消息应答<br>消费者完成一个任务可能需要一段时间，如果其中一个消费者处理一个长的任务并仅只完成了部分突然它挂掉了，会发生什么情况。</p><p>RabbitMQ 一旦向消费者传递了一条消息，便立即将该消息标记为删除。在这种情况下，突然有个消费者挂掉了，我们将丢失正在处理的消息，以及后续发送给该消费者的消息，因为它无法接收到。</p><p>为了保证消息在发送过程中不丢失，引入消息应答机制，消息应答就是：消费者在接收到消息并且处理该消息之后，告诉 rabbitmq 它已经处理了，rabbitmq 可以把该消息删除了。</p><p>自动应答<br>消息发送后立即被认为已经传送成功，这种模式需要在高吞吐量和数据传输安全性方面做权衡，因为这种模式如果消息在接收到之前，消费者那边出现连接或者 channel 关闭，那么消息就丢失了。当然另一方面这种模式消费者那边可以传递过载的消息，没有对传递的消息数量进行限制，当然这样有可能使得消费者这边由于接收太多还来不及处理的消息，导致这些消息的积压，使得内存耗尽，最终这些消费者线程被操作系统杀死，所以这种模式仅适用在消费者可以高效并以某种速率能够处理这些消息的情况下使用。</p><p>手动消息应答的方法<br>Channel.basicAck (用于肯定确认)：RabbitMQ 已知道该消息成功被处理，可以将其丢弃了。</p><p>Channel.basicNack (用于否定确认)</p><p>Channel.basicReject (用于否定确认)：与 Channel.basicNack 相比少一个参数，不处理该消息了直接拒绝，可以将其丢弃了。</p><p>Multiple 的解释：</p><p>手动应答的好处是可以批量应答并且减少网络拥堵 。</p><p>RabbitMQ-00000017</p><p>true 代表批量应答 channel 上未应答的消息：比如说 channel 上有传送 tag 的消息 5、6、7、8， 当前 tag 是 8 那么此时 5-8 的这些还未应答的消息都会被确认收到消息应答。</p><p>false 同上面相比只会应答 tag=8 的消息， 5、6、7 这三个消息依然不会被确认收到消息应答。</p><p>RabbitMQ-00000018</p><p>消息自动重新入队<br>如果消费者由于某些原因失去连接 (其通道已关闭，连接已关闭或 TCP 连接丢失)，导致消息未发送 ACK 确认，RabbitMQ 将了解到消息未完全处理，并将对其重新排队。如果此时其他消费者可以处理，它将很快将其重新分发给另一个消费者。这样，即使某个消费者偶尔死亡，也可以确保不会丢失任何消息。</p><p>RabbitMQ-00000019</p><p>消息手动应答代码<br>默认消息采用的是自动应答，所以我们要想实现消息消费过程中不丢失，需要把自动应答改为手动应答。</p><p>消费者在上面代码的基础上增加了以下内容：</p><p>JAVA<br>1<br>channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false);<br>消息生产者：</p><pre><code class="bash">package com.oddfar.three;import com.oddfar.utils.RabbitMqUtils;import com.rabbitmq.client.Channel;import java.util.Scanner;/** * 消息生产者,消息在手动应答时是不丢失的，放回队列重新消费。 * * @author zhiyuan */public class Task02 &#123;    private static final String TASK_QUEUE_NAME = &quot;ack_queue&quot;;    public static void main(String[] args) throws Exception &#123;        Channel channel = RabbitMqUtils.getChannel();        //声明队列        channel.queueDeclare(TASK_QUEUE_NAME, false, false, false, null);        Scanner sc = new Scanner(System.in);        System.out.println(&quot;请输入信息&quot;);        while (sc.hasNext()) &#123;            String message = sc.nextLine();            //发布消息            channel.basicPublish(&quot;&quot;, TASK_QUEUE_NAME, null, message.getBytes(&quot;UTF-8&quot;));            System.out.println(&quot;生产者发出消息&quot; + message);        &#125;    &#125;&#125;</code></pre><p>消费者 01：</p><pre><code class="bash">package com.oddfar.three;import com.oddfar.utils.RabbitMqUtils;import com.rabbitmq.client.CancelCallback;import com.rabbitmq.client.Channel;import com.rabbitmq.client.DeliverCallback;/** * 消费者01 * * @author jun */public class Work03 &#123;    private static final String TASK_QUEUE_NAME = &quot;ack_queue&quot;;    public static void main(String[] args) throws Exception &#123;        Channel channel = RabbitMqUtils.getChannel();        System.out.println(&quot;C1 等待接收消息处理时间较 短&quot;);        DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; &#123;            String message = new String(delivery.getBody());            try &#123;                Thread.sleep(1000);            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;            System.out.println(&quot;接收到消息:&quot; + message);            /**             * 1.消息标记 tag             * 2.是否批量应答未应答消息             */            channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false);        &#125;;        CancelCallback cancelCallback = (s) -&gt; &#123;            System.out.println(s + &quot;消费者取消消费接口回调逻辑&quot;);        &#125;;        //采用手动应答        boolean autoAck = false;        channel.basicConsume(TASK_QUEUE_NAME, autoAck, deliverCallback, cancelCallback);    &#125;&#125;</code></pre><p>消费者 02：把睡眠时间改成 30 秒。</p><p>正常情况下消息发送方发送两个消息，C1 和 C2 分别接收到消息并进行处理。</p><p>image-20210714222013729</p><p>在发送者发送消息 dd，发出消息之后的把 C2 消费者停掉，按理说该 C2 来处理该消息，但是由于它处理时间较长，在还未处理完，也就是说 C2 还没有执行 ack 代码的时候，C2 被停掉了，此时会看到消息被 C1 接收到了，说明消息 dd 被重新入队，然后分配给能处理消息的 C1 处理了。</p><p>RabbitMQ-00000022</p><p>RabbitMQ-00000023</p><p>RabbitMQ-00000024</p><p>RabbitMQ 持久化<br>当 RabbitMQ 服务停掉以后，消息生产者发送过来的消息不丢失要如何保障？默认情况下 RabbitMQ 退出或由于某种原因崩溃时，它忽视队列和消息，除非告知它不要这样做。确保消息不会丢失需要做两件事：我们需要将队列和消息都标记为持久化。</p><p>队列如何实现持久化</p><p>之前创建的队列都是非持久化的，rabbitmq 如果重启的话，该队列就会被删除掉，如果要队列实现持久化需要在声明队列的时候把 durable 参数设置为持久化。</p><pre><code class="bash">//让队列持久化boolean durable = true;//声明队列channel.queueDeclare(TASK_QUEUE_NAME, durable, false, false, null);注意：如果之前声明的队列不是持久化的，需要把原先队列先删除，或者重新创建一个持久化的队列，不然就会出现错误。</code></pre><p>RabbitMQ-00000026</p><p>以下为控制台中持久化与非持久化队列的 UI 显示区、</p><p>RabbitMQ-00000027</p><p>消息实现持久化需要在消息生产者修改代码，MessageProperties.PERSISTENT_TEXT_PLAIN 添加这个属性。</p><p>RabbitMQ-00000028</p><p>将消息标记为持久化并不能完全保证不会丢失消息。尽管它告诉 RabbitMQ 将消息保存到磁盘，但是这里依然存在当消息刚准备存储在磁盘的时候但是还没有存储完，消息还在缓存的一个间隔点。此时并没有真正写入磁盘。持久性保证并不强，但是对于我们的简单任务队列而言，这已经绰绰有余了。</p><p>不公平分发<br>问题</p><p>在最开始的时候我们学习到 RabbitMQ 分发消息采用的轮训分发，但是在某种场景下这种策略并不是很好，比方说有两个消费者在处理任务，其中有个消费者 1 处理任务的速度非常快，而另外一个消费者 2 处理速度却很慢，这个时候我们还是采用轮训分发的化就会到这处理速度快的这个消费者很大一部分时间处于空闲状态，而处理慢的那个消费者一直在干活，这种分配方式在这种情况下其实就不太好，但是 RabbitMQ 并不知道这种情况它依然很公平的进行分发。</p><p>为了避免这种情况，在消费者中消费之前，我们可以设置参数 channel.basicQos(1);</p><pre><code class="bash">//不公平分发int prefetchCount = 1;channel.basicQos(prefetchCount);//采用手动应答boolean autoAck = false;channel.basicConsume(TASK_QUEUE_NAME, autoAck, deliverCallback, cancelCallback);</code></pre><p>RabbitMQ-00000030</p><p>image-20210714222609107</p><p>意思就是如果这个任务我还没有处理完或者我还没有应答你，你先别分配给我，我目前只能处理一个任务，然后 rabbitmq 就会把该任务分配给没有那么忙的那个空闲消费者，当然如果所有的消费者都没有完 成手上任务，队列还在不停的添加新任务，队列有可能就会遇到队列被撑满的情况，这个时候就只能添加新的 worker 或者改变其他存储任务的策略。</p><p>预取值分发<br>带权的消息分发</p><p>本身消息的发送就是异步发送的，所以在任何时候，channel 上肯定不止只有一个消息，另外来自消费者的手动确认本质上也是异步的。因此这里就存在一个未确认的消息缓冲区，因此希望开发人员能限制此缓冲区的大小，以避免缓冲区里面无限制的未确认消息问题。这个时候就可以通过使用 basic.qos 方法设 置 “预取计数” 值来完成的。</p><p>该值定义通道上允许的未确认消息的最大数量。一旦数量达到配置的数量， RabbitMQ 将停止在通道上传递更多消息，除非至少有一个未处理的消息被确认，例如，假设在通道上有未确认的消息 5、6、7，8，并且通道的预取计数设置为 4，此时 RabbitMQ 将不会在该通道上再传递任何消息，除非至少有一个未应答的消息被 ack。比方说 tag=6 这个消息刚刚被确认 ACK，RabbitMQ 将会感知 这个情况到并再发送一条消息。消息应答和 QoS 预取值对用户吞吐量有重大影响。</p><p>通常，增加预取值将提高向消费者传递消息的速度。虽然自动应答传输消息速率是最佳的，但是，在这种情况下已传递但尚未处理的消息的数量也会增加，从而增加了消费者的 RAM 消耗。应该小心使用具有无限预处理的自动确认模式或手动确认模式，消费者消费了大量的消息如果没有确认的话，会导致消费者连接节点的内存消耗变大，所以找到合适的预取值是一个反复试验的过程，不同的负载该值取值也不同 100 到 300 范 围内的值通常可提供最佳的吞吐量，并且不会给消费者带来太大的风险。</p><p>预取值为 1 是最保守的。当然这将使吞吐量变得很低，特别是消费者连接延迟很严重的情况下，特别是在消费者连接等待时间较长的环境 中。对于大多数应用来说，稍微高一点的值将是最佳的。</p><p>RabbitMQ-00000032</p><p>发布确认<br>发布确认逻辑<br>生产者将信道设置成 confirm 模式，一旦信道进入 confirm 模式，所有在该信道上面发布的消息都将会被指派一个唯一的 ID (从 1 开始)，一旦消息被投递到所有匹配的队列之后，broker 就会发送一个确认给生产者 (包含消息的唯一 ID)，这就使得生产者知道消息已经正确到达目的队列了，如果消息和队列是可持久化的，那么确认消息会在将消息写入磁盘之后发出，broker 回传给生产者的确认消息中 delivery-tag 域包含了确认消息的序列号，此外 broker 也可以设置 basic.ack 的 multiple 域，表示到这个序列号之前的所有消息都已经得到了处理。</p><p>confirm 模式最大的好处在于它是异步的，一旦发布一条消息，生产者应用程序就可以在等信道返回确认的同时继续发送下一条消息，当消息最终得到确认之后，生产者应用便可以通过回调方法来处理该确认消息，如果 RabbitMQ 因为自身内部错误导致消息丢失，就会发送一条 nack 消息， 生产者应用程序同样可以在回调方法中处理该 nack 消息。</p><p>发布确认的策略<br>开启发布确认的方法：发布确认默认是没有开启的，如果要开启，需要调用方法 confirmSelect，每当你要想使用发布确认，都需要在 channel 上调用该方法。</p><p>JAVA<br>1<br>2<br>//开启发布确认<br>channel.confirmSelect();<br>单个确认发布<br>这是一种简单的确认方式，它是一种同步确认发布的方式，也就是发布一个消息之后只有它被确认发布，后续的消息才能继续发布，waitForConfirmsOrDie(long) 这个方法只有在消息被确认的时候才返回，如果在指定时间范围内这个消息没有被确认那么它将抛出异常。</p><p>这种确认方式有一个最大的缺点就是：发布速度特别的慢，因为如果没有确认发布的消息就会阻塞所有后续消息的发布，这种方式最多提供每秒不超过数百条发布消息的吞吐量。当然对于某些应用程序来说这可能已经足够了。</p><pre><code class="bash">/** * 单个发送 */public static void publishMessageIndividually() throws Exception &#123;    Channel channel = RabbitMqUtils.getChannel();    //队列声明    String queueName = UUID.randomUUID().toString();    channel.queueDeclare(queueName, true, false, false, null);    //开启发布确认    channel.confirmSelect();    long begin = System.currentTimeMillis();    for (int i = 0; i &lt; MESSAGE_COUNT; i++) &#123;        String message = i + &quot;&quot;;        channel.basicPublish(&quot;&quot;, queueName, null, message.getBytes());        //服务端返回 false 或超时时间内未返回，生产者可以消息重发        boolean flag = channel.waitForConfirms();        if (flag) &#123;            System.out.println(&quot;消息发送成功&quot;);        &#125;    &#125;    long end = System.currentTimeMillis();    System.out.println(&quot;发布&quot; + MESSAGE_COUNT + &quot;个单独确认消息,耗时&quot; + (end - begin) + &quot;ms&quot;);&#125;</code></pre><p>批量确认发布<br>上面那种方式非常慢，与单个等待确认消息相比，先发布一批消息然后一起确认可以极大地提高吞吐量，当然这种方式的缺点就是：当发生故障导致发布出现问题时，不知道是哪个消息出问题了，我们必须将整个批处理保存在内存中，以记录重要的信息而后重新发布消息。当然这种方案仍然是同步的，也一样阻塞消息的发布。</p><pre><code class="bash">/** * 批量 */public static void publishMessageBatch() throws Exception &#123;    Channel channel = RabbitMqUtils.getChannel();    //队列声明    String queueName = UUID.randomUUID().toString();    channel.queueDeclare(queueName, true, false, false, null);    //开启发布确认    channel.confirmSelect();    //批量确认消息大小    int batchSize = 100;    //未确认消息个数    int outstandingMessageCount = 0;    long begin = System.currentTimeMillis();    for (int i = 0; i &lt; MESSAGE_COUNT; i++) &#123;        String message = i + &quot;&quot;;        channel.basicPublish(&quot;&quot;, queueName, null, message.getBytes());        outstandingMessageCount++;        if (outstandingMessageCount == batchSize) &#123;            channel.waitForConfirms();            outstandingMessageCount = 0;        &#125;    &#125;    //为了确保还有剩余没有确认消息 再次确认    if (outstandingMessageCount &gt; 0) &#123;        channel.waitForConfirms();    &#125;    long end = System.currentTimeMillis();    System.out.println(&quot;发布&quot; + MESSAGE_COUNT + &quot;个批量确认消息,耗时&quot; + (end - begin) + &quot;ms&quot;);&#125;</code></pre><p>异步确认发布<br>异步确认虽然编程逻辑比上两个要复杂，但是性价比最高，无论是可靠性还是效率都没得说， 它是利用回调函数来达到消息可靠性传递的，这个中间件也是通过函数回调来保证是否投递成功， 下面就让我们来详细讲解异步确认是怎么实现的。</p><p>RabbitMQ-00000034</p><p>如何处理异步未确认消息？</p><p>最好的解决方案就是把未确认的消息放到一个基于内存的能被发布线程访问的队列， 比如说用 ConcurrentLinkedQueue 这个队列在 confirm callbacks 与发布线程之间进行消息的传递。</p><p>以上 3 种发布确认速度对比 :</p><p>单独发布消息：同步等待确认，简单，但吞吐量非常有限。</p><p>批量发布消息：批量同步等待确认，简单，合理的吞吐量，一旦出现问题但很难推断出是哪条消息出现了问题。</p><p>异步处理：最佳性能和资源使用，在出现错误的情况下可以很好地控制，但是实现起来稍微难些。</p><p>绑定 bindings<br>什么是 bingding 呢，binding 其实是 exchange 和 queue 之间的桥梁，它告诉我们 exchange 和哪个队列进行了绑定关系。比如说下面这张图告诉我们的就是 X 与 Q1 和 Q2 进行了绑定。</p><p>image-20210715090437837</p><p>image-20210715090506348</p><p>Exchanges<br>RabbitMQ 消息传递模型的核心思想是: 生产者生产的消息从不会直接发送到队列。实际上，通常生产者甚至都不知道这些消息传递传递到了哪些队列中。</p><p>相反，** 生产者只能将消息发送到交换机 (exchange)**，交换机工作的内容非常简单，一方面它接收来自生产者的消息，另一方面将它们推入队列。交换机必须确切知道如何处理收到的消息，是应该把这些消息放到特定队列还是说把他们放到许多队列中还是说应该丢弃它们。这就的由交换机的类型来决定。</p><p>RabbitMQ-00000035</p><p>Exchanges 的类型：</p><p>直接 (direct)<br>主题 (topic)<br>标题 (headers)<br>扇出 (fanout)<br>Fanout exchange<br>Fanout 介绍<br>Fanout 这种类型非常简单。正如从名称中猜到的那样，它是将接收到的所有消息广播到它知道的所有队列中。</p><p>RabbitMQ-00000039</p><p>Fanout 实战</p><p>RabbitMQ-00000040</p><p>Logs 和临时队列的绑定关系如下图：</p><p>RabbitMQ-00000041</p><p>为了说明这种模式，我们将构建一个简单的日志系统。它将由两个程序组成：第一个程序将发出日志消息，第二个程序是消费者。其中我们会启动两个消费者，其中一个消费者接收到消息后把日志存储在磁盘。</p><p>ReceiveLogs01 将接收到的消息打印在控制台：</p><pre><code class="bash">package com.oddfar.five;import com.oddfar.utils.RabbitMqUtils;import com.rabbitmq.client.Channel;import com.rabbitmq.client.DeliverCallback;/** * @author zhiyuan */public class ReceiveLogs01 &#123;    private static final String EXCHANGE_NAME = &quot;logs&quot;;    public static void main(String[] args) throws Exception &#123;        Channel channel = RabbitMqUtils.getChannel();        channel.exchangeDeclare(EXCHANGE_NAME, &quot;fanout&quot;);        /**         * 生成一个临时的队列 队列的名称是随机的         * 当消费者断开和该队列的连接时 队列自动删除         */        String queueName = channel.queueDeclare().getQueue();        //把该临时队列绑定我们的 exchange 其中 routingkey(也称之为 binding key)为空字符串        channel.queueBind(queueName, EXCHANGE_NAME, &quot;&quot;);        System.out.println(&quot;等待接收消息,把接收到的消息打印在屏幕........... &quot;);        //发送回调        DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; &#123;            String message = new String(delivery.getBody(), &quot;UTF-8&quot;);            System.out.println(&quot;控制台打印接收到的消息&quot; + message);        &#125;;        channel.basicConsume(queueName, true, deliverCallback, consumerTag -&gt; &#123;&#125;);    &#125;&#125;</code></pre><blockquote><p>ReceiveLogs02 把消息写出到文件：</p></blockquote><pre><code class="bash">public class ReceiveLogs02 &#123;    private static final String EXCHANGE_NAME = &quot;logs&quot;;    public static void main(String[] args) throws Exception &#123;        Channel channel = RabbitMqUtils.getChannel();        channel.exchangeDeclare(EXCHANGE_NAME, &quot;fanout&quot;);        /**         * 生成一个临时的队列 队列的名称是随机的         * 当消费者断开和该队列的连接时 队列自动删除         */        String queueName = channel.queueDeclare().getQueue();        //把该临时队列绑定我们的 exchange 其中 routingkey(也称之为 binding key)为空字符串        channel.queueBind(queueName, EXCHANGE_NAME, &quot;&quot;);        System.out.println(&quot;等待接收消息,把接收到的消息写到文件........... &quot;);        //发送回调        DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; &#123;            String message = new String(delivery.getBody(), &quot;UTF-8&quot;);            File file = new File(&quot;D:\\test\\rabbitmq_info.txt&quot;);            FileUtils.writeStringToFile(file,message,&quot;UTF-8&quot;);            System.out.println(&quot;数据写入文件成功&quot;);        &#125;;        channel.basicConsume(queueName, true, deliverCallback, consumerTag -&gt; &#123;&#125;);    &#125;&#125;</code></pre><p>EmitLog 发送消息给两个消费者接收：</p><pre><code class="bash">public class EmitLog &#123;    private static final String EXCHANGE_NAME = &quot;logs&quot;;    public static void main(String[] args) throws Exception &#123;        Channel channel = RabbitMqUtils.getChannel();        /**         * 声明一个 exchange         * 1.exchange 的名称         * 2.exchange 的类型         */        channel.exchangeDeclare(EXCHANGE_NAME, &quot;fanout&quot;);        Scanner sc = new Scanner(System.in);        System.out.println(&quot;请输入信息&quot;);        while (sc.hasNext()) &#123;            String message = sc.nextLine();            channel.basicPublish(EXCHANGE_NAME, &quot;&quot;, null, message.getBytes(&quot;UTF-8&quot;));            System.out.println(&quot;生产者发出消息&quot; + message);        &#125;    &#125;    &#125;Direct exchange在本节我们将向其中添加一些特别的功能 — 让某个消费者订阅发布的部分消息。例如我们只把严重错误消息定向存储到日志文件 (以节省磁盘空间)，同时仍然能够在控制台上打印所有日志消息。Direct 介绍上一节中的我们的日志系统将所有消息广播给所有消费者，对此我们想做一些改变，例如我们希望将日志消息写入磁盘的程序仅接收严重错误 (errros)，而不存储哪些警告 (warning) 或信息 (info) 日志 消息避免浪费磁盘空间。Fanout 这种交换类型并不能给我们带来很大的灵活性，它只能进行无意识的广播，在这里我们将使用 direct 这种类型来进行替换，这种类型的工作方式是，消息只去到它绑定的 routingKey 队列中去。RabbitMQ-00000042在上面这张图中，我们可以看到 X 绑定了两个队列，绑定类型是 direct。队列 Q1 绑定键为 orange， 队列 Q2 绑定键有两个：一个绑定键为 black，另一个绑定键为 green。在这种绑定情况下，生产者发布消息到 exchange 上，绑定键为 orange 的消息会被发布到队列 Q1。绑定键为 blackgreen 和的消息会被发布到队列 Q2，其他消息类型的消息将被丢弃。多重绑定RabbitMQ-00000043当然如果 exchange 的绑定类型是 direct，但是它绑定的多个队列的 key 如果都相同，在这种情况下虽然绑定类型是 direct 但是它表现的就和 fanout 有点类似了，就跟广播差不多，如上图所示。Direct 实战关系：RabbitMQ-00000044交换机：RabbitMQ-00000045c2：绑定 disk，routingKey 为 error。c1：绑定 console，routingKey 为 info、warning。```bashpackage com.oddfar.six;import com.oddfar.utils.RabbitMqUtils;import com.rabbitmq.client.BuiltinExchangeType;import com.rabbitmq.client.Channel;import com.rabbitmq.client.DeliverCallback;/** * @author zhiyuan */public class ReceiveLogsDirect01 &#123;    private static final String EXCHANGE_NAME = &quot;direct_logs&quot;;    public static void main(String[] args) throws Exception &#123;        Channel channel = RabbitMqUtils.getChannel();        channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.DIRECT);        String queueName = &quot;disk&quot;;        //队列声明        channel.queueDeclare(queueName, false, false, false, null);        //队列绑定        channel.queueBind(queueName, EXCHANGE_NAME, &quot;error&quot;);        System.out.println(&quot;等待接收消息...&quot;);        //发送回调        DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; &#123;            String message = new String(delivery.getBody(), &quot;UTF-8&quot;);            message = &quot;接收绑定键:&quot; + delivery.getEnvelope().getRoutingKey() + &quot;,消息:&quot; + message;            System.out.println(&quot;error 消息已经接收：\n&quot; + message);        &#125;;        channel.basicConsume(queueName, true, deliverCallback, consumerTag -&gt; &#123;        &#125;);    &#125;&#125;</code></pre><pre><code class="bash">public class ReceiveLogsDirect02 &#123;    private static final String EXCHANGE_NAME = &quot;direct_logs&quot;;    public static void main(String[] args) throws Exception &#123;        Channel channel = RabbitMqUtils.getChannel();        channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.DIRECT);        String queueName = &quot;console&quot;;        //队列声明        channel.queueDeclare(queueName, false, false, false, null);        //队列绑定        channel.queueBind(queueName, EXCHANGE_NAME, &quot;info&quot;);        channel.queueBind(queueName, EXCHANGE_NAME, &quot;warning&quot;);        System.out.println(&quot;等待接收消息...&quot;);        //发送回调        DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; &#123;            String message = new String(delivery.getBody(), &quot;UTF-8&quot;);            message = &quot;接收绑定键:&quot; + delivery.getEnvelope().getRoutingKey() + &quot;,消息:&quot; + message;            System.out.println(&quot;info和warning 消息已经接收：\n&quot; + message);        &#125;;        channel.basicConsume(queueName, true, deliverCallback, consumerTag -&gt; &#123;        &#125;);    &#125;&#125;</code></pre><pre><code class="bash">public class EmitLogDirect &#123;    private static final String EXCHANGE_NAME = &quot;direct_logs&quot;;    public static void main(String[] args) throws Exception &#123;        Channel channel = RabbitMqUtils.getChannel();        channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.DIRECT);        //创建多个 bindingKey        Map&lt;String, String&gt; bindingKeyMap = new HashMap&lt;&gt;();        bindingKeyMap.put(&quot;info&quot;, &quot;普通 info 信息&quot;);        bindingKeyMap.put(&quot;warning&quot;, &quot;警告 warning 信息&quot;);        bindingKeyMap.put(&quot;error&quot;, &quot;错误 error 信息&quot;);        //debug 没有消费这接收这个消息 所有就丢失了        bindingKeyMap.put(&quot;debug&quot;, &quot;调试 debug 信息&quot;);        for (Map.Entry&lt;String, String&gt; bindingKeyEntry : bindingKeyMap.entrySet()) &#123;            //获取 key value            String bindingKey = bindingKeyEntry.getKey();            String message = bindingKeyEntry.getValue();            channel.basicPublish(EXCHANGE_NAME, bindingKey, null, message.getBytes(&quot;UTF-8&quot;));            System.out.println(&quot;生产者发出消息:&quot; + message);        &#125;    &#125;&#125;</code></pre><h1 id="Topics-exchange"><a href="#Topics-exchange" class="headerlink" title="Topics exchange"></a>Topics exchange</h1><h2 id="Topic-的介绍"><a href="#Topic-的介绍" class="headerlink" title="Topic 的介绍"></a>Topic 的介绍</h2><p>在上一个小节中，我们改进了日志记录系统。我们没有使用只能进行随意广播的 fanout 交换机，而是使用了 direct 交换机，从而有能实现有选择性地接收日志。</p><p>尽管使用 direct 交换机改进了我们的系统，但是它仍然存在局限性 — 比方说我们想接收的日志类型有 info.base 和 info.advantage，某个队列只想 info.base 的消息，那这个时候 direct 就办不到了。这个时候就只能使用 topic 类型</p><p>Topic 的要求</p><p>发送到类型是 topic 交换机的消息的 routing_key 不能随意写，必须满足一定的要求，它必须是一个单词列表，以点号分隔开。这些单词可以是任意单词。比如说：”stock.usd.nyse”, “nyse.vmw”, “quick.orange.rabbit”. 这种类型的。当然这个单词列表最多不能超过 255 个字节。</p><p>在这个规则列表中，其中有两个替换符是大家需要注意的：</p><p>***(星号) 可以代替一个单词 **<br>#(井号) 可以替代零个或多个单词<br>Topic 匹配案例<br>下图绑定关系如下</p><p>RabbitMQ-00000046</p><p>Q1–&gt; 绑定的是：</p><p>中间带 orange 带 3 个单词的字符串 (<em>.orange.</em>)<br>Q2–&gt; 绑定的是：</p><p>最后一个单词是 rabbit 的 3 个单词 (<em>.</em>.rabbit)<br>第一个单词是 lazy 的多个单词 (lazy.#)<br>上图是一个队列绑定关系图，我们来看看他们之间数据接收情况是怎么样的：</p><p>例子    说明<br>quick.orange.rabbit    被队列 Q1Q2 接收到<br>azy.orange.elephant    被队列 Q1Q2 接收到<br>quick.orange.fox    被队列 Q1 接收到<br>lazy.brown.fox    被队列 Q2 接收到<br>lazy.pink.rabbit    虽然满足两个绑定但只被队列 Q2 接收一次<br>quick.brown.fox    不匹配任何绑定不会被任何队列接收到会被丢弃<br>quick.orange.male.rabbit    是四个单词不匹配任何绑定会被丢弃<br>lazy.orange.male.rabbit    是四个单词但匹配 Q2<br>注意：</p><p>当一个队列绑定键是 #，那么这个队列将接收所有数据，就有点像 fanout 了<br>如果队列绑定键当中没有 #和 * 出现，那么该队列绑定类型就是 direct 了<br>Topic 实战</p><p>RabbitMQ-00000047</p><p>代码如下：</p><pre><code class="bash">package com.oddfar.seven;import com.oddfar.utils.RabbitMqUtils;import com.rabbitmq.client.BuiltinExchangeType;import com.rabbitmq.client.Channel;import java.util.HashMap;import java.util.Map;/** * 发送端 * * @author zhiyuan */public class EmitLogTopic &#123;    private static final String EXCHANGE_NAME = &quot;topic_logs&quot;;    public static void main(String[] args) throws Exception &#123;        Channel channel = RabbitMqUtils.getChannel();        channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.TOPIC);        /**         * Q1--&gt;绑定的是         *      中间带 orange 带 3 个单词的字符串(*.orange.*)         * Q2--&gt;绑定的是         *      最后一个单词是 rabbit 的 3 个单词(*.*.rabbit)         *      第一个单词是 lazy 的多个单词(lazy.#)         *         */        Map&lt;String, String&gt; bindingKeyMap = new HashMap&lt;&gt;();        bindingKeyMap.put(&quot;quick.orange.rabbit&quot;, &quot;被队列 Q1Q2 接收到&quot;);        bindingKeyMap.put(&quot;lazy.orange.elephant&quot;, &quot;被队列 Q1Q2 接收到&quot;);        bindingKeyMap.put(&quot;quick.orange.fox&quot;, &quot;被队列 Q1 接收到&quot;);        bindingKeyMap.put(&quot;lazy.brown.fox&quot;, &quot;被队列 Q2 接收到&quot;);        bindingKeyMap.put(&quot;lazy.pink.rabbit&quot;, &quot;虽然满足两个绑定但只被队列 Q2 接收一次&quot;);        bindingKeyMap.put(&quot;quick.brown.fox&quot;, &quot;不匹配任何绑定不会被任何队列接收到会被丢弃&quot;);        bindingKeyMap.put(&quot;quick.orange.male.rabbit&quot;, &quot;是四个单词不匹配任何绑定会被丢弃&quot;);        bindingKeyMap.put(&quot;lazy.orange.male.rabbit&quot;, &quot;是四个单词但匹配 Q2&quot;);        for (Map.Entry&lt;String, String&gt; bindingKeyEntry : bindingKeyMap.entrySet()) &#123;            String bindingKey = bindingKeyEntry.getKey();            String message = bindingKeyEntry.getValue();            channel.basicPublish(EXCHANGE_NAME, bindingKey, null, message.getBytes(&quot;UTF-8&quot;));            System.out.println(&quot;生产者发出消息：&quot; + message);        &#125;    &#125;&#125;</code></pre><pre><code class="bash">public class ReceiveLogsTopic01 &#123;    private static final String EXCHANGE_NAME = &quot;topic_logs&quot;;    public static void main(String[] args) throws Exception &#123;        Channel channel = RabbitMqUtils.getChannel();        channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.TOPIC);        //声明 Q1 队列与绑定关系        String queueName = &quot;Q1&quot;;        //声明        channel.queueDeclare(queueName, false, false, false, null);        //绑定        channel.queueBind(queueName, EXCHANGE_NAME, &quot;*.orange.*&quot;);        System.out.println(&quot;等待接收消息........... &quot;);        DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; &#123;            String message = new String(delivery.getBody(), &quot;UTF-8&quot;);            System.out.println(&quot; 接收队列:&quot; + queueName + &quot; 绑定键:&quot; + delivery.getEnvelope().getRoutingKey() + &quot;,消息:&quot; + message);        &#125;;        channel.basicConsume(queueName, true, deliverCallback, consumerTag -&gt; &#123;        &#125;);    &#125;&#125;</code></pre><pre><code class="bash">public class ReceiveLogsTopic02 &#123;    private static final String EXCHANGE_NAME = &quot;topic_logs&quot;;    public static void main(String[] args) throws Exception &#123;        Channel channel = RabbitMqUtils.getChannel();        channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.TOPIC);        //声明 Q2 队列与绑定关系        String queueName = &quot;Q2&quot;;        //声明        channel.queueDeclare(queueName, false, false, false, null);        //绑定        channel.queueBind(queueName, EXCHANGE_NAME, &quot;*.*.rabbit&quot;);        channel.queueBind(queueName, EXCHANGE_NAME, &quot;lazy.#&quot;);        System.out.println(&quot;等待接收消息........... &quot;);        DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; &#123;            String message = new String(delivery.getBody(), &quot;UTF-8&quot;);            System.out.println(&quot; 接收队列:&quot; + queueName + &quot; 绑定键:&quot; + delivery.getEnvelope().getRoutingKey() + &quot;,消息:&quot; + message);        &#125;;        channel.basicConsume(queueName, true, deliverCallback, consumerTag -&gt; &#123;        &#125;);    &#125;&#125;</code></pre><h1 id="死信队列"><a href="#死信队列" class="headerlink" title="死信队列"></a>死信队列</h1><h2 id="死信的概念"><a href="#死信的概念" class="headerlink" title="死信的概念"></a>死信的概念</h2><blockquote><p>先从概念解释上搞清楚这个定义，死信，顾名思义就是无法被消费的消息，字面意思可以这样理解，一般来说，producer 将消息投递到 broker 或者直接到 queue 里了，consumer 从 queue 取出消息进行消费，但某些时候由于特定的原因导致 queue 中的某些消息无法被消费，这样的消息如果没有后续的处理，就变成了死信，有死信自然就有了死信队列。</p></blockquote><p>应用场景：为了保证订单业务的消息数据不丢失，需要使用到 RabbitMQ 的死信队列机制，当消息消费发生异常时，将消息投入死信队列中。还有比如说：用户在商城下单成功并点击去支付后在指定时间未支付时自动失效。</p><p>死信的来源<br>消息 TTL 过期：TTL 是 Time To Live 的缩写，也就是生存时间。</p><p>队列达到最大长度：队列满了，无法再添加数据到 mq 中。</p><p>消息被拒绝：(basic.reject 或 basic.nack) 并且 requeue=false。</p><p>死信实战</p><p>RabbitMQ-00000048</p><p>死信之 TTL<br>消费者 C1 代码：</p><pre><code class="bash">/** * 死信队列 - 消费者01 * * @author zhiyuan */public class Consumer01 &#123;    //普通交换机名称    private static final String NORMAL_EXCHANGE = &quot;normal_exchange&quot;;    //死信交换机名称    private static final String DEAD_EXCHANGE = &quot;dead_exchange&quot;;    public static void main(String[] args) throws Exception &#123;        Channel channel = RabbitMqUtils.getChannel();        //声明死信和普通交换机 类型为 direct        channel.exchangeDeclare(NORMAL_EXCHANGE, BuiltinExchangeType.DIRECT);        channel.exchangeDeclare(DEAD_EXCHANGE, BuiltinExchangeType.DIRECT);        //声明死信队列        String deadQueue = &quot;dead-queue&quot;;        channel.queueDeclare(deadQueue, false, false, false, null);        //死信队列绑定：队列、交换机、路由键（routingKey）        channel.queueBind(deadQueue, DEAD_EXCHANGE, &quot;lisi&quot;);        //正常队列绑定死信队列信息        Map&lt;String, Object&gt; params = new HashMap&lt;&gt;();        //正常队列设置死信交换机 参数 key 是固定值        params.put(&quot;x-dead-letter-exchange&quot;, DEAD_EXCHANGE);        //正常队列设置死信 routing-key 参数 key 是固定值        params.put(&quot;x-dead-letter-routing-key&quot;, &quot;lisi&quot;);        //正常队列        String normalQueue = &quot;normal-queue&quot;;        channel.queueDeclare(normalQueue, false, false, false, params);        channel.queueBind(normalQueue, NORMAL_EXCHANGE, &quot;zhangsan&quot;);        System.out.println(&quot;等待接收消息........... &quot;);        DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; &#123;            String message = new String(delivery.getBody(), &quot;UTF-8&quot;);            System.out.println(&quot;Consumer01 接收到消息&quot; + message);        &#125;;        channel.basicConsume(normalQueue, true, deliverCallback, consumerTag -&gt; &#123;        &#125;);    &#125;&#125;</code></pre><p>生产者代码：</p><pre><code class="bash">public class Producer &#123;    private static final String NORMAL_EXCHANGE = &quot;normal_exchange&quot;;    public static void main(String[] argv) throws Exception &#123;        Channel channel = RabbitMqUtils.getChannel();        channel.exchangeDeclare(NORMAL_EXCHANGE, BuiltinExchangeType.DIRECT);        //设置消息的 TTL 时间 10s        AMQP.BasicProperties properties = new AMQP.BasicProperties().builder().expiration(&quot;10000&quot;).build();        //该信息是用作演示队列个数限制        for (int i = 1; i &lt; 11; i++) &#123;            String message = &quot;info&quot; + i;            channel.basicPublish(NORMAL_EXCHANGE, &quot;zhangsan&quot;, properties, message.getBytes());            System.out.println(&quot;生产者发送消息:&quot; + message);        &#125;    &#125;&#125;</code></pre><p>启动 C1 ，之后关闭消费者，模拟其接收不到消息。再启动 Producer：</p><p>RabbitMQ-00000049</p><p>消费者 C2 代码：以上步骤完成后，启动 C2 消费者，它消费死信队列里面的消息：</p><pre><code class="bash">public class Consumer02 &#123;    //死信交换机名称    private static final String DEAD_EXCHANGE = &quot;dead_exchange&quot;;    public static void main(String[] args) throws Exception &#123;        Channel channel = RabbitMqUtils.getChannel();        //声明交换机        channel.exchangeDeclare(DEAD_EXCHANGE, BuiltinExchangeType.DIRECT);        //声明队列        String deadQueue = &quot;dead-queue&quot;;        channel.queueDeclare(deadQueue, false, false, false, null);        channel.queueBind(deadQueue, DEAD_EXCHANGE, &quot;lisi&quot;);        System.out.println(&quot;等待接收死信消息........... &quot;);        DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; &#123;            String message = new String(delivery.getBody(), &quot;UTF-8&quot;);            System.out.println(&quot;Consumer02 接收到消息&quot; + message);        &#125;;        channel.basicConsume(deadQueue, true, deliverCallback, consumerTag -&gt; &#123;        &#125;);    &#125;&#125;</code></pre><p>RabbitMQ-00000050</p><p>死信之最大长度<br>消息生产者代码去掉 TTL 属性：</p><p>image-20210628101337825</p><p>C1 消费者修改以下代码 <strong>(启动之后关闭该消费者 模拟其接收不到消息)</strong>:</p><p>RabbitMQ-00000051</p><p>JAVA<br>1<br>2<br>//设置正常队列的长度限制，例如发10个，4个则为死信<br>params.put(“x-max-length”,6);<br>注意此时需要把原先队列删除，因为参数改变了。</p><p>C2 消费者代码不变 (启动 C2 消费者)</p><p>RabbitMQ-00000052</p><p>死信之消息被拒<br>消息生产者代码同上生产者一致</p><p>C1 消费者代码 (启动之后关闭该消费者 模拟其接收不到消息)</p><p>拒收消息 “info5” ：</p><pre><code class="bash">public class Consumer01 &#123;    //普通交换机名称    private static final String NORMAL_EXCHANGE = &quot;normal_exchange&quot;;    //死信交换机名称    private static final String DEAD_EXCHANGE = &quot;dead_exchange&quot;;    public static void main(String[] args) throws Exception &#123;        Channel channel = RabbitMqUtils.getChannel();        //声明死信和普通交换机 类型为 direct        channel.exchangeDeclare(NORMAL_EXCHANGE, BuiltinExchangeType.DIRECT);        channel.exchangeDeclare(DEAD_EXCHANGE, BuiltinExchangeType.DIRECT);        //声明死信队列        String deadQueue = &quot;dead-queue&quot;;        channel.queueDeclare(deadQueue, false, false, false, null);        //死信队列绑定：队列、交换机、路由键（routingKey）        channel.queueBind(deadQueue, DEAD_EXCHANGE, &quot;lisi&quot;);                //正常队列绑定死信队列信息        Map&lt;String, Object&gt; params = new HashMap&lt;&gt;();        //正常队列设置死信交换机 参数 key 是固定值        params.put(&quot;x-dead-letter-exchange&quot;, DEAD_EXCHANGE);        //正常队列设置死信 routing-key 参数 key 是固定值        params.put(&quot;x-dead-letter-routing-key&quot;, &quot;lisi&quot;);//        //设置正常队列的长度限制，例如发10个，4个则为死信//        params.put(&quot;x-max-length&quot;,6);                //正常队列        String normalQueue = &quot;normal-queue&quot;;        channel.queueDeclare(normalQueue, false, false, false, params);        channel.queueBind(normalQueue, NORMAL_EXCHANGE, &quot;zhangsan&quot;);        System.out.println(&quot;等待接收消息........... &quot;);                DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; &#123;            String message = new String(delivery.getBody(), &quot;UTF-8&quot;);            if (message.equals(&quot;info5&quot;)) &#123;                System.out.println(&quot;Consumer01 接收到消息&quot; + message + &quot;并拒绝签收该消息&quot;);                //requeue 设置为 false 代表拒绝重新入队 该队列如果配置了死信交换机将发送到死信队列中                channel.basicReject(delivery.getEnvelope().getDeliveryTag(), false);            &#125; else &#123;                System.out.println(&quot;Consumer01 接收到消息&quot; + message);                channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false);            &#125;        &#125;;        //开启手动应答        channel.basicConsume(normalQueue, false, deliverCallback, consumerTag -&gt; &#123;        &#125;);    &#125;&#125;</code></pre><p>RabbitMQ-00000053</p><p>C2 消费者代码不变：启动消费者 1 然后再启动消费者 2</p><p>RabbitMQ-00000054</p><p>延迟队列<br>延迟队列概念：<br>延时队列内部是有序的，最重要的特性就体现在它的延时属性上，延时队列中的元素是希望在指定时间到了以后或之前取出和处理，简单来说，延时队列就是用来存放需要在指定时间被处理的元素的队列。</p><p>延迟队列使用场景：<br>订单在十分钟之内未支付则自动取消；<br>新创建的店铺，如果在十天内都没有上传过商品，则自动发送消息提醒；<br>用户注册成功后，如果三天内没有登陆则进行短信提醒；<br>用户发起退款，如果三天内没有得到处理则通知相关运营人员；<br>预定会议后，需要在预定的时间点前十分钟通知各个与会人员参加会议。<br>这些场景都有一个特点，需要在某个事件发生之后或者之前的指定时间点完成某一项任务，如：发生订单生成事件，在十分钟之后检查该订单支付状态，然后将未支付的订单进行关闭。那我们一直轮询数据，每秒查一次，取出需要被处理的数据，然后处理不就完事了吗？</p><p>如果数据量比较少，确实可以这样做，比如：对于 “如果账单一周内未支付则进行自动结算” 这样的需求， 如果对于时间不是严格限制，而是宽松意义上的一周，那么每天晚上跑个定时任务检查一下所有未支付的账单，确实也是一个可行的方案。</p><p>但对于数据量比较大，并且时效性较强的场景，如：“订单十分钟内未支付则关闭 “，短期内未支付的订单数据可能会有很多，活动期间甚至会达到百万甚至千万级别，对这么庞大的数据量仍旧使用轮询的方式显然是不可取的，很可能在一秒内无法完成所有订单的检查，同时会给数据库带来很大压力，无法满足业务要求而且性能低下。</p><p>RabbitMQ-00000055</p><p>RabbitMQ 中的 TTL<br>TTL 是 RabbitMQ 中一个消息或者队列的属性，表明一条消息或者该队列中的所有消息的最大存活时间，单位是毫秒。</p><p>换句话说，如果一条消息设置了 TTL 属性或者进入了设置 TTL 属性的队列，那么这条消息如果在 TTL 设置的时间内没有被消费，则会成为” 死信”。如果同时配置了队列的 TTL 和消息的 TTL，那么较小的那个值将会被使用，有两种方式设置 TTL。</p><p>队列设置 TTL：在创建队列的时候设置队列的 “x-message-ttl” 属性</p><p>RabbitMQ-00000057</p><p>消息设置 TTL：是针对每条消息设置 TTL</p><p>RabbitMQ-00000056</p><p>两者的区别</p><p>如果设置了队列的 TTL 属性，那么一旦消息过期，就会被队列丢弃 (如果配置了死信队列被丢到死信队列中)，而第二种方式，消息即使过期，也不一定会被马上丢弃，因为消息是否过期是在即将投递到消费者之前判定的，如果当前队列有严重的消息积压情况，则已过期的消息也许还能存活较长时间。</p><p>另外，还需要注意的一点是，如果不设置 TTL，表示消息永远不会过期，如果将 TTL 设置为 0，则表示除非此时可以直接投递该消息到消费者，否则该消息将会被丢弃。</p><p>整合 springboot<br>创建一个空项目：</p><p>RabbitMQ-00000058</p><p>添加依赖：</p><pre><code class="bash">&lt;dependencies&gt;   &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;!--RabbitMQ 依赖--&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;        &lt;scope&gt;test&lt;/scope&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.alibaba&lt;/groupId&gt;        &lt;artifactId&gt;fastjson&lt;/artifactId&gt;        &lt;version&gt;1.2.47&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;        &lt;artifactId&gt;lombok&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;!--swagger--&gt;    &lt;dependency&gt;        &lt;groupId&gt;io.springfox&lt;/groupId&gt;        &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt;        &lt;version&gt;3.0.0&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;io.springfox&lt;/groupId&gt;        &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt;        &lt;version&gt;3.0.0&lt;/version&gt;    &lt;/dependency&gt;    &lt;!--RabbitMQ 测试依赖--&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.amqp&lt;/groupId&gt;        &lt;artifactId&gt;spring-rabbit-test&lt;/artifactId&gt;        &lt;scope&gt;test&lt;/scope&gt;    &lt;/dependency&gt;&lt;/dependencies&gt;</code></pre><p>修改配置文件:</p><pre><code class="bash">spring.rabbitmq.host=42.192.149.71spring.rabbitmq.port=5672spring.rabbitmq.username=adminspring.rabbitmq.password=123456</code></pre><blockquote><p>添加 Swagger 配置类 :</p></blockquote><pre><code class="bash">package com.oddfar.config;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import springfox.documentation.builders.ApiInfoBuilder;import springfox.documentation.service.ApiInfo;import springfox.documentation.service.Contact;import springfox.documentation.spi.DocumentationType;import springfox.documentation.spring.web.plugins.Docket;import springfox.documentation.swagger2.annotations.EnableSwagger2;@Configuration@EnableSwagger2public class SwaggerConfig &#123;    @Bean    public Docket webApiConfig() &#123;        return new Docket(DocumentationType.SWAGGER_2)                .groupName(&quot;webApi&quot;)                .apiInfo(webApiInfo())                .select()                .build();    &#125;    private ApiInfo webApiInfo() &#123;        return new ApiInfoBuilder()                .title(&quot;rabbitmq 接口文档&quot;)                .description(&quot;本文档描述了 rabbitmq 微服务接口定义&quot;)                .version(&quot;1.0&quot;)                .contact(new Contact(&quot;zhiyuan&quot;, &quot;http://oddfar.com&quot;, &quot;test@qq.com&quot;))                .build();    &#125;&#125;</code></pre><h2 id="队列-TTL"><a href="#队列-TTL" class="headerlink" title="队列 TTL"></a>队列 TTL</h2><p>代码架构图</p><p>创建两个队列 QA 和 QB，两者队列 TTL 分别设置为 10S 和 40S，然后在创建一个交换机 X 和死信交换机 Y，它们的类型都是 direct，创建一个死信队列 QD，它们的绑定关系如下：</p><p>RabbitMQ-00000060</p><p>1、配置文件类代码 ：</p><pre><code class="bash">package com.oddfar.config;import org.springframework.amqp.core.*;import org.springframework.beans.factory.annotation.Qualifier;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import java.util.HashMap;import java.util.Map;/** * @author zhiyuan */@Configurationpublic class TtlQueueConfig &#123;    public static final String X_EXCHANGE = &quot;X&quot;;    public static final String QUEUE_A = &quot;QA&quot;;    public static final String QUEUE_B = &quot;QB&quot;;    //死信交换机    public static final String Y_DEAD_LETTER_EXCHANGE = &quot;Y&quot;;    //死信队列    public static final String DEAD_LETTER_QUEUE = &quot;QD&quot;;    // 声明 xExchange    @Bean(&quot;xExchange&quot;)    public DirectExchange xExchange() &#123;        return new DirectExchange(X_EXCHANGE);    &#125;    // 声明 死信队列交换机    @Bean(&quot;yExchange&quot;)    public DirectExchange yExchange() &#123;        return new DirectExchange(Y_DEAD_LETTER_EXCHANGE);    &#125;    //声明队列 A ttl 为 10s 并绑定到对应的死信交换机    @Bean(&quot;queueA&quot;)    public Queue queueA() &#123;        Map&lt;String, Object&gt; args = new HashMap&lt;&gt;(3);        //声明当前队列绑定的死信交换机        args.put(&quot;x-dead-letter-exchange&quot;, Y_DEAD_LETTER_EXCHANGE);        //声明当前队列的死信路由 key        args.put(&quot;x-dead-letter-routing-key&quot;, &quot;YD&quot;);        //声明队列的 TTL        args.put(&quot;x-message-ttl&quot;, 10000);        return QueueBuilder.durable(QUEUE_A).withArguments(args).build();    &#125;    // 声明队列 A 绑定 X 交换机    @Bean    public Binding queueaBindingX(@Qualifier(&quot;queueA&quot;) Queue queueA,                                  @Qualifier(&quot;xExchange&quot;) DirectExchange xExchange) &#123;        return BindingBuilder.bind(queueA).to(xExchange).with(&quot;XA&quot;);    &#125;    //声明队列 B ttl 为 40s 并绑定到对应的死信交换机    @Bean(&quot;queueB&quot;)    public Queue queueB() &#123;        Map&lt;String, Object&gt; args = new HashMap&lt;&gt;(3);        //声明当前队列绑定的死信交换机        args.put(&quot;x-dead-letter-exchange&quot;, Y_DEAD_LETTER_EXCHANGE);        //声明当前队列的死信路由 key        args.put(&quot;x-dead-letter-routing-key&quot;, &quot;YD&quot;);        //声明队列的 TTL        args.put(&quot;x-message-ttl&quot;, 40000);        return QueueBuilder.durable(QUEUE_B).withArguments(args).build();    &#125;    //声明队列 B 绑定 X 交换机    @Bean    public Binding queuebBindingX(@Qualifier(&quot;queueB&quot;) Queue queue1B,                                  @Qualifier(&quot;xExchange&quot;) DirectExchange xExchange) &#123;        return BindingBuilder.bind(queue1B).to(xExchange).with(&quot;XB&quot;);    &#125;    //声明死信队列 QD    @Bean(&quot;queueD&quot;)    public Queue queueD() &#123;        return new Queue(DEAD_LETTER_QUEUE);    &#125;    //声明死信队列 QD 绑定关系    @Bean    public Binding deadLetterBindingQAD(@Qualifier(&quot;queueD&quot;) Queue queueD,                                        @Qualifier(&quot;yExchange&quot;) DirectExchange yExchange) &#123;        return BindingBuilder.bind(queueD).to(yExchange).with(&quot;YD&quot;);    &#125;&#125;</code></pre><p>2、消息生产者代码</p><pre><code class="bash">package com.oddfar.contorller;import lombok.extern.slf4j.Slf4j;import org.springframework.amqp.rabbit.core.RabbitTemplate;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;import java.util.Date;/** * @author zhiyuan */@Slf4j@RequestMapping(&quot;ttl&quot;)@RestControllerpublic class SendMsgController &#123;    @Autowired    private RabbitTemplate rabbitTemplate;    @GetMapping(&quot;sendMsg/&#123;message&#125;&quot;)    public void sendMsg(@PathVariable String message) &#123;        log.info(&quot;当前时间：&#123;&#125;,发送一条信息给两个 TTL 队列:&#123;&#125;&quot;, new Date(), message);        rabbitTemplate.convertAndSend(&quot;X&quot;, &quot;XA&quot;, &quot;消息来自 ttl 为 10S 的队列: &quot; + message);        rabbitTemplate.convertAndSend(&quot;X&quot;, &quot;XB&quot;, &quot;消息来自 ttl 为 40S 的队列: &quot; + message);    &#125;    &#125;</code></pre><p>3、消息消费者代码</p><pre><code class="bash">package com.oddfar.contorller;import lombok.extern.slf4j.Slf4j;import org.springframework.amqp.rabbit.core.RabbitTemplate;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;import java.util.Date;/** * @author zhiyuan */@Slf4j@RequestMapping(&quot;ttl&quot;)@RestControllerpublic class SendMsgController &#123;    @Autowired    private RabbitTemplate rabbitTemplate;    @GetMapping(&quot;sendMsg/&#123;message&#125;&quot;)    public void sendMsg(@PathVariable String message) &#123;        log.info(&quot;当前时间：&#123;&#125;,发送一条信息给两个 TTL 队列:&#123;&#125;&quot;, new Date(), message);        rabbitTemplate.convertAndSend(&quot;X&quot;, &quot;XA&quot;, &quot;消息来自 ttl 为 10S 的队列: &quot; + message);        rabbitTemplate.convertAndSend(&quot;X&quot;, &quot;XB&quot;, &quot;消息来自 ttl 为 40S 的队列: &quot; + message);    &#125;&#125;</code></pre><p>发起一个请求 <a href="http://localhost:8080/ttl/sendMsg/">http://localhost:8080/ttl/sendMsg/</a> 嘻嘻嘻</p><p>image-20210628162017168</p><p>第一条消息在 10S 后变成了死信消息，然后被消费者消费掉，第二条消息在 40S 之后变成了死信消息， 然后被消费掉，这样一个延时队列就打造完成了。</p><p>不过，如果这样使用的话，岂不是每增加一个新的时间需求，就要新增一个队列，这里只有 10S 和 40S 两个时间选项，如果需要一个小时后处理，那么就需要增加 TTL 为一个小时的队列，如果是预定会议室然后提前通知这样的场景，岂不是要增加无数个队列才能满足需求？</p><p>延时队列 TTL 优化<br>在这里新增了一个队列 QC，绑定关系如下，该队列不设置 TTL 时间</p><p>RabbitMQ-00000062</p><p>配置文件类代码：</p><pre><code class="bash">@Configurationpublic class MsgTtlQueueConfig &#123;    public static final String Y_DEAD_LETTER_EXCHANGE = &quot;Y&quot;;    public static final String QUEUE_C = &quot;QC&quot;;    //声明队列 C 死信交换机    @Bean(&quot;queueC&quot;)    public Queue queueB() &#123;        Map&lt;String, Object&gt; args = new HashMap&lt;&gt;(3);        //声明当前队列绑定的死信交换机        args.put(&quot;x-dead-letter-exchange&quot;, Y_DEAD_LETTER_EXCHANGE);        //声明当前队列的死信路由 key        args.put(&quot;x-dead-letter-routing-key&quot;, &quot;YD&quot;);        //没有声明 TTL 属性        return QueueBuilder.durable(QUEUE_C).withArguments(args).build();    &#125;    //声明队列 B 绑定 X 交换机    @Bean    public Binding queuecBindingX(@Qualifier(&quot;queueC&quot;) Queue queueC,                                  @Qualifier(&quot;xExchange&quot;) DirectExchange xExchange) &#123;        return BindingBuilder.bind(queueC).to(xExchange).with(&quot;XC&quot;);    &#125;&#125;</code></pre><p>生产者代码：</p><pre><code class="bash">/** * 延时队列优化 * @param message 消息 * @param ttlTime 延时的毫秒 */@GetMapping(&quot;sendExpirationMsg/&#123;message&#125;/&#123;ttlTime&#125;&quot;)public void sendMsg(@PathVariable String message, @PathVariable String ttlTime) &#123;    rabbitTemplate.convertAndSend(&quot;X&quot;, &quot;XC&quot;, message, correlationData -&gt; &#123;        correlationData.getMessageProperties().setExpiration(ttlTime);        return correlationData;    &#125;);    log.info(&quot;当前时间：&#123;&#125;,发送一条时长&#123;&#125;毫秒 TTL 信息给队列 C:&#123;&#125;&quot;, new Date(), ttlTime, message);&#125;</code></pre><p>发起请求：</p><p><a href="http://localhost:8080/ttl/sendExpirationMsg/">http://localhost:8080/ttl/sendExpirationMsg/</a> 你好 1/20000</p><p><a href="http://localhost:8080/ttl/sendExpirationMsg/">http://localhost:8080/ttl/sendExpirationMsg/</a> 你好 2/2000</p><p>RabbitMQ-00000063</p><p>看起来似乎没什么问题，但是在最开始的时候，就介绍过如果使用在消息属性上设置 TTL 的方式，消息可能并不会按时 “死亡 “。</p><p>因为 RabbitMQ 只会检查第一个消息是否过期，如果过期则丢到死信队列， 如果第一个消息的延时时长很长，而第二个消息的延时时长很短，第二个消息并不会优先得到执行。这也就是为什么第二个延时 2 秒，却后执行。</p><p>此外，我们还可以通过 Rabbitmq 插件实现延迟队列。</p><p>总结<br>延时队列在需要延时处理的场景下非常有用，使用 RabbitMQ 来实现延时队列可以很好的利用 RabbitMQ 的特性，如：消息可靠发送、消息可靠投递、死信队列来保障消息至少被消费一次以及未被正确处理的消息不会被丢弃。另外，通过 RabbitMQ 集群的特性，可以很好的解决单点故障问题，不会因为单个节点挂掉导致延时队列不可用或者消息丢失。</p><p>当然，延时队列还有很多其它选择，比如利用 Java 的 DelayQueue，利用 Redis 的 zset，利用 Quartz 或者利用 kafka 的时间轮，这些方式各有特点，看需要适用的场景。</p><p>发布确认高级<br>在生产环境中由于一些不明原因，导致 RabbitMQ 重启，在 RabbitMQ 重启期间生产者消息投递失败， 导致消息丢失，需要手动处理和恢复。于是，我们开始思考，如何才能进行 RabbitMQ 的消息可靠投递呢？</p><p>确认机制方案：</p><p>RabbitMQ-00000068</p><p>代码架构图：</p><p>RabbitMQ-00000069</p><p>在配置文件当中需要添加</p><p>PROPERTIES<br>1<br>spring.rabbitmq.publisher-confirm-type=correlated<br>NONE 值是禁用发布确认模式，是默认值。</p><p>CORRELATED 值是发布消息成功到交换器后会触发回调方法。</p><p>SIMPLE 值经测试有两种效果，其一效果和 CORRELATED 值一样会触发回调方法，其二在发布消息成功后使用 rabbitTemplate 调用 waitForConfirms 或 waitForConfirmsOrDie 方法等待 broker 节点返回发送结果，根据返回结果来判定下一步的逻辑，要注意的点是 waitForConfirmsOrDie 方法如果返回 false 则会关闭 channel，则接下来无法发送消息到 broker。</p><p>1、添加配置类：</p><pre><code class="bash">@Configurationpublic class ConfirmConfig &#123;    public static final String CONFIRM_EXCHANGE_NAME = &quot;confirm.exchange&quot;;    public static final String CONFIRM_QUEUE_NAME = &quot;confirm.queue&quot;;    //声明业务 Exchange    @Bean(&quot;confirmExchange&quot;)    public DirectExchange confirmExchange() &#123;        return new DirectExchange(CONFIRM_EXCHANGE_NAME);    &#125;    // 声明确认队列    @Bean(&quot;confirmQueue&quot;)    public Queue confirmQueue() &#123;        return QueueBuilder.durable(CONFIRM_QUEUE_NAME).build();    &#125;    // 声明确认队列绑定关系    @Bean    public Binding queueBinding(@Qualifier(&quot;confirmQueue&quot;) Queue queue,                                @Qualifier(&quot;confirmExchange&quot;) DirectExchange exchange) &#123;        return BindingBuilder.bind(queue).to(exchange).with(&quot;key1&quot;);    &#125;&#125;</code></pre><p>2、消息生产者的回调接口</p><pre><code class="bash">@Component@Slf4jpublic class MyCallBack implements RabbitTemplate.ConfirmCallback &#123;    /**     * 交换机不管是否收到消息的一个回调方法     *     * @param correlationData 消息相关数据     * @param ack             交换机是否收到消息     * @param cause           为收到消息的原因     */    @Override    public void confirm(CorrelationData correlationData, boolean ack, String cause) &#123;        String id = correlationData != null ? correlationData.getId() : &quot;&quot;;        if (ack) &#123;            log.info(&quot;交换机已经收到 id 为:&#123;&#125;的消息&quot;, id);        &#125; else &#123;            log.info(&quot;交换机还未收到 id 为:&#123;&#125;消息，原因:&#123;&#125;&quot;, id, cause);        &#125;    &#125;&#125;</code></pre><p>3、消息生产者</p><pre><code class="bash">@RestController@RequestMapping(&quot;/confirm&quot;)@Slf4jpublic class ProducerController &#123;    public static final String CONFIRM_EXCHANGE_NAME = &quot;confirm.exchange&quot;;    @Autowired    private RabbitTemplate rabbitTemplate;    @Autowired    private MyCallBack myCallBack;    //依赖注入 rabbitTemplate 之后再设置它的回调对象    @PostConstruct    public void init() &#123;        rabbitTemplate.setConfirmCallback(myCallBack);    &#125;        /**     * 消息回调和退回     *     * @param message     */    @GetMapping(&quot;sendMessage/&#123;message&#125;&quot;)    public void sendMessage(@PathVariable String message) &#123;        //指定消息 id 为 1        CorrelationData correlationData1 = new CorrelationData(&quot;1&quot;);        String routingKey = &quot;key1&quot;;        rabbitTemplate.convertAndSend(CONFIRM_EXCHANGE_NAME, routingKey, message + routingKey, correlationData1);        log.info(routingKey + &quot;发送消息内容:&#123;&#125;&quot;, message + routingKey);        CorrelationData correlationData2 = new CorrelationData(&quot;2&quot;);        routingKey = &quot;key2&quot;;        rabbitTemplate.convertAndSend(CONFIRM_EXCHANGE_NAME, routingKey, message + routingKey, correlationData2);        log.info(routingKey + &quot;发送消息内容:&#123;&#125;&quot;, message + routingKey);    &#125;&#125;</code></pre><p>4、消息消费者</p><pre><code class="bash">@Component@Slf4jpublic class ConfirmConsumer &#123;    public static final String CONFIRM_QUEUE_NAME = &quot;confirm.queue&quot;;    @RabbitListener(queues = CONFIRM_QUEUE_NAME)    public void receiveMsg(Message message) &#123;        String msg = new String(message.getBody());        log.info(&quot;接受到队列 confirm.queue 消息:&#123;&#125;&quot;, msg);    &#125;&#125;</code></pre><p>访问： <a href="http://localhost:8080/confirm/sendMessage/%E4%BD%A0%E5%A5%BD">http://localhost:8080/confirm/sendMessage/%E4%BD%A0%E5%A5%BD</a></p><p>结果分析：</p><p>image-20210629135636990</p><p>可以看到，发送了两条消息，第一条消息的 RoutingKey 为 “key1”，第二条消息的 RoutingKey 为 “key2”，两条消息都成功被交换机接收，也收到了交换机的确认回调，但消费者只收到了一条消息，因为第二条消息的 RoutingKey 与队列的 BindingKey 不一致，也没有其它队列能接收这个消息，所有第二条消息被直接丢弃了。丢弃的消息交换机是不知道的，需要解决告诉生产者消息传送失败。</p><p>回退消息<br>Mandatory 参数</p><p>JAVA<br>1<br>rabbitTemplate.setReturnsCallback(myCallBack);<br>在仅开启了生产者确认机制的情况下，交换机接收到消息后，会直接给消息生产者发送确认消息，如果发现该消息不可路由，那么消息会被直接丢弃，此时生产者是不知道消息被丢弃这个事件的。</p><p>那么如何让无法被路由的消息帮我想办法处理一下？最起码通知我一声，我好自己处理啊。通过设置 mandatory 参数可以在当消息传递过程中不可达目的地时将消息返回给生产者。</p><p>PROPERTIES<br>1<br>2<br>#消息退回<br>spring.rabbitmq.publisher-returns=true<br>备份交换机<br>有了 mandatory 参数和回退消息，我们获得了对无法投递消息的感知能力，在生产者的消息无法被投递时发现并处理。但有时候，我们并不知道该如何处理这些无法路由的消息，最多打个日志，然后触发报警，再来手动处理。而通过日志来处理这些无法路由的消息是很不优雅的做法，特别是当生产者所在的服务有多台机器的时候，手动复制日志会更加麻烦而且容易出错。而且设置 mandatory 参数会增加生产者的复杂性，需要添加处理这些被退回的消息的逻辑。如果既不想丢失消息，又不想增加生产者的复杂性，该怎么做呢？</p><p>前面在设置死信队列的文章中，我们提到，可以为队列设置死信交换机来存储那些处理失败的消息，可是这些不可路由消息根本没有机会进入到队列，因此无法使用死信队列来保存消息。 在 RabbitMQ 中，有一种备份交换机的机制存在，可以很好的应对这个问题。</p><p>备份交换机可以理解为 RabbitMQ 中交换机的 “备胎”，当我们为某一个交换机声明一个对应的备份交换机时，就是为它创建一个备胎，当交换机接收到一条不可路由消息时，将会把这条消息转发到备份交换机中，由备份交换机来进行转发和处理，通常备份交换机的类型为 Fanout ，这样就能把所有消息都投递到与其绑定的队列中，然后我们在备份交换机下绑定一个队列，这样所有那些原交换机无法被路由的消息，就会都进入这个队列了。当然，我们还可以建立一个报警队列，用独立的消费者来进行监测和报警。</p><p>架构图</p><p>RabbitMQ-00000072</p><p>幂等性<br>概念</p><p>用户对于同一操作发起的一次请求或者多次请求的结果是一致的，不会因为多次点击而产生了副作用。 举个最简单的例子，那就是支付，用户购买商品后支付，支付扣款成功，但是返回结果的时候网络异常， 此时钱已经扣了，用户再次点击按钮，此时会进行第二次扣款，返回结果成功，用户查询余额发现多扣钱 了，流水记录也变成了两条。在以前的单应用系统中，我们只需要把数据操作放入事务中即可，发生错误立即回滚，但是再响应客户端的时候也有可能出现网络中断或者异常等等.</p><p>消息重复消费</p><p>消费者在消费 MQ 中的消息时，MQ 已把消息发送给消费者，消费者在给 MQ 返回 ack 时网络中断， 故 MQ 未收到确认信息，该条消息会重新发给其他的消费者，或者在网络重连后再次发送给该消费者，但实际上该消费者已成功消费了该条消息，造成消费者消费了重复的消息。</p><p>解决思路</p><p>MQ 消费者的幂等性的解决一般使用全局 ID 或者写个唯一标识，比如时间戳或者 UUID ，订单消费者消费 MQ 中的消息也可利用 MQ 的该 id 来判断，或者可按自己的规则生成一个全局唯一 id，每次消费消息时用该 id 先判断该消息是否已消费过。</p><p>消费端的幂等性保障</p><p>在海量订单生成的业务高峰期，生产端有可能就会重复发生了消息，这时候消费端就要实现幂等性， 这就意味着我们的消息永远不会被消费多次，即使我们收到了一样的消息。</p><p>业界主流的幂等性有两种操作:</p><p>唯一 ID + 指纹码机制，用数据库主键去重；<br>利用 redis 的原子性去实现。<br>唯一 ID + 指纹码机制<br>指纹码：我们的一些规则或者时间戳加别的服务给到的唯一信息码，它并不一定是我们系统生成的，基本都是由我们的业务规则拼接而来，但是一定要保证唯一性，然后就利用查询语句进行判断这个 id 是否存在数据库中，优势就是实现简单就一个拼接，然后查询判断是否重复；劣势就是在高并发时，如果是单个数据库就会有写入性能瓶颈当然也可以采用分库分表提升性能，但也不是我们最推荐的方式。</p><p>note Redis 原子性<br>利用 redis 执行 setnx 命令，天然具有幂等性，从而实现不重复消费。</p><p>优先级队列<br>使用场景</p><p>在我们系统中有一个订单催付的场景，我们的客户在天猫下的订单，淘宝会及时将订单推送给我们，如果在用户设定的时间内未付款那么就会给用户推送一条短信提醒，很简单的一个功能对吧。</p><p>但是，天猫商家对我们来说，肯定是要分大客户和小客户的对吧，比如像苹果、小米这样大商家一年起码能给我们创造很大的利润，所以理应当然，他们的订单必须得到优先处理，而曾经我们的后端系统是使用 redis 来存放的定时轮询，大家都知道 redis 只能用 List 做一个简简单单的消息队列，并不能实现一个优先级的场景，所以订单量大了后采用 RabbitMQ 进行改造和优化，如果发现是大客户的订单给一个相对比较高的优先级， 否则就是默认优先级。</p><p>如何添加？</p><p>控制台页面添加</p><p>RabbitMQ-00000076</p><p>队列中代码添加优先级<br>JAVA<br>1<br>2<br>3<br>Map&lt;String, Object&gt; params = new HashMap();<br>params.put(“x-max-priority”, 10);<br>channel.queueDeclare(“hello”, true, false, false, params);<br>消息中代码添加优先级<br>JAVA<br>1<br>AMQP.BasicProperties properties = new AMQP.BasicProperties().builder().priority(10).build();<br>注意事项：</p><p>要让队列实现优先级需要做的事情有如下事情：队列需要设置为优先级队列，消息需要设置消息的优先级，消费者需要等待消息已经发送到队列中才去消费因为，这样才有机会对消息进行排序。</p><p>生产者：</p><pre><code class="bash">public class PriorityProducer &#123;    private static final String QUEUE_NAME = &quot;hello&quot;;    public static void main(String[] args) throws Exception &#123;        Channel channel = RabbitMqUtils.getChannel();        //给消息赋予一个 priority 属性        AMQP.BasicProperties properties = new AMQP.BasicProperties().builder().priority(10).build();        for (int i = 1; i &lt; 11; i++) &#123;            String message = &quot;info&quot; + i;            if (i == 5) &#123;                channel.basicPublish(&quot;&quot;, QUEUE_NAME, properties, message.getBytes());            &#125; else &#123;                channel.basicPublish(&quot;&quot;, QUEUE_NAME, null, message.getBytes());            &#125;            System.out.println(&quot;发送消息完成:&quot; + message);        &#125;    &#125;&#125;</code></pre><p>消费者：</p><pre><code class="bash">public class PriorityConsumer &#123;    private final static String QUEUE_NAME = &quot;hello&quot;;    public static void main(String[] args) throws Exception &#123;        Channel channel = RabbitMqUtils.getChannel();        //设置队列的最大优先级 最大可以设置到 255 官网推荐 1-10 如果设置太高比较吃内存和 CPU        Map&lt;String, Object&gt; params = new HashMap();        params.put(&quot;x-max-priority&quot;, 10);        channel.queueDeclare(QUEUE_NAME, true, false, false, params);        //推送的消息如何进行消费的接口回调        DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; &#123;            String message = new String(delivery.getBody());            System.out.println(message);        &#125;;        //取消消费的一个回调接口 如在消费的时候队列被删除掉了        CancelCallback cancelCallback = (consumerTag) -&gt; &#123;            System.out.println(&quot;消息消费被中断&quot;);        &#125;;        channel.basicConsume(QUEUE_NAME, true, deliverCallback, cancelCallback);    &#125;&#125;</code></pre><p>image-20210629163922085</p><p>惰性队列<br>使用场景</p><p>RabbitMQ 从 3.6.0 版本开始引入了惰性队列的概念。惰性队列会尽可能的将消息存入磁盘中，而在消费者消费到相应的消息时才会被加载到内存中，它的一个重要的设计目标是能够支持更长的队列，即支持更多的消息存储。当消费者由于各种各样的原因 (比如消费者下线、宕机亦或者是由于维护而关闭等) 而致使长时间内不能消费消息造成堆积时，惰性队列就很有必要了。</p><p>默认情况下，当生产者将消息发送到 RabbitMQ 的时候，队列中的消息会尽可能的存储在内存之中， 这样可以更加快速的将消息发送给消费者。即使是持久化的消息，在被写入磁盘的同时也会在内存中驻留一份备份。当 RabbitMQ 需要释放内存的时候，会将内存中的消息换页至磁盘中，这个操作会耗费较长的时间，也会阻塞队列的操作，进而无法接收新的消息。虽然 RabbitMQ 的开发者们一直在升级相关的算法， 但是效果始终不太理想，尤其是在消息量特别大的时候。</p><p>两种模式</p><p>队列具备两种模式：default 和 lazy。默认的为 default 模式，在 3.6.0 之前的版本无需做任何变更。lazy 模式即为惰性队列的模式，可以通过调用 channel.queueDeclare 方法的时候在参数中设置，也可以通过 Policy 的方式设置，如果一个队列同时使用这两种方式设置的话，那么 Policy 的方式具备更高的优先级。 如果要通过声明的方式改变已有队列的模式的话，那么只能先删除队列，然后再重新声明一个新的。</p><p>在队列声明的时候可以通过 “x-queue-mode” 参数来设置队列的模式，取值为 “default” 和 “lazy”。下面示例中演示了一个惰性队列的声明细节：</p><pre><code class="bash">Map&lt;String, Object&gt; args = new HashMap&lt;String, Object&gt;();args.put(&quot;x-queue-mode&quot;, &quot;lazy&quot;);channel.queueDeclare(&quot;myqueue&quot;, false, false, false, args);</code></pre><p>内存开销对比</p><p>RabbitMQ-00000077</p><p>在发送 1 百万条消息，每条消息大概占 1KB 的情况下，普通队列占用内存是 1.2GB，而惰性队列仅仅 占用 1.5MB。</p>]]></content>
      
      
      <categories>
          
          <category> MQ消息队列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 消息中间件 </tag>
            
            <tag> RabbitMQ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>axios</title>
      <link href="/2021/04/06/vue/axios/"/>
      <url>/2021/04/06/vue/axios/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="axios"><a href="#axios" class="headerlink" title="axios"></a>axios</h1><h1 id="基本使用"><a href="#基本使用" class="headerlink" title="基本使用"></a>基本使用</h1><p>增删改查，get查，post增，put改，delete查</p><pre><code class="bash">&lt;body&gt;    &lt;button id=&quot;1&quot;&gt;点我&lt;/button&gt;    &lt;button id=&quot;2&quot;&gt;点我2&lt;/button&gt;    &lt;button id=&quot;3&quot;&gt;点我3&lt;/button&gt;    &lt;button id=&quot;5&quot;&gt;点我5&lt;/button&gt;     &lt;script&gt;         var btn = document.getElementById(&#39;1&#39;)         var btn2 = document.getElementById(&#39;2&#39;)         var btn3 = document.getElementById(&#39;3&#39;)         var btn5 = document.getElementById(&#39;5&#39;)         btn.onclick=function()&#123;            axios(&#123;                method:&#39;GET&#39;,                url: &#39;http://localhost:3000/posts&#39;,            &#125;).then(response=&gt;&#123;                console.log(response)            &#125;);         &#125;         btn2.onclick=function()&#123;            axios(&#123;                method:&#39;POST&#39;,                url: &#39;http://localhost:3000/posts&#39;,                data:&#123;                    title: &quot;hello world&quot;,                    author: &quot;chenhao&quot;                &#125;            &#125;).then(value=&gt;&#123;                console.log(value)            &#125;,reason=&gt;&#123;                console.log(reason)            &#125;);         &#125;         btn3.onclick=function()&#123;            axios(&#123;                method:&#39;delete&#39;,                url: &#39;http://localhost:3000/posts/3&#39;,                &#125;).then(value=&gt;&#123;                console.log(value)            &#125;,reason=&gt;&#123;                console.log(reason)            &#125;);         &#125;         btn5.onclick=function()&#123;            axios(&#123;                method:&#39;PUT&#39;,                url: &#39;http://localhost:3000/posts/2&#39;,                data:&#123;                    title: &quot;hello world&quot;,                    author: &quot;libai&quot;                &#125;            &#125;).then(value=&gt;&#123;                console.log(value)            &#125;,reason=&gt;&#123;                console.log(reason)            &#125;);         &#125;     &lt;/script&gt;&lt;/body&gt;</code></pre><p><img src="https://cdn.jsdelivr.net/gh/jnylife/ImgHosting/img/202112122224926.png" alt="响应结果"></p><h1 id="默认配置"><a href="#默认配置" class="headerlink" title="默认配置"></a>默认配置</h1><pre><code class="bash">axios.defaults.method=&#39;POST&#39;   axios.defaults.baseURL=&#39;http://localhost:3000&#39;</code></pre><h1 id="拦截器"><a href="#拦截器" class="headerlink" title="拦截器"></a>拦截器</h1><pre><code class="bash">         //增加一个请求拦截器axios.interceptors.request.use(function (config) &#123;    // Do something before request is sent    console.log(&quot;请求拦截器成功&quot;)    return config;  &#125;, function (error) &#123;    // Do something with request error        console.log(&quot;请求拦截器失败&quot;)    return Promise.reject(error);  &#125;);//增加一个响应拦截器axios.interceptors.response.use(function (response) &#123;    // Any status code that lie within the range of 2xx cause this function to trigger    // Do something with response data            console.log(&quot;响应拦截器成功&quot;)    return response;  &#125;, function (error) &#123;    // Any status codes that falls outside the range of 2xx cause this function to trigger                console.log(&quot;响应拦截器成功&quot;)    // Do something with response error    return Promise.reject(error);  &#125;);axios(&#123;    method:&#39;GET&#39;,    url: &#39;http://localhost:3000/posts&#39;    &#125;)</code></pre>]]></content>
      
      
      <categories>
          
          <category> Vue </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Axios </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>vue插槽</title>
      <link href="/2021/04/05/vue/vue%E6%8F%92%E6%A7%BD/"/>
      <url>/2021/04/05/vue/vue%E6%8F%92%E6%A7%BD/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>收集表单数据：<br>​ 若：<input type="text"/>，则v-model收集的是value值，用户输入的就是value值。</p><p>​ 若：<input type="radio"/>，则v-model收集的是value值，且要给标签配置value值。</p><p>​ 若：<input type="checkbox"/></p><p>​ 1.没有配置input的value属性，那么收集的就是checked（勾选 or 未勾选，是布尔值）</p><p>​ 2.配置input的value属性:</p><p>​ (1)v-model的初始值是非数组，那么收集的就是checked（勾选 or 未勾选，是布尔值）</p><p>​ (2)v-model的初始值是数组，那么收集的的就是value组成的数组</p><p>​ 备注：v-model的三个修饰符：</p><p>​ lazy：失去焦点再收集数据</p><p>​ number：输入字符串转为有效的数字</p><p>​ trim：输入首尾空格过滤</p><p>过滤器<br>局部过滤器<br>filters:{<br>            timeFormater(value,str=’YYYY年MM月DD日 HH:mm:ss’){<br>                // console.log(‘@’,value)<br>                return dayjs(value).format(str)<br>            }<br>        }<br>全局过滤器</p><p>Vue.filter(‘mySlice’,function(value){<br>    return value.slice(0,4)<br>})<br>内置指令<br>已学</p><p>​ ~~ v-bind : 单向绑定解析表达式, 可简写为 :xxx</p><p>​ v-model : 双向数据绑定</p><p>​ v-for : 遍历数组/对象/字符串</p><p>​ v-on : 绑定事件监听, 可简写为@</p><p>​ v-if : 条件渲染（动态控制节点是否存存在）</p><p>​ v-else : 条件渲染（动态控制节点是否存存在）</p><p>​ v-show : 条件渲染 (动态控制节点是否展示)~~</p><p>v-text<br>​ v-text指令：</p><p>​ 1.作用：向其所在的节点中渲染文本内容。</p><p>​ 2.与插值语法的区别：v-text会替换掉节点中的内容，则不会。</p><p>v-html<br>​ v-html指令：</p><p>​ 1.作用：向指定节点中渲染包含html结构的内容。</p><p>​ 2.与插值语法的区别：</p><p>​ (1).v-html会替换掉节点中所有的内容，则不会。</p><p>​ (2).v-html可以识别html结构。</p><p>​ 3.严重注意：v-html有安全性问题！！！！</p><p>​ (1).在网站上动态渲染任意HTML是非常危险的，容易导致XSS攻击。</p><p>​ (2).一定要在可信的内容上使用v-html，永不要用在用户提交的内容上！</p><p>v-clock<br>​ v-cloak指令（没有值）：</p><p>​ 1.本质是一个特殊属性，Vue实例创建完毕并接管容器后，会删掉v-cloak属性。</p><p>​ 2.使用css配合v-cloak可以解决网速慢时页面展示出的问题。</p><style>    [v-cloak]{        display:none;    }</style><p>v-once<br>​ v-once指令：</p><p>​ 1.v-once所在节点在初次动态渲染后，就视为静态内容了。</p><p>​ 2.以后数据的改变不会引起v-once所在结构的更新，可以用于优化性能。</p><p>v-pre<br>v-pre指令：</p><p>​ 1.跳过其所在节点的编译过程。</p><p>​ 2.可利用它跳过：没有使用指令语法、没有使用插值语法的节点，会加快编译。</p><p>自定义指令<br>​ 需求1：定义一个v-big指令，和v-text功能类似，但会把绑定的数值放大10倍。</p><p>big(element,binding){<br>    console.log(‘big’,this) //注意此处的this是window<br>    // console.log(‘big’)<br>    element.innerText = binding.value * 10<br>​ 需求2：定义一个v-fbind指令，和v-bind功能类似，但可以让其所绑定的input元素默认获取焦点。</p><p>fbind:{<br>    //指令与元素成功绑定时（一上来）<br>    bind(element,binding){<br>        element.value = binding.value<br>    },<br>    //指令所在元素被插入页面时<br>    inserted(element,binding){<br>        element.focus()<br>    },<br>    //指令所在的模板被重新解析时<br>    update(element,binding){<br>        element.value = binding.value<br>    }<br>}<br>​ 自定义指令总结：</p><p>​ 一、定义语法：</p><p>​ (1).局部指令：</p><p>​ new Vue({ new Vue({</p><p>​ directives:{指令名:配置对象} 或 directives{指令名:回调函数}</p><p>​ }) })</p><p>​ (2).全局指令：</p><p>​ Vue.directive(指令名,配置对象) 或 Vue.directive(指令名,回调函数)</p><p>​ 二、配置对象中常用的3个回调：</p><p>​ (1).bind：指令与元素成功绑定时调用。</p><p>​ (2).inserted：指令所在元素被插入页面时调用。</p><p>​ (3).update：指令所在模板结构被重新解析时调用。</p><p>​ 三、备注：</p><p>​ 1.指令定义时不加v-，但使用时要加v-；</p><p>​ 2.指令名如果是多个单词，要使用kebab-case命名方式，不要用camelCase命名。</p><p>定义全局指令</p><p>//定义全局指令<br>Vue.directive(‘fbind’,{<br>    //指令与元素成功绑定时（一上来）<br>    bind(element,binding){<br>        element.value = binding.value<br>    },<br>    //指令所在元素被插入页面时<br>    inserted(element,binding){<br>        element.focus()<br>    },<br>    //指令所在的模板被重新解析时<br>    update(element,binding){<br>        element.value = binding.value<br>    }<br>})<br>vue生命周期<br>​ 生命周期：</p><p>​ 1.又名：生命周期回调函数、生命周期函数、生命周期钩子。</p><p>​ 2.是什么：Vue在关键时刻帮我们调用的一些特殊名称的函数。</p><p>​ 3.生命周期函数的名字不可更改，但函数的具体内容是程序员根据需求编写的。</p><p>​ 4.生命周期函数中的this指向是vm 或 组件实例对象。</p><p>beforeCreate() {<br>    console.log(‘beforeCreate’)<br>},<br>created() {<br>    console.log(‘created’)<br>},<br>beforeMount() {<br>    console.log(‘beforeMount’)<br>},<br>mounted() {<br>    console.log(‘mounted’)<br>},<br>beforeUpdate() {<br>    console.log(‘beforeUpdate’)<br>},<br>updated() {<br>    console.log(‘updated’)<br>},<br>beforeDestroy() {<br>    console.log(‘beforeDestroy’)<br>},<br>destroyed() {<br>    console.log(‘destroyed’)<br>},<br>生命周期</p><p>组件<br>组件就是一块砖，哪里需要往哪搬。</p><p>​ Vue中使用组件的三大步骤：</p><p>​ 一、定义组件(创建组件)</p><p>​ 二、注册组件</p><p>​ 三、使用组件(写组件标签)</p><p>​ 一、如何定义一个组件？</p><p>​ 使用Vue.extend(options)创建，其中options和new Vue(options)时传入的那个options几乎一样，但也有点区别；</p><p>​ 区别如下：</p><p>​ 1.el不要写，为什么？ ——— 最终所有的组件都要经过一个vm的管理，由vm中的el决定服务哪个容器。</p><p>​ 2.data必须写成函数，为什么？ ———— 避免组件被复用时，数据存在引用关系。</p><p>​ 备注：使用template可以配置组件结构。</p><p>​ 二、如何注册组件？</p><p>​ 1.局部注册：靠new Vue的时候传入components选项</p><p>​ 2.全局注册：靠Vue.component(‘组件名’,组件)</p><p>​ 三、编写组件标签：</p><p>​ <school></school></p><p>非单文件组件<br>const school = Vue.extend({<br>         template:<code>          &lt;div&gt;          &lt;h2&gt;&#123;&#123;schname&#125;&#125;&lt;/h2&gt;          &lt;h2&gt;&#123;&#123;schaddress&#125;&#125;&lt;/h2&gt;          &lt;/div&gt;</code>,<br>         data(){<br>             return{<br>             schname:’ynnubs’,<br>             schaddress:’五华区商院路’<br>             }</p><pre><code>     &#125; &#125;)</code></pre><p>​ 几个注意点：</p><p>​ 1.关于组件名:</p><p>​ 一个单词组成：</p><p>​ 第一种写法(首字母小写)：school</p><p>​ 第二种写法(首字母大写)：School</p><p>​ 多个单词组成：</p><p>​ 第一种写法(kebab-case命名)：my-school</p><p>​ 第二种写法(CamelCase命名)：MySchool (需要Vue脚手架支持)</p><p>​ 备注：</p><p>​ (1).组件名尽可能回避HTML中已有的元素名称，例如：h2、H2都不行。</p><p>​ (2).可以使用name配置项指定组件在开发者工具中呈现的名字。</p><p>​ 2.关于组件标签:</p><p>​ 第一种写法：</p><p>​ 第二种写法：</p><p>​ 备注：不用使用脚手架时，会导致后续组件不能渲染。</p><p>​ 3.一个简写方式：</p><p>​ const school = Vue.extend(options) 可简写为：const school = options</p><p>VueComponent<br>​ 关于VueComponent：</p><p>​ 1.school组件本质是一个名为VueComponent的构造函数，且不是程序员定义的，是Vue.extend生成的。</p><p>​ 2.我们只需要写或，Vue解析时会帮我们创建school组件的实例对象，</p><p>​ 即Vue帮我们执行的：new VueComponent(options)。</p><p>​ 3.特别注意：每次调用Vue.extend，返回的都是一个全新的VueComponent！！！！</p><p>​ 4.关于this指向：</p><p>​ (1).组件配置中：</p><p>​ data函数、methods中的函数、watch中的函数、computed中的函数 它们的this均是【VueComponent实例对象】。</p><p>​ (2).new Vue(options)配置中：</p><p>​ data函数、methods中的函数、watch中的函数、computed中的函数 它们的this均是【Vue实例对象】。</p><p>​ 5.VueComponent的实例对象，以后简称vc（也可称之为：组件实例对象）。</p><p>​ Vue的实例对象，以后简称vm。</p><p>一个重要的内置关系<br>​ 1.一个重要的内置关系：VueComponent.prototype.proto === Vue.prototype</p><p>​ 2.为什么要有这个关系：让组件实例对象（vc）可以访问到 Vue原型上的属性、方法。</p><p>前言：在JS里，万物皆对象。方法（Function）是对象，方法的原型(Function.prototype)是对象。因此，它们都会具有对象共有的特点。</p><p>即：对象具有属性__proto__，可称为隐式原型，一个对象的隐式原型指向构造该对象的构造函数的原型，这也保证了实例能够访问在构造函数原型中定义的属性和方法。</p><p>image-20220102155502091</p><p>单文件组件<br>创建School.vue</p><template>     <div class="demo">            <h2></h2>            <h2></h2>            </div></template><script>   export default ({        name:School,            data(){                return{                schname:'ynnubs',                schaddress:'五华区商院路'                }     <pre><code>        &#125;    &#125;)</code></pre><p></script><br>创建App.vue</p><template>  <div>      <School><School>  </div></template><script>import School from './School.vue'export default {    name:'app',    components:{        School    }}</script><style></style><p>创建main.js</p><p>import App from ‘./App.vue’<br>new Vue({<br>    el:’#root’,<br>    template:<code>&lt;App&gt;&lt;/App&gt;</code>,<br>    components:{App}<br>})<br>创建a.html</p><!DOCTYPE html><html lang="en"><head>    <meta charset="UTF-8">    <meta http-equiv="X-UA-Compatible" content="IE=edge">    <meta name="viewport" content="width=device-width, initial-scale=1.0">    <title>Document</title></head>]]></content>
      
      
      <categories>
          
          <category> Vue </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Vue </tag>
            
            <tag> 插槽 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>vue脚手架</title>
      <link href="/2021/03/30/vue/vue%E8%84%9A%E6%89%8B%E6%9E%B6/"/>
      <url>/2021/03/30/vue/vue%E8%84%9A%E6%89%8B%E6%9E%B6/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="脚手架文件结构"><a href="#脚手架文件结构" class="headerlink" title="脚手架文件结构"></a>脚手架文件结构</h1><p>├── node_modules<br>├── public<br>│ ├── favicon.ico: 页签图标<br>│ └── index.html: 主页面<br>├── src<br>│ ├── assets: 存放静态资源<br>│ │ └── logo.png<br>│ │── component: 存放组件<br>│ │ └── HelloWorld.vue<br>│ │── App.vue: 汇总所有组件<br>│ │── main.js: 入口文件<br>├── .gitignore: git版本管制忽略的配置<br>├── babel.config.js: babel的配置文件<br>├── package.json: 应用包配置文件<br>├── README.md: 应用描述文件<br>├── package-lock.json：包版本控制文件</p><h1 id="关于不同版本的Vue"><a href="#关于不同版本的Vue" class="headerlink" title="关于不同版本的Vue"></a>关于不同版本的Vue</h1><ol><li>vue.js与vue.runtime.xxx.js的区别：<ul><li>vue.js是完整版的Vue，包含：核心功能 + 模板解析器。</li><li>vue.runtime.xxx.js是运行版的Vue，只包含：核心功能；没有模板解析器。</li></ul></li><li>因为vue.runtime.xxx.js没有模板解析器，所以不能使用template这个配置项，需要使用render函数接收到的createElement函数去指定具体内容。</li></ol><h1 id="vue-config-js配置文件"><a href="#vue-config-js配置文件" class="headerlink" title="vue.config.js配置文件"></a>vue.config.js配置文件</h1><ol><li>使用vue inspect &gt; output.js可以查看到Vue脚手架的默认配置。</li><li>使用vue.config.js可以对脚手架进行个性化定制，详情见：<a href="https://cli.vuejs.org/zh">https://cli.vuejs.org/zh</a></li></ol><h1 id="ref属性"><a href="#ref属性" class="headerlink" title="ref属性"></a>ref属性</h1><ol><li>被用来给元素或子组件注册引用信息（id的替代者）</li><li>应用在html标签上获取的是真实DOM元素，应用在组件标签上是组件实例对象（vc）</li><li>使用方式：<ul><li>打标识：<h1 ref="xxx">…..</h1> 或 <School ref="xxx"></School><br>获取：this.$refs.xxx<br>props配置项<br>功能：让组件接收外部传过来的数据</li></ul></li></ol><p>传递数据：<Demo name="xxx"/></p><p>接收数据：</p><p>第一种方式（只接收）：props:[‘name’]</p><p>第二种方式（限制类型）：props:{name:String}</p><p>第三种方式（限制类型、限制必要性、指定默认值）：</p><p>props:{<br> name:{<br> type:String, //类型<br> required:true, //必要性<br> default:’老王’ //默认值<br> }<br>}<br>备注：props是只读的，Vue底层会监测你对props的修改，如果进行了修改，就会发出警告，若业务需求确实需要修改，那么请复制props的内容到data中一份，然后去修改data中的数据。</p><p>mixin(混入)<br>功能：可以把多个组件共用的配置提取成一个混入对象</p><p>使用方式：</p><p>第一步定义混合：</p><p>{<br>    data(){….},<br>    methods:{….}<br>    ….<br>}<br>第二步使用混入：</p><p>全局混入：Vue.mixin(xxx)<br>局部混入：mixins:[‘xxx’]</p><p>插件<br>功能：用于增强Vue</p><p>本质：包含install方法的一个对象，install的第一个参数是Vue，第二个以后的参数是插件使用者传递的数据。</p><p>定义插件：</p><p>对象.install = function (Vue, options) {<br>    // 1. 添加全局过滤器<br>    Vue.filter(….)</p><pre><code>// 2. 添加全局指令Vue.directive(....)// 3. 配置全局混入(合)Vue.mixin(....)// 4. 添加实例方法Vue.prototype.$myMethod = function () &#123;...&#125;Vue.prototype.$myProperty = xxxx</code></pre><p>}<br>使用插件：Vue.use()</p><p>scoped样式<br>作用：让样式在局部生效，防止冲突。<br>写法：<style scoped><br>总结TodoList案例<br>组件化编码流程：</p><p>(1).拆分静态组件：组件要按照功能点拆分，命名不要与html元素冲突。</p><p>(2).实现动态组件：考虑好数据的存放位置，数据是一个组件在用，还是一些组件在用：</p><p>​ 1).一个组件在用：放在组件自身即可。</p><p>​ 2). 一些组件在用：放在他们共同的父组件上（状态提升）。</p><p>(3).实现交互：从绑定事件开始。</p><p>props适用于：</p><p>(1).父组件 ==&gt; 子组件 通信</p><p>(2).子组件 ==&gt; 父组件 通信（要求父先给子一个函数）</p><p>使用v-model时要切记：v-model绑定的值不能是props传过来的值，因为props是不可以修改的！</p><p>props传过来的若是对象类型的值，修改对象中的属性时Vue不会报错，但不推荐这样做。</p><p>webStorage<br>存储内容大小一般支持5MB左右（不同浏览器可能还不一样）</p><p>浏览器端通过 Window.sessionStorage 和 Window.localStorage 属性来实现本地存储机制。</p><p>相关API：</p><p>xxxxxStorage.setItem(‘key’, ‘value’);</p><pre><code>   该方法接受一个键和值作为参数，会把键值对添加到存储中，如果键名存在，则更新其对应的值。</code></pre><p>xxxxxStorage.getItem(‘person’);</p><p>​ 该方法接受一个键名作为参数，返回键名对应的值。</p><p>xxxxxStorage.removeItem(‘key’);</p><p>​ 该方法接受一个键名作为参数，并把该键名从存储中删除。</p><p>xxxxxStorage.clear()</p><p>​ 该方法会清空存储中的所有数据。</p><p>备注：</p><p>SessionStorage存储的内容会随着浏览器窗口关闭而消失。<br>LocalStorage存储的内容，需要手动清除才会消失。<br>xxxxxStorage.getItem(xxx)如果xxx对应的value获取不到，那么getItem的返回值是null。<br>JSON.parse(null)的结果依然是null。<br>组件的自定义事件<br>一种组件间通信的方式，适用于：子组件 ===&gt; 父组件</p><p>使用场景：A是父组件，B是子组件，B想给A传数据，那么就要在A中给B绑定自定义事件（事件的回调在A中）。</p><p>绑定自定义事件：</p><p>第一种方式，在父组件中：&lt;Demo @atguigu=”test”/&gt; 或 <Demo v-on:atguigu="test"/></p><p>第二种方式，在父组件中：</p><Demo ref="demo"/>......mounted(){   this.$refs.xxx.$on('atguigu',this.test)}若想让自定义事件只能触发一次，可以使用once修饰符，或$once方法。<p>​ 4. 触发自定义事件：this.$emit(‘atguigu’,数据)</p><p>​ 5. 解绑自定义事件this.$off(‘atguigu’)</p><p>6.组件上也可以绑定原生DOM事件，需要使用native修饰符。</p><p>注意：通过this.$refs.xxx.$on(‘atguigu’,回调)绑定自定义事件时，回调要么配置在methods中，要么用箭头函数，否则this指向会出问题！</p>]]></content>
      
      
      <categories>
          
          <category> Vue </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Vue </tag>
            
            <tag> 脚手架 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>vue组件</title>
      <link href="/2021/03/30/vue/vue%E7%BB%84%E4%BB%B6/"/>
      <url>/2021/03/30/vue/vue%E7%BB%84%E4%BB%B6/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="组件"><a href="#组件" class="headerlink" title="组件"></a>组件</h1><p><strong>组件就是一块砖，哪里需要往哪搬。</strong></p><h2 id="Vue中使用组件的三大步骤："><a href="#Vue中使用组件的三大步骤：" class="headerlink" title="Vue中使用组件的三大步骤："></a>Vue中使用组件的三大步骤：</h2><ol><li>定义组件(创建组件)</li><li>注册组件</li><li>使用组件(写组件标签)</li></ol><h2 id="如何定义一个组件？"><a href="#如何定义一个组件？" class="headerlink" title="如何定义一个组件？"></a>如何定义一个组件？</h2><blockquote><p>使用Vue.extend(options)创建，其中options和new Vue(options)时传入的那个options几乎一样，但也有点区别；</p></blockquote><p><em>​区别如下：</em></p><ul><li><p>el不要写，为什么？ ——— 最终所有的组件都要经过一个vm的管理，由vm中的el决定服务哪个容器。</p></li><li><p>data必须写成函数，为什么？ ———— 避免组件被复用时，数据存在引用关系。</p></li></ul><p><strong>​备注</strong>：使用template可以配置组件结构。</p><h2 id="如何注册组件？"><a href="#如何注册组件？" class="headerlink" title="如何注册组件？"></a>如何注册组件？</h2><ol><li><p>局部注册：靠new Vue的时候传入components选项</p></li><li><p>全局注册：靠Vue.component(‘组件名’,组件)</p></li><li><p>编写组件标签：</p></li></ol><p>​ <code> <school></school> </code></p><h1 id="非单文件组件"><a href="#非单文件组件" class="headerlink" title="非单文件组件"></a>非单文件组件</h1><pre><code class="bash">const school = Vue.extend(&#123;         template:`         &lt;div&gt;         &lt;h2&gt;&#123;&#123;schname&#125;&#125;&lt;/h2&gt;         &lt;h2&gt;&#123;&#123;schaddress&#125;&#125;&lt;/h2&gt;         &lt;/div&gt;`,         data()&#123;             return&#123;             schname:&#39;ynnubs&#39;,             schaddress:&#39;五华区商院路&#39;             &#125;           &#125;     &#125;)</code></pre><p>​ 几个注意点：</p><p>​ 1.关于组件名:</p><p>​ 一个单词组成：</p><p>​ 第一种写法(首字母小写)：school</p><p>​ 第二种写法(首字母大写)：School</p><p>​ 多个单词组成：</p><p>​ 第一种写法(kebab-case命名)：my-school</p><p>​ 第二种写法(CamelCase命名)：MySchool (需要Vue脚手架支持)</p><p>​ 备注：</p><p>​ (1).组件名尽可能回避HTML中已有的元素名称，例如：h2、H2都不行。</p><p>​ (2).可以使用name配置项指定组件在开发者工具中呈现的名字。</p><p>​ 2.关于组件标签:</p><p>​ 第一种写法：</p><p>​ 第二种写法：</p><p>​ 备注：不用使用脚手架时，会导致后续组件不能渲染。</p><p>​ 3.一个简写方式：</p><p>​ const school = Vue.extend(options) 可简写为：const school = options</p><h2 id="VueComponent"><a href="#VueComponent" class="headerlink" title="VueComponent"></a>VueComponent</h2><p>​</p><ol><li><p>school组件本质是一个名为VueComponent的构造函数，且不是程序员定义的，是Vue.extend生成的。</p></li><li><p>我们只需要写或，Vue解析时会帮我们创建school组件的实例对象，即Vue帮我们执行的：new VueComponent(options)。</p></li><li><p>特别注意：每次调用Vue.extend，返回的都是一个全新的VueComponent！！！！</p></li><li><p>关于this指向：</p><ul><li>组件配置中：data函数、methods中的函数、watch中的函数、computed中的函数 它们的this均是【VueComponent实例对象】。</li><li>new Vue(options)配置中：data函数、methods中的函数、watch中的函数、computed中的函数 它们的this均是【Vue实例对象】。</li></ul></li><li><p>VueComponent的实例对象，以后简称vc（也可称之为：组件实例对象），Vue的实例对象，以后简称vm。</p></li></ol><h2 id="一个重要的内置关系"><a href="#一个重要的内置关系" class="headerlink" title="一个重要的内置关系"></a>一个重要的内置关系</h2><p>​</p><ol><li><p>一个重要的内置关系：<code>VueComponent.prototype.proto === Vue.prototype</code></p></li><li><p>为什么要有这个关系：<code>让组件实例对象（vc）可以访问到 Vue原型上的属性、方法。</code></p></li></ol><p>前言：在JS里，万物皆对象。方法（Function）是对象，方法的原型(Function.prototype)是对象。因此，它们都会具有对象共有的特点。</p><blockquote><p>即，对象具有属性<code><strong>proto</strong></code>，可称为隐式原型，一个对象的隐式原型指向构造该对象的构造函数的原型，这也保证了实例能够访问在构造函数原型中定义的属性和方法。</p></blockquote><p><img src="https://cdn.jsdelivr.net/gh/jnylife/ImgHosting/img/202201021555154.png"></p><h2 id="单文件组件"><a href="#单文件组件" class="headerlink" title="单文件组件"></a>单文件组件</h2><blockquote><p>创建School.vue</p></blockquote><pre><code class="bash">&lt;template&gt;     &lt;div class=&quot;demo&quot;&gt;            &lt;h2&gt;&#123;&#123;schname&#125;&#125;&lt;/h2&gt;            &lt;h2&gt;&#123;&#123;schaddress&#125;&#125;&lt;/h2&gt;            &lt;/div&gt;&lt;/template&gt;&lt;script&gt;   export default (&#123;        name:School,            data()&#123;                return&#123;                schname:&#39;ynnubs&#39;,                schaddress:&#39;五华区商院路&#39;                &#125;                 &#125;        &#125;)&lt;/script&gt;</code></pre><blockquote><p>创建App.vue</p></blockquote><pre><code class="bash">&lt;template&gt;  &lt;div&gt;      &lt;School&gt;&lt;School&gt;  &lt;/div&gt;&lt;/template&gt;&lt;script&gt;import School from &#39;./School.vue&#39;export default &#123;    name:&#39;app&#39;,    components:&#123;        School    &#125;&#125;&lt;/script&gt;&lt;style&gt;&lt;/style&gt;</code></pre><blockquote><p>创建main.js</p></blockquote><pre><code class="bash">import App from &#39;./App.vue&#39;new Vue(&#123;    el:&#39;#root&#39;,    template:`&lt;App&gt;&lt;/App&gt;`,    components:&#123;App&#125;&#125;)</code></pre><blockquote><p>创建a.html</p></blockquote><pre><code class="bash">&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt;    &lt;meta charset=&quot;UTF-8&quot;&gt;    &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge&quot;&gt;    &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt;    &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt;    &lt;div id=&quot;root&quot;&gt;      &lt;/div&gt;    &lt;script src=&quot;../js/vue.js&quot;&gt;&lt;/script&gt;    &lt;script src=&quot;./main.js&quot;&gt;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt;</code></pre>]]></content>
      
      
      <categories>
          
          <category> Vue </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Vue </tag>
            
            <tag> 组件 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>vue生命周期</title>
      <link href="/2021/03/26/vue/vue%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/"/>
      <url>/2021/03/26/vue/vue%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="vue生命周期"><a href="#vue生命周期" class="headerlink" title="vue生命周期"></a>vue生命周期</h1><p>​<br><em>生命周期：</em></p><p>​ 1. 又名：生命周期回调函数、生命周期函数、生命周期钩子。</p><p>​ 2. 是什么：Vue在关键时刻帮我们调用的一些特殊名称的函数。</p><p>​ 3. 生命周期函数的名字不可更改，但函数的具体内容是程序员根据需求编写的。</p><p>​ 4. 生命周期函数中的this指向是vm 或 组件实例对象。</p><pre><code class="bash">beforeCreate() &#123;    console.log(&#39;beforeCreate&#39;)&#125;,created() &#123;    console.log(&#39;created&#39;)&#125;,beforeMount() &#123;    console.log(&#39;beforeMount&#39;)&#125;,mounted() &#123;    console.log(&#39;mounted&#39;)&#125;,beforeUpdate() &#123;    console.log(&#39;beforeUpdate&#39;)&#125;,updated() &#123;    console.log(&#39;updated&#39;)&#125;,beforeDestroy() &#123;    console.log(&#39;beforeDestroy&#39;)&#125;,destroyed() &#123;    console.log(&#39;destroyed&#39;)&#125;,</code></pre><p><img src="https://cdn.jsdelivr.net/gh/jnylife/ImgHosting/img/202112311739681.png"></p>]]></content>
      
      
      <categories>
          
          <category> Vue </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Vue </tag>
            
            <tag> Vue生命周期 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ES6特性</title>
      <link href="/2021/03/18/vue/ES6%E7%89%B9%E6%80%A7/"/>
      <url>/2021/03/18/vue/ES6%E7%89%B9%E6%80%A7/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>ECMAScript 和 JavaScript 的关系<br>一个常见的问题是，ECMAScript 和 JavaScript 到底是什么关系？</p><p>要讲清楚这个问题，需要回顾历史。1996 年 11 月，JavaScript 的创造者 Netscape 公司，决定将 JavaScript 提交给标准化组织 ECMA，希望这种语言能够成为国际标准。次年，ECMA 发布 262 号标准文件（ECMA-262）的第一版，规定了浏览器脚本语言的标准，并将这种语言称为 ECMAScript，这个版本就是 1.0 版。</p><p>该标准从一开始就是针对 JavaScript 语言制定的，但是之所以不叫 JavaScript，有两个原因。一是商标，Java 是 Sun 公司的商标，根据授权协议，只有 Netscape 公司可以合法地使用 JavaScript 这个名字，且 JavaScript 本身也已经被 Netscape 公司注册为商标。二是想体现这门语言的制定者是 ECMA，不是 Netscape，这样有利于保证这门语言的开放性和中立性。</p><p>因此，ECMAScript 和 JavaScript 的关系是，前者是后者的规格，后者是前者的一种实现。</p><p>let特点<br>变量不能重复声明</p><p>let star = ‘罗志祥’;<br>let star = ‘小猪’;<br>image-20211210121526853</p><p>块儿级作用域</p><p>{<br>    let girl = ‘周扬青’;<br>}<br>console.log(girl);</p><p>在里面定义的变量外面找不到</p><p>不存在变量提升</p><p>console.log(song);<br>let song = ‘lemon tree’ //无效写法，无法作用于console.log<br>不影响作用域链</p><p>{<br>let school = ‘ynnubs’<br>function fn(){<br> console.log(school)<br>}<br>fn();<br>}<br>通俗来讲，就是在外面定义的变量里面找得到，反之，函数里面定义的变量外面就找不到。</p><p>案例<br>let items = document.getElementsByClassName(‘item’);<br>//遍历并绑定事件<br>for(let i = 0;i&lt;items.length;i++){<br>    items[i].onclick = function(){<br>        //修改当前元素的背景颜色<br>        // this.style.background = ‘pink’;<br>        items[i].style.background = ‘pink’;<br>    }<br>}<br>const定义常量<br>一定要赋初始值<br>一般常量使用大写。<br>常量的值不能修改<br>块级作用域<br>对于数组和对象的元素修改，不算做对常量的修改，不会报错。<br>变量解构赋值<br>数组的解构<br>const F4 = [‘小沈阳’,’刘能’,’赵四’,’宋小宝’];<br>let [xiao, liu, zhao, song] = F4;<br>console.log(xiao);<br>console.log(liu);<br>console.log(zhao);<br>console.log(song);<br>对象的解构<br>const zhao = {<br>    name: ‘赵本山’,<br>    age: ‘不详’,<br>    xiaopin: function(){<br>        console.log(“我可以演小品”);<br>    }<br>};</p><p>let {name, age, xiaopin} = zhao;<br>console.log(name);<br>console.log(age);<br>console.log(xiaopin);<br>xiaopin();</p><p>/<em>let {xiaopin} = zhao;<br>xiaopin();  可以单独的解构</em>/<br>模板字符串<br>声明</p><p>   ES6 引入新的声明字符串的方式 『``』<br>​ let str = 我也是一个字符串哦!;<br>​ console.log(str, typeof str);</p><p>内容中可以直接出现换行符</p><p>let str = <code>&lt;ul&gt;             &lt;li&gt;沈腾&lt;/li&gt;             &lt;li&gt;玛丽&lt;/li&gt;             &lt;li&gt;魏翔&lt;/li&gt;             &lt;li&gt;艾伦&lt;/li&gt;             &lt;/ul&gt;</code>;<br>变量拼接</p><p>let lovest = ‘魏翔’;<br>let out = <code>$&#123;lovest&#125;是我心目中最搞笑的演员!!</code>;<br>console.log(out);<br>简化对象写法<br>ES6 允许在大括号里面，直接写入变量和函数，作为对象的属性和方法。这样的书写更加简洁。</p><p>let name = ‘aaa’;<br>      let change = function(){<br>          console.log(‘我们可以改变你!!’);<br>      }</p><pre><code>  const school = &#123;      name,      change,      improve()&#123;          console.log(&quot;我们可以提高你的技能&quot;);      &#125;  &#125;  console.log(school);</code></pre><p>箭头函数<br>ES6 允许使用「箭头」（=&gt;）定义函数。</p><p>let fn = (a,b) =&gt; {<br>    return a + b;<br>}</p><p>let result = fn(1, 2);<br>console.log(result);<br>//1. this 是静态的. this 始终指向函数声明时所在作用域下的 this 的值<br>      function getName(){<br>          console.log(this.name);<br>      }<br>      let getName2 = () =&gt; {<br>          console.log(this.name);<br>      }</p><pre><code>  //设置 window 对象的 name 属性  window.name = &#39;aaa&#39;;  const school = &#123;      name: &quot;ATGUIGU&quot;  &#125;  //直接调用  // getName();  // getName2();  //call 方法调用  // getName.call(school);  // getName2.call(school);  //2. 不能作为构造实例化对象  // let Person = (name, age) =&gt; &#123;  //     this.name = name;  //     this.age = age;  // &#125;  // let me = new Person(&#39;xiao&#39;,30);  // console.log(me);  //3. 不能使用 arguments 变量  // let fn = () =&gt; &#123;  //     console.log(arguments);  // &#125;  // fn(1,2,3);  //4. 箭头函数的简写      //1) 省略小括号, 当形参有且只有一个的时候      // let add = n =&gt; &#123;      //     return n + n;      // &#125;      // console.log(add(9));      //2) 省略花括号, 当代码体只有一条语句的时候, 此时 return 必须省略      // 而且语句的执行结果就是函数的返回值      let pow = n =&gt; n * n;                console.log(pow(8));</code></pre><p>扩展运算符<br>扩展运算符能将『数组』转换为逗号分隔的『参数序列』，也就是将数组转成了实参。</p><p>const tfboys = [‘易烊千玺’,’王源’,’王俊凯’];<br>// =&gt; ‘易烊千玺’,’王源’,’王俊凯’</p><p>// 声明一个函数<br>function chunwan(){<br>    console.log(arguments);<br>}</p><p>chunwan(…tfboys);// chunwan(‘易烊千玺’,’王源’,’王俊凯’)</p><p>拓展运算符应用<br>数组的合并</p><p>const kuaizi = [‘王太利’,’肖央’];<br>const fenghuang = [‘曾毅’,’玲花’];<br>// const zuixuanxiaopingguo = kuaizi.concat(fenghuang);<br>const zuixuanxiaopingguo = […kuaizi, …fenghuang];<br>console.log(zuixuanxiaopingguo);<br>数组的克隆</p><p>const sanzhihua = [‘E’,’G’,’M’];<br>const sanyecao = […sanzhihua];//  [‘E’,’G’,’M’]<br>console.log(sanyecao);<br>将伪数组转为真正的数组</p><p>const divs = document.querySelectorAll(‘div’);<br>const divArr = […divs];<br>console.log(divArr);// arguments<br>symbol的基本使用<br>ES5 的对象属性名都是字符串，这容易造成属性名的冲突。比如，你使用了一个他人提供的对象，但又想为这个对象添加新的方法（mixin 模式），新方法的名字就有可能与现有方法产生冲突。如果有一种机制，保证每个属性的名字都是独一无二的就好了，这样就从根本上防止属性名的冲突。这就是 ES6 引入Symbol的原因。</p><p>ES5 的对象属性名都是字符串，这容易造成属性名的冲突。比如，你使用了一个他人提供的对象，但又想为这个对象添加新的方法（mixin 模式），新方法的名字就有可能与现有方法产生冲突。如果有一种机制，保证每个属性的名字都是独一无二的就好了，这样就从根本上防止属性名的冲突。这就是 ES6 引入Symbol的原因。</p><p>Symbol 值通过Symbol函数生成。这就是说，对象的属性名现在可以有两种类型，一种是原来就有的字符串，另一种就是新增的 Symbol 类型。凡是属性名属于 Symbol 类型，就都是独一无二的，可以保证不会与其他属性名产生冲突。</p><p>let s = Symbol();</p><p>typeof s<br>// “symbol”<br>上面代码中，变量s就是一个独一无二的值。typeof运算符的结果，表明变量s是 Symbol 数据类型，而不是字符串之类的其他类型。</p><p>注意，Symbol函数前不能使用new命令，否则会报错。这是因为生成的 Symbol 是一个原始类型的值，不是对象。也就是说，由于 Symbol 值不是对象，所以不能添加属性。基本上，它是一种类似于字符串的数据类型。</p><p>Symbol函数可以接受一个字符串作为参数，表示对 Symbol 实例的描述，主要是为了在控制台显示，或者转为字符串时，比较容易区分。</p><p>let s1 = Symbol(‘foo’);<br>let s2 = Symbol(‘bar’);</p><p>s1 // Symbol(foo)<br>s2 // Symbol(bar)</p><p>s1.toString() // “Symbol(foo)”<br>s2.toString() // “Symbol(bar)”<br>上面代码中，s1和s2是两个 Symbol 值。如果不加参数，它们在控制台的输出都是Symbol()，不利于区分。有了参数以后，就等于为它们加上了描述，输出的时候就能够分清，到底是哪一个值。</p><p>迭代器（遍历器）<br>JavaScript 原有的表示“集合”的数据结构，主要是数组（Array）和对象（Object），ES6 又添加了Map和Set。这样就有了四种数据集合，用户还可以组合使用它们，定义自己的数据结构，比如数组的成员是Map，Map的成员是对象。这样就需要一种统一的接口机制，来处理所有不同的数据结构。</p><p>遍历器（Iterator）就是这样一种机制。它是一种接口，为各种不同的数据结构提供统一的访问机制。任何数据结构只要部署 Iterator 接口，就可以完成遍历操作（即依次处理该数据结构的所有成员）。</p><p>Iterator 的作用有三个：一是为各种数据结构，提供一个统一的、简便的访问接口；二是使得数据结构的成员能够按某种次序排列；三是 ES6 创造了一种新的遍历命令for…of循环，Iterator 接口主要供for…of消费。</p><p>Iterator 的遍历过程是这样的。</p><p>（1）创建一个指针对象，指向当前数据结构的起始位置。也就是说，遍历器对象本质上，就是一个指针对象。</p><p>（2）第一次调用指针对象的next方法，可以将指针指向数据结构的第一个成员。</p><p>（3）第二次调用指针对象的next方法，指针就指向数据结构的第二个成员。</p><p>（4）不断调用指针对象的next方法，直到它指向数据结构的结束位置。</p><p>每一次调用next方法，都会返回数据结构的当前成员的信息。具体来说，就是返回一个包含value和done两个属性的对象。其中，value属性是当前成员的值，done属性是一个布尔值，表示遍历是否结束。</p><p>下面是一个模拟next方法返回值的例子。</p><p>const banji = {<br>         name: “终极一班”,<br>         stus: [<br>             ‘xiaoming’,<br>             ‘xiaoning’,<br>             ‘xiaotian’,<br>             ‘knight’<br>         ],<br>         <a href="">Symbol.iterator</a> {<br>             //索引变量<br>             let index = 0;<br>             //<br>             let _this = this;<br>             return {<br>                 next: function () {<br>                     if (index &lt; _this.stus.length) {<br>                         const result = { value: _this.stus[index], done: false };<br>                         //下标自增<br>                         index++;<br>                         //返回结果<br>                         return result;<br>                     }else{<br>                         return {value: undefined, done: true};<br>                     }<br>                 }<br>             };<br>         }<br>     }</p><pre><code> //遍历这个对象  for (let v of banji) &#123;     console.log(v); &#125;</code></pre><p>参考作者：阮一峰</p><p>授权：署名-非商用许可证</p>]]></content>
      
      
      <categories>
          
          <category> Vue </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>vue的事件监听</title>
      <link href="/2021/03/11/vue/vue%E7%9A%84%E4%BA%8B%E4%BB%B6%E7%9B%91%E5%90%AC/"/>
      <url>/2021/03/11/vue/vue%E7%9A%84%E4%BA%8B%E4%BB%B6%E7%9B%91%E5%90%AC/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="事件处理"><a href="#事件处理" class="headerlink" title="事件处理"></a>事件处理</h1><p>​ </p><h2 id="事件的基本使用："><a href="#事件的基本使用：" class="headerlink" title="事件的基本使用："></a>事件的基本使用：</h2><ul><li>使用v-on:xxx 或 @xxx 绑定事件，其中xxx是事件名；</li><li>事件的回调需要配置在methods对象中，最终会在vm上；</li><li>methods中配置的函数，不要用箭头函数！否则this就不是vm了；</li><li>methods中配置的函数，都是被Vue所管理的函数，this的指向是vm 或 组件实例对象；</li><li>@click=”demo” 和 @click=”demo($event)” 效果一致，但后者可以传参；</li></ul><pre><code class="bash">    &lt;div id=&quot;root&quot;&gt;        &lt;h2&gt;欢迎来到&#123;&#123;name&#125;&#125;学习&lt;/h2&gt;        &lt;!-- &lt;button v-on:click=&quot;showInfo&quot;&gt;点我提示信息&lt;/button&gt; --&gt;        &lt;button @click=&quot;showInfo1&quot;&gt;点我提示信息1（不传参）&lt;/button&gt;        &lt;button @click=&quot;showInfo2($event,66)&quot;&gt;点我提示信息2（传参）&lt;/button&gt;    &lt;/div&gt;&lt;script type=&quot;text/javascript&quot;&gt;    Vue.config.productionTip = false //阻止 vue 在启动时生成生产提示。    const vm = new Vue(&#123;        el:&#39;#root&#39;,        data:&#123;            name:&#39;jny&#39;,        &#125;,        methods:&#123;            showInfo1(event)&#123;                // console.log(event.target.innerText)                // console.log(this) //此处的this是vm                alert(&#39;你好！&#39;)            &#125;,            showInfo2(event,number)&#123;                console.log(event,number)                // console.log(event.target.innerText)                // console.log(this) //此处的this是vm                alert(&#39;你好！！&#39;)            &#125;        &#125;    &#125;)&lt;/script&gt;</code></pre><h1 id="事件修饰符"><a href="#事件修饰符" class="headerlink" title="事件修饰符"></a>事件修饰符</h1><ol><li>prevent：阻止默认事件（常用）；a标签点击默认跳转，通过@click.prevent阻止页面跳转。</li></ol><pre><code class="bash">   &lt;div id=&quot;root&quot;&gt;&lt;a href=&quot;jnylife.com&quot; @click.prevent=&quot;showtip&quot;&gt;hello&lt;/a&gt;   &lt;/div&gt;   &lt;script&gt;       Vue.config.productionTip= false       const vm = new Vue(&#123;       el:&#39;#root&#39;,       methods:&#123;           showtip()&#123;               alert(&#39;hello&#39;)           &#125;       &#125;       &#125;)   &lt;/script&gt;</code></pre><ol start="2"><li>stop：阻止事件冒泡（常用）；@click.stop阻止事件冒泡，防止将事件传递给父元素。</li></ol><pre><code class="bash">&lt;div class=&quot;demo1&quot; @click=&quot;showInfo&quot;&gt;                &lt;button @click.stop=&quot;showInfo&quot;&gt;点我提示信息&lt;/button&gt;                &lt;!-- 修饰符可以连续写 --&gt;                            &lt;/div&gt;</code></pre><ol start="3"><li>once：事件只触发一次（常用）</li></ol><pre><code class="bash">&lt;button @click.once=&quot;showInfo&quot;&gt;点我提示信息&lt;/button&gt;</code></pre><ol start="4"><li><p>capture：使用事件的捕获模式；</p></li><li><p>self：只有event.target是当前操作的元素时才触发事件；</p></li><li><p>passive：事件的默认行为立即执行，无需等待事件回调执行完毕；</p></li></ol><h1 id="键盘事件"><a href="#键盘事件" class="headerlink" title="键盘事件"></a>键盘事件</h1><p>​</p><ol><li>Vue中常用的按键别名：</li></ol><blockquote></blockquote><p>​ - 回车 =&gt; enter<br>​ - 删除 =&gt; delete (捕获“删除”和“退格”键)<br>​ - 退出 =&gt; esc<br>​ - 空格 =&gt; space<br>​ - 换行 =&gt; tab (特殊，必须配合keydown去使用)<br>​ - 上 =&gt; up<br>​ - 下 =&gt; down</p><ul><li>左 =&gt; left<br>​ - 右 =&gt; right</li></ul><pre><code class="bash">&lt;div id=&quot;root&quot;&gt;       &lt;input type=&quot;text&quot;  @keydown.enter=&quot;showtip&quot;&gt;   &lt;/div&gt;   &lt;script&gt;       Vue.config.productionTip= false       const vm = new Vue(&#123;       el:&#39;#root&#39;,       methods:&#123;           showtip()&#123;               alert(&#39;hello&#39;)           &#125;       &#125;       &#125;)   &lt;/script&gt;</code></pre><p>​ @keyup.enter表示当按下并松开enter键的时候，出发showtip事件。</p><p><img src="https://cdn.jsdelivr.net/gh/jnylife/ImgHosting/img/202112150943361.gif"></p><ol start="2"><li>Vue未提供别名的按键，可以使用按键原始的key值去绑定，但注意要转为kebab-case（短横线命名）</li></ol><p>​3. 系统修饰键（用法特殊）：ctrl、alt、shift、meta</p><p>​ - 配合keyup使用：按下修饰键的同时，再按下其他键（如：ctrl+A,shift+A），随后释放其他键，事件才被触发。</p><p>​ - 配合keydown使用：正常触发事件。</p><p>​4. 也可以使用keyCode去指定具体的按键（不推荐）</p><p><img src="https://cdn.jsdelivr.net/gh/jnylife/ImgHosting/img/202112150958862.png"></p><p>​ 5.Vue.config.keyCodes.自定义键名 = 键码，可以去定制按键别名</p><h1 id="事件知识点补充"><a href="#事件知识点补充" class="headerlink" title="事件知识点补充"></a>事件知识点补充</h1><pre><code class="bash">&lt;div class=&quot;demo1&quot; @click=&quot;showInfo&quot;&gt;&lt;a href=&quot;http://www.jnylife.com&quot; @click.prevent.stop=&quot;showInfo&quot;&gt;点我提示信息&lt;/a&gt;&lt;/div&gt;</code></pre><p><code>@click.prevent.stop</code> 既能够阻止事件冒泡，又能够阻止a标签的默认跳转事件</p><pre><code class="bash">&lt;input type=&quot;text&quot;    @keyup.ctrl.y=&quot;showtip&quot;&gt;</code></pre><p><code>@keyup.ctrl.y 只有当按下并松开组合键ctrl+y的时候，才触发事件。</code></p>]]></content>
      
      
      <categories>
          
          <category> Vue </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Vue </tag>
            
            <tag> 事件处理 </tag>
            
            <tag> 事件修饰符 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>vue样式绑定</title>
      <link href="/2021/03/04/vue/vue%E6%A0%B7%E5%BC%8F%E7%BB%91%E5%AE%9A/"/>
      <url>/2021/03/04/vue/vue%E6%A0%B7%E5%BC%8F%E7%BB%91%E5%AE%9A/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>收集表单数据：<br>​ 若：<input type="text"/>，则v-model收集的是value值，用户输入的就是value值。</p><p>​ 若：<input type="radio"/>，则v-model收集的是value值，且要给标签配置value值。</p><p>​ 若：<input type="checkbox"/></p><p>​ 1.没有配置input的value属性，那么收集的就是checked（勾选 or 未勾选，是布尔值）</p><p>​ 2.配置input的value属性:</p><p>​ (1)v-model的初始值是非数组，那么收集的就是checked（勾选 or 未勾选，是布尔值）</p><p>​ (2)v-model的初始值是数组，那么收集的的就是value组成的数组</p><p>​ 备注：v-model的三个修饰符：</p><p>​ lazy：失去焦点再收集数据</p><p>​ number：输入字符串转为有效的数字</p><p>​ trim：输入首尾空格过滤</p><p>过滤器<br>局部过滤器<br>filters:{<br>            timeFormater(value,str=’YYYY年MM月DD日 HH:mm:ss’){<br>                // console.log(‘@’,value)<br>                return dayjs(value).format(str)<br>            }<br>        }<br>全局过滤器</p><p>Vue.filter(‘mySlice’,function(value){<br>    return value.slice(0,4)<br>})<br>内置指令<br>已学</p><p>​ ~~ v-bind : 单向绑定解析表达式, 可简写为 :xxx</p><p>​ v-model : 双向数据绑定</p><p>​ v-for : 遍历数组/对象/字符串</p><p>​ v-on : 绑定事件监听, 可简写为@</p><p>​ v-if : 条件渲染（动态控制节点是否存存在）</p><p>​ v-else : 条件渲染（动态控制节点是否存存在）</p><p>​ v-show : 条件渲染 (动态控制节点是否展示)~~</p><p>v-text<br>​ v-text指令：</p><p>​ 1.作用：向其所在的节点中渲染文本内容。</p><p>​ 2.与插值语法的区别：v-text会替换掉节点中的内容，则不会。</p><p>v-html<br>​ v-html指令：</p><p>​ 1.作用：向指定节点中渲染包含html结构的内容。</p><p>​ 2.与插值语法的区别：</p><p>​ (1).v-html会替换掉节点中所有的内容，则不会。</p><p>​ (2).v-html可以识别html结构。</p><p>​ 3.严重注意：v-html有安全性问题！！！！</p><p>​ (1).在网站上动态渲染任意HTML是非常危险的，容易导致XSS攻击。</p><p>​ (2).一定要在可信的内容上使用v-html，永不要用在用户提交的内容上！</p><p>v-clock<br>​ v-cloak指令（没有值）：</p><p>​ 1.本质是一个特殊属性，Vue实例创建完毕并接管容器后，会删掉v-cloak属性。</p><p>​ 2.使用css配合v-cloak可以解决网速慢时页面展示出的问题。</p><style>    [v-cloak]{        display:none;    }</style><p>v-once<br>​ v-once指令：</p><p>​ 1.v-once所在节点在初次动态渲染后，就视为静态内容了。</p><p>​ 2.以后数据的改变不会引起v-once所在结构的更新，可以用于优化性能。</p><p>v-pre<br>v-pre指令：</p><p>​ 1.跳过其所在节点的编译过程。</p><p>​ 2.可利用它跳过：没有使用指令语法、没有使用插值语法的节点，会加快编译。</p><p>自定义指令<br>​ 需求1：定义一个v-big指令，和v-text功能类似，但会把绑定的数值放大10倍。</p><p>big(element,binding){<br>    console.log(‘big’,this) //注意此处的this是window<br>    // console.log(‘big’)<br>    element.innerText = binding.value * 10<br>​ 需求2：定义一个v-fbind指令，和v-bind功能类似，但可以让其所绑定的input元素默认获取焦点。</p><p>fbind:{<br>    //指令与元素成功绑定时（一上来）<br>    bind(element,binding){<br>        element.value = binding.value<br>    },<br>    //指令所在元素被插入页面时<br>    inserted(element,binding){<br>        element.focus()<br>    },<br>    //指令所在的模板被重新解析时<br>    update(element,binding){<br>        element.value = binding.value<br>    }<br>}<br>​ 自定义指令总结：</p><p>​ 一、定义语法：</p><p>​ (1).局部指令：</p><p>​ new Vue({ new Vue({</p><p>​ directives:{指令名:配置对象} 或 directives{指令名:回调函数}</p><p>​ }) })</p><p>​ (2).全局指令：</p><p>​ Vue.directive(指令名,配置对象) 或 Vue.directive(指令名,回调函数)</p><p>​ 二、配置对象中常用的3个回调：</p><p>​ (1).bind：指令与元素成功绑定时调用。</p><p>​ (2).inserted：指令所在元素被插入页面时调用。</p><p>​ (3).update：指令所在模板结构被重新解析时调用。</p><p>​ 三、备注：</p><p>​ 1.指令定义时不加v-，但使用时要加v-；</p><p>​ 2.指令名如果是多个单词，要使用kebab-case命名方式，不要用camelCase命名。</p><p>定义全局指令</p><p>//定义全局指令<br>Vue.directive(‘fbind’,{<br>    //指令与元素成功绑定时（一上来）<br>    bind(element,binding){<br>        element.value = binding.value<br>    },<br>    //指令所在元素被插入页面时<br>    inserted(element,binding){<br>        element.focus()<br>    },<br>    //指令所在的模板被重新解析时<br>    update(element,binding){<br>        element.value = binding.value<br>    }<br>})<br>vue生命周期<br>​ 生命周期：</p><p>​ 1.又名：生命周期回调函数、生命周期函数、生命周期钩子。</p><p>​ 2.是什么：Vue在关键时刻帮我们调用的一些特殊名称的函数。</p><p>​ 3.生命周期函数的名字不可更改，但函数的具体内容是程序员根据需求编写的。</p><p>​ 4.生命周期函数中的this指向是vm 或 组件实例对象。</p><p>beforeCreate() {<br>    console.log(‘beforeCreate’)<br>},<br>created() {<br>    console.log(‘created’)<br>},<br>beforeMount() {<br>    console.log(‘beforeMount’)<br>},<br>mounted() {<br>    console.log(‘mounted’)<br>},<br>beforeUpdate() {<br>    console.log(‘beforeUpdate’)<br>},<br>updated() {<br>    console.log(‘updated’)<br>},<br>beforeDestroy() {<br>    console.log(‘beforeDestroy’)<br>},<br>destroyed() {<br>    console.log(‘destroyed’)<br>},<br>生命周期</p><p>组件<br>组件就是一块砖，哪里需要往哪搬。</p><p>​ Vue中使用组件的三大步骤：</p><p>​ 一、定义组件(创建组件)</p><p>​ 二、注册组件</p><p>​ 三、使用组件(写组件标签)</p><p>​ 一、如何定义一个组件？</p><p>​ 使用Vue.extend(options)创建，其中options和new Vue(options)时传入的那个options几乎一样，但也有点区别；</p><p>​ 区别如下：</p><p>​ 1.el不要写，为什么？ ——— 最终所有的组件都要经过一个vm的管理，由vm中的el决定服务哪个容器。</p><p>​ 2.data必须写成函数，为什么？ ———— 避免组件被复用时，数据存在引用关系。</p><p>​ 备注：使用template可以配置组件结构。</p><p>​ 二、如何注册组件？</p><p>​ 1.局部注册：靠new Vue的时候传入components选项</p><p>​ 2.全局注册：靠Vue.component(‘组件名’,组件)</p><p>​ 三、编写组件标签：</p><p>​ <school></school></p><p>非单文件组件<br>const school = Vue.extend({<br>         template:<code>          &lt;div&gt;          &lt;h2&gt;&#123;&#123;schname&#125;&#125;&lt;/h2&gt;          &lt;h2&gt;&#123;&#123;schaddress&#125;&#125;&lt;/h2&gt;          &lt;/div&gt;</code>,<br>         data(){<br>             return{<br>             schname:’ynnubs’,<br>             schaddress:’五华区商院路’<br>             }</p><pre><code>     &#125; &#125;)</code></pre><p>​ 几个注意点：</p><p>​ 1.关于组件名:</p><p>​ 一个单词组成：</p><p>​ 第一种写法(首字母小写)：school</p><p>​ 第二种写法(首字母大写)：School</p><p>​ 多个单词组成：</p><p>​ 第一种写法(kebab-case命名)：my-school</p><p>​ 第二种写法(CamelCase命名)：MySchool (需要Vue脚手架支持)</p><p>​ 备注：</p><p>​ (1).组件名尽可能回避HTML中已有的元素名称，例如：h2、H2都不行。</p><p>​ (2).可以使用name配置项指定组件在开发者工具中呈现的名字。</p><p>​ 2.关于组件标签:</p><p>​ 第一种写法：</p><p>​ 第二种写法：</p><p>​ 备注：不用使用脚手架时，会导致后续组件不能渲染。</p><p>​ 3.一个简写方式：</p><p>​ const school = Vue.extend(options) 可简写为：const school = options</p><p>VueComponent<br>​ 关于VueComponent：</p><p>​ 1.school组件本质是一个名为VueComponent的构造函数，且不是程序员定义的，是Vue.extend生成的。</p><p>​ 2.我们只需要写或，Vue解析时会帮我们创建school组件的实例对象，</p><p>​ 即Vue帮我们执行的：new VueComponent(options)。</p><p>​ 3.特别注意：每次调用Vue.extend，返回的都是一个全新的VueComponent！！！！</p><p>​ 4.关于this指向：</p><p>​ (1).组件配置中：</p><p>​ data函数、methods中的函数、watch中的函数、computed中的函数 它们的this均是【VueComponent实例对象】。</p><p>​ (2).new Vue(options)配置中：</p><p>​ data函数、methods中的函数、watch中的函数、computed中的函数 它们的this均是【Vue实例对象】。</p><p>​ 5.VueComponent的实例对象，以后简称vc（也可称之为：组件实例对象）。</p><p>​ Vue的实例对象，以后简称vm。</p><p>一个重要的内置关系<br>​ 1.一个重要的内置关系：VueComponent.prototype.proto === Vue.prototype</p><p>​ 2.为什么要有这个关系：让组件实例对象（vc）可以访问到 Vue原型上的属性、方法。</p><p>前言：在JS里，万物皆对象。方法（Function）是对象，方法的原型(Function.prototype)是对象。因此，它们都会具有对象共有的特点。</p><p>即：对象具有属性__proto__，可称为隐式原型，一个对象的隐式原型指向构造该对象的构造函数的原型，这也保证了实例能够访问在构造函数原型中定义的属性和方法。</p><p>image-20220102155502091</p><p>单文件组件<br>创建School.vue</p><template>     <div class="demo">            <h2></h2>            <h2></h2>            </div></template><script>   export default ({        name:School,            data(){                return{                schname:'ynnubs',                schaddress:'五华区商院路'                }     <pre><code>        &#125;    &#125;)</code></pre><p></script><br>创建App.vue</p><template>  <div>      <School><School>  </div></template><script>import School from './School.vue'export default {    name:'app',    components:{        School    }}</script><style></style><p>创建main.js</p><p>import App from ‘./App.vue’<br>new Vue({<br>    el:’#root’,<br>    template:<code>&lt;App&gt;&lt;/App&gt;</code>,<br>    components:{App}<br>})<br>创建a.html</p><!DOCTYPE html><html lang="en"><head>    <meta charset="UTF-8">    <meta http-equiv="X-UA-Compatible" content="IE=edge">    <meta name="viewport" content="width=device-width, initial-scale=1.0">    <title>Document</title></head>]]></content>
      
      
      <categories>
          
          <category> Vue </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Vue </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>初识vue</title>
      <link href="/2021/03/01/vue/%E5%88%9D%E8%AF%86vue/"/>
      <url>/2021/03/01/vue/%E5%88%9D%E8%AF%86vue/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="初识Vue"><a href="#初识Vue" class="headerlink" title="初识Vue"></a>初识Vue</h1><ol><li>想让Vue工作，就必须创建一个Vue实例，且要传入一个配置对象；</li><li>root容器里的代码依然符合html规范，只不过混入了一些特殊的Vue语法；</li><li>root容器里的代码被称为<strong>【Vue模板】</strong>；</li><li>Vue实例和容器是一一对应的,Vue实例会解析Vue模板，把解析后的结果输出。</li><li>真实开发中只有一个Vue实例，并且会配合着组件一起使用；</li><li>中的xxx要写js表达式，且xxx可以自动读取到data中的所有属性；</li><li>一旦data中的数据发生改变，那么页面中用到该数据的地方也会自动更新；<br>​<br>注意区分：js表达式 和 js代码(语句)</li></ol><blockquote><p>表达式：一个表达式会产生一个值，可以放在任何一个需要值的地方：</p></blockquote><p>(1). a(2). a+b (3). demo(1)(4). x === y ? ‘a’ : ‘b’</p><blockquote><p>js代码(语句)</p></blockquote><p>(1). if(){} (2). for(){}</p><p>​</p><pre><code class="bash">&lt;div id=&quot;demo&quot;&gt;    &lt;h1&gt;Hello，&#123;&#123;name.toUpperCase()&#125;&#125;，&#123;&#123;address&#125;&#125;&lt;/h1&gt;&lt;/div&gt;&lt;script type=&quot;text/javascript&quot; &gt;    Vue.config.productionTip = false //阻止 vue 在启动时生成生产提示。    //创建Vue实例    new Vue(&#123;        el:&#39;#demo&#39;, //el用于指定当前Vue实例为哪个容器服务，值通常为css选择器字符串。        data:&#123; //data中用于存储数据，数据供el所指定的容器去使用，值我们暂时先写成一个对象。            name:&#39;jny&#39;,            address:&#39;昆明&#39;        &#125;    &#125;)&lt;/script&gt;</code></pre><h1 id="模板语法"><a href="#模板语法" class="headerlink" title="模板语法"></a>模板语法</h1><p>​ Vue模板语法有2大类：</p><p>​1. 插值语法：</p><p>​ - 功能：用于解析标签体内容。</p><p>​ - 写法：，xxx是js表达式，且可以直接读取到data中的所有属性。</p><p>​ 2. 指令语法：</p><p>​ - 功能：用于解析标签（包括：标签属性、标签体内容、绑定事件…..）。</p><p>​ - 举例：v-bind:href=”xxx” 或 简写为 :href=”xxx”，xxx同样要写js表达式，</p><p>​ 且可以直接读取到data中的所有属性。</p><pre><code class="bash">&lt;div id=&quot;root&quot;&gt;       &lt;h2&gt;hello,&#123;&#123;name&#125;&#125;&lt;/h2&gt;     &lt;a v-bind:href=&quot;blog.url&quot;&gt;点去我的博客&lt;/a&gt;         &lt;a  :href=&quot;blog.url&quot;&gt;点去&#123;&#123;blog.name&#125;&#125;&lt;/a&gt;   &lt;/div&gt;          &lt;script&gt;           Vue.config.productionTip= false//设置为 false 以阻止 vue 在启动时生成生产提示。                      //创建Vue实例          new Vue(&#123;               el:&#39;#root&#39;,//用于指定当年Vue实例为哪个容器服务，值通常为CSS选择器字符串。               data:&#123;//data中用于存储数据，数据供el所指定的容器使用，值暂时写成对象                   name: &#39;jny&#39;,                  blog:&#123;                     url:&#39;https://jnylife.com&#39;,                    name:&#39;jnylife&#39;               &#125;                                &#125;           &#125;)       &lt;/script&gt;</code></pre><h1 id="数据绑定"><a href="#数据绑定" class="headerlink" title="数据绑定"></a>数据绑定</h1><h2 id="v-bind完成的是单向绑定。"><a href="#v-bind完成的是单向绑定。" class="headerlink" title="v-bind完成的是单向绑定。"></a>v-bind完成的是单向绑定。</h2><p><img src="https://cdn.jsdelivr.net/gh/jnylife/ImgHosting/img/202112132055961.png"></p><p>当我修改<strong>blog:jnylife1</strong>时：</p><p><img src="https://cdn.jsdelivr.net/gh/jnylife/ImgHosting/img/202112132057460.png"></p><p>输入框内容也随之改变</p><p><img src="https://cdn.jsdelivr.net/gh/jnylife/ImgHosting/img/202112132058418.png"></p><p>反之，当我修改输入框的内容时，<strong>blog：jnylife1</strong>的值依然不变，这是一个单向绑定，数据只能从data流向页面。</p><h1 id="v-model完成的是双向绑定。"><a href="#v-model完成的是双向绑定。" class="headerlink" title="v-model完成的是双向绑定。"></a>v-model完成的是双向绑定。</h1><pre><code class="bash">双向数据绑定：&lt;input type=&quot;text&quot; name=&quot;&quot;  v-model:value=&quot;blog&quot;&gt;</code></pre><p>当我修改<strong>blog:jnylife123</strong>时：</p><p><img src="https://cdn.jsdelivr.net/gh/jnylife/ImgHosting/img/202112132106992.gif"></p><p>数据不仅能从data流向页面，还可以从页面流向data。</p><blockquote><ol><li>双向绑定一般都应用在表单类元素上（如：input、select等）</li><li>v-model:value 可以简写为 v-model，因为v-model默认收集的就是value值。</li></ol></blockquote><p>简写：</p><pre><code class="bash">&lt;div id=&quot;root&quot;&gt;    单向数据绑定：&lt;input type=&quot;text&quot; name=&quot;&quot;  :value=&quot;blog&quot;&gt;&lt;br/&gt;    双向数据绑定：&lt;input type=&quot;text&quot; name=&quot;&quot;  v-model=&quot;blog&quot;&gt;&lt;/div&gt;</code></pre><h1 id="el的两种写法"><a href="#el的两种写法" class="headerlink" title="el的两种写法"></a>el的两种写法</h1><ol><li><p>new Vue时候配置el属性。</p></li><li><p>先创建Vue实例，随后再通过vm.$mount(‘#root’)指定el的值。</p></li></ol><pre><code class="bash"> const v = new Vue(&#123;    //el:&#39;#root&#39;, //第一种写法    data:&#123;        name:&#39;尚硅谷&#39;    &#125;&#125;)console.log(v)v.$mount(&#39;#root&#39;) //第二种写法，mount挂载。</code></pre><h1 id="data的两种写法"><a href="#data的两种写法" class="headerlink" title="data的两种写法"></a>data的两种写法</h1><ul><li>对象式</li><li>函数式</li></ul><p>在data对象里写方法可以将data:function(){}简写为data(){}</p><p>如何选择：目前哪种写法都可以，以后学习到组件时，data必须使用函数式，否则会报错。</p><pre><code>new Vue(&#123;    el:&#39;#root&#39;,    //data的第一种写法：对象式    /* data:&#123;        name:&#39;尚硅谷&#39;    &#125; */    //data的第二种写法：函数式    data()&#123;        console.log(&#39;@@@&#39;,this) //此处的this是Vue实例对象        return&#123;            name:&#39;aaa&#39;        &#125;    &#125;&#125;)</code></pre><blockquote><p>一个重要的原则：由Vue管理的函数，一定不要写箭头函数，一旦写了箭头函数，this就不再是Vue实例了。</p></blockquote><h1 id="MVVM模型"><a href="#MVVM模型" class="headerlink" title="MVVM模型"></a>MVVM模型</h1><ol><li>M：模型(Model) ：对应data 中的数据</li><li>V：视图(View) ：模板</li><li>VM：视图模型(ViewModel) ： Vue 实例对象</li></ol><p>双向数据绑定，data对象通过数据绑定，将bue模板解析，vue实例对象监听view的DOM并将值返回给MODEL</p><p><img src="https://cdn.jsdelivr.net/gh/jnylife/ImgHosting/img/202112141120961.png"></p><p>观察发现：</p><ol><li><p>data中所有的属性，最后都出现在了vm身上。</p></li><li><p>vm身上所有的属性 及 Vue原型上所有属性，在Vue模板中都可以直接使用。</p></li></ol><pre><code>&lt;div id=&quot;root&quot;&gt;    &lt;h1&gt;测试一下1：&#123;&#123;1+1&#125;&#125;&lt;/h1&gt;    &lt;h1&gt;测试一下2：&#123;&#123;$options&#125;&#125;&lt;/h1&gt;    &lt;h1&gt;测试一下3：&#123;&#123;$emit&#125;&#125;&lt;/h1&gt;    &lt;h1&gt;测试一下4：&#123;&#123;_c&#125;&#125;&lt;/h1&gt;&lt;/div&gt;</code></pre><p><img src="https://cdn.jsdelivr.net/gh/jnylife/ImgHosting/img/202112141055289.png"></p><h1 id="MVVM和MVC有什么区别"><a href="#MVVM和MVC有什么区别" class="headerlink" title="MVVM和MVC有什么区别"></a>MVVM和MVC有什么区别</h1><blockquote><p>MVVM与MVC的区别有：1、mvvm各部分的通信是双向的，而mvc各部分通信是单向的；2、mvvm是真正将页面与数据逻辑分离放到js里去实现，而mvc里面未分离。</p></blockquote><ul><li>MVC</li></ul><p>MVC是包括view视图层、controller控制层、model数据层。各部分之间的通信都是单向的。</p><p>View 传送指令到 ControllerController 完成业务逻辑后，要求 Model 改变状态Model 将新的数据发送到 View，用户得到反馈</p><p><img src="https://cdn.jsdelivr.net/gh/jnylife/ImgHosting/img/202112141102010.jpeg"></p><ul><li>MVVM</li></ul><p>MVVM包括view视图层、model数据层、viewmodel层。各部分通信都是双向的。采用双向数据绑定，View的变动，自动反映在 ViewModel，反之亦然。其中ViewModel层，就是View和Model层的粘合剂，他是一个放置用户输入验证逻辑，视图显示逻辑，发起网络请求和其他各种各样的代码的极好的地方。说白了，就是把原来ViewController层的业务逻辑和页面逻辑等剥离出来放到ViewModel层</p><p><img src="https://cdn.jsdelivr.net/gh/jnylife/ImgHosting/img/202112141102444.jpeg"></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><blockquote><p>在MVC里，View是可以直接访问Model的，所以View里会包含Model信息以及一些业务逻辑。 MVC模型关注的是Model的不变，所以在MVC模型里，Model不依赖于View，但是 View是依赖于Model的。不仅如此，因为有一些业务逻辑在View里实现了，导致要更改View也是比较困难的，至少那些业务逻辑是无法重用的。</p></blockquote><blockquote><p>MVVM在概念上是真正将页面与数据逻辑分离的模式，它把数据绑定工作放到一个JS里去实现，而这个JS文件的主要功能是完成数据的绑定，即把model绑定到UI的元素上。此外MVVM另一个重要特性双向绑定，它更方便你去同时维护页面上都依赖于某个字段的N个区域，而不用手动更新它们。</p></blockquote><h1 id="Object-defineProperty"><a href="#Object-defineProperty" class="headerlink" title="Object.defineProperty"></a>Object.defineProperty</h1><p>使用Object.defineProperty方法给person对象添加属性。</p><pre><code> let person=&#123;     name:&quot;小王&quot;,     height:&quot;175&quot;,   &#125;Object.defineProperty(person,&#39;age&#39;,&#123;     value:18 &#125;) console.log(person)</code></pre><p><img src="https://cdn.jsdelivr.net/gh/jnylife/ImgHosting/img/202112141141351.png"></p><p>age颜色是淡的，用<font color="red">for(keys in person){console.log(person[keys])}</font>遍历一下看看。</p><p><img src="https://cdn.jsdelivr.net/gh/jnylife/ImgHosting/img/202112141143676.png"></p><p>age属性不在里面。</p><p>也可以用<font color="red">console.log(Object.keys(person))</font>遍历一下里面的属性。</p><p>age属性依然不在里面。</p><p>添加enumerable：true属性即可被遍历到。</p><pre><code class="bash">          let number = 18Object.defineProperty(person,&#39;age&#39;,&#123;            value:18,            enumerable:true,//默认为false，调为true，意为可枚举的。               writeable:true,//可以被修改的，通过Object.defineProperty定义的键值是不能被修改的，默认false。                   configurable:true ,//控制属性是否可以被删除，默认值是false               //当有人读取person的age属性时，get函数(getter)就会被调用，且返回值就是age的值            get()&#123;                    console.log(&#39;有人读取age属性了&#39;)                    return number                &#125;,           //当有人修改person的age属性时，set函数(setter)就会被调用，且会收到修改的具体值            set(value)&#123;                    console.log(&#39;有人修改了age属性，且值是&#39;,value)                    number = value                &#125;        &#125;)</code></pre><h1 id="Vue中的数据代理"><a href="#Vue中的数据代理" class="headerlink" title="Vue中的数据代理"></a>Vue中的数据代理</h1><h2 id="数据代理"><a href="#数据代理" class="headerlink" title="数据代理"></a>数据代理</h2><p><strong>数据代理</strong>：通过一个对象代理对另一个对象中属性的操作（读/写），此处我通过obj2代理obj的x属性，我只需要修改obj2的x值，就能够改变obj的x值</p><pre><code class="bash">&lt;script&gt;   let obj=&#123;x:100&#125;   let obj2=&#123;y:200&#125;     Object.defineProperty(obj2,&#39;x&#39;,&#123;    get()&#123;        return obj.x    &#125;,    set(value)&#123;        obj.x=value    &#125;   &#125;)   console.log(obj2)&lt;/script&gt;</code></pre><p><img src="https://cdn.jsdelivr.net/gh/jnylife/ImgHosting/img/202112141352905.png"></p><h1 id="Vue中的数据代理-1"><a href="#Vue中的数据代理-1" class="headerlink" title="Vue中的数据代理"></a>Vue中的数据代理</h1><ol><li>Vue中的数据代理：通过vm对象来代理data对象中属性的操作（读/写）</li><li>Vue中数据代理的好处：更加方便的操作data中的数据</li></ol><h2 id="基本原理："><a href="#基本原理：" class="headerlink" title="基本原理："></a>基本原理：</h2><p>​ - 通过Object.defineProperty()把data对象中所有属性添加到vm上。</p><p>​ - 为每一个添加到vm上的属性，都指定一个getter/setter。</p><p>​ - 在getter/setter内部去操作（读/写）data中对应的属性。</p><p><img src="https://cdn.jsdelivr.net/gh/jnylife/ImgHosting/img/202112141441804.png"></p>]]></content>
      
      
      <categories>
          
          <category> Vue </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Vue </tag>
            
            <tag> 数据代理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JDK11新特性概览</title>
      <link href="/2021/02/20/java/JDK11%E6%96%B0%E7%89%B9%E6%80%A7%E6%A6%82%E8%A7%88/"/>
      <url>/2021/02/20/java/JDK11%E6%96%B0%E7%89%B9%E6%80%A7%E6%A6%82%E8%A7%88/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><strong>Java 11</strong> 于 2018 年 9 月 25 日正式发布，这是很重要的一个版本！Java 11 和 2017 年 9 月份发布的 Java 9 以及 2018 年 3 月份发布的 Java 10 相比，其最大的区别就是：在长期支持(Long-Term-Support)方面，Oracle 表示会对 <strong>Java 11</strong> 提供大力支持，这一支持将会持续至** 2026 年 9 月<strong>。这是据 <strong>Java 8</strong> 以后支持的</strong>首个长期版本**。</p><p><img src="https://cdn.jsdelivr.net/gh/junian455/pic@master/img/20210603202746605.png"></p><p><strong>概览（精选了一部分）:</strong></p><p><a href="https://openjdk.java.net/jeps/321">JEP 321：HTTP Client 标准化</a><br><a href="https://openjdk.java.net/jeps/333">JEP 333：ZGC(可伸缩低延迟垃圾收集器)</a><br><a href="https://openjdk.java.net/jeps/323">JEP 323：Lambda 参数的局部变量语法</a><br><a href="https://openjdk.java.net/jeps/330">JEP 330：启动单文件源代码程序</a></p><h1 id="HTTP-Client-标准化"><a href="#HTTP-Client-标准化" class="headerlink" title="HTTP Client 标准化"></a>HTTP Client 标准化</h1><p>Java 11 对 Java 9 中引入并在 Java 10 中进行了更新的 Http Client API 进行了标准化，在前两个版本中进行孵化的同时，Http Client 几乎被完全重写，并且现在完全支持异步非阻塞。</p><p>并且，Java 11 中，Http Client 的包名由 <code>jdk.incubator.http </code>改为<code>java.net.http</code>，该 API 通过<code> CompleteableFuture </code>提供非阻塞请求和响应语义。使用起来也很简单，如下：</p><pre><code class="bash">var request = HttpRequest.newBuilder()    .uri(URI.create(&quot;https://javastack.cn&quot;))    .GET()    .build();var client = HttpClient.newHttpClient();// 同步HttpResponse&lt;String&gt; response = client.send(request, HttpResponse.BodyHandlers.ofString());System.out.println(response.body());// 异步client.sendAsync(request, HttpResponse.BodyHandlers.ofString())    .thenApply(HttpResponse::body)    .thenAccept(System.out::println);</code></pre><h1 id="String-增强"><a href="#String-增强" class="headerlink" title="String 增强"></a>String 增强</h1><p>Java 11 增加了一系列的字符串处理方法：</p><pre><code class="bash">//判断字符串是否为空&quot; &quot;.isBlank();//true//去除字符串首尾空格&quot; Java &quot;.strip();// &quot;Java&quot;//去除字符串首部空格&quot; Java &quot;.stripLeading();   // &quot;Java &quot;//去除字符串尾部空格&quot; Java &quot;.stripTrailing();  // &quot; Java&quot;//重复字符串多少次&quot;Java&quot;.repeat(3);             // &quot;JavaJavaJava&quot;//返回由行终止符分隔的字符串集合。&quot;A\nB\nC&quot;.lines().count();    // 3&quot;A\nB\nC&quot;.lines().collect(Collectors.toList());</code></pre><h1 id="Optional-增强"><a href="#Optional-增强" class="headerlink" title="Optional 增强"></a>Optional 增强</h1><p>新增了<code>empty()</code>方法来判断指定的 <code>Optional </code>对象是否为空。</p><pre><code class="bash">var op = Optional.empty();System.out.println(op.isEmpty());//判断指定的 Optional 对象是否为空</code></pre><h1 id="ZGC-可伸缩低延迟垃圾收集器"><a href="#ZGC-可伸缩低延迟垃圾收集器" class="headerlink" title="ZGC(可伸缩低延迟垃圾收集器)"></a>ZGC(可伸缩低延迟垃圾收集器)</h1><p><code>ZGC</code> 即<code> Z Garbage Collector</code>，是一个可伸缩的、低延迟的垃圾收集器。</p><p>ZGC 主要为了满足如下目标进行设计：</p><ul><li>GC 停顿时间不超过 10ms</li><li>即能处理几百 MB 的小堆，也能处理几个 TB 的大堆</li><li>应用吞吐能力不会下降超过 15%（与 G1 回收算法相比）</li><li>方便在此基础上引入新的 GC 特性和利用 colored 针以及 Load barriers 优化奠定基础</li><li>当前只支持 Linux/x64 位平台</li><li>ZGC 目前 处在实验阶段，只支持 Linux/x64 平台。</li></ul><p>与 CMS 中的 ParNew 和 G1 类似，ZGC 也采用标记-复制算法，不过 ZGC 对该算法做了重大改进。</p><p>在 ZGC 中出现 Stop The World 的情况会更少！</p><p>详情可以看 ： <a href="https://tech.meituan.com/2020/08/06/new-zgc-practice-in-meituan.html">《新一代垃圾回收器 ZGC 的探索与实践》</a></p><h1 id="Lambda-参数的局部变量语法"><a href="#Lambda-参数的局部变量语法" class="headerlink" title="Lambda 参数的局部变量语法"></a>Lambda 参数的局部变量语法</h1><p>从 Java 10 开始，便引入了局部变量类型推断这一关键特性。类型推断允许使用关键字 var 作为局部变量的类型而不是实际类型，编译器根据分配给变量的值推断出类型。</p><p>Java 10 中对 var 关键字存在几个限制</p><ul><li>只能用于局部变量上</li><li>声明时必须初始化</li><li>不能用作方法参数</li><li>不能在 Lambda 表达式中使用</li></ul><p>Java11 开始允许开发者在 Lambda 表达式中使用 var 进行参数声明。</p><pre><code class="bash">// 下面两者是等价的Consumer&lt;String&gt; consumer = (var i) -&gt; System.out.println(i);Consumer&lt;String&gt; consumer = (String i) -&gt; System.out.println(i);</code></pre><h1 id="启动单文件源代码程序"><a href="#启动单文件源代码程序" class="headerlink" title="启动单文件源代码程序"></a>启动单文件源代码程序</h1><p>这意味着我们可以运行单一文件的 Java 源代码。此功能允许使用 Java 解释器直接执行 Java 源代码。源代码在内存中编译，然后由解释器执行，不需要在磁盘上生成 .class 文件了。唯一的约束在于所有相关的类必须定义在同一个 Java 文件中。</p><p>对于 Java 初学者并希望尝试简单程序的人特别有用，并且能和 jshell 一起使用。一定能程度上增强了使用 Java 来写脚本程序的能力。</p><h1 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h1><ul><li><p><strong>新的垃圾回收器 Epsilon</strong> ：一个完全消极的 GC 实现，分配有限的内存资源，最大限度的降低内存占用和内存吞吐延迟时间</p></li><li><p><strong>低开销的 Heap Profiling</strong> ：Java 11 中提供一种低开销的 Java 堆分配采样方法，能够得到堆分配的 Java 对象信息，并且能够通过 JVMTI 访问堆信息</p></li><li><p><strong>TLS1.3 协议</strong> ：Java 11 中包含了传输层安全性（TLS）1.3 规范（RFC 8446）的实现，替换了之前版本中包含的 TLS，包括 TLS 1.2，同时还改进了其他 TLS 功能，例如 OCSP 装订扩展（RFC 6066，RFC 6961），以及会话散列和扩展主密钥扩展（RFC 7627），在安全性和性能方面也做了很多提升</p></li><li><p><strong>飞行记录器(Java Flight Recorder)</strong> ：飞行记录器之前是商业版 JDK 的一项分析工具，但在 Java 11 中，其代码被包含到公开代码库中，这样所有人都能使用该功能了。</p></li><li><p>……</p></li></ul><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><blockquote><p>JDK 11 Release Notes：<a href="https://www.oracle.com/java/technologies/javase/11-relnote-issues.html">https://www.oracle.com/java/technologies/javase/11-relnote-issues.html</a><br>Java 11 – Features and Comparison： <a href="https://www.geeksforgeeks.org/java-11-features-and-comparison/">https://www.geeksforgeeks.org/java-11-features-and-comparison/</a></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> jdk </tag>
            
            <tag> optional </tag>
            
            <tag> stream流 </tag>
            
            <tag> LocalDateTime </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RESTful API</title>
      <link href="/2021/02/12/restful/RESTful%20API/"/>
      <url>/2021/02/12/restful/RESTful%20API/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="RESTful-API"><a href="#RESTful-API" class="headerlink" title="RESTful API"></a>RESTful API</h1><blockquote><p>REST 指 Representational State Transfer，可以翻译为 “表现层状态转化”。</p></blockquote><h2 id="主要思想"><a href="#主要思想" class="headerlink" title="主要思想"></a>主要思想</h2><ul><li><p>对网络上的所有资源，都有一个统一资源标识符 URI(Uniform Resource Identifier)；</p></li><li><p>这些资源可以有多种表现形式，即 REST 中的 “表现层” Representation，比如，文本可以用 txt 格式表现，也可以用 HTML 格式、XML 格式、JSON 格式表现。URI 只代表资源的实体，不代表它的形式；</p></li><li><p>“无状态 (Stateless)” 思想：服务端不应该保存客户端状态，只需要处理当前的请求，不需了解请求的历史，客户端每一次请求中包含处理该请求所需的一切信息；</p></li><li><p>客户端使用 HTTP 协议中的 GET/POST/PUT/DELETE 方法对服务器的资源进行操作，即 REST 中的” 状态转化 “。</p></li></ul><h2 id="设计原则"><a href="#设计原则" class="headerlink" title="设计原则"></a>设计原则</h2><ul><li><p>URL 设计</p><ul><li>最好只使用名词，而使用 GET/POST/PUT/DELETE 方法的不同表示不同的操作；比如使用 <code>POST /user</code> 代替 <code>/user/create</code>。</li><li>GET：获取资源；POST：新建 / 更新资源；PUT：更新资源；DELETE：删除资源。</li><li>对于只支持 GET/POST 的客户端，使用<code> X-HTTP-Method-Override </code>属性，覆盖 POST 方法。</li><li>避免多级 URL，比如使用 <code>GET /authors/12?categories=2 </code>代替<code> GET /authors/12/categories/2 </code>。</li><li>避免在 URI 中带上版本号。不同的版本，可以理解成同一种资源的不同表现形式，所以应该采用同一个 URI，版本号可以在 HTTP 请求头信息的 Accept 字段中进行区分。</li></ul></li><li><p>状态码：服务器应该返回尽可能精确的状态码，客户端只需查看状态码，就可以判断出发生了什么情况。见计算机网络部分 – <a href="">HTTP 请求有哪些常见状态码？</a>。</p></li><li><p>服务器回应：在响应中放上其它 API 的链接，方便用户寻找。</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 系统设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> RESTful </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Git</title>
      <link href="/2021/02/04/git/git/"/>
      <url>/2021/02/04/git/git/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Git"><a href="#Git" class="headerlink" title="Git"></a>Git</h1><h2 id="Git-工作流程"><a href="#Git-工作流程" class="headerlink" title="Git 工作流程"></a>Git 工作流程</h2><p><strong>一般工作流程如下：</strong></p><ul><li>克隆 Git 资源作为工作目录。</li><li>在克隆的资源上添加或修改文件。</li><li>如果其他人修改了，你可以更新资源。</li><li>在提交前查看修改。</li><li>提交修改。</li><li>在修改完成后，如果发现错误，可以撤回提交并再次修改并提交。</li></ul><p>下图展示了 Git 的工作流程：</p><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210630211311678.png"></p><h2 id="Git-工作区、暂存区和版本库"><a href="#Git-工作区、暂存区和版本库" class="headerlink" title="Git 工作区、暂存区和版本库"></a>Git 工作区、暂存区和版本库</h2><ul><li>工作区：就是你在电脑里能看到的目录。</li><li>暂存区：英文叫 stage 或 index。一般存放在 .git 目录下的 index 文件（.git/index）中，所以我们把暂存区有时也叫作索引。</li><li>版本库：工作区有一个隐藏目录 .git，这个不算工作区，而是 Git 的版本库。</li></ul><p>下面这个图展示了工作区、版本库中的暂存区和版本库之间的关系：</p><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210630211414031.png"></p><ul><li><p>图中左侧为工作区，右侧为版本库。在版本库中标记为 “index” 的区域是暂存区（stage/index），标记为 “master” 的是 master 分支所代表的目录树。</p></li><li><p>图中我们可以看出此时 “HEAD” 实际是指向 master 分支的一个” 游标”。所以图示的命令中出现 HEAD 的地方可以用 master 来替换。</p></li><li><p>图中的 objects 标识的区域为 Git 的对象库，实际位于 “.git/objects” 目录下，里面包含了创建的各种对象及内容。</p></li><li><p>当对工作区修改（或新增）的文件执行 git add 命令时，暂存区的目录树被更新，同时工作区修改（或新增）的文件内容被写入到对象。库中的一个新的对象中，而该对象的 ID 被记录在暂存区的文件索引中。</p></li><li><p>当执行提交操作（git commit）时，暂存区的目录树写到版本库（对象库）中，master 分支会做相应的更新。即 master 指向的目录树就是提交时暂存区的目录树。</p></li><li><p>当执行 git reset HEAD 命令时，暂存区的目录树会被重写，被 master 分支指向的目录树所替换，但是工作区不受影响。</p></li><li><p>当执行 git rm –cached 命令时，会直接从暂存区删除文件，工作区则不做出改变。</p></li><li><p>当执行 git checkout . 或者 git checkout – 命令时，会用暂存区全部或指定的文件替换工作区的文件。这个操作很危险，会清除工作区中未添加到暂存区中的改动。</p></li><li><p>当执行 git checkout HEAD . 或者 git checkout HEAD 命令时，会用 HEAD 指向的 master 分支中的全部或者部分文件替换暂存区和以及工作区中的文件。这个命令也是极具危险性的，因为不但会清除工作区中未提交的改动，也会清除暂存区中未提交的改动。</p></li></ul><h2 id="Git-常用命令"><a href="#Git-常用命令" class="headerlink" title="Git 常用命令"></a>Git 常用命令</h2><ul><li><p><code>git init</code>：初始化仓库。</p></li><li><p><code>git clone</code>：拷贝一份远程仓库，也就是下载一个项目。</p></li><li><p><code>git remote（远程仓库操作）add origin ***.git</code>：添加文件到仓库。</p></li><li><p><code>git push -u origin master</code></p></li><li><p><code>git push origin dev</code>：推送到远程仓库的 dev 分支。</p></li><li><p><code>git log</code>：查看历史提交记录。</p></li><li><p><code>git log --graph --pretty=oneline --abbrev-commit</code></p></li><li><p><code>git status</code>：查看仓库当前的状态，显示有变更的文件。</p></li><li><p><code>git diff</code>： 比较文件的不同，即暂存区和工作区的差异。</p></li><li><p><code>git add *</code>：添加文件到仓库。</p></li><li><p><code>git commit -m "message"</code>：提交暂存区到本地仓库。<br>commit 之后又改了一个小 bug，但是又不想增加一个 commit，可以用：git commit –amend –no-edit，直接将改动添加到上一次的 commit 中。</p></li><li><p><code>git push</code>：上传远程代码并合并。</p></li><li><p><code>git pull</code>：下载远程代码并合并。</p></li><li><p><code>touch .gitignore</code>：忽略 git 不必要提交的文件。</p></li><li><p><code>git mv</code>：移动或重命名工作区文件。</p></li><li><p><code>git rm</code>：删除工作区文件。</p></li></ul><h2 id="Git-标签管理"><a href="#Git-标签管理" class="headerlink" title="Git 标签管理"></a>Git 标签管理</h2><ul><li>首先切换到需要打标签的分支上，然后使用 <code>git tag v1.0 </code>就可以在当前 commit 打上 v1.0 的标签。</li><li><code>git tag v1.0 commitID</code> 对特定 commit 打标签。</li><li>打标签时加上 message：<code>git tag -a <tagname> -m "message"</code>。</li><li><code>git tag</code> 查看所有标签。</li><li><code>git show [tagname]</code> 查看标签详细信息。</li><li><code>git push origin <tagname></code> 可以推送一个本地标签到远程仓库。</li><li><code>git push origin --tags</code> 可以推送全部未推送过的本地标签。</li><li><code>git tag -d <tagname> </code> 可以删除一个本地标签。</li><li><code> git push origin :refs/tags/<tagname> </code> 可以删除一个远程标签（先从本地删除）。</li></ul><h2 id="Git-撤销与回滚"><a href="#Git-撤销与回滚" class="headerlink" title="Git 撤销与回滚"></a>Git 撤销与回滚</h2><ul><li><p>暂存区：<code>git add</code> 之后 commit 之前存在的区域；工作区：git commit 之后存在的区域；远程仓库：git <code>push </code> 之后；</p></li><li><p>作了修改，但还没 <code>git add</code>，撤销到上一次提交：<code>git checkout -f -- filename；git checkout -f -- .</code></p></li><li><p>作了修改，并且已经 git add，但还没 git commit：</p><ul><li>先将暂存区的修改撤销：git reset HEAD filename/git reset HEAD；此时修改只存在于工作区，变为了 “unstaged changes”；</li><li>再利用上面的 checkout 命令从工作区撤销修改。</li></ul></li><li><p>git add 之后，作了修改，想丢弃这次修改：git checkout -f –filename 会回到最近一次 git add。</p></li><li><p>作了修改，并且已经 git commit 了，想撤销这次的修改：</p><ul><li>git revert commitID. 其实，git revert 可以用来撤销任意一次的修改，不一定要是最近一次。</li><li>git reset –hard commitID/git reset –hard HEAD^（HEAD 表示当前版本，几个 ^ 表示倒数第几个版本，倒数第 100 个版本可以用 HEAD~100）；参数 –hard：强制将暂存区和工作区都同步到指定的版本。</li><li>git reset 和 git revert 的区别是：reset 是用来回滚的，将 HEAD 的指针指向了想要回滚的版本，作为最新的版本，而后面的版本也都没有了；而 revert 只是用来撤销某一次更改，对之后的更改并没有影响。</li><li>然后再用 git push -f 提交到远程仓库。</li></ul></li></ul><h2 id="Git-分支管理"><a href="#Git-分支管理" class="headerlink" title="Git 分支管理"></a>Git 分支管理</h2><ul><li>创建分支: <code>git branch test</code>。</li><li>切换分支: git checkout test。</li><li>创建并切换分支：git checkout -b test。</li><li>将 test 分支的更改合并到 master 分支：先在 test 分支上 commit、push，再：git checkout master; git merge test。</li><li>如果合并时产生冲突：先手动解决冲突，再合并。</li><li>删除分支：git branch -d test。</li><li>git stash<ul><li>如果当前分支还有任务没有做完，也不想提交，但此时需要切换或者创建其它分支，就可以使用 stash 将当前分支的所有修改（包括暂存区）先储藏起来；然后就可以切换到其它分支。</li><li>在其它分支工作完成之后，首先切换回原来的分支，然后使用 git stash list 命令查看。</li><li>可以使用 git stash apply <stash number> 恢复之前储藏的工作现场，再使用 git stash drop <stash number> 删除掉储藏的内容。</li><li>也可以直接用 git stash pop 恢复并删除内容。</li></ul></li><li>如果在其它分支上做了一个修改（比如修复了一个 bug，这次修改有一个 commitID），想要将这次修改应用到当前分支上，可以使用：git cherry-pick commitID，可以复制一个特定的提交到当前分支。</li></ul>]]></content>
      
      
      <categories>
          
          <category> Git </category>
          
      </categories>
      
      
        <tags>
            
            <tag> git </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Elasticsearch索引，文档映射关系</title>
      <link href="/2021/01/10/elasticsearch%E5%85%A8%E6%96%87%E6%A3%80%E7%B4%A2/Elasticsearch%E7%B4%A2%E5%BC%95%EF%BC%8C%E6%96%87%E6%A1%A3%E6%98%A0%E5%B0%84%E5%85%B3%E7%B3%BB/"/>
      <url>/2021/01/10/elasticsearch%E5%85%A8%E6%96%87%E6%A3%80%E7%B4%A2/Elasticsearch%E7%B4%A2%E5%BC%95%EF%BC%8C%E6%96%87%E6%A1%A3%E6%98%A0%E5%B0%84%E5%85%B3%E7%B3%BB/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Elasticsearch中的数据格式"><a href="#Elasticsearch中的数据格式" class="headerlink" title="Elasticsearch中的数据格式"></a>Elasticsearch中的数据格式</h1><blockquote><p>Elasticsearch 是面向文档型数据库，一条数据在这里就是一个文档。为了方便大家理解，我们将 Elasticsearch 里存储文档数据和关系型数据库 MySQL 存储数据的概念进行一个类比。</p></blockquote><p><img src="https://cdn.jsdelivr.net/gh/junian455/pic@master/img/2021082515041222.png"></p><blockquote><p>ES 里的 Index 可以看做一个库，而 Types 相当于表，Documents 则相当于表的行。这里 Types 的概念已经被逐渐弱化，Elasticsearch 6.X 中，一个 index 下已经只能包含一个 type，Elasticsearch 7.X 中, Type 的概念已经被删除了。</p></blockquote><h1 id="索引操作"><a href="#索引操作" class="headerlink" title="索引操作"></a>索引操作</h1><h2 id="创建索引"><a href="#创建索引" class="headerlink" title="创建索引"></a>创建索引</h2><blockquote><p>在ES中创建一个索引，就相当于在mysql中创建了一个数据库，而mysql中的数据库肯定是不能重复的，也即ES中的索引也不能重复，所以这是一个幂等性操作，需要发送PUT请求（如果重复发送PUT请求、重复添加索引，会返回错误信息），这里不能发送POST请求。</p></blockquote><h2 id="查看指定索引"><a href="#查看指定索引" class="headerlink" title="查看指定索引"></a>查看指定索引</h2><blockquote><p>在 Postman 中，向 ES 服务器发 GET 请求。这里的路径和上面的创建索引是一样的，只是请求方式不一样。</p></blockquote><h2 id="查看全部索引"><a href="#查看全部索引" class="headerlink" title="查看全部索引"></a>查看全部索引</h2><blockquote><p>在 Postman 中，向 ES 服务器发 GET 请求。<br>health 当前服务器健康状态：green(集群完整) yellow(单点正常、集群不完整) red(单点不正常)<br>status 索引打开、关闭状态<br>index 索引名<br>uuid 索引统一编号<br>pri 主分片数量<br>rep 副本数量<br>docs.count 可用文档数量<br>docs.deleted 文档删除状态（逻辑删除）<br>store.size 主分片和副分片整体占空间大小<br>pri.store.size 主分片占空间大小</p></blockquote><h2 id="删除索引"><a href="#删除索引" class="headerlink" title="删除索引"></a>删除索引</h2><blockquote><p>在 Postman 中，向 ES 服务器发 DELETE 请求。</p></blockquote><h1 id="文档操作"><a href="#文档操作" class="headerlink" title="文档操作"></a>文档操作</h1><h2 id="创建文档"><a href="#创建文档" class="headerlink" title="创建文档"></a>创建文档</h2><blockquote><p>索引已经创建好了，接下来我们来创建文档，并添加数据。这里的文档可以类比为关系型数据库中的表数据，添加的数据格式为 JSON 格式<br>在 Postman 中，向 ES 服务器发 POST 请求。</p></blockquote><h2 id="查看单个文档：主键查询"><a href="#查看单个文档：主键查询" class="headerlink" title="查看单个文档：主键查询"></a>查看单个文档：主键查询</h2><blockquote><p>查看文档时，需要指明文档的唯一性标识，类似于 MySQL 中数据的主键查询。在 Postman 中，向 ES 服务器发 GET 请求。</p></blockquote><h2 id="查看所有文档：全查询"><a href="#查看所有文档：全查询" class="headerlink" title="查看所有文档：全查询"></a>查看所有文档：全查询</h2><blockquote><p>“query”：这里的 query 代表一个查询对象，里面可以有不同的查询属性<br>“match_all”：查询类型，例如：match_all(代表查询所有)， match，term ， range 等等<br>{查询条件}：查询条件会根据类型的不同，写法也有差异</p></blockquote><h2 id="修改文档中的全部字段"><a href="#修改文档中的全部字段" class="headerlink" title="修改文档中的全部字段"></a>修改文档中的全部字段</h2><blockquote><p>修改数据时，也可以只修改某一给条数据的局部信息，也可以修改所有字段信息。<br>修完完之后，再次发送GET请求，查看修改后的文档内容。</p></blockquote><pre><code class="bash">&#123;    &quot;title&quot;:&quot;OPPO手机&quot;,    &quot;category&quot;:&quot;OPPO&quot;,    &quot;images&quot;:&quot;http://www.szh.com/szh.jpg&quot;,    &quot;price&quot;:2400.00&#125;</code></pre><h2 id="修改文档中的某个字段"><a href="#修改文档中的某个字段" class="headerlink" title="修改文档中的某个字段"></a>修改文档中的某个字段</h2><pre><code class="bash">&#123;    &quot;doc&quot; : &#123;        &quot;title&quot;:&quot;VIVO手机&quot;,        &quot;category&quot;:&quot;VIVO&quot;    &#125;&#125;</code></pre><h2 id="删除文档"><a href="#删除文档" class="headerlink" title="删除文档"></a>删除文档</h2><blockquote><p>删除一个文档不会立即从磁盘上移除，它只是被标记成已删除（逻辑删除）。在 Postman 中，向 ES 服务器发 DELETE 请求。</p></blockquote><h1 id="条件查询"><a href="#条件查询" class="headerlink" title="条件查询"></a>条件查询</h1><h2 id="条件查询文档内容"><a href="#条件查询文档内容" class="headerlink" title="条件查询文档内容"></a>条件查询文档内容</h2><blockquote><p>match 匹配类型查询，会把查询条件进行分词，然后进行查询，多个词条之间是 or 的关系。<br>在 Postman 中，向 ES 服务器发 GET 请求。</p></blockquote><blockquote><p>上面这种查询方式的请求参数是直接跟在请求路径之后的，这种方式不太好，因为有可能造成乱码问题。<br>所以一般采用下面这种方式，将请求参数存放在请求体中。</p></blockquote><pre><code class="bash">&#123;    &quot;query&quot; : &#123;        &quot;match&quot; : &#123;            &quot;category&quot; : &quot;华为&quot;        &#125;    &#125;&#125;</code></pre><h2 id="分页查询-排序文档内容"><a href="#分页查询-排序文档内容" class="headerlink" title="分页查询 + 排序文档内容"></a>分页查询 + 排序文档内容</h2><blockquote><p>默认情况下，Elasticsearch 在搜索的结果中，会把文档中保存在_source 的所有字段都返回。如果我们只想获取其中的部分字段，我们可以添加_source 的过滤</p></blockquote><ul><li>sort 可以让我们按照不同的字段进行排序，并且通过 order 指定排序的方式。desc 降序，asc 升序。</li><li>from：当前页的起始索引，默认从 0 开始。 from = (pageNum - 1) * size。</li><li>size：每页显示多少条。</li></ul><pre><code class="bash">&#123;    &quot;query&quot; : &#123;        &quot;match_all&quot; : &#123;         &#125;    &#125;,    &quot;from&quot; : 0, // (页码-1)*每页条数, 第一页：(1-1)*2=0, 第二页：(2-1)*2=2    &quot;size&quot; : 2,    &quot;_source&quot; : [&quot;title&quot;,&quot;price&quot;],    &quot;sort&quot; : &#123;        &quot;price&quot; : &#123;            &quot;order&quot; : &quot;desc&quot;        &#125;    &#125;&#125;</code></pre><h2 id="多条件查询：and"><a href="#多条件查询：and" class="headerlink" title="多条件查询：and"></a>多条件查询：and</h2><blockquote><p><code>bool</code>把各种其它查询通过<code>must</code>（必须 and ）、<code>must_not</code>（必须不）、<code>should</code>（应该 or）的方式进行组合 。</p></blockquote><pre><code class="bash">&#123;    &quot;query&quot; : &#123;        &quot;bool&quot; : &#123;            &quot;must&quot; : [                &#123;                    &quot;match&quot; : &#123;                        &quot;category&quot; : &quot;小米&quot;                    &#125;                &#125;,                &#123;                    &quot;match&quot; : &#123;                        &quot;price&quot; : 3999.00                    &#125;                &#125;            ]        &#125;     &#125;&#125;</code></pre><h2 id="多条件查询：or"><a href="#多条件查询：or" class="headerlink" title="多条件查询：or"></a>多条件查询：or</h2><blockquote><p><code>bool</code>把各种其它查询通过<code>must</code>（必须 and ）、<code>must_not</code>（必须不）、<code>should</code>（应该 or）的方式进行组合 。</p></blockquote><pre><code class="bash">&#123;    &quot;query&quot; : &#123;        &quot;bool&quot; : &#123;            &quot;should&quot; : [                &#123;                    &quot;match&quot; : &#123;                        &quot;category&quot; : &quot;VIVO&quot;                    &#125;                &#125;,                &#123;                    &quot;match&quot; : &#123;                        &quot;price&quot; : 5999.00                    &#125;                &#125;            ]        &#125;    &#125;&#125;</code></pre><h2 id="多条件查询：大于、小于"><a href="#多条件查询：大于、小于" class="headerlink" title="多条件查询：大于、小于"></a>多条件查询：大于、小于</h2><blockquote><p>range 查询找出那些落在指定区间内的数字或者时间。range 查询允许以下字符：<br>gt 大于&gt;            gte 大于等于&gt;=              lt 小于&lt;             lte 小于等于&lt;=</p></blockquote><pre><code class="bash">&#123;    &quot;query&quot; : &#123;        &quot;bool&quot; : &#123;            &quot;must&quot; : [                &#123;                    &quot;match&quot; : &#123;                        &quot;category&quot; : &quot;小米&quot;                    &#125;                &#125;            ],            &quot;filter&quot; : &#123;                &quot;range&quot; : &#123;                    &quot;price&quot; : &#123;                        &quot;gt&quot; : 3000.00,                        &quot;lt&quot; : 4000.00                    &#125;                &#125;            &#125;        &#125;    &#125;&#125;</code></pre><h2 id="全文查询-高亮显示"><a href="#全文查询-高亮显示" class="headerlink" title="全文查询 + 高亮显示"></a>全文查询 + 高亮显示</h2><blockquote><p>在进行关键字搜索时，搜索出的内容中的关键字会显示不同的颜色，称之为高亮。<br>在使用 match 查询的同时，加上一个<strong>highlight 属性</strong>：</p><ul><li>pre_tags：前置标签</li><li>post_tags：后置标签</li><li>fields：需要高亮的字段</li><li>title：这里声明 title 字段需要高亮，后面可以为这个字段设置特有配置，也可以空</li></ul></blockquote><p><img src=""></p><blockquote><p>当我们将查询条件中的 match_phrase 改为 match 之后，再次查询，结果仍然是有的。这就很奇怪了，我文档中分类信&gt;息只有小米 、没有 小 啊，为什么还能查询到结果呢？      这是因为ES在保存文档数据时，会将数据进行分词、拆解操作，并将拆解后的数据保存到倒排索引中，这样即使使用文字的一部分（小米可以查询到、小也可以查询到）也能查询到数&gt; 据，这种方式就称为 全文检索。       也就是说文档中的category是小米，通过 小、米、小米 均可以查询到。<br>如果我们写的是 小华，则ES会帮我们查询出：%小%、%华% 相关的所有数据，这里就是进行了数据分词、拆解，进而采用倒排索引的方式查询。<br>假如说，我不想采用采用这种全文检索的匹配模式，需要将 match 改为 match_phrase。</p></blockquote><h2 id="聚合查询：根据价格分组、对价格求平均值"><a href="#聚合查询：根据价格分组、对价格求平均值" class="headerlink" title="聚合查询：根据价格分组、对价格求平均值"></a>聚合查询：根据价格分组、对价格求平均值</h2><blockquote><p>聚合允许使用者对 es 文档进行统计分析，类似与关系型数据库中的 group by，当然还有很多其他的聚合，例如取最大值、平均值等等。</p></blockquote><ul><li>对某个字段取最大值 max</li><li>对某个字段取最小值 min</li><li>对某个字段求和 sum</li><li>对某个字段取平均值 avg</li><li>对某个字段的值进行去重之后再取总数 distinct</li></ul><pre><code class="bash">&#123;    &quot;aggs&quot; : &#123; //聚合操作        &quot;price_group&quot; : &#123; //名称，自定义            &quot;terms&quot; : &#123; //分组                &quot;field&quot; : &quot;price&quot; //分组字段            &#125;        &#125;    &#125;,    &quot;size&quot; : 0&#125;</code></pre><pre><code class="bash">&#123;    &quot;aggs&quot; : &#123; //聚合操作        &quot;price_avg&quot; : &#123; //名称，自定义            &quot;avg&quot; : &#123; //分组                &quot;field&quot; : &quot;price&quot; //分组字段            &#125;        &#125;    &#125;,    &quot;size&quot; : 0&#125;</code></pre><h1 id="映射操作"><a href="#映射操作" class="headerlink" title="映射操作"></a>映射操作</h1><p>有了索引库，等于有了数据库中的 database。</p><blockquote><p>接下来就需要建索引库(index)中的映射了，类似于数据库(database)中的表结构(table)。创建数据库表需要设置字段名称，类型，长度，约束等；索引库也一样，需要知道这个类型下有哪些字段，每个字段有哪些约束信息，这就叫做映射(mapping)。</p></blockquote><p><strong>映射数据说明：</strong></p><blockquote><p>字段名：任意填写，下面指定许多属性，例如：title、subtitle、images、price</p></blockquote><ol><li><p>type：类型，Elasticsearch 中支持的数据类型非常丰富，说几个关键的：</p><pre><code>            String 类型，又分两种：                      text：可分词                      keyword：不可分词，数据会作为完整字段进行匹配            Numerical：数值类型，分两类                      基本数据类型：long、integer、short、byte、double、float、half_float                      浮点数的高精度类型：scaled_float            Date：日期类型            Array：数组类型            Object：对象</code></pre></li><li><p>index：是否索引，默认为 true，也就是说你不进行任何配置，所有字段都会被索引。</p><pre><code>             true：字段会被索引，则可以用来进行搜索             false：字段不会被索引，不能用来搜索</code></pre></li><li><p>store：是否将数据进行独立存储，默认为 false</p><pre><code>              原始的文本会存储在_source 里面，默认情况下其他提取出来的字段都不是独立存储的，是从_source 里面提取出来的。当然你也可以独立的存储某个字段，只要设置&quot;store&quot;: true 即可，获取独立存储的字段要比从_source 中解析快得多，但是也会占用更多的空间，所以要根据实际业务需求来设置</code></pre></li><li><p>analyzer：分词器，这里的 ik_max_word 即使用 ik 分词器</p></li></ol><p>首先是 <a href="http://127.0.0.1:9200/user">http://127.0.0.1:9200/user</a> ，发送PUT请求，创建一个user索引，然后在这个索引下创建一个映射。</p><p>就类似于在mysql中创建一个名为 user 的数据库，在这个数据库中定义一张表的结构如下：👇👇👇</p><p>text 类型为true表示 name 字段可以支持 分词、拆解 操作的查询；而 keyword 类型为true表示 sex 字段仅支持完全匹配的模式；最后 keyword 类型为false表示 tel 字段不支持查询。</p><pre><code class="bash">&#123;    &quot;properties&quot; : &#123;        &quot;name&quot; : &#123;            &quot;type&quot; : &quot;text&quot;,            &quot;index&quot; : true        &#125;,        &quot;sex&quot; : &#123;            &quot;type&quot; : &quot;keyword&quot;,            &quot;index&quot; : true        &#125;,        &quot;tel&quot; : &#123;            &quot;type&quot; : &quot;keyword&quot;,            &quot;index&quot; : false        &#125;    &#125;&#125;</code></pre><p>1.Elasticsearch中的数据格式<br>Elasticsearch 是面向文档型数据库，一条数据在这里就是一个文档。为了方便大家理解，我们将 Elasticsearch 里存储文档数据和关系型数据库 MySQL 存储数据的概念进行一个类比。</p><p>ES 里的 Index 可以看做一个库，而 Types 相当于表，Documents 则相当于表的行。这里 Types 的概念已经被逐渐弱化，Elasticsearch 6.X 中，一个 index 下已经只能包含一个 type，Elasticsearch 7.X 中, Type 的概念已经被删除了。</p><p>2.索引操作<br>2.1 创建索引<br>在ES中创建一个索引，就相当于在mysql中创建了一个数据库，而mysql中的数据库肯定是不能重复的，也即ES中的索引也不能重复，所以这是一个幂等性操作，需要发送PUT请求（如果重复发送PUT请求、重复添加索引，会返回错误信息），这里不能发送POST请求。</p><p>2.2 查看指定索引<br>在 Postman 中，向 ES 服务器发 GET 请求。这里的路径和上面的创建索引是一样的，只是请求方式不一样。</p><p>2.3 查看全部索引<br>在 Postman 中，向 ES 服务器发 GET 请求。</p><p>health 当前服务器健康状态：green(集群完整) yellow(单点正常、集群不完整) red(单点不正常)<br>status 索引打开、关闭状态<br>index 索引名<br>uuid 索引统一编号<br>pri 主分片数量<br>rep 副本数量<br>docs.count 可用文档数量<br>docs.deleted 文档删除状态（逻辑删除）<br>store.size 主分片和副分片整体占空间大小<br>pri.store.size 主分片占空间大小</p><p>2.4 删除索引<br>在 Postman 中，向 ES 服务器发 DELETE 请求。</p><p>3.文档操作<br>3.1 创建文档<br>索引已经创建好了，接下来我们来创建文档，并添加数据。这里的文档可以类比为关系型数据库中的表数据，添加的数据格式为 JSON 格式</p><p>在 Postman 中，向 ES 服务器发 POST 请求。</p><p>{<br>    “title”:”小米手机”,<br>    “category”:”小米”,<br>    “image”:”<a href="http://www.szh.com/szh.jpg&quot;">http://www.szh.com/szh.jpg&quot;</a>,<br>    “price”:3999.00<br>}</p><p>上面的数据创建后，由于没有指定数据唯一性标识（ID），默认情况下，ES 服务器会随机生成一个。</p><p>如果想要自定义唯一性标识，需要在创建时指定。推荐使用下面这种方式创建文档。</p><p>3.2 查看单个文档：主键查询<br>查看文档时，需要指明文档的唯一性标识，类似于 MySQL 中数据的主键查询。在 Postman 中，向 ES 服务器发 GET 请求。</p><p>3.3 查看所有文档：全查询</p><h1 id="“query”：这里的-query-代表一个查询对象，里面可以有不同的查询属性"><a href="#“query”：这里的-query-代表一个查询对象，里面可以有不同的查询属性" class="headerlink" title="“query”：这里的 query 代表一个查询对象，里面可以有不同的查询属性"></a>“query”：这里的 query 代表一个查询对象，里面可以有不同的查询属性</h1><h1 id="“match-all”：查询类型，例如：match-all-代表查询所有-，-match，term-，-range-等等"><a href="#“match-all”：查询类型，例如：match-all-代表查询所有-，-match，term-，-range-等等" class="headerlink" title="“match_all”：查询类型，例如：match_all(代表查询所有)， match，term ， range 等等"></a>“match_all”：查询类型，例如：match_all(代表查询所有)， match，term ， range 等等</h1><h1 id="查询条件-：查询条件会根据类型的不同，写法也有差异"><a href="#查询条件-：查询条件会根据类型的不同，写法也有差异" class="headerlink" title="{查询条件}：查询条件会根据类型的不同，写法也有差异"></a>{查询条件}：查询条件会根据类型的不同，写法也有差异</h1><p>3.4 修改文档中的全部字段<br>修改数据时，也可以只修改某一给条数据的局部信息，也可以修改所有字段信息。</p><p>修完完之后，再次发送GET请求，查看修改后的文档内容。</p><p>{<br>    “title”:”OPPO手机”,<br>    “category”:”OPPO”,<br>    “images”:”<a href="http://www.szh.com/szh.jpg&quot;">http://www.szh.com/szh.jpg&quot;</a>,<br>    “price”:2400.00<br>}</p><p>3.5 修改文档中的某个字段<br>{<br>    “doc” : {<br>        “title”:”VIVO手机”,<br>        “category”:”VIVO”<br>    }<br>}</p><p>3.6 删除文档<br>删除一个文档不会立即从磁盘上移除，它只是被标记成已删除（逻辑删除）。在 Postman 中，向 ES 服务器发 DELETE 请求。</p><p>3.7 条件查询文档内容<br>match 匹配类型查询，会把查询条件进行分词，然后进行查询，多个词条之间是 or 的关系。</p><p>在 Postman 中，向 ES 服务器发 GET 请求。</p><p>上面这种查询方式的请求参数是直接跟在请求路径之后的，这种方式不太好，因为有可能造成乱码问题。</p><p>所以一般采用下面这种方式，将请求参数存放在请求体中。</p><p>{<br>    “query” : {<br>        “match” : {<br>            “category” : “华为”<br>        }<br>    }<br>}</p><h2 id="分页查询-排序文档内容-1"><a href="#分页查询-排序文档内容-1" class="headerlink" title="分页查询 + 排序文档内容"></a>分页查询 + 排序文档内容</h2><blockquote><p>默认情况下，Elasticsearch 在搜索的结果中，会把文档中保存在_source 的所有字段都返回。如果我们只想获取其中的部分字段，我们可以添加_source 的过滤</p></blockquote><ul><li>sort 可以让我们按照不同的字段进行排序，并且通过 order 指定排序的方式。desc 降序，asc 升序。</li><li>from：当前页的起始索引，默认从 0 开始。 from = (pageNum - 1) * size。</li><li>size：每页显示多少条。</li></ul><pre><code class="bash">&#123;    &quot;query&quot; : &#123;        &quot;match_all&quot; : &#123;         &#125;    &#125;,    &quot;from&quot; : 0, // (页码-1)*每页条数, 第一页：(1-1)*2=0, 第二页：(2-1)*2=2    &quot;size&quot; : 2,    &quot;_source&quot; : [&quot;title&quot;,&quot;price&quot;],    &quot;sort&quot; : &#123;        &quot;price&quot; : &#123;            &quot;order&quot; : &quot;desc&quot;        &#125;    &#125;&#125;</code></pre><h2 id="多条件查询：and-1"><a href="#多条件查询：and-1" class="headerlink" title="多条件查询：and"></a>多条件查询：and</h2><blockquote><p><code>bool</code>把各种其它查询通过<code>must</code>（必须 and ）、<code>must_not</code>（必须不）、<code>should</code>（应该 or）的方式进行组合 。</p></blockquote><pre><code class="bash">&#123;    &quot;query&quot; : &#123;        &quot;bool&quot; : &#123;            &quot;must&quot; : [                &#123;                    &quot;match&quot; : &#123;                        &quot;category&quot; : &quot;小米&quot;                    &#125;                &#125;,                &#123;                    &quot;match&quot; : &#123;                        &quot;price&quot; : 3999.00                    &#125;                &#125;            ]        &#125;     &#125;&#125;</code></pre><h2 id="多条件查询：or-1"><a href="#多条件查询：or-1" class="headerlink" title="多条件查询：or"></a>多条件查询：or</h2><blockquote><p><code>bool</code>把各种其它查询通过<code>must</code>（必须 and ）、<code>must_not</code>（必须不）、<code>should</code>（应该 or）的方式进行组合 。</p></blockquote><pre><code class="bash">&#123;    &quot;query&quot; : &#123;        &quot;bool&quot; : &#123;            &quot;should&quot; : [                &#123;                    &quot;match&quot; : &#123;                        &quot;category&quot; : &quot;VIVO&quot;                    &#125;                &#125;,                &#123;                    &quot;match&quot; : &#123;                        &quot;price&quot; : 5999.00                    &#125;                &#125;            ]        &#125;    &#125;&#125;</code></pre><h2 id="多条件查询：大于、小于-1"><a href="#多条件查询：大于、小于-1" class="headerlink" title="多条件查询：大于、小于"></a>多条件查询：大于、小于</h2><blockquote><p>range 查询找出那些落在指定区间内的数字或者时间。range 查询允许以下字符：<br>gt 大于&gt;            gte 大于等于&gt;=              lt 小于&lt;             lte 小于等于&lt;=</p></blockquote><pre><code class="bash">&#123;    &quot;query&quot; : &#123;        &quot;bool&quot; : &#123;            &quot;must&quot; : [                &#123;                    &quot;match&quot; : &#123;                        &quot;category&quot; : &quot;小米&quot;                    &#125;                &#125;            ],            &quot;filter&quot; : &#123;                &quot;range&quot; : &#123;                    &quot;price&quot; : &#123;                        &quot;gt&quot; : 3000.00,                        &quot;lt&quot; : 4000.00                    &#125;                &#125;            &#125;        &#125;    &#125;&#125;</code></pre><h2 id="全文查询-高亮显示-1"><a href="#全文查询-高亮显示-1" class="headerlink" title="全文查询 + 高亮显示"></a>全文查询 + 高亮显示</h2><blockquote><p>在进行关键字搜索时，搜索出的内容中的关键字会显示不同的颜色，称之为高亮。 </p></blockquote><p>在使用 match 查询的同时，加上一个 <strong>highlight 属性</strong>：</p><ul><li>pre_tags：前置标签</li><li>post_tags：后置标签</li><li>fields：需要高亮的字段</li><li>title：这里声明 title 字段需要高亮，后面可以为这个字段设置特有配置，也可以空</li></ul><pre><code class="bash">&#123;    &quot;query&quot; : &#123;        &quot;match_phrase&quot; : &#123;            &quot;category&quot; : &quot;小&quot;        &#125;    &#125;,    &quot;highlight&quot; : &#123;        &quot;fields&quot; : &#123;            &quot;category&quot; : &#123;&#125;        &#125;    &#125;&#125;</code></pre><ol><li><p>当我们将查询条件中的 match_phrase 改为 match 之后，再次查询，结果仍然是有的。这就很奇怪了，我文档中分类信息只有 小米 、没有 小 啊，为什么还能查询到结果呢？      这是因为ES在保存文档数据时，会将数据进行分词、拆解操作，并将拆解后的数据保存到倒排索引中，这样即使使用文字的一部分（小米可以查询到、小也可以查询到）也能查询到数据，这种方式就称为 全文检索。       也就是说文档中的category是小米，通过 小、米、小米 均可以查询到。</p></li><li><p>如果我们写的是 小华，则ES会帮我们查询出：%小%、%华% 相关的所有数据，这里就是进行了数据分词、拆解，进而采用倒排索引的方式查询。</p></li><li><p>假如说，我不想采用采用这种全文检索的匹配模式，需要将 match 改为 match_phrase。</p></li></ol><h2 id="聚合查询：根据价格分组、对价格求平均值-1"><a href="#聚合查询：根据价格分组、对价格求平均值-1" class="headerlink" title="聚合查询：根据价格分组、对价格求平均值"></a>聚合查询：根据价格分组、对价格求平均值</h2><p>聚合允许使用者对 es 文档进行统计分析，类似与关系型数据库中的 group by，当然还有很多其他的聚合，例如取最大值、平均值等等。</p><p>对某个字段取最大值 max<br>对某个字段取最小值 min<br>对某个字段求和 sum<br>对某个字段取平均值 avg<br>对某个字段的值进行去重之后再取总数 distinct</p><pre><code class="bash">&#123;    &quot;aggs&quot; : &#123; //聚合操作        &quot;price_group&quot; : &#123; //名称，自定义            &quot;terms&quot; : &#123; //分组                &quot;field&quot; : &quot;price&quot; //分组字段            &#125;        &#125;    &#125;,    &quot;size&quot; : 0&#125;&#123;    &quot;aggs&quot; : &#123; //聚合操作        &quot;price_avg&quot; : &#123; //名称，自定义            &quot;avg&quot; : &#123; //分组                &quot;field&quot; : &quot;price&quot; //分组字段            &#125;        &#125;    &#125;,    &quot;size&quot; : 0&#125;</code></pre><h1 id="映射操作-1"><a href="#映射操作-1" class="headerlink" title="映射操作"></a>映射操作</h1><p>有了索引库，等于有了数据库中的 database。</p><p>接下来就需要建索引库(index)中的映射了，类似于数据库(database)中的表结构(table)。创建数据库表需要设置字段名称，类型，长度，约束等；索引库也一样，需要知道这个类型下有哪些字段，每个字段有哪些约束信息，这就叫做映射(mapping)。</p><p>映射数据说明：</p><p>字段名：任意填写，下面指定许多属性，例如：title、subtitle、images、price<br>type：类型，Elasticsearch 中支持的数据类型非常丰富，说几个关键的：<br>                   String 类型，又分两种：<br>                             text：可分词</p><pre><code>                         keyword：不可分词，数据会作为完整字段进行匹配               Numerical：数值类型，分两类                         基本数据类型：long、integer、short、byte、double、float、half_float                         浮点数的高精度类型：scaled_float               Date：日期类型               Array：数组类型               Object：对象</code></pre><p>index：是否索引，默认为 true，也就是说你不进行任何配置，所有字段都会被索引。<br>                    true：字段会被索引，则可以用来进行搜索<br>                    false：字段不会被索引，不能用来搜索</p><p>store：是否将数据进行独立存储，默认为 false<br>                     原始的文本会存储在_source 里面，默认情况下其他提取出来的字段都不是独立存储的，是从_source 里面提取出来的。当然你也可以独立的存储某个字段，只要设置”store”: true 即可，获取独立存储的字段要比从_source 中解析快得多，但是也会占用更多的空间，所以要根据实际业务需求来设置</p><p>analyzer：分词器，这里的 ik_max_word 即使用 ik 分词器<br>首先是 <a href="http://127.0.0.1:9200/user">http://127.0.0.1:9200/user</a> ，发送PUT请求，创建一个user索引，然后在这个索引下创建一个映射。</p><p>就类似于在mysql中创建一个名为 user 的数据库，在这个数据库中定义一张表的结构如下：👇👇👇</p><p>text 类型为true表示 name 字段可以支持 分词、拆解 操作的查询；而 keyword 类型为true表示 sex 字段仅支持完全匹配的模式；最后 keyword 类型为false表示 tel 字段不支持查询。</p><p>{<br>    “properties” : {<br>        “name” : {<br>            “type” : “text”,<br>            “index” : true<br>        },<br>        “sex” : {<br>            “type” : “keyword”,<br>            “index” : true<br>        },<br>        “tel” : {<br>            “type” : “keyword”,<br>            “index” : false<br>        }<br>    }<br>}</p><p>索引有了，映射也有了（数据库有了、表结构有了，就差向表中添加数据了），也就是需要添加文档内容。</p><p>因为name字段是 支持 text 模式查询，即支持 分词、拆解 操作，做倒排索引，所以虽然文档中的name字段为张起灵，但是经过分词拆解，name为 张、起、灵、起灵 这几种都可以查询出数据。</p><p>由于 sex 字段不支持text分词拆解，仅支持keyword完全匹配的模式，所以源文档数据中 sex 为 man，这里只写个 m 是查询不到的。</p><p>最后的 tel 字段是最苛刻的，压根不支持 text、keyword 两种查询模式，所以这里就算是写成和文档中的 tel 一样，也查询不到，因为 tel 字段不支持查询。</p>]]></content>
      
      
      <categories>
          
          <category> Elasticsearch全文检索 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Elasticsearch—使用Java API实现ES中的索引、映射、文档操作</title>
      <link href="/2021/01/10/elasticsearch%E5%85%A8%E6%96%87%E6%A3%80%E7%B4%A2/Elasticsearch%E2%80%94%E4%BD%BF%E7%94%A8Java%20API%E5%AE%9E%E7%8E%B0ES%E4%B8%AD%E7%9A%84%E7%B4%A2%E5%BC%95%E3%80%81%E6%98%A0%E5%B0%84%E3%80%81%E6%96%87%E6%A1%A3%E6%93%8D%E4%BD%9C/"/>
      <url>/2021/01/10/elasticsearch%E5%85%A8%E6%96%87%E6%A3%80%E7%B4%A2/Elasticsearch%E2%80%94%E4%BD%BF%E7%94%A8Java%20API%E5%AE%9E%E7%8E%B0ES%E4%B8%AD%E7%9A%84%E7%B4%A2%E5%BC%95%E3%80%81%E6%98%A0%E5%B0%84%E3%80%81%E6%96%87%E6%A1%A3%E6%93%8D%E4%BD%9C/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="开篇"><a href="#开篇" class="headerlink" title="开篇"></a>开篇</h1><blockquote><p>在上一篇文章中，对ES中的创建/查看/删除索引、创建定义映射、创建/查看/修改/删除文档的这些操作有了一定的了解认识，但是是通过Postman + JSON串的方法来实现的。文章链接：<a href="https://junian455.github.io/2021/01/10/elasticsearch%E5%85%A8%E6%96%87%E6%A3%80%E7%B4%A2/Elasticsearch%E7%B4%A2%E5%BC%95%EF%BC%8C%E6%96%87%E6%A1%A3%E6%98%A0%E5%B0%84%E5%85%B3%E7%B3%BB/">文章链接</a></p></blockquote><p>那么，这篇文章，仍然是对ES中的索引、映射、文档进行操作，只是方法换成了Java API。</p><h1 id="创建ES客户端：完成与ES服务端的连接"><a href="#创建ES客户端：完成与ES服务端的连接" class="headerlink" title="创建ES客户端：完成与ES服务端的连接"></a>创建ES客户端：完成与ES服务端的连接</h1><p>后面的一二十个案例都是依照这个模板代码来的。</p><pre><code class="bash">public class ESTestClient &#123;    public static void main(String[] args) throws IOException &#123;        //创建ES客户端        RestHighLevelClient esClient = new RestHighLevelClient(                RestClient.builder(new HttpHost(&quot;localhost&quot;,9200,&quot;http&quot;))        );         //关闭ES客户端        esClient.close();    &#125;&#125;</code></pre><h2 id="创建索引"><a href="#创建索引" class="headerlink" title="创建索引"></a>创建索引</h2><pre><code class="bash">public class ESTestIndexCreate &#123;    public static void main(String[] args) throws IOException &#123;        //创建ES客户端        RestHighLevelClient esClient = new RestHighLevelClient(                RestClient.builder(new HttpHost(&quot;localhost&quot;,9200,&quot;http&quot;))        );         //创建索引 --- 请求对象        CreateIndexRequest request = new CreateIndexRequest(&quot;user&quot;);        //发送请求 --- 获取响应        CreateIndexResponse response = esClient.indices().create(request, RequestOptions.DEFAULT);         //响应状态        boolean acknowledged = response.isAcknowledged();        System.out.println(&quot;索引操作：&quot; + acknowledged);         //关闭ES客户端        esClient.close();    &#125;&#125;</code></pre><h2 id="查看索引"><a href="#查看索引" class="headerlink" title="查看索引"></a>查看索引</h2><pre><code class="bash">public class ESTestIndexSearch &#123;    public static void main(String[] args) throws IOException &#123;        //创建ES客户端        RestHighLevelClient esClient = new RestHighLevelClient(                RestClient.builder(new HttpHost(&quot;localhost&quot;,9200,&quot;http&quot;))        );         //查询索引 --- 请求对象        GetIndexRequest request = new GetIndexRequest(&quot;user&quot;);        //发送请求 --- 获取响应        GetIndexResponse response = esClient.indices().get(request, RequestOptions.DEFAULT);         //响应状态        System.out.println(response.getAliases());        System.out.println(response.getMappings());        System.out.println(response.getSettings());         //关闭ES客户端        esClient.close();    &#125;&#125;</code></pre><h2 id="删除索引"><a href="#删除索引" class="headerlink" title="删除索引"></a>删除索引</h2><pre><code class="bash">public class ESTestIndexDelete &#123;    public static void main(String[] args) throws IOException &#123;        //创建ES客户端        RestHighLevelClient esClient = new RestHighLevelClient(                RestClient.builder(new HttpHost(&quot;localhost&quot;,9200,&quot;http&quot;))        );         //删除索引 --- 请求对象        DeleteIndexRequest request = new DeleteIndexRequest(&quot;user&quot;);        //发送请求 --- 获取响应        AcknowledgedResponse response = esClient.indices().delete(request,RequestOptions.DEFAULT);         //响应状态        System.out.println(response.isAcknowledged());         //关闭ES客户端        esClient.close();    &#125;&#125;</code></pre><h2 id="创建文档"><a href="#创建文档" class="headerlink" title="创建文档"></a>创建文档</h2><blockquote><p>索引有了，就相当于有了数据库。接下来就需要向数据库中建表、添加数据。建表自然要有表结构（有哪些属性、这些属性分别都是什么数据类型），也就是ES中的映射，在Java代码中就可以采用实体类来实现。</p></blockquote><pre><code class="bash">public class User &#123;     private String name;    private String sex;    private Integer age;     //getter and setter&#125;```bash ```bashpublic class ESTestDocInsert &#123;    public static void main(String[] args) throws IOException &#123;        //创建ES客户端        RestHighLevelClient esClient = new RestHighLevelClient(                RestClient.builder(new HttpHost(&quot;localhost&quot;,9200,&quot;http&quot;))        );         //创建文档 --- 请求对象        IndexRequest request = new IndexRequest();        //设置索引及索引中文档的唯一性标识id（如果不指定，则ES会默认随机生成一个id）        request.index(&quot;user&quot;).id(&quot;1001&quot;);         //创建数据对象（文档内容）        User user = new User();        user.setName(&quot;张起灵&quot;);        user.setSex(&quot;man&quot;);        user.setAge(21);         //向ES中插入数据，必须将数据格式转换为JSON        ObjectMapper objectMapper = new ObjectMapper();        String userJson = objectMapper.writeValueAsString(user);        request.source(userJson, XContentType.JSON);         //发送请求 --- 获取响应        IndexResponse response = esClient.index(request, RequestOptions.DEFAULT);        System.out.println(response.getResult());         //关闭ES客户端        esClient.close();    &#125;&#125;</code></pre><h2 id="修改文档"><a href="#修改文档" class="headerlink" title="修改文档"></a>修改文档</h2><pre><code class="bash">public class ESTestDocUpdate &#123;    public static void main(String[] args) throws IOException &#123;        //创建ES客户端        RestHighLevelClient esClient = new RestHighLevelClient(                RestClient.builder(new HttpHost(&quot;localhost&quot;,9200,&quot;http&quot;))        );         //修改文档 --- 请求对象        UpdateRequest request = new UpdateRequest();        //配置修改参数 --- 表示要修改user索引中id为1001的文档内容        request.index(&quot;user&quot;).id(&quot;1001&quot;);        //将修改后的内容，以JSON格式写入请求体中        request.doc(XContentType.JSON,&quot;age&quot;,18);         //发送请求 --- 获取响应        UpdateResponse response = esClient.update(request,RequestOptions.DEFAULT);        System.out.println(response.getResult());         //关闭ES客户端        esClient.close();    &#125;&#125;</code></pre><h2 id="查看文档"><a href="#查看文档" class="headerlink" title="查看文档"></a>查看文档</h2><pre><code class="bash">public class ESTestDocSearch &#123;    public static void main(String[] args) throws IOException &#123;        //创建ES客户端        RestHighLevelClient esClient = new RestHighLevelClient(                RestClient.builder(new HttpHost(&quot;localhost&quot;,9200,&quot;http&quot;))        );         //查询文档 --- 请求对象        GetRequest request = new GetRequest();        //设置请求参数 --- 表示要查询user索引中id为1001的文档内容        request.index(&quot;user&quot;).id(&quot;1001&quot;);         //发送请求 --- 获取响应        GetResponse response = esClient.get(request,RequestOptions.DEFAULT);        System.out.println(response.getSourceAsString());         //关闭ES客户端        esClient.close();    &#125;&#125;</code></pre><h2 id="删除文档"><a href="#删除文档" class="headerlink" title="删除文档"></a>删除文档</h2><pre><code class="bash">public class ESTestDocDelete &#123;    public static void main(String[] args) throws IOException &#123;        //创建ES客户端        RestHighLevelClient esClient = new RestHighLevelClient(                RestClient.builder(new HttpHost(&quot;localhost&quot;,9200,&quot;http&quot;))        );         //删除文档 --- 请求对象        DeleteRequest request = new DeleteRequest();        //设置请求参数 --- 表示要删除user索引中id为1001的文档        request.index(&quot;user&quot;).id(&quot;1001&quot;);                //发送请求 --- 获取响应        DeleteResponse response = esClient.delete(request,RequestOptions.DEFAULT);        System.out.println(response.getResult());         //关闭ES客户端        esClient.close();    &#125;&#125;</code></pre><h2 id="批量创建文档"><a href="#批量创建文档" class="headerlink" title="批量创建文档"></a>批量创建文档</h2><pre><code class="bash">public class ESTestDocInsertBatch &#123;   public static void main(String[] args) throws IOException &#123;       //创建ES客户端       RestHighLevelClient esClient = new RestHighLevelClient(               RestClient.builder(new HttpHost(&quot;localhost&quot;,9200,&quot;http&quot;))       );       //批量新增文档 --- 请求对象       BulkRequest request = new BulkRequest();       //以JSON格式批量新增文档 --- 存入请求体中       request.add(new IndexRequest().index(&quot;user&quot;).id(&quot;1001&quot;).source(XContentType.JSON, &quot;name&quot;, &quot;张起灵&quot;,&quot;sex&quot;,&quot;boy&quot;,&quot;age&quot;,21));       request.add(new IndexRequest().index(&quot;user&quot;).id(&quot;1002&quot;).source(XContentType.JSON, &quot;name&quot;, &quot;小哥&quot;,&quot;sex&quot;,&quot;boy&quot;,&quot;age&quot;,18));       request.add(new IndexRequest().index(&quot;user&quot;).id(&quot;1003&quot;).source(XContentType.JSON, &quot;name&quot;, &quot;小宋&quot;,&quot;sex&quot;,&quot;boy&quot;,&quot;age&quot;,20));       //发送请求 --- 获取响应       BulkResponse response = esClient.bulk(request, RequestOptions.DEFAULT);       System.out.println(response.getTook());       //关闭ES客户端       esClient.close();   &#125;&#125;</code></pre><h2 id="批量删除文档"><a href="#批量删除文档" class="headerlink" title="批量删除文档"></a>批量删除文档</h2><pre><code class="bash">public class ESTestDocDeleteBatch &#123;    public static void main(String[] args) throws IOException &#123;        //创建ES客户端        RestHighLevelClient esClient = new RestHighLevelClient(                RestClient.builder(new HttpHost(&quot;localhost&quot;,9200,&quot;http&quot;))        );         //批量删除文档 --- 请求对象        BulkRequest request = new BulkRequest();        //将要删除的文档id存入请求体中        request.add(new DeleteRequest().index(&quot;user&quot;).id(&quot;1001&quot;));        request.add(new DeleteRequest().index(&quot;user&quot;).id(&quot;1002&quot;));        request.add(new DeleteRequest().index(&quot;user&quot;).id(&quot;1003&quot;));         //发送请求 --- 获取响应        BulkResponse response = esClient.bulk(request,RequestOptions.DEFAULT);        System.out.println(response.getTook());        System.out.println(response.getItems());         //关闭ES客户端        esClient.close();    &#125;&#125;</code></pre><h2 id="全量查询"><a href="#全量查询" class="headerlink" title="全量查询"></a>全量查询</h2><blockquote><p>因为上面两个代码案例分别进行了批量创建、批量删除。所以这里首先执行一次批量创建的代码，确保索引中有多条数据供我们查询。</p></blockquote><pre><code class="bash">public class ESTestDocInsertBatch &#123;    public static void main(String[] args) throws IOException &#123;        //创建ES客户端        RestHighLevelClient esClient = new RestHighLevelClient(                RestClient.builder(new HttpHost(&quot;localhost&quot;,9200,&quot;http&quot;))        );         //批量新增文档 --- 请求对象        BulkRequest request = new BulkRequest();        //以JSON格式批量新增文档 --- 存入请求体中        request.add(new IndexRequest().index(&quot;user&quot;).id(&quot;1001&quot;).source(XContentType.JSON, &quot;name&quot;, &quot;张起灵&quot;,&quot;sex&quot;,&quot;boy&quot;,&quot;age&quot;,21));        request.add(new IndexRequest().index(&quot;user&quot;).id(&quot;1002&quot;).source(XContentType.JSON, &quot;name&quot;, &quot;小哥&quot;,&quot;sex&quot;,&quot;boy&quot;,&quot;age&quot;,18));        request.add(new IndexRequest().index(&quot;user&quot;).id(&quot;1003&quot;).source(XContentType.JSON, &quot;name&quot;, &quot;小宋&quot;,&quot;sex&quot;,&quot;boy&quot;,&quot;age&quot;,20));        request.add(new IndexRequest().index(&quot;user&quot;).id(&quot;1004&quot;).source(XContentType.JSON, &quot;name&quot;, &quot;冷少&quot;,&quot;sex&quot;,&quot;boy&quot;,&quot;age&quot;,25));        request.add(new IndexRequest().index(&quot;user&quot;).id(&quot;1005&quot;).source(XContentType.JSON, &quot;name&quot;, &quot;Java软件工程师&quot;,&quot;sex&quot;,&quot;girl&quot;,&quot;age&quot;,40));         //发送请求 --- 获取响应        BulkResponse response = esClient.bulk(request, RequestOptions.DEFAULT);        System.out.println(response.getTook());         //关闭ES客户端        esClient.close();    &#125;&#125;</code></pre><blockquote><p>下面首先进行全量查询操作。</p></blockquote><pre><code class="bash">public class ESTestDocQuery &#123;    public static void main(String[] args) throws IOException &#123;        //创建ES客户端        RestHighLevelClient esClient = new RestHighLevelClient(                RestClient.builder(new HttpHost(&quot;localhost&quot;,9200,&quot;http&quot;))        );         //1.查询索引中的全部文档 --- matchAllQuery 全量查询        //创建搜索请求对象        SearchRequest request = new SearchRequest();        //设置参数 --- 表示查询哪个索引中的文档内容        request.indices(&quot;user&quot;);        //构建查询的请求体 --- 存入搜索请求对象中        request.source(new SearchSourceBuilder().query(QueryBuilders.matchAllQuery()));         //发送请求 --- 获取响应        SearchResponse response = esClient.search(request,RequestOptions.DEFAULT);        //获取查询到的结果集        SearchHits hits = response.getHits();        System.out.println(hits.getTotalHits()); //结果集的条数        System.out.println(response.getTook());  //总耗时        //遍历结果集        for (SearchHit hit : hits) &#123;            System.out.println(hit.getSourceAsString());        &#125;         //关闭ES客户端        esClient.close();    &#125;&#125;</code></pre><h2 id="条件查询"><a href="#条件查询" class="headerlink" title="条件查询"></a>条件查询</h2><blockquote><p>做匹配查询，查询年龄age=21的文档内容。</p></blockquote><pre><code class="bash">public class ESTestDocQuery &#123;    public static void main(String[] args) throws IOException &#123;        //创建ES客户端        RestHighLevelClient esClient = new RestHighLevelClient(                RestClient.builder(new HttpHost(&quot;localhost&quot;,9200,&quot;http&quot;))        );         //2.条件查询--- termQuery age=21        //创建搜索请求对象        SearchRequest request = new SearchRequest();        //设置参数 --- 表示查询哪个索引中的文档内容        request.indices(&quot;user&quot;);        //构建查询的请求体 --- 存入搜索请求对象中        request.source(new SearchSourceBuilder().query(QueryBuilders.termQuery(&quot;age&quot;,21)));         //发送请求 --- 获取响应        SearchResponse response = esClient.search(request,RequestOptions.DEFAULT);        //获取查询到的结果集        SearchHits hits = response.getHits();        System.out.println(hits.getTotalHits()); //结果集的条数        System.out.println(response.getTook());  //总耗时        //遍历结果集        for (SearchHit hit : hits) &#123;            System.out.println(hit.getSourceAsString());        &#125;         //关闭ES客户端        esClient.close();    &#125;&#125;</code></pre><h2 id="分页查询"><a href="#分页查询" class="headerlink" title="分页查询"></a>分页查询</h2><blockquote><p>做全量查询，对查询结果进行分页显示，每页2条数据，查询第1页。<br>查看第几页：（页码 - 1）*每页条数</p></blockquote><pre><code class="bash">public class ESTestDocQuery &#123;    public static void main(String[] args) throws IOException &#123;        //创建ES客户端        RestHighLevelClient esClient = new RestHighLevelClient(                RestClient.builder(new HttpHost(&quot;localhost&quot;,9200,&quot;http&quot;))        );         //3.分页查询        //创建搜索请求对象        SearchRequest request = new SearchRequest();        //设置参数 --- 表示查询哪个索引中的文档内容        request.indices(&quot;user&quot;);        //构建查询的请求体        SearchSourceBuilder builder = new SearchSourceBuilder().query(QueryBuilders.matchAllQuery());        builder.from(0);        builder.size(2);        //将构建好的查询请求体存入搜索请求对象中        request.source(builder);         //发送请求 --- 获取响应        SearchResponse response = esClient.search(request,RequestOptions.DEFAULT);        //获取查询到的结果集        SearchHits hits = response.getHits();        System.out.println(hits.getTotalHits()); //结果集的条数        System.out.println(response.getTook());  //总耗时        //遍历结果集        for (SearchHit hit : hits) &#123;            System.out.println(hit.getSourceAsString());        &#125;         //关闭ES客户端        esClient.close();    &#125;&#125;</code></pre><h2 id="排序查询"><a href="#排序查询" class="headerlink" title="排序查询"></a>排序查询</h2><blockquote><p>做全量查询，对查询结果中的年龄age字段做降序排序。</p></blockquote><pre><code class="bash">public class ESTestDocQuery &#123;    public static void main(String[] args) throws IOException &#123;        //创建ES客户端        RestHighLevelClient esClient = new RestHighLevelClient(                RestClient.builder(new HttpHost(&quot;localhost&quot;,9200,&quot;http&quot;))        );         //4.对查询结果进行排序        //创建搜索请求对象        SearchRequest request = new SearchRequest();        //设置参数 --- 表示查询哪个索引中的文档内容        request.indices(&quot;user&quot;);        //构建查询的请求体        SearchSourceBuilder builder = new SearchSourceBuilder().query(QueryBuilders.matchAllQuery());        builder.sort(&quot;age&quot;, SortOrder.DESC);        //将构建好的查询请求体存入搜索请求对象中        request.source(builder);         //发送请求 --- 获取响应        SearchResponse response = esClient.search(request,RequestOptions.DEFAULT);        //获取查询到的结果集        SearchHits hits = response.getHits();        System.out.println(hits.getTotalHits()); //结果集的条数        System.out.println(response.getTook());  //总耗时        //遍历结果集        for (SearchHit hit : hits) &#123;            System.out.println(hit.getSourceAsString());        &#125;         //关闭ES客户端        esClient.close();    &#125;&#125;</code></pre><h2 id="过滤字段查询"><a href="#过滤字段查询" class="headerlink" title="过滤字段查询"></a>过滤字段查询</h2><blockquote><p>做全量查询，同时排除性别sex字段。</p></blockquote><pre><code class="bash">public class ESTestDocQuery &#123;    public static void main(String[] args) throws IOException &#123;        //创建ES客户端        RestHighLevelClient esClient = new RestHighLevelClient(                RestClient.builder(new HttpHost(&quot;localhost&quot;,9200,&quot;http&quot;))        );         //5.过滤字段        //创建搜索请求对象        SearchRequest request = new SearchRequest();        //设置参数 --- 表示查询哪个索引中的文档内容        request.indices(&quot;user&quot;);        //构建查询的请求体        SearchSourceBuilder builder = new SearchSourceBuilder().query(QueryBuilders.matchAllQuery());        String[] excludes = &#123;&quot;sex&quot;&#125;;        String[] includes = &#123;&#125;;        builder.fetchSource(includes,excludes);        //将构建好的查询请求体存入搜索请求对象中        request.source(builder);         //发送请求 --- 获取响应        SearchResponse response = esClient.search(request,RequestOptions.DEFAULT);        //获取查询到的结果集        SearchHits hits = response.getHits();        System.out.println(hits.getTotalHits()); //结果集的条数        System.out.println(response.getTook());  //总耗时        //遍历结果集        for (SearchHit hit : hits) &#123;            System.out.println(hit.getSourceAsString());        &#125;         //关闭ES客户端        esClient.close();    &#125;&#125;</code></pre><h2 id="组合条件查询"><a href="#组合条件查询" class="headerlink" title="组合条件查询"></a>组合条件查询</h2><blockquote><p>查询年龄 age=18 或者 name=张起灵 的文档内容。</p></blockquote><pre><code class="bash">public class ESTestDocQuery &#123;    public static void main(String[] args) throws IOException &#123;        //创建ES客户端        RestHighLevelClient esClient = new RestHighLevelClient(                RestClient.builder(new HttpHost(&quot;localhost&quot;,9200,&quot;http&quot;))        );         //6.组合查询        //创建搜索请求对象        SearchRequest request = new SearchRequest();        //设置参数 --- 表示查询哪个索引中的文档内容        request.indices(&quot;user&quot;);        //构建查询的请求体        SearchSourceBuilder builder = new SearchSourceBuilder();        BoolQueryBuilder boolQueryBuilder = QueryBuilders.boolQuery();        boolQueryBuilder.should(QueryBuilders.matchQuery(&quot;age&quot;,18));        boolQueryBuilder.should(QueryBuilders.matchQuery(&quot;name&quot;,&quot;张起灵&quot;));        builder.query(boolQueryBuilder);        //将构建好的查询请求体存入搜索请求对象中        request.source(builder);         //发送请求 --- 获取响应        SearchResponse response = esClient.search(request,RequestOptions.DEFAULT);        //获取查询到的结果集        SearchHits hits = response.getHits();        System.out.println(hits.getTotalHits()); //结果集的条数        System.out.println(response.getTook());  //总耗时        //遍历结果集        for (SearchHit hit : hits) &#123;            System.out.println(hit.getSourceAsString());        &#125;         //关闭ES客户端        esClient.close();    &#125;&#125;</code></pre><h2 id="范围查询"><a href="#范围查询" class="headerlink" title="范围查询"></a>范围查询</h2><blockquote><p>查询年龄age字段大于等于18、小于25的文档内容。</p></blockquote><pre><code class="bash">public class ESTestDocQuery &#123;    public static void main(String[] args) throws IOException &#123;        //创建ES客户端        RestHighLevelClient esClient = new RestHighLevelClient(                RestClient.builder(new HttpHost(&quot;localhost&quot;,9200,&quot;http&quot;))        );         //7.范围查询        //创建搜索请求对象        SearchRequest request = new SearchRequest();        //设置参数 --- 表示查询哪个索引中的文档内容        request.indices(&quot;user&quot;);        //构建查询的请求体        SearchSourceBuilder builder = new SearchSourceBuilder();        RangeQueryBuilder rangeQueryBuilder = QueryBuilders.rangeQuery(&quot;age&quot;);        rangeQueryBuilder.gte(18);        rangeQueryBuilder.lt(25);        builder.query(rangeQueryBuilder);        //将构建好的查询请求体存入搜索请求对象中        request.source(builder);         //发送请求 --- 获取响应        SearchResponse response = esClient.search(request,RequestOptions.DEFAULT);        //获取查询到的结果集        SearchHits hits = response.getHits();        System.out.println(hits.getTotalHits()); //结果集的条数        System.out.println(response.getTook());  //总耗时        //遍历结果集        for (SearchHit hit : hits) &#123;            System.out.println(hit.getSourceAsString());        &#125;         //关闭ES客户端        esClient.close();    &#125;&#125;</code></pre><h2 id="模糊查询"><a href="#模糊查询" class="headerlink" title="模糊查询"></a>模糊查询</h2><blockquote><p>builder.query(QueryBuilders.fuzzyQuery(“name”,”小张”).fuzziness(Fuzziness.ONE)); 最后的这个枚举类型 ONE，表示查询结果中允许与我定义的name字段为 小张 相差1个字符，也就是说，查询出的结果要么包含 小、要么包含 张、或者就是小张。</p></blockquote><pre><code class="bash">public class ESTestDocQuery &#123;    public static void main(String[] args) throws IOException &#123;        //创建ES客户端        RestHighLevelClient esClient = new RestHighLevelClient(                RestClient.builder(new HttpHost(&quot;localhost&quot;,9200,&quot;http&quot;))        );         //8.模糊查询        //创建搜索请求对象        SearchRequest request = new SearchRequest();        //设置参数 --- 表示查询哪个索引中的文档内容        request.indices(&quot;user&quot;);        //构建查询的请求体        SearchSourceBuilder builder = new SearchSourceBuilder();        //FuzzyQueryBuilder fuzzyQueryBuilder = QueryBuilders.fuzzyQuery(&quot;name&quot;,&quot;小张&quot;);        //fuzzyQueryBuilder.fuzziness(Fuzziness.ONE);        //builder.query(fuzzyQueryBuilder);        //上面三行代码 等价于 下面这行代码        builder.query(QueryBuilders.fuzzyQuery(&quot;name&quot;,&quot;小张&quot;).fuzziness(Fuzziness.ONE));        //将构建好的查询请求体存入搜索请求对象中        request.source(builder);         //发送请求 --- 获取响应        SearchResponse response = esClient.search(request,RequestOptions.DEFAULT);        //获取查询到的结果集        SearchHits hits = response.getHits();        System.out.println(hits.getTotalHits()); //结果集的条数        System.out.println(response.getTook());  //总耗时        //遍历结果集        for (SearchHit hit : hits) &#123;            System.out.println(hit.getSourceAsString());        &#125;         //关闭ES客户端        esClient.close();    &#125;&#125;</code></pre><h2 id="聚合查询"><a href="#聚合查询" class="headerlink" title="聚合查询"></a>聚合查询</h2><blockquote><p>查询age字段，年龄最大的文档内容。</p></blockquote><pre><code class="bash">public class ESTestDocQuery &#123;    public static void main(String[] args) throws IOException &#123;        //创建ES客户端        RestHighLevelClient esClient = new RestHighLevelClient(                RestClient.builder(new HttpHost(&quot;localhost&quot;,9200,&quot;http&quot;))        );         //9.聚合查询        //创建搜索请求对象        SearchRequest request = new SearchRequest();        //设置参数 --- 表示查询哪个索引中的文档内容        request.indices(&quot;user&quot;);        //构建查询的请求体        SearchSourceBuilder builder = new SearchSourceBuilder();        AggregationBuilder aggregationBuilder = AggregationBuilders.max(&quot;maxAge&quot;).field(&quot;age&quot;);        builder.aggregation(aggregationBuilder);        //将构建好的查询请求体存入搜索请求对象中        request.source(builder);         //发送请求 --- 获取响应        SearchResponse response = esClient.search(request,RequestOptions.DEFAULT);        //获取查询到的结果集        SearchHits hits = response.getHits();        System.out.println(hits.getTotalHits()); //结果集的条数        System.out.println(response.getTook());  //总耗时        //遍历结果集        for (SearchHit hit : hits) &#123;            System.out.println(hit.getSourceAsString());        &#125;         //关闭ES客户端        esClient.close();    &#125;&#125;</code></pre><h2 id="分组查询"><a href="#分组查询" class="headerlink" title="分组查询"></a>分组查询</h2><blockquote><p>根据age年龄字段进行group分组查询。</p></blockquote><pre><code class="bash">public class ESTestDocQuery &#123;    public static void main(String[] args) throws IOException &#123;        //创建ES客户端        RestHighLevelClient esClient = new RestHighLevelClient(                RestClient.builder(new HttpHost(&quot;localhost&quot;,9200,&quot;http&quot;))        );         //10.分组查询        //创建搜索请求对象        SearchRequest request = new SearchRequest();        //设置参数 --- 表示查询哪个索引中的文档内容        request.indices(&quot;user&quot;);        //构建查询的请求体        SearchSourceBuilder builder = new SearchSourceBuilder();        AggregationBuilder aggregationBuilder = AggregationBuilders.terms(&quot;ageGroup&quot;).field(&quot;age&quot;);        builder.aggregation(aggregationBuilder);        //将构建好的查询请求体存入搜索请求对象中        request.source(builder);         //发送请求 --- 获取响应        SearchResponse response = esClient.search(request,RequestOptions.DEFAULT);        //获取查询到的结果集        SearchHits hits = response.getHits();        System.out.println(hits.getTotalHits()); //结果集的条数        System.out.println(response.getTook());  //总耗时        //遍历结果集        for (SearchHit hit : hits) &#123;            System.out.println(hit.getSourceAsString());        &#125;         //关闭ES客户端 </code></pre>]]></content>
      
      
      <categories>
          
          <category> Elasticsearch全文检索 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>MyBatis</title>
      <link href="/2020/12/25/mybatis/Mybatis/"/>
      <url>/2020/12/25/mybatis/Mybatis/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Mybatis"><a href="#Mybatis" class="headerlink" title="Mybatis"></a>Mybatis</h1><p>什么是 Mybatis？<br>答：MyBatis 是一个优秀的持久层框架，是一个半 ORM（对象关系映射）框架，它对 jdbc 的操作数据库的过程进行封装，使开发者只需要关注 SQL 本身，而不需要花费精力去处理例如加载驱动、创建连接、创建 statement 等繁杂的过程。</p><p>Mybatis 通过 xml 或注解的方式将要执行的 statement 配置起来，并通过 java 对象和 statement 中的 sql 进行映射生成最终执行的 sql 语句，最后由 mybatis 框架执行 sql 并将结果映射成 java 对象并返回。</p><p>Mybatis 的优点与缺点？<br>优点：</p><p>基于 SQL 语句编程，相当灵活，不会对应用程序或者数据库的现有设计造成任何影响，SQL 写在 XML 里，解除 sql 与程序代码的耦合，便于统一管理；提供 XML 标签，支持编写动态 SQL 语句，并可重用。<br>与 JDBC 相比，减少了 JDBC 大量冗余的代码，不需要手动开关连接。<br>很好的与各种数据库兼容。<br>能够与 Spring 很好的集成。<br>提供映射标签，支持对象与数据库的 ORM 字段关系映射；提供对象关系映射标签，支持对象关系组件维护。<br>缺点：</p><p>SQL 语句的编写工作量较大，尤其当字段多、关联表多时，对开发人员编写 SQL 语句的功底有一定要求。<br>SQL 语句依赖于数据库，导致数据库移植性差，不能随意更换数据库。<br>Mybatis 和 Hibernate 有什么区别？<br>Mybatis 和 hibernate 不同，它不完全是一个 ORM 框架，因为 MyBatis 需要程序员自己编写 Sql 语句。<br>Hibernate 对象 / 关系映射能力强，数据库无关性好，对于关系模型要求高的软件，如果用 hibernate 开发可以节省很多代码，提高效率。<br>Mybatis 直接编写原生态 sql，可以严格控制 sql 执行性能，灵活度高，非常适合对关系数据模型要求不高的软件开发，因为这类软件需求变化频繁，一但需求变化要求迅速输出成果。但是灵活的前提是 mybatis 无法做到数据库无关性，如果需要实现支持多种数据库的软件，则需要自定义多套 sql 映射文件，工作量大。<br>#{} 和 ${} 的区别是什么？<br>${} 是 Properties 文件中的变量占位符，它可以用于标签属性值和 sql 内部，属于静态文本替换，比如 ${driver} 会被静态替换为 com.mysql.jdbc.Driver。<br>#{} 是 sql 的参数占位符，Mybatis 会将 sql 中的#{} 替换为？号，在 sql 执行前会使用 PreparedStatement 的参数设置方法，按序给 sql 的？号占位符设置参数值，比如 ps.setInt (0, parameterValue)，#{item.name} 的取值方式为使用反射从参数对象中获取 item 对象的 name 属性值，相当于 param.getItem().getName()。<br>Xml 映射文件中，除了常见的 select|insert|updae|delete 标签之外，还有哪些标签？<br>答：还有很多其他的标签，<resultMap>、<parameterMap>、<sql>、<include>、<selectKey>，加上动态 sql 的 9 个标签，trim|where|set|foreach|if|choose|when|otherwise|bind 等，其中为 sql 片段标签，通过 <include> 标签引入 sql 片段，<selectKey> 为不支持自增的主键生成策略标签。</p><p>如何获取自动生成的 (主) 键值？<br>答：insert 方法总是返回一个 int 值 ，这个值代表的是插入的行数。</p><p>如果采用自增长策略，自动生成的键值在 insert 方法执行完后可以被设置到传入的参数对象中。</p><p>Mybatis 的一级、二级缓存？<br>一级缓存：Mybatis 的一级缓存是指 SQLSession，一级缓存的作用域是 SQlSession，Mabits 默认开启一级缓存。在同一个 sqlSession 中两次执行相同的 sql 语句，第一次执行完毕会将数据库中查询的数据写到缓存（内存），第二次会从缓存中获取数据将不再从数据库查询，从而提高查询效率。当一个 sqlSession 结束后该 sqlSession 中的一级缓存也就不存在了。<br>1：一级缓存是默认开启的；<br>2：底层其实是基于 hashmap 的本地内存缓存；<br>3：作用域是 session（其实就相当于一个方法）；<br>4：当 session 关闭或者刷新的时候缓存清空；<br>5：不同 sqlsession 之间缓存互不影响。</p><p>二级缓存： 二级缓存是 mapper 级别的，Mybatis 默认是没有开启二级缓存的。多个 SqlSession 去操作同一个 Mapper 的 sql 语句，多个 SqlSession 去操作数据库得到数据会存在二级缓存区域，多个 SqlSession 可以共用二级缓存，二级缓存是多个 SqlSession 共享的。<br>1：首先 mybatis 默认是没有开启二级缓存的；<br>2：二级缓存需要我们手动开启，它是 mapper 级别的缓存；<br>3：同一个 namespace 下的所有操作语句，都影响着同一个 Cache，即二级缓存被多个 SqlSession 共享，是一个全局的变量。</p><p>使用 MyBatis 的 mapper 接口调用时有哪些要求？<br>Mapper 接口方法名和 mapper.xml 中定义的每个 sql 的 id 相同；<br>Mapper 接口方法的输入参数类型和 mapper.xml 中定义的每个 sql 的 parameterType 的类型相同；<br>Mapper 接口方法的输出参数类型和 mapper.xml 中定义的每个 sql 的 resultType 的类型相同；<br>Mapper.xml 文件中的 namespace 即是 mapper 接口的类路径。<br>当实体类中的属性名和表中的字段名不一样，怎么办？<br>第 1 种： 通过在查询的 sql 语句中定义字段名的别名，让字段名的别名和实体类的属性名一致。<br>第 2 种： 通过 `` 来映射字段名和实体类属性名的一一对应的关系。<br>模糊查询 like 语句该怎么写？<br>第 1 种：在 Java 代码中添加 sql 通配符；<br>第 2 种：在 sql 语句中拼接通配符，会引起 sql 注入<br>MyBatis 实现一对一有几种方式？具体怎么操作的？<br>联合查询是几个表联合查询，只查询一次，通过在 resultMap 里面配置 association 节点配置一对一的类就可以完成；<br>嵌套查询是先查一个表，根据这个表里面的结果的外键 id，去再另外一个表里面查询数据，也是通过 association 配置，但另外一个表的查询通过 select 属性配置。<br>什么是 MyBatis 的接口绑定？有哪些实现方式？<br>答：接口绑定，就是在 MyBatis 中任意定义接口，然后把接口里面的方法和 SQL 语句绑定，我们直接调用接口方法就可以，这样比起原来了 SqlSession 提供的方法我们可以有更加灵活的选择和设置。 接口绑定有两种实现方式：</p><p>注解绑定，就是在接口的方法上面加上 @Select、@Update 等注解，里面包含 Sql 语句来绑定；<br>外一种就是通过 xml 里面写 SQL 来绑定，在这种情况下，要指定 xml 映射文件里面的 namespace 必须为接口的全路径名。当 Sql 语句比较简单时候，用注解绑定，当 SQL 语句比较复杂时候，用 xml 绑定一般用 xml 绑定的比较多。<br>Mybatis 是如何防止 SQL 注入的？<br>MyBatis 启用了预编译功能，在 SQL 执行前，会先将上面的 SQL 发送给数据库进行编译；执行时，直接使用编译好的 SQL，替换占位符 “?” 就可以了。因为 SQL 注入只能对编译过程起作用，所以这样的方式就很好地避免了 SQL 注入的问题。</p><p>最佳实践中，通常一个 Xml 映射文件，都会写一个 Dao 接口与之对应，请问，这个 Dao 接口的工作原理是什么？Dao 接口里的方法，参数不同时，方法能重载吗？<br>答：Dao 接口，就是人们常说的 Mapper 接口，接口的全限名，就是映射文件中的 namespace 的值，接口的方法名，就是映射文件中 MappedStatement 的 id 值，接口方法内的参数，就是传递给 sql 的参数。Mapper 接口是没有实现类的，当调用接口方法时，接口全限名 + 方法名拼接字符串作为 key 值，可唯一定位一个 MappedStatement，举例：com.mybatis3.mappers.StudentDao.findStudentById，可以唯一找到 namespace 为 com.mybatis3.mappers.StudentDao 下面 id = findStudentById 的 MappedStatement。在 Mybatis 中，每一个 <select>、<insert>、<update>、<delete> 标签，都会被解析为一个 MappedStatement 对象。</p><p>Dao 接口里的方法，是不能重载的，因为是全限名 + 方法名的保存和寻找策略。</p><p>Dao 接口的工作原理是 JDK 动态代理，Mybatis 运行时会使用 JDK 动态代理为 Dao 接口生成代理 proxy 对象，代理对象 proxy 会拦截接口方法，转而执行 MappedStatement 所代表的 sql，然后将 sql 执行结果返回。</p><p>Mybatis 是如何进行分页的？分页插件的原理是什么？<br>答：Mybatis 使用 RowBounds 对象进行分页，它是针对 ResultSet 结果集执行的内存分页，而非物理分页，可以在 sql 内直接书写带有物理分页的参数来完成物理分页功能，也可以使用分页插件来完成物理分页。</p><p>分页插件的基本原理是使用 Mybatis 提供的插件接口，实现自定义插件，在插件的拦截方法内拦截待执行的 sql，然后重写 sql，根据 dialect 方言，添加对应的物理分页语句和物理分页参数。</p><p>举例：select _ from student，拦截 sql 后重写为：select t._ from （select * from student）t limit 0，10</p><p>简述 Mybatis 的插件运行原理，以及如何编写一个插件？<br>答：Mybatis 仅可以编写针对 ParameterHandler、ResultSetHandler、StatementHandler、Executor 这 4 种接口的插件，Mybatis 使用 JDK 的动态代理，为需要拦截的接口生成代理对象以实现接口方法拦截功能，每当执行这 4 种接口对象的方法时，就会进入拦截方法，具体就是 InvocationHandler 的 invoke() 方法，当然，只会拦截那些你指定需要拦截的方法。</p><p>实现 Mybatis 的 Interceptor 接口并复写 intercept() 方法，然后在给插件编写注解，指定要拦截哪一个接口的哪些方法即可，记住，别忘了在配置文件中配置你编写的插件。</p><p>Mybatis 执行批量插入，能返回数据库主键列表吗？<br>答：能，JDBC 都能，Mybatis 当然也能。</p><p>Mybatis 动态 sql 是做什么的？都有哪些动态 sql？能简述一下动态 sql 的执行原理不？<br>答：Mybatis 动态 sql 可以让我们在 Xml 映射文件内，以标签的形式编写动态 sql，完成逻辑判断和动态拼接 sql 的功能，Mybatis 提供了 9 种动态 sql 标签 trim|where|set|foreach|if|choose|when|otherwise|bind。</p><p>其执行原理为，使用 OGNL 从 sql 参数对象中计算表达式的值，根据表达式的值动态拼接 sql，以此来完成动态 sql 的功能。</p><p>Mybatis 是如何将 sql 执行结果封装为目标对象并返回的？都有哪些映射形式？<br>答：第一种是使用 <resultMap> 标签，逐一定义列名和对象属性名之间的映射关系。第二种是使用 sql 列的别名功能，将列别名书写为对象属性名，比如 T_NAME AS NAME，对象属性名一般是 name，小写，但是列名不区分大小写，Mybatis 会忽略列名大小写，智能找到与之对应对象属性名，你甚至可以写成 T_NAME AS NaMe，Mybatis 一样可以正常工作。</p><p>有了列名与属性名的映射关系后，Mybatis 通过反射创建对象，同时使用反射给对象的属性逐一赋值并返回，那些找不到映射关系的属性，是无法完成赋值的。</p><p>Mybatis 能执行一对一、一对多的关联查询吗？都有哪些实现方式，以及它们之间的区别。<br>答：能，Mybatis 不仅可以执行一对一、一对多的关联查询，还可以执行多对一，多对多的关联查询，多对一查询，其实就是一对一查询，只需要把 selectOne() 修改为 selectList() 即可；多对多查询，其实就是一对多查询，只需要把 selectOne() 修改为 selectList() 即可。</p><p>关联对象查询，有两种实现方式，一种是单独发送一个 sql 去查询关联对象，赋给主对象，然后返回主对象。另一种是使用嵌套查询，嵌套查询的含义为使用 join 查询，一部分列是 A 对象的属性值，另外一部分列是关联对象 B 的属性值，好处是只发一个 sql 查询，就可以把主对象和其关联对象查出来。</p><p>那么问题来了，join 查询出来 100 条记录，如何确定主对象是 5 个，而不是 100 个？其去重复的原理是 <resultMap> 标签内的 <id> 子标签，指定了唯一确定一条记录的 id 列，Mybatis 根据列值来完成 100 条记录的去重复功能，<id> 可以有多个，代表了联合主键的语意。</p><p>同样主对象的关联对象，也是根据这个原理去重复的，尽管一般情况下，只有主对象会有重复记录，关联对象一般不会重复。</p><p>举例：下面 join 查询出来 6 条记录，一、二列是 Teacher 对象列，第三列为 Student 对象列，Mybatis 去重复处理后，结果为 1 个老师 6 个学生，而不是 6 个老师 6 个学生。</p><p>SQL<br>1<br>2<br>3<br>t_id t_name s_id</p><p>| 1 | teacher | 38 | | 1 | teacher | 39 | | 1 | teacher | 40 | | 1 | teacher | 41 | | 1 | teacher | 42 | | 1 | teacher | 43 |<br>Mybatis 是否支持延迟加载？如果支持，它的实现原理是什么？<br>答：Mybatis 仅支持 association 关联对象和 collection 关联集合对象的延迟加载，association 指的就是一对一，collection 指的就是一对多查询。在 Mybatis 配置文件中，可以配置是否启用延迟加载 lazyLoadingEnabled=true|false。</p><p>它的原理是，使用 CGLIB 创建目标对象的代理对象，当调用目标方法时，进入拦截器方法，比如调用 a.getB().getName()，拦截器 invoke() 方法发现 a.getB() 是 null 值，那么就会单独发送事先保存好的查询关联 B 对象的 sql，把 B 查询上来，然后调用 a.setB (b)，于是 a 的对象 b 属性就有值了，接着完成 a.getB().getName() 方法的调用。这就是延迟加载的基本原理。</p><p>当然了，不光是 Mybatis，几乎所有的包括 Hibernate，支持延迟加载的原理都是一样的。</p><p>Mybatis 的 Xml 映射文件中，不同的 Xml 映射文件，id 是否可以重复？<br>答：不同的 Xml 映射文件，如果配置了 namespace，那么 id 可以重复；如果没有配置 namespace，那么 id 不能重复；毕竟 namespace 不是必须的，只是最佳实践而已。</p><p>原因就是 namespace+id 是作为 Map&lt;String, MappedStatement&gt; 的 key 使用的，如果没有 namespace，就剩下 id，那么，id 重复会导致数据互相覆盖。有了 namespace，自然 id 就可以重复，namespace 不同，namespace+id 自然也就不同。</p><p>Mybatis 中如何执行批处理？<br>答：使用 BatchExecutor 完成批处理。</p><p>Mybatis 都有哪些 Executor 执行器？它们之间的区别是什么？<br>答：Mybatis 有三种基本的 Executor 执行器，<strong>SimpleExecutor、ReuseExecutor、BatchExecutor。</strong></p><p>SimpleExecutor：每执行一次 update 或 select，就开启一个 Statement 对象，用完立刻关闭 Statement 对象。</p><p>``ReuseExecutor`：执行 update 或 select，以 sql 作为 key 查找 Statement 对象，存在就使用，不存在就创建，用完后，不关闭 Statement 对象，而是放置于 Map&lt;String, Statement&gt; 内，供下一次使用。简言之，就是重复使用 Statement 对象。</p><p>BatchExecutor：执行 update（没有 select，JDBC 批处理不支持 select），将所有 sql 都添加到批处理中（addBatch ()），等待统一执行（executeBatch ()），它缓存了多个 Statement 对象，每个 Statement 对象都是 addBatch () 完毕后，等待逐一执行 executeBatch () 批处理。与 JDBC 批处理相同。</p><p>作用范围：Executor 的这些特点，都严格限制在 SqlSession 生命周期范围内。</p><p>Mybatis 中如何指定使用哪一种 Executor 执行器？<br>答：在 Mybatis 配置文件中，可以指定默认的 ExecutorType 执行器类型，也可以手动给 DefaultSqlSessionFactory 的创建 SqlSession 的方法传递 ExecutorType 类型参数。</p><p>Mybatis 是否可以映射 Enum 枚举类？<br>答：Mybatis 可以映射枚举类，不单可以映射枚举类，Mybatis 可以映射任何对象到表的一列上。映射方式为自定义一个 TypeHandler，实现 TypeHandler 的 setParameter() 和 getResult() 接口方法。TypeHandler 有两个作用，一是完成从 javaType 至 jdbcType 的转换，二是完成 jdbcType 至 javaType 的转换，体现为 setParameter() 和 getResult() 两个方法，分别代表设置 sql 问号占位符参数和获取列查询结果。</p><p>Mybatis 映射文件中，如果 A 标签通过 include 引用了 B 标签的内容，请问，B 标签能否定义在 A 标签的后面，还是说必须定义在 A 标签的前面？<br>答：虽然 Mybatis 解析 Xml 映射文件是按照顺序解析的，但是，被引用的 B 标签依然可以定义在任何地方，Mybatis 都可以正确识别。</p><p>原理是，Mybatis 解析 A 标签，发现 A 标签引用了 B 标签，但是 B 标签尚未解析到，尚不存在，此时，Mybatis 会将 A 标签标记为未解析状态，然后继续解析余下的标签，包含 B 标签，待所有标签解析完毕，Mybatis 会重新解析那些被标记为未解析的标签，此时再解析 A 标签时，B 标签已经存在，A 标签也就可以正常解析完成了。</p><p>简述 Mybatis 的 Xml 映射文件和 Mybatis 内部数据结构之间的映射关系？<br>答：Mybatis 将所有 Xml 配置信息都封装到 All-In-One 重量级对象 Configuration 内部。在 Xml 映射文件中，<parameterMap> 标签会被解析为 ParameterMap 对象，其每个子元素会被解析为 ParameterMapping 对象。<resultMap> 标签会被解析为 ResultMap 对象，其每个子元素会被解析为 ResultMapping 对象。每一个 <select>、<insert>、<update>、<delete> 标签均会被解析为 MappedStatement 对象，标签内的 sql 会被解析为 BoundSql 对象。</p><p>为什么说 Mybatis 是半自动 ORM 映射工具？它与全自动的区别在哪里？<br>答：Hibernate 属于全自动 ORM 映射工具，使用 Hibernate 查询关联对象或者关联集合对象时，可以根据对象关系模型直接获取，所以它是全自动的。而 Mybatis 在查询关联对象或关联集合对象时，需要手动编写 sql 来完成，所以，称之为半自动 ORM 映射工具。</p>]]></content>
      
      
      <categories>
          
          <category> MyBatis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MyBatis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>docker基本操作</title>
      <link href="/2020/12/20/docker/docker%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/"/>
      <url>/2020/12/20/docker/docker%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="docker基本操作"><a href="#docker基本操作" class="headerlink" title="docker基本操作"></a>docker基本操作</h2>]]></content>
      
      
      <categories>
          
          <category> Docker </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SpringBoot 自动装配原理</title>
      <link href="/2020/12/11/spring/SpringBoot%20%E8%87%AA%E5%8A%A8%E8%A3%85%E9%85%8D%E5%8E%9F%E7%90%86/"/>
      <url>/2020/12/11/spring/SpringBoot%20%E8%87%AA%E5%8A%A8%E8%A3%85%E9%85%8D%E5%8E%9F%E7%90%86/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="什么是-SpringBoot-自动装配？"><a href="#什么是-SpringBoot-自动装配？" class="headerlink" title="什么是 SpringBoot 自动装配？"></a>什么是 SpringBoot 自动装配？</h1><p>现在提到自动装配的时候，一般会和 Spring Boot 联系在一起。但是，实际上 Spring Framework 早就实现了这个功能。Spring Boot 只是在其基础上，通过 SPI 的方式，做了进一步优化。</p><blockquote><p>SpringBoot 定义了一套接口规范，这套规范规定：SpringBoot 在启动时会扫描外部引用 jar 包中的<code> META-INF/spring.factories</code> 文件，将文件中配置的类型信息加载到 Spring 容器（此处涉及到 JVM 类加载机制与 Spring 的容器知识），并执行类中定义的各种操作。对于外部 jar 来说，只需要按照 SpringBoot 定义的标准，就能将自己的功能装置进 SpringBoot。</p></blockquote><p>没有 Spring Boot 的情况下，如果需要引入第三方依赖，需要手动配置，非常麻烦。但是，Spring Boot 中，我们直接引入一个 starter 即可。比如你想要在项目中使用 redis 的话，直接在项目中引入对应的 starter 即可。</p><pre><code class="bash">&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt;</code></pre><p>引入 starter 之后，通过少量注解和一些简单的配置就能使用第三方组件提供的功能了。在我看来，自动装配可以简单理解为：通过注解或者一些简单的配置就能在 Spring Boot 的帮助下实现某块功能。</p><h1 id="SpringBoot-是如何实现自动装配的？"><a href="#SpringBoot-是如何实现自动装配的？" class="headerlink" title="SpringBoot 是如何实现自动装配的？"></a>SpringBoot 是如何实现自动装配的？</h1><p>我们先看一下 SpringBoot 的核心注解 <code>SpringBootApplication</code> 。</p><pre><code class="bash">@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited&lt;1.&gt;@SpringBootConfiguration&lt;2.&gt;@ComponentScan&lt;3.&gt;@EnableAutoConfigurationpublic @interface SpringBootApplication &#123;&#125;@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Configuration //实际上它也是一个配置类public @interface SpringBootConfiguration &#123;&#125;</code></pre><p>大概可以把 <code>@SpringBootApplication</code> 看作是 <code>@Configuration、@EnableAutoConfiguration、@ComponentScan </code>注解的集合。根据 SpringBoot 官网，这三个注解的作用分别是：</p><ul><li><p><code>@EnableAutoConfiguration</code> ：启用 SpringBoot 的自动配置机制；</p></li><li><p><code>@Configuration</code> ：允许在上下文中注册额外的 bean 或导入其他配置类；</p></li><li><p><code>@ComponentScan</code> ： 扫描被 @Component (@Service,@Controller) 注解的 bean，注解默认会扫描启动类所在的包下所有的类 ，可以自定义不扫描某些 bean。如下图所示，容器中将排除 </code>TypeExcludeFilter</code> 和 </code>AutoConfigurationExcludeFilter</code>。</p></li></ul><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/bcc73490afbe4c6ba62acde6a94ffdfd~tplv-k3u1fbpfcp-watermark.image"></p><p><code>@EnableAutoConfiguration</code> 是实现自动装配的重要注解，我们以这个注解入手。</p><h2 id="EnableAutoConfiguration：实现自动装配的核心注解"><a href="#EnableAutoConfiguration：实现自动装配的核心注解" class="headerlink" title="@EnableAutoConfiguration：实现自动装配的核心注解"></a>@EnableAutoConfiguration：实现自动装配的核心注解</h2><p><code>EnableAutoConfiguration</code> 只是一个简单地注解，自动装配核心功能的实现实际是通过 <code>AutoConfigurationImportSelector</code> 类。</p><pre><code class="bash">@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@AutoConfigurationPackage //作用：将main包下的所有组件注册到容器中@Import(&#123;AutoConfigurationImportSelector.class&#125;) //加载自动装配类 xxxAutoconfigurationpublic @interface EnableAutoConfiguration &#123;    String ENABLED_OVERRIDE_PROPERTY = &quot;spring.boot.enableautoconfiguration&quot;;    Class&lt;?&gt;[] exclude() default &#123;&#125;;    String[] excludeName() default &#123;&#125;;&#125;</code></pre><p>我们现在重点分析下 <code>AutoConfigurationImportSelector</code> 类到底做了什么？</p><h2 id="AutoConfigurationImportSelector：加载自动装配类"><a href="#AutoConfigurationImportSelector：加载自动装配类" class="headerlink" title="AutoConfigurationImportSelector：加载自动装配类"></a>AutoConfigurationImportSelector：加载自动装配类</h2><p><code>AutoConfigurationImportSelector </code>类的继承体系如下：</p><pre><code class="bash">public class AutoConfigurationImportSelector implements DeferredImportSelector, BeanClassLoaderAware, ResourceLoaderAware, BeanFactoryAware, EnvironmentAware, Ordered &#123;&#125;public interface DeferredImportSelector extends ImportSelector &#123;&#125;public interface ImportSelector &#123;    String[] selectImports(AnnotationMetadata var1);&#125;</code></pre><p>可以看出，<code>AutoConfigurationImportSelector </code>类实现了 <code>ImportSelector </code>接口，也就实现了这个接口中的 <code>selectImports</code> 方法，该方法主要用于<strong>获取所有符合条件的类的全限定类名，这些类需要被加载到 IoC 容器中。</strong></p><pre><code class="bash">private static final String[] NO_IMPORTS = new String[0];public String[] selectImports(AnnotationMetadata annotationMetadata) &#123;        // &lt;1&gt;.判断自动装配开关是否打开        if (!this.isEnabled(annotationMetadata)) &#123;            return NO_IMPORTS;        &#125; else &#123;          //&lt;2&gt;.获取所有需要装配的bean            AutoConfigurationMetadata autoConfigurationMetadata = AutoConfigurationMetadataLoader.loadMetadata(this.beanClassLoader);            AutoConfigurationImportSelector.AutoConfigurationEntry autoConfigurationEntry = this.getAutoConfigurationEntry(autoConfigurationMetadata, annotationMetadata);            return StringUtils.toStringArray(autoConfigurationEntry.getConfigurations());        &#125;    &#125;</code></pre><p>这里我们需要重点关注一下 <code>getAutoConfigurationEntry()</code> 方法，这个方法主要负责加载自动配置类的。</p><p>该方法调用链如下：</p><p><img src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/3c1200712655443ca4b38500d615bb70~tplv-k3u1fbpfcp-watermark.image"></p><p>现在我们结合 <code>getAutoConfigurationEntry()</code> 的源码来详细分析一下：</p><pre><code class="bash">private static final AutoConfigurationEntry EMPTY_ENTRY = new AutoConfigurationEntry();AutoConfigurationEntry getAutoConfigurationEntry(AutoConfigurationMetadata autoConfigurationMetadata, AnnotationMetadata annotationMetadata) &#123;        //&lt;1&gt;.        if (!this.isEnabled(annotationMetadata)) &#123;            return EMPTY_ENTRY;        &#125; else &#123;            //&lt;2&gt;.            AnnotationAttributes attributes = this.getAttributes(annotationMetadata);            //&lt;3&gt;.            List&lt;String&gt; configurations = this.getCandidateConfigurations(annotationMetadata, attributes);            //&lt;4&gt;.            configurations = this.removeDuplicates(configurations);            Set&lt;String&gt; exclusions = this.getExclusions(annotationMetadata, attributes);            this.checkExcludedClasses(configurations, exclusions);            configurations.removeAll(exclusions);            configurations = this.filter(configurations, autoConfigurationMetadata);            this.fireAutoConfigurationImportEvents(configurations, exclusions);            return new AutoConfigurationImportSelector.AutoConfigurationEntry(configurations, exclusions);        &#125;    &#125;</code></pre><blockquote><ol><li>判断自动装配开关是否打开。默认 spring.boot.enableautoconfiguration=true，可在 application.properties 或 application.yml 中设置。</li><li>用于获取 EnableAutoConfiguration 注解中的 exclude 和 excludeName。</li><li>获取需要自动装配的所有配置类，读取 META-INF/spring.factories</li></ol></blockquote><pre><code class="bash">spring-boot/spring-boot-project/spring-boot-autoconfigure/src/main/resources/META-INF/spring.factories</code></pre><p><img src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/58c51920efea4757aa1ec29c6d5f9e36~tplv-k3u1fbpfcp-watermark.image"></p><p>从上图可以看到这个文件的配置内容都被我们读取到了。<code>XXXAutoConfiguration</code> 的作用就是按需加载组件。</p><p>不光是这个依赖下的 <code>META-INF/spring.factories </code>被读取到，所有 Spring Boot Starter 下的 <code>META-INF/spring.factories</code> 都会被读取到。</p><ol start="4"><li>到这里可能面试官会问你:<code>“spring.factories </code>中这么多配置，每次启动都要全部加载么？”。很明显，这是不现实的。debug 到后面你会发现，configurations 的值变小了。</li></ol><p><img src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/267f8231ae2e48d982154140af6437b0~tplv-k3u1fbpfcp-watermark.image"></p><p>因为，这一步又经历了一遍筛选，<code>@ConditionalOnXXX </code>中的所有条件都满足，该类才会生效。</p><pre><code class="bash">@Configuration// 检查相关的类：RabbitTemplate 和 Channel是否存在// 存在才会加载@ConditionalOnClass(&#123; RabbitTemplate.class, Channel.class &#125;)@EnableConfigurationProperties(RabbitProperties.class)@Import(RabbitAnnotationDrivenConfiguration.class)public class RabbitAutoConfiguration &#123;&#125;</code></pre><p>Spring Boot 提供的条件注解：</p><ul><li><code>@ConditionalOnBean</code>：当容器里有指定 Bean 的条件下</li><li><code>@ConditionalOnMissingBean</code>：当容器里没有指定 Bean 的情况下</li><li><code>@ConditionalOnSingleCandidate</code>：当指定 Bean 在容器中只有一个，或者虽然有多个但是指定首选 Bean</li><li><code>@ConditionalOnClass</code>：当类路径下有指定类的条件下</li><li><code>@ConditionalOnMissingClass</code>：当类路径下没有指定类的条件下</li><li><code>@ConditionalOnProperty</code>：指定的属性是否有指定的值</li><li><code>@ConditionalOnResource</code>：类路径是否有指定的值</li><li><code>@ConditionalOnExpression</code>：基于 SpEL 表达式作为判断条件</li><li><code>@ConditionalOnJava</code>：基于 Java 版本作为判断条件</li><li><code>@ConditionalOnJndi</code>：在 JNDI 存在的条件下差在指定的位置</li><li><code>@ConditionalOnNotWebApplication</code>：当前项目不是 Web 项目的条件下</li><li><code>@ConditionalOnWebApplication</code>：当前项目是 Web 项 目的条件下</li></ul><h2 id="如何实现一个-Starter"><a href="#如何实现一个-Starter" class="headerlink" title="如何实现一个 Starter"></a>如何实现一个 Starter</h2><p>光说不练假把式，现在就来撸一个 starter，实现自定义线程池。</p><p>第一步，创建 <code>threadpool-spring-boot-starter</code> 工程：</p><p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1ff0ebe7844f40289eb60213af72c5a6~tplv-k3u1fbpfcp-watermark.image"></p><p>第二步，引入 Spring Boot 相关依赖：</p><p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5e14254276604f87b261e5a80a354cc0~tplv-k3u1fbpfcp-watermark.image"></p><p>第三步，创建 <code>ThreadPoolAutoConfiguration</code>：</p><p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1843f1d12c5649fba85fd7b4e4a59e39~tplv-k3u1fbpfcp-watermark.image"></p><p>第四步，在 threadpool-spring-boot-starter 工程的 resources 包下创建 META-INF/spring.factories 文件：</p><p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/97b738321f1542ea8140484d6aaf0728~tplv-k3u1fbpfcp-watermark.image"></p><p>最后新建工程引入 <code>threadpool-spring-boot-starter</code>：</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/edcdd8595a024aba85b6bb20d0e3fed4~tplv-k3u1fbpfcp-watermark.image"></p><p>测试通过！！！</p><p><img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/9a265eea4de742a6bbdbbaa75f437307~tplv-k3u1fbpfcp-watermark.image"></p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>Spring Boot 通过 <code>@EnableAutoConfiguration</code> 开启自动装配，通过 SpringFactoriesLoader 最终加载 <code>META-INF/spring.factories </code>中的自动配置类实现自动装配，自动配置类其实就是通过 <code>@Conditional </code>按需加载的配置类，想要其生效必须引入<code> spring-boot-starter-xxx</code> 包实现起步依赖。</p>]]></content>
      
      
      <categories>
          
          <category> SpringBoot </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring </tag>
            
            <tag> SpringBoot </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spring</title>
      <link href="/2020/11/28/spring/Spring/"/>
      <url>/2020/11/28/spring/Spring/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Spring-基本概念"><a href="#Spring-基本概念" class="headerlink" title="Spring 基本概念"></a>Spring 基本概念</h1><h2 id="Spring-IOC-的理解"><a href="#Spring-IOC-的理解" class="headerlink" title="Spring IOC 的理解"></a>Spring IOC 的理解</h2><p>IOC （Inverse of Control）控制反转。将之前程序中需要手动创建对象的操作，交由 Spring 框架来实现，创建对象的操作被反转到了 Spring 框架。对象的生命周期由 Spring 来管理，只需要直接从 Spring 那里去获取一个对象。</p><h2 id="Spring-DI-的理解"><a href="#Spring-DI-的理解" class="headerlink" title="Spring DI 的理解"></a>Spring DI 的理解</h2><p>DI（Dependency Injection）依赖注入。Spring 框架创建 Bean 对象时，动态的将依赖对象注入到 Bean 组件中，实现依赖对象的注入。</p><h2 id="BeanFactory-接口和-ApplicationContext-接口不同点"><a href="#BeanFactory-接口和-ApplicationContext-接口不同点" class="headerlink" title="BeanFactory 接口和 ApplicationContext 接口不同点"></a>BeanFactory 接口和 ApplicationContext 接口不同点</h2><ol><li><p>ApplicationContext 接口继承 BeanFactory 接口，Spring 核心工厂是 BeanFactory，BeanFactory 采取延迟加载，第一次 getBean 时才会初始化 Bean，而 ApplicationContext 是会在加载配置文件时初始化 Bean。</p></li><li><p>ApplicationContext 是对 BeanFactory 扩展，它可以进行国际化处理、 事件传递和 Bean 自动装配以及各种不同应用层的 Context 实现。</p></li></ol><p>开发中基本都在使用 ApplicationContext，Web 项目使 用 WebApplicationContext ，很少用到 BeanFactory。</p><h2 id="Spring-核心类以及作用"><a href="#Spring-核心类以及作用" class="headerlink" title="Spring 核心类以及作用"></a>Spring 核心类以及作用</h2><ul><li><p>BeanFactory：产生一个新的实例，可以实现单例模式；</p></li><li><p>BeanWrapper：提供统一的 get 及 set 方法；</p></li><li><p>ApplicationContext：提供框架的实现，包括 BeanFactory 的所有功能</p></li></ul><h1 id="Spring-的事务"><a href="#Spring-的事务" class="headerlink" title="Spring 的事务"></a>Spring 的事务</h1><p>事务是数据库操作的最小工作单元，是作为单个逻辑工作单元执行的一系列操作。这些操作作为一个整体一起向系统提交，要么都执行，要么都不执行；事务是一组不可再分割的操作集合（工作逻辑单元）。</p><p>事务特性：ACID</p><ul><li>原子性：事务不可分割 。</li><li>一致性：事务执行的前后，数据完整性保持一致 。</li><li>隔离性：一个事务执行的时候，不应该受到其他事务的打扰。</li><li>持久性：事务一旦结束，数据就永久的保存到数据库。</li></ul><p>Spring 中有自己的事务管理机制，使用 TransactionMananger 进行管理，可以通过 Spring 的注入来完成此功能。Spring 提供了以下几个事务处理的类：</p><ul><li><p>TransactionDefinition：事务属性定义，定义了事务传播行为类型（ 7 种），事务隔离类型（ 5 种），超时设置、事务隔离级别、只读、回滚规则)。</p></li><li><p>TranscationStatus：代表了当前的事务，可以提交、回滚。</p></li><li><p>PlatformTransactionManager：这个是 Spring 提供的用于管理事务的基础接口。通过这个接口，Spring 可以为如 JDBC、Hibernate 等提供对应的事务管理器，具体的实现就是各个平台来实现。</p></li></ul><p>事务定义样例：</p><pre><code>TransactionDefinition td = new TransactionDefinition();TransactionStatus ts = transactionManager.getTransaction(td); try&#123;    //do sth    transactionManager.commit(ts);&#125;catch(Exception e)&#123;    transactionManager.rollback(ts);&#125;</code></pre><h2 id="Spring-的事务实现方式"><a href="#Spring-的事务实现方式" class="headerlink" title="Spring 的事务实现方式"></a>Spring 的事务实现方式</h2><p>Spring 事务管理实现方式有两种：编程式事务管理和声明式事务。</p><p><strong>编程式事务</strong></p><p>使用 TransactionTemplate 或使用底层的 PlatformTransactionManager， 显式的方式调用 beginTransaction () 开启事务、commit () 提交事务、 rollback () 回滚事务，编写代码形式来声明事务，粒度较细，比较灵活，但开发起来比较繁琐： 每次都要开启、提交、回滚。</p><p><strong>声明式事务</strong></p><p>底层是建立在 Spring AOP 的基础上，在方法执行前后进行拦截，并在目标方法开始执行前创建新事务或加入一个已存在事务，最后在目标方法执行完后根据情况提交或者回滚事务。</p><p>声明式事务的优点：不需要编程，减少了代码的耦合，在配置文件中配置并在目标方法上添加 @Transactional 注解来实现。</p><h2 id="Spring-事务中的隔离级别有哪几种？"><a href="#Spring-事务中的隔离级别有哪几种？" class="headerlink" title="Spring 事务中的隔离级别有哪几种？"></a>Spring 事务中的隔离级别有哪几种？</h2><ul><li><p>TransactionDefinition 接口中定义了五个表示隔离级别的常量：</p></li><li><p>TransactionDefinition.ISOLATION_DEFAULT: 使用后端数据库默认的隔离级别，Mysql 默认采用的 REPEATABLE_READ 隔离级别 Oracle 默认采用的 READ_COMMITTED 隔离级别.</p></li><li><p>TransactionDefinition.ISOLATION_READ_UNCOMMITTED: 最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读</p></li><li><p>TransactionDefinition.ISOLATION_READ_COMMITTED: 允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生</p></li><li><p>TransactionDefinition.ISOLATION_REPEATABLE_READ: 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。</p></li><li><p>TransactionDefinition.ISOLATION_SERIALIZABLE: 最高的隔离级别，完全服从 ACID 的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说， 该级别可以防止脏读、不可重复读以及幻读。但是这将严重影响程序的性能。通常情况下也不会用到该级别。</p></li></ul><h2 id="Spring-事务中哪几种事务传播行为？"><a href="#Spring-事务中哪几种事务传播行为？" class="headerlink" title="Spring 事务中哪几种事务传播行为？"></a>Spring 事务中哪几种事务传播行为？</h2><p><strong>支持当前事务的情况：</strong></p><ul><li>TransactionDefinition.PROPAGATION_REQUIRED： 如果当前存在事务，则加入该事务；如果当前没有事务，则创建一个新的事务。</li><li>TransactionDefinition.PROPAGATION_SUPPORTS： 如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行。</li><li>TransactionDefinition.PROPAGATION_MANDATORY： 如果当前存在事务，则加入该事务；如果当前没有事务，则抛出异常。（mandatory：强制性）</li></ul><p><strong>不支持当前事务的情况：</strong></p><ul><li>TransactionDefinition.PROPAGATION_REQUIRES_NEW： 创建一个新的事务，如果当前存在事务，则把当前事务挂起。</li><li>TransactionDefinition.PROPAGATION_NOT_SUPPORTED： 以非事务方式运行，如果当前存在事务，则把当前事务挂起。</li><li>TransactionDefinition.PROPAGATION_NEVER： 以非事务方式运行，如果当前存在事务，则抛出异常。</li></ul><p><strong>其他情况：</strong></p><p>TransactionDefinition.PROPAGATION_NESTED： 如果当前存在事务，则创建一个事务作为当前事务的嵌套事务来运行；如果当前没有事务，则该取值等价于 TransactionDefinition.PROPAGATION_REQUIRED。<br>@Transactional (rollbackFor = Exception.class) 注解了解吗？<br>我们知道：Exception 分为运行时异常 RuntimeException 和非运行时异常。事务管理对于企业应用来说是至关重要的，即使出现异常情况，它也可以保证数据的一致性。</p><p>当 @Transactional 注解作用于类上时，该类的所有 public 方法将都具有该类型的事务属性，同时，我们也可以在方法级别使用该标注来覆盖类级别的定义。如果类或者方法加了这个注解，那么这个类里面的方法抛出异常，就会回滚，数据库里面的数据也会回滚。</p><p>在 @Transactional 注解中如果不配置 rollbackFor 属性，那么事物只会在遇到 RuntimeException 的时候才会回滚，加上 rollbackFor=Exception.class, 可以让事物在遇到非运行时异常时也回滚。</p><p>Spring AOP<br>AOP（Aspect Oriented Programming）面向切面编程，通过预编译方式和运行期动态代理实现程序功能的统一维护的一种技术。利用 AOP 可以对业务逻辑的各个部分进行隔离，从而使得业务逻辑各部分之间的耦合度降低，提高程序的可重用性，同时提高了开发的频率。即通过分离横切关注点来增加程序的模块化。AOP 在不修改现有代码的情况下对现有代码添加功能，这个是 AOP 最重要的能力。</p><p>AOP：面向切面编程，允许程序模块化横向切割关注点， 或横切典型的责任划分，如日志和事务管理。</p><p>Spring AOP 和 AspectJ AOP 有什么区别？<br>Spring AOP 属于运行时增强，而 AspectJ 是编译时增强。 Spring AOP 基于代理 (Proxying)，而 AspectJ 基于字节码操作 (Bytecode Manipulation)。</p><p>Spring AOP 已经集成了 AspectJ ，AspectJ 应该算的上是 Java 生态系统中最完整的 AOP 框架了。AspectJ 相比于 Spring AOP 功能更加强大，但是 Spring AOP 相对来说更简单，</p><p>如果我们的切面比较少，那么两者性能差异不大。但是，当切面太多的话，最好选择 AspectJ ，它比 Spring AOP 快很多。</p><p>@Component 和 @Bean 的区别是什么？<br>作用对象不同: @Component 注解作用于类，而 @Bean 注解作用于方法。<br>@Component 通常是通过类路径扫描来自动侦测以及自动装配到 Spring 容器中（我们可以使用 @ComponentScan 注解定义要扫描的路径从中找出标识了需要装配的类自动装配到 Spring 的 bean 容器中）。@Bean 注解通常是我们在标有该注解的方法中定义产生这个 bean,@Bean 告诉了 Spring 这是某个类的示例，当我需要用它的时候还给我。<br>@Bean 注解比 Component 注解的自定义性更强，而且很多地方我们只能通过 @Bean 注解来注册 bean。比如当我们引用第三方库中的类需要装配到 Spring 容器时，则只能通过 @Bean 来实现。<br>将一个类声明为 Spring 的 bean 的注解有哪些？</p><p>我们一般使用 @Autowired 注解自动装配 bean，要想把类标识成可用于 @Autowired 注解自动装配的 bean 的类，采用以下注解可实现：</p><p>@Component ：通用的注解，可标注任意类为 Spring 组件。如果一个 Bean 不知道属于哪个层，可以使用 @Component 注解标注。<br>@Repository : 对应持久层即 Dao 层，主要用于数据库相关操作。<br>@Service : 对应服务层，主要涉及一些复杂的逻辑，需要用到 Dao 层。<br>@Controller : 对应 Spring MVC 控制层，主要用户接受用户请求并调用 Service 层返回数据给前端页面。<br>@RestController vs @Controller<br>Spring 的通知类型<br>通知是个在方法执行前或执行后要做的动作，实际上是程序执行时要通过 Spring AOP 框架触发的代码段。</p><p>Spring 的通知类型总共有 5 种：前置通知、环绕通知、后置通知、异常通知、 最终通知。</p><p>前置通知（Before advice）：在目标方法执行之前执行的通知。在某连接点（ join point ）之前执行的通知，但这个通知不能阻止连接点前的 执行（除非它抛出一个异常）。<br>环绕通知（Around Advice）： 在目标方法执行之前和之后都可以执行额外代码的通知。也可以选择是否继续执行连接点或直接返回它们自己的返回值或抛出异常来结束执行。<br>后置通知（After (finally) advice）：目标方法执行之后（某连接点退 出的时候）执行的通知（不论是正常返回还是异常退出）。<br>异常后通知（After throwing advice）：在方法抛出异常退出时执行的通知。<br>最终通知（After returning advice）： 在某连接点（join point）正常完成后执行的通知：例如，一个方法没有抛出任何异常，正常返回。<br>Spring 通知类型使用场景分别有哪些<br>通知类型    使用场景<br>环绕通知    控制事务 权限控制<br>后置通知 记录日志（方法已经成功调用）    记录日志（方法已经成功调用<br>异常通知    异常处理 控制事务<br>最终通知    记录日志（方法已经调用，但不一定成功）<br>Spring Beans 的理解<br>Spring Beans 是被实例的，组装的及被 Spring 容器管理的 Java 对象；<br>Spring Beans 会被 Spring 容器自动完成 @bean 对象的实例化 ；<br>Spring 框架定义的 Beans 都是默认为单例，也可以配置为多例。<br>Spring 的优点<br>提供控制反转能力，将对象的创建交给了 Spring，降低了代码耦合性、 侵入性。<br>Spring 是 POJO 编程，使得可持续构建和可测试能力提高 。<br>Spring 是开源免费的 。<br>方便集成各种优秀的框架。<br>Spring 和 Struts 的区别<br>Spring：</p><p>具备 IOC/DI、AOP 等通用能力，提高研发效率 ；<br>除了支持 Web 层建设以外，还提供了 J2EE 整体服务 ；<br>方便与其他不同技术结合使用，例如：Hibernate，Mybatis 等 ；<br>Spring 拦截机制是方法级别 。<br>Struts：</p><p>是一个基于 MVC 模式的一个 Web 层的处理器；<br>Struts 拦截机制是类级别。<br>Spring 框架组成<br>主要七大模块：</p><p>Spring AOP 面向切面编程<br>Spring ORM Hibernate|mybatis|JDO<br>Spring Core 提供 Bean 工厂 IOC<br>Spring Dao JDBC 支持<br>Spring Context 提供了关于 UI 支持、邮件支持等<br>Spring Web 提供了 Web 的一些工具类的支持<br>Spring MVC 提供了 Web MVC、Webviews、JSP、PDF、Export<br>BeanFactory 的理解<br>BeanFactory 用于管理 Bean 的，通过 BeanFactory 可以从 Spring 中获取注册到其中的 Bean 来使用。<br>BeanFactory 实现基于工厂模式，提供了控制反转功能，把应用的配置和依赖从真正的应用代码中分离。<br>最 常 用 的 BeanFactory 实 现 是 XmlBeanFactory 、 XmlWebApplicationContext、ClassPathXmlApplicationContext 等。<br>Spring 中的 Web 模块<br>Spring 的 Web 模块是构建在 application context 模块基础之上，提供一个适合 Web 应用的上下文。</p><p>这个模块也包括支持多种面向 Web 的任务，如透明地处理多个文件上传请求和程序级请求参数的绑定到你的业务对象。</p><p>BeanFactory 和 Application contexts 区别<br>BeanFactory 提供了最简单的容器功能，只提供了实例化对象和拿对象的功能。<br>Application contexts 应用上下文，继承 BeanFactory 接口，它是 Spring 的一个更高级的容器，提供了更多有用的功能。<br>Spring 依赖注入的理解<br>通常情况下，当需要调用一个其他对象的时候，采用 new 的方式进行对象的创 建，导致对象之间耦合性增强，后续代码维护比较困难。</p><p>Spring 框架提供了依赖注入的能力，对象统一由 Spring 容器创建，Spring 容器会负责程序之间的关系。这样控制权由应用代码转移到 Spring 容器，控制权发生了反转，就是 Spring 的控制反转。创建依赖对象的工作交由 Spring 容器来完成，然后注入调用者，这就是依赖注入。</p><p>Bean 装配<br>Spring 容器根据 Bean 之间的依赖关系，将 Bean 通过依赖注入进行组装在一起，这就是 Bean 装配。</p><p>Bean 的自动装配<br>在 Spring 框架里面是使用 和 配置方式进行依赖注入，如果 Bean 对象较多的情况下注入工作就比较麻烦，XML 文件会变得很难维护，所以为了简化 XML 配置文件，提高开发效率可以使用 @autowire（自动装配），能通过 Bean 工厂自动处理 Bean 之间的协作。</p><p>自动装配有几种方式<br>有五种自动装配的方式，可以用来指导 Spring 容器用自动装配方式来进行依赖注入。</p><p>no：默认设置，表示没有自动装配，通过显式设置 Bean 引用来进行装配。<br>byName：根据 Bean 的名称注入对象依赖项。<br>byType：根据类型注入对象依赖项。<br>constructor：通过调用类的构造函数来注入依赖项。<br>autodetect：先尝试 constructor 来自动装配，若不成功，则使用 byType 方式。<br>基于注解的容器配置<br>开发者通过在相应的类、方法或属性上使用注解的方式，直接在组件类中进行配置， 而不是使用 XML 表述 Bean 的装配关系。</p><p>JdbcTemplate 类的作用<br>JDBCTemplate 类提供了很多便利的方法解决诸如把数据库数据转变成基本数据类型或对象，执行写好的或可调用的数据库操作语句，提供自定义的数据错误处理。</p><p>Aspect 切面<br>AOP 核心就是切面，它将多个类的通用行为封装成可重用的模块，该模块含有 一组 API 提供横切功能。比如，一个日志模块可以被称作日志的 AOP 切面。 根据需求的不同，一个应用程序可以有若干切面。在 Spring AOP 中，切面通过带有 @Aspect 注解的类实现。</p><p>Spring AOP 中的织入的理解<br>织入是将切面和到其他应用类型或对象连接或创建一个被通知对象的过程。 织入可以在编译时，加载时，或运行时完成。</p><p>说说自己对于 Spring MVC 了解？<br>Model1 时代 : 很多学 Java 后端比较晚的朋友可能并没有接触过 Model1 模式下的 JavaWeb 应用开发。在 Model1 模式下，整个 Web 应用几乎全部用 JSP 页面组成，只用少量的 JavaBean 来处理数据库连接、访问等操作。这个模式下 JSP 即是控制层又是表现层。显而易见，这种模式存在很多问题。比如①将控制逻辑和表现逻辑混杂在一起，导致代码重用率极低；②前端和后端相互依赖，难以进行测试并且开发效率极低</p><p>Model2 时代 ：学过 Servlet 并做过相关 Demo 的朋友应该了解 “Java Bean (Model)+ JSP（View,）+Servlet（Controller） ” 这种开发模式，这就是早期的 JavaWeb MVC 开发模式。Model: 系统涉及的数据，也就是 dao 和 bean。View：展示模型中的数据，只是用来展示。Controller：处理用户请求都发送给 ，返回数据给 JSP 并展示给用户。</p><p>Model2 模式下还存在很多问题，Model2 的抽象和封装程度还远远不够，使用 Model2 进行开发时不可避免地会重复造轮子，这就大大降低了程序的可维护性和复用性。于是很多 JavaWeb 开发相关的 MVC 框架应运而生比如 Struts2，但是 Struts2 比较笨重。随着 Spring 轻量级开发框架的流行，Spring 生态圈出现了 Spring MVC 框架， Spring MVC 是当前最优秀的 MVC 框架。相比于 Struts2 ， Spring MVC 使用更加简单和方便，开发效率更高，并且 Spring MVC 运行速度更快。</p><p>MVC 是一种设计模式，Spring MVC 是一款很优秀的 MVC 框架。Spring MVC 可以帮助我们进行更简洁的 Web 层的开发，并且它天生与 Spring 框架集成。Spring MVC 下我们一般把后端项目分为 Service 层（处理业务）、Dao 层（数据库操作）、Entity 层（实体类）、Controller 层 (控制层，返回数据给前台页面)。</p><p>Spring MVC 的流程<br>用户发送请求至前端控制器 DispatcherServlet<br>DispatcherServlet 收到请求调用 HandlerMapping 处理器映射器。<br>处理器映射器根据请求 url 找到具体的处理器，生成处理器对象及处理器拦截器（如果有则生成）一并返回给 DispatcherServlet。<br>DispatcherServlet 通过 HandlerAdapter 处理器适配器调用处理器<br>执行处理器（Controller，也叫后端控制器）。<br>Controller 执行完成返回 ModelAndView。<br>HandlerAdapter 将 controller 执行结果 ModelAndView 返回给 DispatcherServlet。<br>DispatcherServlet 将 ModelAndView 传给 View Reslover 视图解析器。<br>View Reslover 解析后返回具体 View。<br>DispatcherServlet 对 View 进行渲染视图（即将模型数据填充至视图中）。<br>DispatcherServlet 响应用户。<br>Spring 配置文件<br>Spring 配置文件是个 XML 文件，这个文件包含了类信息，描述了如何配置它们，以及如何相互调用。</p><p>@RequestMapping 注解用在类上的作用<br>用于类上，表示类中的所有响应请求的方法都是以该地址作为父路径。</p><p>把某个请求映射到特定的方法上面<br>在方法上面加上注解 @RequestMapping，并且在这个注解里面写上要拦截的路径。</p><p>Spring 对 DAO 的支持<br>Spring 提供的 DAO （数据访问对象）支持主要的目的是便于以标准的方式使用不同的数据访问技术。</p><p>简化 DAO 组件的开发。Spring 提供了一套抽象 DAO 类供你扩展。这些抽象类提供了一些方法，用来简化代码开发。<br>IOC 容器的使用，提供了 DAO 组件与业务逻辑组件之间的解耦。所有的 DAO 组件，都由容器负责注入到业务逻辑组件中，其业务组件无须关心 DAO 组件的实现。<br>面向接口编程及 DAO 模式的使用，提高了系统组件之间的解耦，降低 了系统重构的成本。<br>方便的事务管理：Spring 的声明式事务管理力度是方法级。<br>异常包 装 ： Spring 能够包装 Hibernate 异 常 ， 把 它 们 从 CheckedException 变为 RuntimeException；开发者可选择在恰当的 层处理数据中不可恢复的异常，从而避免烦琐的 catch/throw 及异常声明。<br>Spring 事务传播类型</p><p>image-20210804195443771</p><p>Spring 应用场景题<br>Spring 配置 Bean 实例化的方式<br>使用类构造器实例化（默认无参数）<br>XML<br>1<br><bean id="bean1" class="cn.itcast.spring.b_instance.Bean1"></bean><br>使用静态工厂方法实例化（简单工厂模式）<br>下面这段配置的含义：调用 Bean2Factory 的 getBean2 方法得到 bean2 。</p><p>XML<br>1<br>2<br>3<br>&lt;bean id=”bean2” class=”cn.heu.spring.b_instance.Bean2Factory” </p><p>factorymethod=”getBean2”&gt;</bean><br>使用实例工厂方法实例化（工厂方法模式）<br>创建工厂实例 bean3Facory，再通过工厂实例创建目标 bean 实例 。</p><p>XML<br>1<br>2<br>3<br><bean id="bean3Factory" class="cn.heu.spring.b_instance.Bean3Factory"/></p><p>id=”bean3” factorybean=”bean3Factory” factorymethod=”getBean3”&gt;</bean><br>Bean 注入属性有哪几种方式<br>属性注入方式，通过 setXXX () 方法注入 Bean 的属性值或者依赖对象。</p><p>构造函数注入方式，使用的前提：Bean 必须提供带参的构造函数 。</p><p>工厂方法注入方式 。</p><p>Spring 中实现时间处理<br>在 applicationContext.xml 中配置事件源、监听器，先得到事件源，调用事件源的方法，通知监听器。</p><p>**Spring 中更高效的使用 JDBC **<br>传统的 JDBC 实现有两个不足之处：</p><p>连接需要自己管理操作</p><p>JDBC 操作代码封装与编写重复实现</p><p>JdbcTemplate 的优点有：</p><p>配置基于模板化处理</p><p>JdbcTemplate 是线程安全类</p><p>实例化操作比较简单，仅需要传递 DataSource</p><p>自动完成资源的创建和释放工作</p><p>对 JDBC 的核心流程进行了封装，简化了对 JDBC 的操作</p><p>创建一次 JdbcTemplate，到处可用，避免重复开发</p><p>设计模式在 Spring 框架中的使用<br>工厂模式：BeanFactory 就是简单工厂模式的体现，用来创建对象的实例。</p><p>单例模式：Bean 默认为单例模式。</p><p>代理模式：Spring 的 AOP 功能用到了 JDK 的动态代理和 CGLIB 字节码生成技术。</p><p>模板方法：用来解决代码重复的问题。比如：RestTemplate, JmsTemplate, JpaTemplate。</p><p>观察者模式：定义对象键一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都会得到通知被制动更新，如 Spring 中 listener 的实现：ApplicationListener。</p><p>Spring 框架的优点<br>非侵入式设计：代码与框架的依赖性比较低。</p><p>代码解耦：提供控制反转能力，对象的创建和依赖关系的维护工作都交给 Spring 容器的管理，大大的降低了对象之间的耦合性。</p><p>可复用性提高：支持 AOP ，允许将一些通用能力（打印日志、事务处理、 安全操作等）进行集中式处理。</p><p>MVC 框架：Spring 的 Web 框架是个精心设计的框架，是 Web 框架的一个很好的替代品。</p><p>事务支持方便：Spring 提供一个持续的事务管理接口，配置化完成对事务的管理，减少手动编程。</p><p>异常处理：Spring 提供方便的 API 把具体技术相关的异常（比如由 JDBC、Hibernate or JDO 抛出的）转化为一致的 unchecked 异常。</p><p>方便程序测试：提供了对 Junit4 的支持，可以通过注解方便的测试 Spring 程序。</p><p>哪种依赖注入方式建议使用，构造器注入，还是 Setter 方法注 入<br>两种依赖方式都可以使用，构造器注入和 setter 方法注入。最好的解决方案是用构造器参数实现强制依赖，setter 方法实现可选依赖。</p><p>定义类的作用域<br>可以通过 Bean 定义中的 scope 属性来定义。如，当 Spring 要在需要的时候每次生产一个新的 Bean 实例 ， Bean 的 scope 属性被指定 为 prototype。另一方面，一个 Bean 每次使用的时候必须返回同一个实例，这个 Bean 的 scope 属性必须设为 singleton。</p><p>Spring 支持的几种 Bean 的作用域<br>Spring 框架支持以下五种 Bean 的作用域：</p><p>singleton：Bean 在每个 Spring IOC 容器中只有一个实例。</p><p>prototype：一个 Bean 的定义可以有多个实例。</p><p>request：每次 http 请求都会创建一个 Bean，该作用域仅在基于 Web 的 Spring ApplicationContext 情形下有效。</p><p>session：在一个 HTTP Session 中，一个 Bean 定义对应一个实例。 该作用域仅在基于 Web 的 Spring ApplicationContext 情形下有效。</p><p>global-session：在一个全局的 HTTP Session 中，一个 Bean 定义对 应一个实例。该作用域仅在基于 Web 的 Spring ApplicationContext 情形下有效。</p><p>缺省的 Spring Bean 的作用域是 Singleton。</p><p>可以在 Spring 中注入一个 null 和一个空字符串吗<br>可以</p><p>Spring 中如何注入一个 Java 集合<br>Spring 提供以下几种集合的配置元素：</p><p>类型用于注入一列值，允许有相同的值。</p><p>类型用于注入一组值，不允许有相同的值。</p><p>类型用于注入一组键值对，键和值都可以为任意类型。</p><p>类型用于注入一组键值对，键和值都只能为 String 类型。</p><p>什么是基于 Java 的 Spring 注解配置？给一些注解的例子<br>基于 Java 的配置，允许你在少量的 Java 注解的帮助下，进行你的大部分 Spring 配置而非通过 XML 文件.</p><p>以 @Configuration 注解为例，它用来标记类可以当做一个 Bean 的定义，被 Spring IOC 容器使用。另一个例子是 @Bean 注解，它表示此方法将要返回一 个对象，作为一个 Bean 注册进 Spring 应用上下文。</p><p>你更倾向用那种事务管理类型<br>声明式事务管理，因为它对应用代码侵入性很少，更符合一个无侵入的轻量级容器的思想。 声明式事务管理要优于编程式事务管理，虽然比编程式事务管理（这种方式允许 你通过代码控制事务）少了一点灵活性。</p><p>Bean 的调用方式有哪些<br>有三种方式可以得到 Bean 并进行调用。</p><ol><li>使用 BeanWrapper</li></ol><p>JAVA<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>HelloWorld hw=new HelloWorld(); </p><p>BeanWrapper bw=new BeanWrapperImpl(hw); </p><p>bw.setPropertyvalue(”msg”,”HelloWorld”); </p><p>system.out.println(bw.getPropertyCalue(”msg”));<br>2. 使用 BeanFactory</p><p>JAVA<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>InputStream is=new FileInputStream(”config.xml”);</p><p>XmlBeanFactory factory=new XmlBeanFactory(<strong>is</strong>); </p><p>HelloWorld hw=(HelloWorld) factory.getBean(”HelloWorld”); </p><p>system.out.println(hw.getMsg());<br>3. 使用 ApplicationConttext</p><p>JAVA<br>1<br>2<br>3<br>4<br>5<br>ApplicationContext actx=new FleSystemXmlApplicationContext(”config.xml”); </p><p>HelloWorld hw=(HelloWorld) actx.getBean(”HelloWorld”); </p><p>System.out.println(hw.getMsg());<br>使用 @ResponseBody 注解。</p><p>Spring MVC 里面拦截器是怎么写的<br>有两种写法，一种是实现接口，另外一种是继承适配器类，然后在 Spring MVC 的配置文件中配置拦截器即可.</p><p>当一个方法向 AJAX 返回特殊对象，譬如 Object、List 等，需要做什么处理<br>加上 @ResponseBody 注解。</p><p>如何使用 Spring MVC 完成 JSON 操作<br>配置 MappingJacksonHttpMessageConverter</p><p>使用 @RequestBody 注解或 ResponseEntity 作为返回值</p><p>Spring MVC 常用的一些注解<br>@RequestMapping：处理请求地址映射的注解，可用于类或方法上。</p><p>@PathVariable：绑定 URI 模板变量值是用来获得请求 url 中的动态参数。</p><p>@RequestParam：用于将指定的请求参数赋值给方法中的形参。</p><p>@RequestBody：读取 Request 请求的 body 部分数据。</p><p>@ResponseBody：用于将 Controller 的方法返回的对象，通过适当的 HttpMessageConverter 转换为指定格式后，写入到 Response 对象的 body 数据区。</p><p>Spring 深度理解<br>Spring 的生命周期<br>Bean 容器找到配置文件中 Spring Bean 的定义。<br>Bean 容器利用 Java Reflection API 创建一个 Bean 的实例。<br>如果涉及到一些属性值 利用 set() 方法设置一些属性值。<br>如果 Bean 实现了 BeanNameAware 接口，调用 setBeanName() 方法，传入 Bean 的名字。<br>如果 Bean 实现了 BeanClassLoaderAware 接口，调用 setBeanClassLoader() 方法，传入 ClassLoader 对象的实例。<br>与上面的类似，如果实现了其他 *.Aware 接口，就调用相应的方法。<br>如果有和加载这个 Bean 的 Spring 容器相关的 BeanPostProcessor 对象，执行 postProcessBeforeInitialization() 方法<br>如果 Bean 实现了 InitializingBean 接口，执行 afterPropertiesSet() 方法。<br>如果 Bean 在配置文件中的定义包含 init-method 属性，执行指定的方法。<br>如果有和加载这个 Bean 的 Spring 容器相关的 BeanPostProcessor 对象，执行 postProcessAfterInitialization() 方法<br>当要销毁 Bean 的时候，如果 Bean 实现了 DisposableBean 接口，执行 destroy() 方法。<br>当要销毁 Bean 的时候，如果 Bean 在配置文件中的定义包含 destroy-method 属性，执行指定的方法。<br>实例化对象；<br>填充属性值及引用；<br>调用 BeanNameAware 的 setBeanName(String name) 设置 bean 的 id；<br>调用 BeanFactoryAware 的 setBeanFactory(BeanFactory beanFactory) 设置 BeanFactory Bean 工厂；<br>同上：ApplicationContextAware``setApplicationContext(ApplicationContext applicationContext)；<br>如果实现 BeanPostProcessor，则 调用 postProcessBeforeInitialization () 初始化前的后置处理方法；<br>如果实现了 InitializingBean 接口，则使用 afterPropertiesSet() 来初始化属性；<br>如果实现 BeanPostProcessor，则 调用 postProcessAfterInitialization () 初始化后的后置处理方法；<br>此时，bean 就可以使用了；<br>DisposableBean 接口 destroy() 销毁 bean。不过在 Spring5.0 开始，DisposableBean.destroy () 已经是过时的方法了，可直接使用 close ()。</p><p>image-20210807163127693<br>Spring 如何处理线程并发问题<br>Spring 使用 ThreadLocal 解决线程安全问题。</p><p>ThreadLocal 和线程同步机制都是为了解决多线程中相同变量的访问冲突问题。在同步机制中，通过对象的锁机制保证同一时间只有一个线程访问变量。这时该变量是多个线程共享的，使用同步机制要求程序慎密地分析什么时候对变量进行读写，什么时候需要锁定某个对象，什么时候释放对象锁等繁杂的问题，程 序设计和编写难度相对较大。</p><p>而 ThreadLocal 则从另一个角度来解决多线程的并发访问。 ThreadLocal 会为每一个线程提供一个独立的变量副本，从而隔离了多个线程对数据的访问冲突。因为每一个线程都拥有自己的变量副本，从而也就没有必要对该变量进行同步了。 ThreadLocal 提供了线程安全的共享对象，在编写多线程代码时，可以把不安全的变量封装进 ThreadLocal。概括起来说，对于多线程资源共享的问题，同步机制采用了 “以时间换空间” 的方式，而 ThreadLocal 采用了 “以空间换时间” 的方式。前者仅提供一份变量，让不同的线程排队访问，而后者为每一个线程都提供了一份变量，因此可以同时访问而互不影响。</p><p>核心容器（应用上下文）模块的理解<br>这是基本的 Spring 模块，提供 Spring 框架的基础功能，BeanFactory 是任何以 Spring 为基础的应用的核心。Spring 框架建立在此模块之上，它使 Spring 成为一个容器。</p><p>为什么说 Spring 是一个容器<br>Spring 容器是整个 Spring 框架的核心，通常我们说的 Spring 容器就是 Bean 工厂，Bean 工厂负责创建和初始化 Bean、装配 Bean 并且管理应用程序中 的 bean.spring 中 提供了两个核心接 口 — BeanFactory 和 ApplicationContext，ApplicationContext 是 BeanFactory 子接口，它提供了比 BeanFactory 更完善的功能。</p><p>Spring 框架中的单例 Beans 是线程安全的么<br>Spring 框架并没有对单例 Bean 进行任何多线程的封装处理。关于单例 Bean 的线程安全和并发问题需要开发者自行去搞定。但实际上，大部分的 Spring Bean 并没有可变的状态 (比如 Service 类和 DAO 类)，所以在某种程度上说 Spring 的单例 Bean 是线程安全的。如果你的 Bean 有多种状态的话（比如 View Model 对象），就需要自行保证线程安全。最浅显的解决办法就是将多 态 Bean 的作用域由 “singleton” 变为 “prototype”。</p><p>什么是 Spring 的内部 Bean<br>当一个 Bean 仅被用作另一个 Bean 的属性时，它能被声明为一个内部 Bean， 为了定义 inner Bean，在 Spring 的基于 XML 的配置元数据中，可以 在 或 元素内使用 元素，内部 Bean 通常是匿名的，它们的 Scope 一般是 prototype。</p><p>自动装配有哪些局限性<br>重写： 你仍需用 和 配置来定义依赖，意味着总要重写自动装配。</p><p>基本数据类型：不能自动装配简单的属性，如基本数据类型、String 字符串和类。</p><p>模糊特性：自动装配不如显式装配精确，如果有可能，建议使用显式装配。</p><p>IOC 的优点是什么<br>IOC 或依赖注入把应用的代码量降到最低。它使应用容易测试，单元测试不再需要单例和 JNDI 查找机制。最小的代价和最小的侵入性使松散耦合得以实现。IOC 容器支持加载服务时的饿汉式初始化和懒加载。</p><p>Spring 框架的事务管理有哪些优点<br>它为不同的事务 API 如 JTA、JDBC、Hibernate、JPA 和 JDO，提供一个不变的编程模式。</p><p>它为编程式事务管理提供了一套简单的 API 而不是一些复杂的事务 API。</p><p>它支持声明式事务管理。</p><p>它和 Spring 各种数据访问抽象层很好得集成。</p><p>在 Spring AOP 中，关注点和横切关注的区别是什么<br>关注点是应用中一个模块的行为，一个关注点可能会被定义成一个我们想实现的一个功能。</p><p>横切关注点是一个关注点，此关注点是整个应用都会使用的功能，并影响 整个应用，比如日志、安全和数据传输，几乎应用的每个模块都需要的功能。因此这些都属于横切关注点。</p><p>Spring AOP 的底层实现原理<br>Spring AOP 中的动态代理主要有两种方式， JDK 动态代理和 CGLIB 动态代理 。</p><p>JDK 动态代理通过反射来接收被代理的类，并且要求被代理的类必须实现一个接口。JDK 动态代理的核心是 InvocationHandler 接口和 Proxy 类。<br>创建代理类 proxy 实现 Invocation 接口，重写 invoke () 方法；<br>将被代理类作为构造函数的参数传入代理类 proxy；<br>调用 Proxy.newProxyInsatnce (classloader,interfaces,handler) 方法生成代理类。<br>如果目标类没有实现接口，那么 Spring AOP 会选择使用 CGLIB 来动态代理目标类 。CGLIB（ Code Generation Library），是一个代码生成的类库，可以在运行时动态的生成某个类的子类，注意， CGLIB 是通 过继承的方式做的动态代理，因此如果某个类被标记为 final，那么它是无法使用 CGLIB 做动态代理的 。<br>如何给 Spring 容器提供配置元数据<br>XML 配置文件</p><p>基于注解的配置</p><p>基于 Java 的配置</p><p>哪些是重要的 Bean 生命周期方法，能重载它们吗<br>有两个重要的 Bean 生命周期方法，第一个是 setup， 它是在容器加载 Bean 的时候被调用。第二个方法是 teardown 它是在容器卸载类的时候被调用。</p><p>Bean 标签有两个重要的属性（ init-method 和 destroy-method ）， 用它们你可以自己定制初始化和注销方法 。</p><p>Spring MVC 的控制器是不是单例模式，如果是，有什么问题，怎么解决<br>是单例模式，所以在多线程访问的时候有线程安全问题，不要用同步，会影响性能的，解决方案是在控制器里面不能写字段。</p><p>Spring 中循环注入的方式<br>举个列子我有一个类 A，A 有一个构造器里面的参数是类 B，然后类 B 里面有个构造器参数是类 C，类 C 里面有个构造器参数是类 A，就</p><p>是我们会发现其实引用循环了 A 里面有 B 的引用，B 里面有 C 的引用，C 里面又有 A 的引用。</p><p>当我们用 Spring 来加载 A 的时候 Spring 的流程是这样的（构造器注入）：</p><p>Spring 创建 A 首先去当前创建池中去查找当前 A 是否在创建，如果发明没有创建则准备其构造器需要的参数 B，然后把创建 A 的标识放入当前创建池中。</p><p>Spring 创建 B 首先去当前创建池中去查找当前 B 是否在创建，如果发现没有创建则准备其构造器需要的参数 C，然后把创建 B 的标识放入当前创建池中。</p><p>Spring 创建 C 首先去当前创建池中去查找当前 C 是否在创建，如果发现没有创建则准备其构造器需要的参数 A，然后把创建 C 的标识放入当前创建池中。</p><p>Spring 创建 C 需要的 A，这个时候会发现在当前创建池中已经有 A 的标识，A 正在创建中则抛出 BeanCurrentlyInCreationException。</p><p>构造器的循环注入是没有办法解决的，所以只能我们避免。</p><p>set 方式的循环注入：</p><p>Spring 创建 A，首先根据其无参构造器创建一个对象 A，然后提前暴露出创建出来的这个 A 对象，然后再当前的创建池中放入创建 A 的标识，然后进行 set 方法注入 B。</p><p>Spring 创建 B，首先根据其无参构造器创建一个对象 B，然后提前暴露出创建出来的这个 B 对象，然后在当前的创建池中放入创建 B 的标识，然后进行 set 方法的注入 C。</p><p>Spring 创建 C，首先根据其无参构造器创建一个对象 C，然后提前暴露出创建处理的这个 C 对象，然后在当前的创建池中放入创建 C 的标识，然后进行 set 方法的注入 A。</p><p>在第三步注入 A 的时候由于提前暴露出来了创建出来的 A 对象所以不会报 BeanCurrentlyInCreationException 的错误。</p><p>Spring Boot 相关<br>什么是 Spring Boot<br>能够简化 Spring 应用的初始搭建以及开发过程，使用特定的方式来进行配置（ properties 或 yml 文件），如：创建独立的 Spring 引用程序 main 方法运行、嵌入的 Tomcat 无需部署 war 文件、 简化 Maven 配置、自动配置 Spring 添加对应功能 starter 自动化配置等。</p><p>Spring Boot 自动配置的原理<br>Spring Boot 启动的时候会通过 @EnableAutoConfiguration 注解找到 META-INF/spring.factories 配置文件中的所有自动配置类，并对其进行加载，而这些自动配置类都是以 AutoConfiguration 结尾来命名的，它实际上就是一个 JavaConfig 形式的 Spring 容器配置类，它能通过以 Properties 结尾命名的类中取得在全局配置文件中配置的属性如：server.port，而 XxxxProperties 类是通过 @ConfigurationProperties 注解与全局配置文件中对应的属性进行绑定的。</p><p>为什么要用 Spring Boot<br>独立运行、简化配置、自动配置、代码生成和 XML 配置、应用监控、上手容易等</p><p>理解 Spring Boot 中的 Starters<br>Starters 理解为启动器，它包含了一系列可以集成到应用里面的依赖包，方便开发者快速集成 Spring 及其他技术，避免投入很多精力寻找依赖包或者代码的工作。Spring 的官方启动器都是以 spring-boot-starter- 命名的，代表了一个特定的应用类型。</p><p>Spring Boot 有哪几种读取配置的方式<br>Spring Boot 可以通过 @PropertySource、@Value、@Environment、 @ConfigurationProperties 来绑定变量。</p>]]></content>
      
      
      <categories>
          
          <category> Spring </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spring 概念 </tag>
            
            <tag> IOC </tag>
            
            <tag> AOP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>执行引擎</title>
      <link href="/2020/11/22/jvm/%E6%89%A7%E8%A1%8C%E5%BC%95%E6%93%8E/"/>
      <url>/2020/11/22/jvm/%E6%89%A7%E8%A1%8C%E5%BC%95%E6%93%8E/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="执行引擎概述"><a href="#执行引擎概述" class="headerlink" title="执行引擎概述"></a>执行引擎概述</h1><p><img src="https://img-blog.csdnimg.cn/20210312204217491.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMzNjI2OTk2,size_16,color_FFFFFF,t_70"></p><ul><li><p>执行引擎是 Java 虚拟机核心的组成部分之一。</p></li><li><p>“虚拟机” 是一个相对于 “物理机” 的概念，这两种机器都有代码执行能力，其区别是物理机的执行引擎是直接建立在处理器、缓存、指令集和操作系统层面上的，而虚拟机的执行引擎则是由软件自行实现的，因此可以不受物理条件制约地定制指令集与执行引擎的结构体系，能够执行那些不被硬件直接支持的指令集格式。</p></li><li><p>JVM 的主要任务是负责装载字节码到其内部，但字节码并不能够直接运行在操作系统之上，因为字节码指令并非等价于本地机器指令，它内部包含的仅仅只是一些能够被 JVM 所识别的字节码指令、符号表，以及其他辅助信息。</p></li><li><p>如果想要让一个 Java 程序运行起来，执行引擎（Execution Engine）的任务就是将字节码指令解释 / 编译为对应平台上的本地机器指令才可以。简单来说， JVM 中的执行引擎充当了将高级语言翻译为机器语言的译者。</p></li></ul><p><img src="https://img-blog.csdnimg.cn/20210312204606700.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMzNjI2OTk2,size_16,color_FFFFFF,t_70"></p><ul><li><p>前端编译：从 Java 程序 — 字节码文件的这个过程叫前端编译。</p></li><li><p>执行引擎这里有两种行为：一种是解释执行，一种是编译执行（这里的是后端编译）。</p></li></ul><h1 id="执行引擎工作过程"><a href="#执行引擎工作过程" class="headerlink" title="执行引擎工作过程"></a>执行引擎工作过程</h1><ol><li>执行引擎在执行的过程中究竟需要执行什么样的字节码指令完全依赖于 PC 寄存器；</li><li>每当执行完一项指令操作后，PC 寄存器就会更新下一条需要被执行的指令地址；</li><li>方法在执行的过程中，执行引擎有可能会通过存储在局部变量表中的对象引用准确定位到存储在 Java 堆区中的对象实例信息，以及通过对象头中的元数据指针定位到目标对象的类型信息；</li></ol><p><img src="https://img-blog.csdnimg.cn/20210312205144688.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMzNjI2OTk2,size_16,color_FFFFFF,t_70"></p><blockquote><p>从外观上来看，所有的 Java 虚拟机的执行引擎输入、处理、输出都是一致的：输入的是字节码二进制流，处理过程是字节码解析执行、即时编译的等效过程，输出的是执行过程。</p></blockquote><p><strong>高级语言、汇编语言、机器指令之间关系</strong></p><p><img src="https://img-blog.csdnimg.cn/2021031221034462.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMzNjI2OTk2,size_16,color_FFFFFF,t_70"></p><p><strong>字节码</strong></p><ul><li>字节码是一种中间状态（中间码）的二进制代码（文件），它比机器码更抽象，需要直译器转译后才能成为机器码；</li><li>字节码主要为了实现特定软件运行和软件环境、与硬件环境无关；</li><li>字节码的实现方式是通过编译器和虚拟机器。编译器将源码编译成字节码，特定平台上的虚拟机器将字节码转译为可以直接执行的指令；</li><li>字节码典型的应用为：Java bytecode 。</li></ul><h1 id="Java-代码编译和执行过程"><a href="#Java-代码编译和执行过程" class="headerlink" title="Java 代码编译和执行过程"></a>Java 代码编译和执行过程</h1><blockquote><p>解释执行和即时编译</p></blockquote><p>大部分的程序代码转换成物理机的目标代码或虚拟机能执行的指令集之前，都需要经过下图中的各个步骤：</p><ol><li><p>前面橙色部分是编译生成生成字节码文件的过程（ javac 编译器来完成，也就是前端编译器），和 JVM 没有关系；</p></li><li><p>后面绿色（解释执行）和蓝色（即时编译）才是 JVM 需要考虑的过程。</p></li></ol><p><img src="https://img-blog.csdnimg.cn/20210312205349621.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMzNjI2OTk2,size_16,color_FFFFFF,t_70"></p><p>javac 编译器（前端编译器）流程图如下所示：</p><p><img src="https://img-blog.csdnimg.cn/20210312205455996.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMzNjI2OTk2,size_16,color_FFFFFF,t_70"></p><p>Java 字节码的执行是由 JVM 执行引擎来完成，流程图如下所示：</p><p>用一个总图来说说 解释器和编译器：</p><h1 id="什么是解释器？什么是-JIT-编译器？"><a href="#什么是解释器？什么是-JIT-编译器？" class="headerlink" title="什么是解释器？什么是 JIT 编译器？"></a>什么是解释器？什么是 JIT 编译器？</h1><ol><li><p>解释器：当 Java 虚拟机启动时会根据预定义的规范对字节码采用逐行解释的方式执行，将每条字节码文件中的内容 “翻译” 为对应平台的本地机器指令执行。</p></li><li><p>JIT（Just In Time Compiler）编译器：就是虚拟机将源代码一次性直接编译成和本地机器平台相关的机器语言，但并不是马上执行。</p></li></ol><p>为什么 Java 是半编译半解释型语言？</p><ul><li><p>JDK1.0 时代，将 Java 语言定位为 “解释执行” 还是比较准确的。再后来，Java 也发展出可以直接生成本地代码的编译器。</p></li><li><p>现在 JVM 在执行 Java 代码的时候，通常都会将解释执行与编译执行二者结合起来进行。</p></li><li><p>JIT 编译器将字节码翻译成本地代码后，就可以做一个缓存操作，存储在方法区的 JIT 代码缓存中（执行效率更高）。</p></li></ul><h2 id="解释器"><a href="#解释器" class="headerlink" title="解释器"></a>解释器</h2><p><strong>为什么要有解释器？</strong></p><ol><li><p>JVM 设计者们的初衷仅仅只是单纯地为了满足 Java 程序实现跨平台特性。因此为了避免采用静态编译的方式由高级语言直接生成本地机器指令，从而诞生了实现解释器在运行时采用逐行解释字节码执行程序的想法（也就是产生了一个中间产品字节码）。</p></li><li><p>解释器真正意义上所承担的角色就是一个运行时 “翻译者”，将字节码文件中的内容 “翻译” 为对应平台的本地机器指令执行。</p></li><li><p>当一条字节码指令被解释执行完成后，接着再根据 PC 寄存器中记录的下一条需要被执行的字节码指令执行解释操作。</p></li></ol><p><img src="https://img-blog.csdnimg.cn/20210312210911202.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMzNjI2OTk2,size_16,color_FFFFFF,t_70"></p><p>为什么 Java 源文件不直接翻译成机器码，而是翻译成字节码文件？可能是因为直接翻译的代码是比较大的。</p><h2 id="解释器的分类"><a href="#解释器的分类" class="headerlink" title="解释器的分类"></a>解释器的分类</h2><ul><li><p>在 Java 的发展历史里，一共有两套解释执行器，即古老的字节码解释器、现在普遍使用的模板解释器。</p><ul><li>字节码解释器在执行时通过纯软件代码模拟字节码的执行，效率非常低下。</li><li>模板解释器将每一条字节码和一个模板函数相关联，模板函数中直接产生这条字节码执行时的机器码，从而很大程度上提高了解释器的性能。</li></ul></li></ul><ul><li><p>在 HotSpot VM 中，解释器主要由 Interpreter 模块和 Code 模块构成。</p><ul><li>Interpreter 模块：实现了解释器的核心功能。</li><li>Code 模块：用于管理 HotSpot VM 在运行时生成的本地机器指令。</li></ul></li></ul><h2 id="解释器的现状"><a href="#解释器的现状" class="headerlink" title="解释器的现状"></a>解释器的现状</h2><ol><li><p>由于解释器在设计和实现上非常简单，因此除了 Java 语言之外，还有许多高级语言同样也是基于解释器执行的，比如 Python、Perl、Ruby 等。但是在今天，基于解释器执行已经沦落为低效的代名词，并且时常被一些 C/C++ 程序员所调侃。</p></li><li><p>为了解决这个问题， JVM 平台支持一种叫作即时编译的技术。即时编译的目的是避免函数被解释执行，而是将整个函数体编译成为机器码，每次函数执行时，只执行编译后的机器码即可，这种方式可以使执行效率大幅度提升。</p></li><li><p>不过无论如何，基于解释器的执行模式仍然为中间语言的发展做出了不可磨灭的贡献。</p></li></ol><h2 id="JIT-编译器"><a href="#JIT-编译器" class="headerlink" title="JIT 编译器"></a>JIT 编译器</h2><p><strong>Java 代码执行的分类：</strong></p><ul><li><p>第一种是将源代码编译成字节码文件，然后在运行时通过解释器将字节码文件转为机器码执行；</p></li><li><p>第二种是编译执行（直接编译成机器码）。现代虚拟机为了提高执行效率，会使用即时编译技术（JIT，Just In Time）将方法编译成机器码后再执行。</p></li></ul><blockquote><p>HotSpot VM 是目前市面上高性能虚拟机的代表作之一。它采用解释器与即时编译器并存的架构。在 Java 虚拟机运行时，解释器和即时编译器能够相互协作，各自取长补短，尽力去选择最合适的方式来权衡编译本地代码的时间和直接解释执行代码的时间。</p></blockquote><h2 id="为什么还需要解释器呢？"><a href="#为什么还需要解释器呢？" class="headerlink" title="为什么还需要解释器呢？"></a>为什么还需要解释器呢？</h2><ul><li><p>当程序启动后，解释器可以马上发挥作用，响应速度快，省去编译的时间，立即执行。</p></li><li><p>编译器要想发挥作用，把代码编译成本地代码，需要一定的执行时间，但编译为本地代码后，执行效率高。</p></li><li><p>尽管如 JRockit VM 中程序的执行性能会非常高效，但程序在启动时必然需要花费更长的时间来进行编译。对于服务端应用来说，启动时间并非是关注重点，但对于那些看中启动时间的应用场景而言，或许就需要采用解释器与即时编译器并存的架构来换取一个平衡点。</p></li><li><p>当虚拟机启动的时候，解释器可以首先发挥作用，而不必等待即时编译器全部编译完成再执行，这样可以省去许多不必要的编译时间。随着程序运行时间的推移，即时编译器逐渐发挥作用，根据热点探测功能，将有价值的字节码编译为本地机器指令，以换取更高的程序执行效率。</p></li><li><p>同时，解释执行在编译器进行激进优化不成立的时候，作为编译器的 “逃生门”（后备方案）。</p></li></ul><h2 id="JIT-编译器相关概念"><a href="#JIT-编译器相关概念" class="headerlink" title="JIT 编译器相关概念"></a>JIT 编译器相关概念</h2><ol><li><p>Java 语言的 “编译期” 其实是一段 “不确定” 的操作过程，因为它可能是指一个前端编译器（其实叫 “编译器的前端” 更准确一些）把 .java 文件转变成 .class 文件的过程；</p></li><li><p>也可能是指虚拟机的后端运行期编译器（ JIT 编译器，Just In Time Compiler）把字节码转变成机器码的过程；</p></li><li><p>还可能是指使用静态提前编译器（ AOT 编译器，Ahead of Time Compiler）直接把 .java 文件编译成本地机器代码的过程。（可能是后续发展的趋势）</p></li></ol><p><strong>典型的编译器：</strong></p><ul><li><p>前端编译器：Sun 的 javac 、Eclipse JDT 中的增量式编译器（ECJ）。</p></li><li><p>JIT 编译器：HotSpot VM 的 C1、C2 编译器。</p></li><li><p>AOT 编译器：GNU Compiler for the Java（GCJ）、Excelsior JET。</p></li></ul><p><strong>热点代码及探测方式</strong></p><ol><li><p>当然是否需要启动 JIT 编译器将字节码直接编译为对应平台的本地机器指令，则需要根据代码被调用执行的频率而定。</p></li><li><p>关于那些需要被编译为本地代码的字节码，也被称之为 “热点代码”，JIT 编译器在运行时会针对那些频繁被调用的 “热点代码” 做出深度优化，将其直接编译为对应平台的本地机器指令，以此提升 Java 程序的执行性能。</p></li><li><p>一个被多次调用的方法，或者是一个方法体内部循环次数较多的循环体都可以被称之为 “热点代码”，因此都可以通过 JIT 编译器编译为本地机器指令。由于这种编译方式发生在方法的执行过程中，因此也被称之为栈上替换，或简称为 OSR (On StackReplacement) 编译。</p></li><li><p>一个方法究竟要被调用多少次，或者一个循环体究竟需要执行多少次循环才可以达到这个标准？必然需要一个明确的阈值，JIT 编译器才会将这些 “热点代码” 编译为本地机器指令执行。这里主要依靠热点探测功能。</p></li><li><p>目前 HotSpot VM 所采用的热点探测方式是基于计数器的热点探测。</p></li><li><p>采用基于计数器的热点探测，HotSpot VM 将会为每一个方法都建立 2 个不同类型的计数器，分别为方法调用计数器（Invocation Counter）和回边计数器（Back Edge Counter）。</p></li></ol><ul><li><p>方法调用计数器用于统计方法的调用次数。</p></li><li><p>回边计数器则用于统计循环体执行的循环次数。</p></li></ul><p><strong>方法调用计数器</strong></p><ul><li><p>这个计数器就用于统计方法被调用的次数，它的默认阀值在 Client 模式下是 1500 次，在 Server 模式下是 10000 次。超过这个阈值，就会触发 JIT 编译。</p></li><li><p>这个阀值可以通过虚拟机参数 -XX:CompileThreshold 来人为设定。</p></li><li><p>当一个方法被调用时，会先检查该方法是否存在被 JIT 编译过的版本，</p><ul><li>如果存在，则优先使用编译后的本地代码来执行；</li><li>如果不存在已被编译过的版本，则将此方法的调用计数器值加 1，然后判断方法调用计数器与回边计数器值之和是否超过方法调用计数器的阀值；</li><li>如果已超过阈值，那么将会向即时编译器提交一个该方法的代码编译请求；</li><li>如果未超过阈值，则使用解释器对字节码文件解释执行。</li></ul></li></ul><p><img src="https://img-blog.csdnimg.cn/20210312211906839.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMzNjI2OTk2,size_16,color_FFFFFF,t_70"></p><p><strong>热度衰减</strong></p><ol><li><p>如果不做任何设置，方法调用计数器统计的并不是方法被调用的绝对次数，而是一个相对的执行频率，即一段时间之内方法被调用的次数。当超过一定的时间限度，如果方法的调用次数仍然不足以让它提交给即时编译器编译，那这个方法的调用计数器就会被减少一半，这个过程称为方法调用计数器热度的衰减（Counter Decay），而这段时间就称为此方法统计的半衰周期（Counter Half LifeTime）（半衰周期是化学中的概念，比如出土的文物通过查看 C60 来获得文物的年龄）。</p></li><li><p>进行热度衰减的动作是在虚拟机进行垃圾收集时顺便进行的，可以使用虚拟机参数 -XX:-UseCounterDecay 来关闭热度衰减，让方法计数器统计方法调用的绝对次数，这样的话，只要系统运行时间足够长，绝大部分方法都会被编译成本地代码。</p></li><li><p>另外，可以使用 -XX:CounterHalfLifeTime 参数设置半衰周期的时间，单位是秒。</p></li></ol><p><strong>回边计数器</strong></p><blockquote><p>它的作用是统计一个方法中循环体代码执行的次数，在字节码中遇到控制流向后跳转的指令称为 “回边”（Back Edge）。显然，建立回边计数器统计的目的就是为了触发 OSR 编译。</p></blockquote><p><img src="https://img-blog.csdnimg.cn/20210312211955156.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMzNjI2OTk2,size_16,color_FFFFFF,t_70"></p><p><em>HotSpot VM 可以设置程序执行方法</em></p><p>缺省情况下 HotSpot VM 是采用解释器与即时编译器并存的架构，当然开发人员可以根据具体的应用场景，通过命令显式地为 Java 虚拟机指定在运行时到底是完全采用解释器执行，还是完全采用即时编译器执行。如下所示：</p><ol><li><p>-Xint：完全采用解释器模式执行程序；</p></li><li><p>-Xcomp：完全采用即时编译器模式执行程序。如果即时编译出现问题，解释器会介入执行；</p></li><li><p>-Xmixed：采用解释器 + 即时编译器的混合模式共同执行程序。</p></li></ol><p><img src="https://img-blog.csdnimg.cn/20210312212100230.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMzNjI2OTk2,size_16,color_FFFFFF,t_70"></p><pre><code>/** * 测试解释器模式和JIT编译模式 *  -Xint  : 花费的时间为：4585ms *  -Xcomp : 花费的时间为：871ms *  -Xmixed : 花费的时间为：867ms */public class IntCompTest &#123;    public static void main(String[] args) &#123;        long start = System.currentTimeMillis();        testPrimeNumber(1000000);        long end = System.currentTimeMillis();        System.out.println(&quot;花费的时间为：&quot; + (end - start));    &#125;    public static void testPrimeNumber(int count)&#123;        for (int i = 0; i &lt; count; i++) &#123;            //计算100以内的质数            label:for(int j = 2;j &lt;= 100;j++)&#123;                for(int k = 2;k &lt;= Math.sqrt(j);k++)&#123;                    if(j % k == 0)&#123;                        continue label;                    &#125;                &#125;                //System.out.println(j);            &#125;        &#125;    &#125;&#125;</code></pre><blockquote><p>结论：只用解释器执行是真的慢！</p></blockquote><h2 id="HotSpot-VM-JIT-分类"><a href="#HotSpot-VM-JIT-分类" class="headerlink" title="HotSpot VM JIT 分类"></a>HotSpot VM JIT 分类</h2><p>在 HotSpot VM 中内嵌有两个 JIT 编译器，分别为 Client Compiler 和 Server Compiler ，但大多数情况下我们简称为 C1 编译器 和 C2 编译器。开发人员可以通过如下命令显式指定 Java 虚拟机在运行时到底使用哪一种即时编译器，如下所示：</p><ol><li><p>-client：指定 Java 虚拟机运行在 Client 模式下，并使用 C1 编译器。C1 编译器会对字节码进行简单和可靠的优化，耗时短，以达到更快的编译速度。</p></li><li><p>-server：指定 Java 虚拟机运行在 server 模式下，并使用 C2 编译器。C2 进行耗时较长的优化，以及激进优化，但优化的代码执行效率更高。（使用 C++ 编写）</p></li></ol><p><strong>C1 和 C2 编译器不同的优化策略</strong></p><ol><li>在不同的编译器上有不同的优化策略，C1 编译器上主要有方法内联，去虚拟化、冗余消除。</li></ol><ul><li>方法内联：将引用的函数代码编译到引用点处，这样可以减少栈帧的生成，减少参数传递以及跳转过程。</li><li>去虚拟化：对唯一的实现类进行内联。</li><li>冗余消除：在运行期间把一些不会执行的代码折叠掉。</li></ul><ol start="2"><li>C2 的优化主要是在全局层面，逃逸分析是优化的基础。基于逃逸分析在 C2 上有如下几种优化：</li></ol><ul><li>标量替换：用标量值代替聚合对象的属性值。</li><li>栈上分配：对于未逃逸的对象分配对象在栈而不是堆。</li><li>同步消除：清除同步操作，通常指 synchronized。</li></ul><blockquote><p>也就是说之前的逃逸分析，只有在 C2（ server 模式下）才会触发。那是否说明 C1 就用不了了</p></blockquote><p><strong>分层编译策略</strong></p><ol><li><p>分层编译（Tiered Compilation）策略：程序解释执行（不开启性能监控）可以触发 C1 编译，将字节码编译成机器码，可以进行简单优化，也可以加上性能监控，C2 编译会根据性能监控信息进行激进优化。</p></li><li><p>不过在 Java7 版本之后，一旦开发人员在程序中显式指定命令 “-server” 时，默认将会开启分层编译策略，由 C1 编译器和 C2 编译器相互协作共同来执行编译任务。</p></li></ol><blockquote><p>一般来讲，JIT 编译出来的机器码性能比解释器解释执行的性能高；C2 编译器启动时长比 C1 慢，系统稳定执行以后，C2 编译器执行速度远快于 C1 编译器。</p></blockquote><p><strong>Graal 编译器</strong></p><ol><li><p>自 JDK10 起，HotSpot 又加入了一个全新的即时编译器：Graal 编译器；</p></li><li><p>编译效果短短几年时间就追平了 C2 编译器，未来可期（对应还出现了 Graal 虚拟机，是有可能替代 Hotspot 的虚拟机的）；</p></li><li><p>目前，带着实验状态标签，需要使用开关参数去激活才能使用。</p></li></ol><pre><code>-XX:+UnlockExperimentalvMOptions -XX:+UseJVMCICompiler</code></pre><p><strong>AOT 编译器</strong></p><ol><li><p>JDK9 引入了 AOT 编译器（静态提前编译器，Ahead of Time Compiler）；</p></li><li><p>Java 9 引入了实验性 AOT 编译工具 jaotc 。它借助了 Graal 编译器，将所输入的 Java 类文件转换为机器码，并存放至生成的动态共享库之中。</p></li><li><p>所谓 AOT 编译，是与即时编译相对立的一个概念。即时编译指的是在程序的运行过程中，将字节码转换为可在硬件上直接运行的机器码，并部署至托管环境中的过程。而 AOT 编译指的则是，在程序运行之前，便将字节码转换为机器码的过程。</p></li></ol><pre><code>.java -&gt; .class -&gt; (使用jaotc) -&gt; .so</code></pre><h2 id="AOT-编译器编译器的优缺点："><a href="#AOT-编译器编译器的优缺点：" class="headerlink" title="AOT 编译器编译器的优缺点："></a>AOT 编译器编译器的优缺点：</h2><p><strong>最大的好处：</strong></p><ol><li>Java 虚拟机加载已经预编译成二进制库，可以直接执行；</li><li>不必等待即时编译器的预热，减少 Java 应用给人带来 “第一次运行慢” 的不良体验。</li></ol><p><strong>缺点：</strong></p><ol><li>破坏了 Java “一次编译，到处运行”，必须为每个不同的硬件、OS 编译对应的发行包；</li><li>降低了 Java 链接过程的动态性，加载的代码在编译器就必须全部已知；</li><li>还需要继续优化中，最初只支持 Linux X64 java base 。</li></ol>]]></content>
      
      
      <categories>
          
          <category> JVM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 执行引擎 </tag>
            
            <tag> 解释器 </tag>
            
            <tag> 编译器 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>垃圾回收算法</title>
      <link href="/2020/11/15/jvm/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%AE%97%E6%B3%95/"/>
      <url>/2020/11/15/jvm/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%AE%97%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>垃圾收集的三个经典问题：</p><blockquote><p>1.哪些内存需要回收？（对象是否可以被回收的两种经典算法: 引用计数法和可达性分析算法）<br>2.什么时候回收？（堆的新生代、老年代、永久代的垃圾回收时机，MinorGC和FullGC）<br>3.如何回收？（三种经典垃圾回收算法(标记清除算法、复制算法、标记整理算法)及分代收集算法和七种垃圾收集器)）</p></blockquote><p><strong>本篇文章主要针对上述第三个问题详细介绍下垃圾回收中的相关算法。</strong></p><h1 id="标记阶段：引用计数算法"><a href="#标记阶段：引用计数算法" class="headerlink" title="标记阶段：引用计数算法"></a>标记阶段：引用计数算法</h1><h2 id="标记阶段的目的"><a href="#标记阶段的目的" class="headerlink" title="标记阶段的目的"></a>标记阶段的目的</h2><p><strong>垃圾标记阶段：主要是为了判断对象是否存活</strong></p><ul><li>在堆里存放着几乎所有的 Java 对象实例，在 GC 执行垃圾回收之前，首先需要区分出内存中哪些是存活对象，哪些是已经死亡的对象。只有被标记为己经死亡的对象，GC 才会在执行垃圾回收时，释放掉其所占用的内存空间，因此这个过程我们可以称为垃圾标记阶段。</li><li>那么在 JVM 中究竟是如何标记一个死亡对象呢？简单来说，当一个对象已经不再被任何的存活对象继续引用时，就可以宣判为已经死亡。</li><li>判断对象存活一般有两种方式：引用计数算法和可达性分析算法。</li></ul><h1 id="引用计数算法"><a href="#引用计数算法" class="headerlink" title="引用计数算法"></a>引用计数算法</h1><ol><li>引用计数算法（Reference Counting）比较简单，对每个对象保存一个整型的引用计数器属性，用于记录对象被引用的情况。</li><li>对于一个对象 A，只要有任何一个对象引用了 A，则 A 的引用计数器就加 1；当引用失效时，引用计数器就减 1。只要对象 A 的引用计数器的值为 0，即表示对象 A 不可能再被使用，可进行回收。</li><li>优点：实现简单，垃圾对象便于辨识；判定效率高，回收没有延迟性。</li><li>缺点：</li></ol><ul><li>它需要单独的字段存储计数器，这样的做法增加了存储空间的开销。 - 每次赋值都需要更新计数器，伴随着加法和减法操作，这增加了时间开销。 - 引用计数器有一个严重的问题，即无法处理循环引用的情况。这是一条致命缺陷，导致在 Java 的垃圾回收器中没有使用这类算法。</li></ul><p><strong>循环引用</strong></p><p>当 p 的指针断开的时候，内部的引用形成一个循环，这就是循环引用，从而造成内存泄漏。</p><p><img src="https://img-blog.csdnimg.cn/20210331173116629.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMzNjI2OTk2,size_16,color_FFFFFF,t_70" alt="循环引用"></p><p><strong>举例说明：证明 java 使用的不是引用计数算法</strong></p><pre><code>/** *  *  * 证明：java使用的不是引用计数算法 */public class RefCountGC &#123;    //这个成员属性唯一的作用就是占用一点内存    private byte[] bigSize = new byte[5 * 1024 * 1024];//5MB    Object reference = null;    public static void main(String[] args) &#123;        RefCountGC obj1 = new RefCountGC();        RefCountGC obj2 = new RefCountGC();        obj1.reference = obj2;        obj2.reference = obj1;        obj1 = null;        obj2 = null;        //显式的执行垃圾回收行为        //这里发生GC，obj1和obj2能否被回收？        System.gc();    &#125;&#125;</code></pre><p>运行结果：</p><pre><code class="bash">[GC (System.gc()) [PSYoungGen: 15490K-&gt;808K(76288K)] 15490K-&gt;816K(251392K), 0.0061980 secs] [Times: user=0.00 sys=0.00, real=0.36 secs] [Full GC (System.gc()) [PSYoungGen: 808K-&gt;0K(76288K)] [ParOldGen: 8K-&gt;672K(175104K)] 816K-&gt;672K(251392K), [Metaspace: 3479K-&gt;3479K(1056768K)], 0.0045983 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] Heap PSYoungGen      total 76288K, used 655K [0x000000076b500000, 0x0000000770a00000, 0x00000007c0000000)  eden space 65536K, 1% used [0x000000076b500000,0x000000076b5a3ee8,0x000000076f500000)  from space 10752K, 0% used [0x000000076f500000,0x000000076f500000,0x000000076ff80000)  to   space 10752K, 0% used [0x000000076ff80000,0x000000076ff80000,0x0000000770a00000) ParOldGen       total 175104K, used 672K [0x00000006c1e00000, 0x00000006cc900000, 0x000000076b500000)  object space 175104K, 0% used [0x00000006c1e00000,0x00000006c1ea8070,0x00000006cc900000) Metaspace       used 3486K, capacity 4496K, committed 4864K, reserved 1056768K  class space    used 385K, capacity 388K, committed 512K, reserved 1048576K</code></pre><p>能够看到，上述进行了 GC 收集的行为，将上述的新生代中的两个对象都进行回收了。</p><pre><code class="bash">PSYoungGen: 15490K-&gt;808K(76288K)] 15490K-&gt;816K(251392K)</code></pre><p>如果使用引用计数算法，那么这两个对象将会无法回收。而现在两个对象被回收了，说明 Java 使用的不是引用计数算法来进行标记的。</p><p><img src="https://img-blog.csdnimg.cn/20210331210925958.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMzNjI2OTk2,size_16,color_FFFFFF,t_70" alt="引用计数算法"></p><p>小结</p><ul><li>引用计数算法，是很多语言的资源回收选择，例如因人工智能而更加火热的 Python，它更是同时支持引用计数和垃圾收集机制。</li><li>具体哪种最优是要看场景的，业界有大规模实践中仅保留引用计数机制，以提高吞吐量的尝试。<br>Java 并没有选择引用计数，是因为其存在一个基本的难题，也就是很难处理循环引用关系。</li></ul><p>Python 如何解决循环引用？</p><ul><li>手动解除：很好理解，就是在合适的时机，解除引用关系。</li><li>使用弱引用 weakref，weakref 是 Python 提供的标准库，旨在解决循环引用。</li></ul><h1 id="标记阶段：可达性分析算法"><a href="#标记阶段：可达性分析算法" class="headerlink" title="标记阶段：可达性分析算法"></a>标记阶段：可达性分析算法</h1><p><strong>可达性分析算法：也可以称为根搜索算法、追踪性垃圾收集.</strong></p><ol><li><p>相对于引用计数算法而言，可达性分析算法不仅同样具备实现简单和执行高效等特点，更重要的是该算法可以有效地解决在引用计数算法中循环引用的问题，防止内存泄漏的发生。</p></li><li><p>相较于引用计数算法，这里的可达性分析就是 Java、C# 选择的。这种类型的垃圾收集通常也叫作追踪性垃圾收集（Tracing Garbage Collection）。</p></li></ol><h2 id="可达性分析实现思路"><a href="#可达性分析实现思路" class="headerlink" title="可达性分析实现思路"></a>可达性分析实现思路</h2><ul><li>所谓 ”GCRoots” 根集合就是一组必须活跃的引用。</li><li>其基本思路如下：</li></ul><ol><li>可达性分析算法是以根对象集合（GCRoots）为起始点，按照从上至下的方式搜索被根对象集合所连接的目标对象是否可达；</li><li>使用可达性分析算法后，内存中的存活对象都会被根对象集合直接或间接连接着，搜索所走过的路径称为引用链（Reference Chain）；</li><li>如果目标对象没有任何引用链相连，则是不可达的，就意味着该对象己经死亡，可以标记为垃圾对象；</li><li>在可达性分析算法中，只有能够被根对象集合直接或者间接连接的对象才是存活对象。</li></ol><h2 id="GC-Roots-可以是哪些元素？"><a href="#GC-Roots-可以是哪些元素？" class="headerlink" title="GC Roots 可以是哪些元素？"></a>GC Roots 可以是哪些元素？</h2><ol><li>虚拟机栈中引用的对象，比如：各个线程被调用的方法中使用到的参数、局部变量等；</li><li>本地方法栈内 JNI（通常说的本地方法）引用的对象；</li><li>方法区中类静态属性引用的对象，比如：Java 类的引用类型静态变量；</li><li>方法区中常量引用的对象，比如：字符串常量池（StringTable）里的引用；</li><li>所有被同步锁 synchronized 持有的对象；</li><li>Java 虚拟机内部的引用，基本数据类型对应的 Class 对象，一些常驻的异常对象（如：NullPointerException、OutofMemoryError），系统类加载器；</li><li>反映 java 虚拟机内部情况的 JMXBean、JVMTI 中注册的回调、本地代码缓存等。</li></ol><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul><li>除了堆空间的周边，比如：虚拟机栈、本地方法栈、方法区、字符串常量池等地方对堆空间进行引用的，都可以作为 GC Roots 进行可达性分析；</li><li>除了这些固定的 GC Roots 集合以外，根据用户所选用的垃圾收集器以及当前回收的内存区域不同，还可以有其他对象 “临时性” 地加入，共同构成完整 GC Roots 集合。比如：分代收集和局部回收（PartialGC）；</li><li>如果只针对 Java 堆中的某一块区域进行垃圾回收（比如：典型的只针对新生代），必须考虑到内存区域是虚拟机自己的实现细节，更不是孤立封闭的，这个区域的对象完全有可能被其他区域的对象所引用，这时候就需要一并将关联的区域对象也加入 GC Roots 集合中去考虑，才能保证可达性分析的准确性。</li></ul><p>小技巧</p><blockquote><p>由于 Root 采用栈方式存放变量和指针，所以如果一个指针，它保存了堆内存里面的对象，但是自己又不存放在堆内存里面，那它就是一个 Root 。</p></blockquote><p>注意</p><ol><li>如果要使用可达性分析算法来判断内存是否可回收，那么分析工作必须在一个能保障一致性的快照中进行。这点不满足的话分析结果的准确性就无法保证。</li><li>这点也是导致 GC 进行时必须 “Stop The World” 的一个重要原因。即使是号称（几乎）不会发生停顿的 CMS 收集器中，枚举根节点时也是必须要停顿的。<h1 id="对象的-finalization-机制"><a href="#对象的-finalization-机制" class="headerlink" title="对象的 finalization 机制"></a>对象的 finalization 机制</h1></li></ol><h2 id="finalize-方法机制"><a href="#finalize-方法机制" class="headerlink" title="finalize () 方法机制"></a>finalize () 方法机制</h2><p><strong>对象销毁前的回调函数：finalize ()</strong></p><ol><li>Java 语言提供了对象终止（finalization）机制来允许开发人员提供对象被销毁之前的自定义处理逻辑。</li><li>当垃圾回收器发现没有引用指向一个对象，即：垃圾回收此对象之前，总会先调用这个对象的 finalize () 方法。</li><li>finalize () 方法允许在子类中被重写，用于在对象被回收时进行资源释放。通常在这个方法中进行一些资源释放和清理的工作，比如关闭文件、套接字和数据库连接等。</li></ol><p>Object 类中 finalize () 源码：</p><pre><code class="bash">// 等待被重写protected void finalize() throws Throwable &#123; &#125;</code></pre><ol><li>永远不要主动调用某个对象的 finalize () 方法，应该交给垃圾回收机制调用。理由包括下面三点：</li></ol><ul><li>在 finalize () 时可能会导致对象复活； - finalize () 方法的执行时间是没有保障的，它完全由 GC 线程决定，极端情况下，若不发生 GC ，则 finalize () 方法将没有执行机会； - 一个糟糕的 finalize () 会严重影响 GC 的性能。比如 finalize 是个死循环。</li></ul><ol start="2"><li>从功能上来说，finalize () 方法与 C++ 中的析构函数比较相似，但是 Java 采用的是基于垃圾回收器的自动内存管理机制，所以 finalize () 方法在本质上不同于 C++ 中的析构函数。</li><li>finalize () 方法对应了一个 finalize 线程，因为优先级比较低，即使主动调用该方法，也不会因此就直接进行回收。</li></ol><h2 id="生存还是死亡？"><a href="#生存还是死亡？" class="headerlink" title="生存还是死亡？"></a>生存还是死亡？</h2><p>由于 finalize () 方法的存在，虚拟机中的对象一般处于三种可能的状态。</p><ol><li>如果从所有的根节点都无法访问到某个对象，说明对象己经不再使用了。一般来说，此对象需要被回收。但事实上，也并非是 “非死不可” 的，这时候它们暂时处于 “缓刑” 阶段。一个无法触及的对象有可能在某一个条件下 “复活” 自己，如果这样，那么对它立即进行回收就是不合理的。为此，定义虚拟机中的对象可能的三种状态。如下：</li></ol><ul><li>可触及的：从根节点开始，可以到达这个对象。</li><li>可复活的：对象的所有引用都被释放，但是对象有可能在 finalize () 中复活。</li><li>不可触及的：对象的 finalize () 被调用，并且没有复活，那么就会进入不可触及状态。不可触及的对象不可能被复活，<strong>因为 finalize () 只会被调用一次。</strong></li></ul><ol start="2"><li>以上 3 种状态中，是由于 finalize () 方法的存在进行的区分。只有在对象不可触及时才可以被回收。</li></ol><h2 id="具体过程"><a href="#具体过程" class="headerlink" title="具体过程"></a>具体过程</h2><p>判定一个对象 objA 是否可回收，至少要经历两次标记过程：</p><ol><li>如果对象 objA 到 GC Roots 没有引用链，则进行第一次标记。</li><li>进行筛选，判断此对象是否有必要执行 finalize () 方法</li></ol><ul><li><p>如果对象 objA 没有重写 finalize () 方法，或者 finalize () 方法已经被虚拟机调用过，则虚拟机视为 “没有必要执行”，objA 被判定为不可触及的。</p></li><li><p>如果对象 objA 重写了 finalize () 方法，且还未执行过，那么 objA 会被插入到 F-Queue 队列中，由一个虚拟机自动<br>创建的、低优先级的 Finalizer 线程触发其 finalize () 方法执行。</p></li><li><p>finalize () 方法是对象逃脱死亡的最后机会，稍后 GC 会对 F-Queue 队列中的对象进行第二次标记。如果 objA 在 finalize () 方法中与引用链上的任何一个对象建立了联系，那么在第二次标记时，objA 会被移出 “即将回收” 集合。之后，对象会再次出现没有引用存在的情况。在这个情况下，finalize () 方法不会被再次调用，对象会直接变成不可触及的状态，也就是说，一个对象的 finalize () 方法只会被调用一次。<br>通过 JVisual VM 查看 Finalizer 线程</p></li></ul><p><strong>通过 JVisual VM 查看 Finalizer 线程</strong></p><p><img src="https://img-blog.csdnimg.cn/20210401094021836.png" alt="JVisual VM 查看 Finalizer 线程"></p><p><strong>代码演示 finalize () 方法可复活对象</strong></p><p>重写 CanReliveObj 类的 finalize () 方法，在调用其 finalize () 方法时，将 obj 指向当前类对象 this 。</p><pre><code>/** * 测试Object类中finalize()方法，即对象的finalization机制。 * */public class CanReliveObj &#123;    public static CanReliveObj obj;//类变量，属于 GC Root    //此方法只能被调用一次    @Override    protected void finalize() throws Throwable &#123;        super.finalize();        System.out.println(&quot;调用当前类重写的finalize()方法&quot;);        obj = this;//当前待回收的对象在finalize()方法中与引用链上的一个对象obj建立了联系    &#125;    public static void main(String[] args) &#123;        try &#123;            obj = new CanReliveObj();            // 对象第一次成功拯救自己            obj = null;            System.gc();//调用垃圾回收器            System.out.println(&quot;第1次 gc&quot;);            // 因为Finalizer线程优先级很低，暂停2秒，以等待它            Thread.sleep(2000);            if (obj == null) &#123;                System.out.println(&quot;obj is dead&quot;);            &#125; else &#123;                System.out.println(&quot;obj is still alive&quot;);            &#125;            System.out.println(&quot;第2次 gc&quot;);            // 下面这段代码与上面的完全相同，但是这次自救却失败了            obj = null;            System.gc();            // 因为Finalizer线程优先级很低，暂停2秒，以等待它            Thread.sleep(2000);            if (obj == null) &#123;                System.out.println(&quot;obj is dead&quot;);            &#125; else &#123;                System.out.println(&quot;obj is still alive&quot;);            &#125;        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;    &#125;&#125;</code></pre><p><strong>如果注释掉 finalize () 方法</strong></p><pre><code class="bash">//此方法只能被调用一次   @Override   protected void finalize() throws Throwable &#123;       super.finalize();       System.out.println(&quot;调用当前类重写的finalize()方法&quot;);       obj = this;//当前待回收的对象在finalize()方法中与引用链上的一个对象obj建立了联系   &#125;</code></pre><p>输出结果：</p><pre><code class="bash">第1次 gcobj is dead第2次 gcobj is dead放开 finalize () 方法</code></pre><p>输出结果：</p><pre><code class="bash">第1次 gc调用当前类重写的finalize()方法obj is still alive第2次 gcobj is dead</code></pre><p>第一次自救成功，但由于 finalize () 方法只会执行一次，所以第二次自救失败。</p><h1 id="JProfiler-的-GC-Roots-溯源"><a href="#JProfiler-的-GC-Roots-溯源" class="headerlink" title="JProfiler 的 GC Roots 溯源"></a>JProfiler 的 GC Roots 溯源</h1><p>在实际开发中，很少会查看所有的 GC Roots 。一般都是查看某一个或几个对象的 GC Root 是哪个，这个过程叫 GC Roots 溯源。</p><p>使用 JProfiler 进行 GC Roots 溯源示例代码：</p><pre><code class="bash">public class GCRootsTest &#123;    public static void main(String[] args) &#123;        List&lt;Object&gt; numList = new ArrayList&lt;&gt;();        Date birth = new Date();        for (int i = 0; i &lt; 100; i++) &#123;            numList.add(String.valueOf(i));            try &#123;                Thread.sleep(10);            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;        &#125;        System.out.println(&quot;数据添加完毕，请操作：&quot;);        new Scanner(System.in).next();        numList = null;        birth = null;        System.out.println(&quot;numList、birth已置空，请操作：&quot;);        new Scanner(System.in).next();        System.out.println(&quot;结束&quot;);    &#125;&#125;</code></pre><p>上述代码就是不断的创建一个 1M 小字节数组，然后让内存溢出。同时限制一下内存大小，使用 HeapDumpOnOutOfMemoryError 将出错时候的 dump 文件输出。</p><pre><code class="bash">-Xms8m -Xmx8m -XX:HeapDumpOnOutOfMemoryError</code></pre><p>将生成的 dump 文件打开，然后点击 Biggest Objects 就能够看到超大对象。</p><p><img src="https://img-blog.csdnimg.cn/20210402110752330.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMzNjI2OTk2,size_16,color_FFFFFF,t_70" alt="大对象oom"></p><p>之后通过线程，还能够定位到哪里出现 OOM 。<br><img src="https://img-blog.csdnimg.cn/20210402110844972.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMzNjI2OTk2,size_16,color_FFFFFF,t_70" alt="大对象oom"></p><h1 id="清除阶段：标记-清除算法"><a href="#清除阶段：标记-清除算法" class="headerlink" title="清除阶段：标记 - 清除算法"></a>清除阶段：标记 - 清除算法</h1><p><strong>垃圾清除阶段</strong></p><p>当成功区分出内存中存活对象和死亡对象后，GC 接下来的任务就是执行垃圾回收，释放掉无用对象所占用的内存空间，以便有足够的可用内存空间为新对象分配内存。目前在 JVM 中比较常见的三种垃圾收集算法是</p><ul><li>标记 - 清除算法（Mark-Sweep）</li><li>复制算法（Copying）</li><li>标记 - 压缩算法（Mark-Compact）</li></ul><p><strong>背景</strong></p><p>标记 - 清除算法（Mark-Sweep）是一种非常基础和常见的垃圾收集算法，该算法被 J.McCarthy 等人在 1960 年提出并并应用于 Lisp 语言。</p><h2 id="执行过程"><a href="#执行过程" class="headerlink" title="执行过程"></a>执行过程</h2><p>当堆中的有效内存空间（available memory）被耗尽的时候，就会停止整个程序（也被称为 stop the world），然后进行两项工作，第一项则是标记，第二项则是清除。</p><ol><li><p>标记：Collector 从引用根节点开始遍历，标记所有被引用的对象。一般是在对象的 Header 中记录为可达对象。注意：标记的是被引用的对象，也就是可达对象，并非标记的是即将被清除的垃圾对象。</p></li><li><p>清除：Collector 对堆内存从头到尾进行线性的遍历，如果发现某个对象在其 Header 中没有标记为可达对象，则将其回收。</p></li></ol><p><img src="https://img-blog.csdnimg.cn/20210401100222678.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMzNjI2OTk2,size_16,color_FFFFFF,t_70" alt="标记 - 清除算法"></p><h2 id="什么是清除？"><a href="#什么是清除？" class="headerlink" title="什么是清除？"></a>什么是清除？</h2><p>这里所谓的清除并不是真的置空，而是把需要清除的对象地址保存在空闲的地址列表里。下次有新对象需要加载时，判断垃圾的位置空间是否够，如果够，就存放覆盖原有的地址。</p><p>关于空闲列表在为对象分配内存的时候提过：</p><ol><li>如果内存规整：采用指针碰撞的方式进行内存分配。</li><li>如果内存不规整：虚拟机需要维护一个列表，空闲列表分配。</li></ol><h2 id="标记-清除算法的缺点"><a href="#标记-清除算法的缺点" class="headerlink" title="标记 - 清除算法的缺点"></a>标记 - 清除算法的缺点</h2><ul><li>标记清除算法的效率不算高；</li><li>在进行 GC 的时候，需要停止整个应用程序，用户体验较差；</li><li>这种方式清理出来的空闲内存是不连续的，产生内碎片，需要维护一个空闲列表。</li></ul><h1 id="清除阶段：复制算法"><a href="#清除阶段：复制算法" class="headerlink" title="清除阶段：复制算法"></a>清除阶段：复制算法</h1><p><strong>背景</strong></p><p>为了解决标记 - 清除算法在垃圾收集效率方面的缺陷，M.L.Minsky 于 1963 年发表了著名的论文， “使用双存储区的 Lisp 语言垃圾收集器 CA LISP Garbage Collector Algorithm Using Serial Secondary Storage）”。M.L.Minsky 在该论文中描述的算法被人们称为复制（Copying）算法，它也被 M.L.Minsky 本人成功地引入到了 Lisp 语言的一个实现版本中。</p><p><strong>核心思想</strong></p><ul><li>将活着的内存空间分为两块，每次只使用其中一块，在垃圾回收时将正在使用的内存中的存活对象复制到未被使用的内存块中，之后清除正在使用的内存块中的所有对象，交换两个内存的角色，最后完成垃圾回收。</li></ul><p><img src="https://img-blog.csdnimg.cn/20210401100733620.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMzNjI2OTk2,size_16,color_FFFFFF,t_70"></p><ul><li>把可达的对象，直接复制到另外一个区域中复制完成后，A 区就没有用了，里面的对象可以直接清除掉，新生代里面就用到了复制算法，Eden 区和 S0 区存活对象整体复制到 S1 区。</li></ul><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/20210401100906971.png"></p><h2 id="复制算法的优缺点"><a href="#复制算法的优缺点" class="headerlink" title="复制算法的优缺点"></a>复制算法的优缺点</h2><p><strong>优点</strong></p><ol><li>没有标记和清除过程，实现简单，运行高效；</li><li>复制过去以后保证空间的连续性，不会出现 “碎片” 问题。</li></ol><p><strong>缺点</strong></p><ol><li>此算法的缺点也是很明显的，就是需要两倍的内存空间；</li><li>对于 G1 这种分拆成大量 region 的 GC，复制而不是移动，意味着 GC 需要维护 region 之间对象引用关系，不管是内存占用或者时间开销也不小。</li></ol><p><strong>复制算法的应用场景</strong></p><ol><li>如果系统中的垃圾对象很多，复制算法需要复制的存活对象数量并不会太大，效率较高；</li><li>老年代大量的对象存活，那么复制的对象将会有很多，效率会很低；</li><li>在新生代，对常规应用的垃圾回收，一次通常可以回收 70% - 99% 的内存空间，回收性价比很高，所以现在的商业虚拟机都是用这种收集算法回收新生代。</li></ol><p><img src="https://img-blog.csdnimg.cn/20210401101142291.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMzNjI2OTk2,size_16,color_FFFFFF,t_70" alt="复制算法"></p><h1 id="清除阶段：标记-压缩算法"><a href="#清除阶段：标记-压缩算法" class="headerlink" title="清除阶段：标记 - 压缩算法"></a>清除阶段：标记 - 压缩算法</h1><p><strong>背景</strong></p><ol><li>复制算法的高效性是建立在存活对象少、垃圾对象多的前提下的。这种情况在新生代经常发生，但是在老年代，更常见的情况是大部分对象都是存活对象。如果依然使用复制算法，由于存活对象较多，复制的成本也将很高，因此，基于老年代垃圾回收的特性，需要使用其他的算法。</li><li>标记 - 清除算法的确可以应用在老年代中，但是该算法不仅执行效率低下，而且在执行完内存回收后还会产生内存碎片，所以 JVM 的设计者需要在此基础之上进行改进。标记 - 压缩（Mark-Compact）算法由此诞生。</li><li>1970 年前后，G.L.Steele、C.J.Chene 和 D.s.Wise 等研究者发布标记 - 压缩算法。在许多现代的垃圾收集器中，人们都使用了标记 - 压缩算法或其改进版本。</li></ol><p><strong>执行过程</strong></p><ol><li>第一阶段和标记清除算法一样，从根节点开始标记所有被引用对象；</li><li>第二阶段将所有的存活对象压缩到内存的一端，按顺序排放，之后，清理边界外所有的空间。</li></ol><p><img src="https://img-blog.csdnimg.cn/20210401101401134.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMzNjI2OTk2,size_16,color_FFFFFF,t_70" alt="标记 - 压缩算法"></p><h2 id="标记-压缩算法与标记-清除算法的比较"><a href="#标记-压缩算法与标记-清除算法的比较" class="headerlink" title="标记 - 压缩算法与标记 - 清除算法的比较"></a>标记 - 压缩算法与标记 - 清除算法的比较</h2><ol><li><p>标记 - 压缩算法的最终效果等同于标记 - 清除算法执行完成后，再进行一次内存碎片整理，因此，也可以把它称为标记 - 清除 - 压缩（Mark-Sweep-Compact）算法。</p></li><li><p>二者的本质差异在于标记 - 清除算法是一种非移动式的回收算法，标记 - 压缩是移动式的。是否移动回收后的存活对象是一项优缺点并存的风险决策。</p></li><li><p>可以看到，标记的存活对象将会被整理，按照内存地址依次排列，而未被标记的内存会被清理掉。如此一来，当需要给新对象分配内存时，JVM 只需要持有一个内存的起始地址即可，这比维护一个空闲列表显然少了许多开销。</p></li></ol><h2 id="标记-压缩算法的优缺点"><a href="#标记-压缩算法的优缺点" class="headerlink" title="标记 - 压缩算法的优缺点"></a>标记 - 压缩算法的优缺点</h2><p><strong>优点</strong></p><ol><li>消除了标记 - 清除算法当中，内存区域分散的缺点，需要给新对象分配内存时，JVM 只需要持有一个内存的起始地址即可；</li><li>消除了复制算法当中，内存减半的高额代价。</li></ol><p><strong>缺点</strong></p><ol><li>从效率上来说，标记 - 压缩算法要低于复制算法；</li><li>移动对象的同时，如果对象被其他对象引用，则还需要调整引用的地址（因为 HotSpot 虚拟机采用的不是句柄池的方式，而是直接指针）；</li><li>移动过程中，需要全程暂停用户应用程序。即：STW 。</li></ol><h1 id="垃圾回收算法小结"><a href="#垃圾回收算法小结" class="headerlink" title="垃圾回收算法小结"></a>垃圾回收算法小结</h1><p><strong>对比三种清除阶段的算法</strong></p><ol><li>效率上来说，复制算法是当之无愧的老大，但是却浪费了太多内存；</li><li>而为了尽量兼顾上面提到的三个指标，标记 - 压缩算法相对来说更平滑一些，但是效率上不尽如人意，它比复制算法多了一个标记的阶段，比标记 - 清除多了一个整理内存的阶段。</li></ol><table><thead><tr><th></th><th align="right">标记清除</th><th align="center">标记整理</th><th align="center">复制</th></tr></thead><tbody><tr><td>速率</td><td align="right">中等</td><td align="center">最慢</td><td align="center">最快</td></tr><tr><td>空间开销</td><td align="right">少（但是会堆积碎片）</td><td align="center">少（但是会堆积碎片）</td><td align="center">通常需要活对象的2倍空间（不堆积碎片）</td></tr><tr><td>移动对象</td><td align="right">否</td><td align="center">是</td><td align="center">是</td></tr></tbody></table><h1 id="分代收集算法"><a href="#分代收集算法" class="headerlink" title="分代收集算法"></a>分代收集算法</h1><p>Q：难道就没有一种最优的算法吗？<br>A：无，没有最好的算法，只有最合适的算法。</p><p><strong>为什么要使用分代收集算法</strong></p><ol><li><p>前面所有这些算法中，并没有一种算法可以完全替代其他算法，它们都具有自己独特的优势和特点。分代收集算法应运而生。</p></li><li><p>分代收集算法，是基于这样一个事实：不同的对象的生命周期是不一样的。因此，不同生命周期的对象可以采取不同的收集方式，以便提高回收效率。一般是把 Java 堆分为新生代和老年代，这样就可以根据各个年代的特点使用不同的回收算法，以提高垃圾回收的效率。</p></li><li><p>在 Java 程序运行的过程中，会产生大量的对象，其中有些对象是与业务信息相关：<br>比如 Http 请求中的 Session 对象、线程、Socket 连接，这类对象跟业务直接挂钩，因此生命周期比较长； - 还有一些对象，主要是程序运行过程中生成的临时变量，这些对象生命周期会比较短，比如：String 对象，由于其不变类的特性，系统会产生大量的这些对象，有些对象甚至只用一次即可回收。</p></li></ol><p><strong>目前几乎所有的 GC 都采用分代收集算法执行垃圾回收的。</strong></p><p>在 HotSpot 中，基于分代的概念，GC 所使用的内存回收算法必须结合年轻代和老年代各自的特点。</p><ol><li>年轻代（Young Gen）</li></ol><ul><li>年轻代特点：区域相对老年代较小，对象生命周期短、存活率低，回收频繁。 - 这种情况复制算法的回收整理，速度是最快的。复制算法的效率只和当前存活对象大小有关，因此很适用于年轻代的回收。而复制算法内存利用率不高的问题，通过 hotspot 中的两个 survivor 的设计得到缓解。</li></ul><ol start="2"><li>老年代（Tenured Gen）</li></ol><ul><li><p>老年代特点：区域较大，对象生命周期长、存活率高，回收不及年轻代频繁。</p></li><li><p>这种情况存在大量存活率高的对象，复制算法明显变得不合适。一般是由标记 - 清除或者是标记 - 清除与标记 - 整理的混合实现。</p><ul><li>Mark 阶段的开销与存活对象的数量成正比。</li><li>Sweep 阶段的开销与所管理区域的大小成正相关。</li><li>Compact 阶段的开销与存活对象的数据成正比。</li></ul></li></ul><ol start="3"><li><p>以 HotSpot 中的 CMS 回收器为例，CMS 是基于 Mark-Sweep 实现的，对于对象的回收效率很高。对于碎片问题，CMS 采用基于 Mark-Compact 算法的 Serial Old 回收器作为补偿措施：当内存回收不佳（碎片导致的 Concurrent Mode Failure 时），将采用 Serial Old 执行 Full GC 以达到对老年代内存的整理。</p></li><li><p>分代的思想被现有的虚拟机广泛使用。几乎所有的垃圾回收器都区分新生代和老年代。</p></li></ol><h1 id="增量收集算法和分区算法"><a href="#增量收集算法和分区算法" class="headerlink" title="增量收集算法和分区算法"></a>增量收集算法和分区算法</h1><h2 id="增量收集算法"><a href="#增量收集算法" class="headerlink" title="增量收集算法"></a>增量收集算法</h2><p>上述现有的算法，在垃圾回收过程中，应用软件将处于一种 Stop the World 的状态。在 Stop the World 状态下，应用程序所有的线程都会挂起，暂停一切正常的工作，等待垃圾回收的完成。如果垃圾回收时间过长，应用程序会被挂起很久，将严重影响用户体验或者系统的稳定性。为了解决这个问题，即对实时垃圾收集算法的研究直接导致了增量收集（Incremental Collecting）算法的诞生。</p><p><strong>增量收集算法基本思想</strong></p><ol><li><p>如果一次性将所有的垃圾进行处理，需要造成系统长时间的停顿，那么就可以让垃圾收集线程和应用程序线程交替执行。每次垃圾收集线程只收集一小片区域的内存空间，接着切换到应用程序线程。依次反复，直到垃圾收集完成。</p></li><li><p>总的来说，增量收集算法的基础仍是传统的标记 - 清除和复制算法。增量收集算法通过对线程间冲突的妥善处理，允许垃圾收集线程以分阶段的方式完成标记、清理或复制工作。</p></li></ol><p><strong>增量收集算法的缺点</strong></p><ul><li>使用这种方式，由于在垃圾回收过程中，间断性地还执行了应用程序代码，所以能减少系统的停顿时间。但是，因为线程切换和上下文转换的消耗，会使得垃圾回收的总体成本上升，造成系统吞吐量的下降。</li></ul><h2 id="分区算法（主要针对-G1-收集器来说的）"><a href="#分区算法（主要针对-G1-收集器来说的）" class="headerlink" title="分区算法（主要针对 G1 收集器来说的）"></a>分区算法（主要针对 G1 收集器来说的）</h2><ol><li><p>一般来说，在相同条件下，堆空间越大，一次 GC 时所需要的时间就越长，有关 GC 产生的停顿也越长。为了更好地控制 GC 产生的停顿时间，将一块大的内存区域分割成多个小块，根据目标的停顿时间，每次合理地回收若干个小区间，而不是整个堆空间，从而减少一次 GC 所产生的停顿。</p></li><li><p>分代算法将按照对象的生命周期长短划分成两个部分，分区算法将整个堆空间划分成连续的不同小区间。每一个小区间都独立使用，独立回收。这种算法的好处是可以控制一次回收多少个小区间。</p></li></ol><p><img src="https://img-blog.csdnimg.cn/20210401103816816.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMzNjI2OTk2,size_16,color_FFFFFF,t_70" alt="分区算法"></p>]]></content>
      
      
      <categories>
          
          <category> JVM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 可达性分析 </tag>
            
            <tag> 标记清除算法 </tag>
            
            <tag> 复制算法 </tag>
            
            <tag> 标记压缩算法 </tag>
            
            <tag> 分代收集算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>垃圾回收器</title>
      <link href="/2020/11/10/jvm/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/"/>
      <url>/2020/11/10/jvm/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="垃圾回收器"><a href="#垃圾回收器" class="headerlink" title="垃圾回收器"></a>垃圾回收器</h1><h2 id="垃圾收集的三个经典问题："><a href="#垃圾收集的三个经典问题：" class="headerlink" title="垃圾收集的三个经典问题："></a>垃圾收集的三个经典问题：</h2><ol><li>哪些内存需要回收？（对象是否可以被回收的两种经典算法: 引用计数法和可达性分析算法）</li><li>什么时候回收？（堆的新生代、老年代、永久代的垃圾回收时机，MinorGC和FullGC）</li><li>如何回收？（三种经典垃圾回收算法(标记清除算法、复制算法、标记整理算法)及分代收集算法和七种垃圾收集器)）</li></ol><blockquote><p>本篇文章主要针对上述第三个问题详细介绍下垃圾回收中的相关算法。</p></blockquote><p>标记阶段：引用计数算法<br>标记阶段的目的<br>垃圾标记阶段：主要是为了判断对象是否存活</p><p>在堆里存放着几乎所有的 Java 对象实例，在 GC 执行垃圾回收之前，首先需要区分出内存中哪些是存活对象，哪些是已经死亡的对象。只有被标记为己经死亡的对象，GC 才会在执行垃圾回收时，释放掉其所占用的内存空间，因此这个过程我们可以称为垃圾标记阶段。<br>那么在 JVM 中究竟是如何标记一个死亡对象呢？简单来说，当一个对象已经不再被任何的存活对象继续引用时，就可以宣判为已经死亡。<br>判断对象存活一般有两种方式：引用计数算法和可达性分析算法。<br>引用计数算法<br>引用计数算法（Reference Counting）比较简单，对每个对象保存一个整型的引用计数器属性，用于记录对象被引用的情况。<br>对于一个对象 A，只要有任何一个对象引用了 A，则 A 的引用计数器就加1；当引用失效时，引用计数器就减1。只要对象 A 的引用计数器的值为0，即表示对象 A 不可能再被使用，可进行回收。<br>优点：实现简单，垃圾对象便于辨识；判定效率高，回收没有延迟性。<br>缺点：<br>它需要单独的字段存储计数器，这样的做法增加了存储空间的开销。 - 每次赋值都需要更新计数器，伴随着加法和减法操作，这增加了时间开销。 - 引用计数器有一个严重的问题，即无法处理循环引用的情况。这是一条致命缺陷，导致在 Java 的垃圾回收器中没有使用这类算法。<br>循环引用</p><p>当 p 的指针断开的时候，内部的引用形成一个循环，这就是循环引用，从而造成内存泄漏。</p><p>举例说明：证明 java 使用的不是引用计数算法</p><pre><code class="bash">/** *  *  * 证明：java使用的不是引用计数算法 */public class RefCountGC &#123;    //这个成员属性唯一的作用就是占用一点内存    private byte[] bigSize = new byte[5 * 1024 * 1024];//5MB    Object reference = null;    public static void main(String[] args) &#123;        RefCountGC obj1 = new RefCountGC();        RefCountGC obj2 = new RefCountGC();        obj1.reference = obj2;        obj2.reference = obj1;        obj1 = null;        obj2 = null;        //显式的执行垃圾回收行为        //这里发生GC，obj1和obj2能否被回收？        System.gc();    &#125;&#125;</code></pre><p>运行结果：</p><pre><code class="bash">[GC (System.gc()) [PSYoungGen: 15490K-&gt;808K(76288K)] 15490K-&gt;816K(251392K), 0.0061980 secs] [Times: user=0.00 sys=0.00, real=0.36 secs] [Full GC (System.gc()) [PSYoungGen: 808K-&gt;0K(76288K)] [ParOldGen: 8K-&gt;672K(175104K)] 816K-&gt;672K(251392K), [Metaspace: 3479K-&gt;3479K(1056768K)], 0.0045983 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] Heap PSYoungGen      total 76288K, used 655K [0x000000076b500000, 0x0000000770a00000, 0x00000007c0000000)  eden space 65536K, 1% used [0x000000076b500000,0x000000076b5a3ee8,0x000000076f500000)  from space 10752K, 0% used [0x000000076f500000,0x000000076f500000,0x000000076ff80000)  to   space 10752K, 0% used [0x000000076ff80000,0x000000076ff80000,0x0000000770a00000) ParOldGen       total 175104K, used 672K [0x00000006c1e00000, 0x00000006cc900000, 0x000000076b500000)  object space 175104K, 0% used [0x00000006c1e00000,0x00000006c1ea8070,0x00000006cc900000) Metaspace       used 3486K, capacity 4496K, committed 4864K, reserved 1056768K  class space    used 385K, capacity 388K, committed 512K, reserved 1048576K</code></pre><blockquote><p>能够看到，上述进行了 GC 收集的行为，将上述的新生代中的两个对象都进行回收了。</p></blockquote><pre><code class="bash">PSYoungGen: 15490K-&gt;808K(76288K)] 15490K-&gt;816K(251392K)</code></pre><blockquote><p>如果使用引用计数算法，那么这两个对象将会无法回收。而现在两个对象被回收了，说明 Java 使用的不是引用计数算法来进行标记的。</p></blockquote><p>小结</p><p>引用计数算法，是很多语言的资源回收选择，例如因人工智能而更加火热的 Python，它更是同时支持引用计数和垃圾收集机制。<br>具体哪种最优是要看场景的，业界有大规模实践中仅保留引用计数机制，以提高吞吐量的尝试。<br>Java 并没有选择引用计数，是因为其存在一个基本的难题，也就是很难处理循环引用关系。<br>Python如何解决循环引用？</p><p>手动解除：很好理解，就是在合适的时机，解除引用关系。<br>使用弱引用 weakref，weakref 是 Python 提供的标准库，旨在解决循环引用。<br>标记阶段：可达性分析算法<br>可达性分析算法：也可以称为根搜索算法、追踪性垃圾收集.</p><p>相对于引用计数算法而言，可达性分析算法不仅同样具备实现简单和执行高效等特点，更重要的是该算法可以有效地解决在引用计数算法中循环引用的问题，防止内存泄漏的发生。<br>相较于引用计数算法，这里的可达性分析就是 Java、C# 选择的。这种类型的垃圾收集通常也叫作追踪性垃圾收集（Tracing Garbage Collection）。<br>可达性分析实现思路<br>所谓 ”GCRoots” 根集合就是一组必须活跃的引用。<br>其基本思路如下：<br>可达性分析算法是以根对象集合（GCRoots）为起始点，按照从上至下的方式搜索被根对象集合所连接的目标对象是否可达；<br>使用可达性分析算法后，内存中的存活对象都会被根对象集合直接或间接连接着，搜索所走过的路径称为引用链（Reference Chain）；<br>如果目标对象没有任何引用链相连，则是不可达的，就意味着该对象己经死亡，可以标记为垃圾对象；<br>在可达性分析算法中，只有能够被根对象集合直接或者间接连接的对象才是存活对象。</p><h3 id="GC-Roots-可以是哪些元素？"><a href="#GC-Roots-可以是哪些元素？" class="headerlink" title="GC Roots 可以是哪些元素？"></a>GC Roots 可以是哪些元素？</h3><p>虚拟机栈中引用的对象，比如：各个线程被调用的方法中使用到的参数、局部变量等；<br>本地方法栈内 JNI（通常说的本地方法）引用的对象；<br>方法区中类静态属性引用的对象，比如：Java 类的引用类型静态变量；<br>方法区中常量引用的对象，比如：字符串常量池（StringTable）里的引用；<br>所有被同步锁 synchronized 持有的对象；<br>Java虚拟机内部的引用，基本数据类型对应的 Class 对象，一些常驻的异常对象（如：NullPointerException、OutofMemoryError），系统类加载器；<br>反映 java 虚拟机内部情况的 JMXBean、JVMTI 中注册的回调、本地代码缓存等。<br>总结</p><p>除了堆空间的周边，比如：虚拟机栈、本地方法栈、方法区、字符串常量池等地方对堆空间进行引用的，都可以作为 GC Roots 进行可达性分析；<br>除了这些固定的 GC Roots 集合以外，根据用户所选用的垃圾收集器以及当前回收的内存区域不同，还可以有其他对象 “临时性” 地加入，共同构成完整 GC Roots 集合。比如：分代收集和局部回收（PartialGC）；<br>如果只针对 Java 堆中的某一块区域进行垃圾回收（比如：典型的只针对新生代），必须考虑到内存区域是虚拟机自己的实现细节，更不是孤立封闭的，这个区域的对象完全有可能被其他区域的对象所引用，这时候就需要一并将关联的区域对象也加入 GC Roots 集合中去考虑，才能保证可达性分析的准确性。<br>小技巧</p><p>由于 Root 采用栈方式存放变量和指针，所以如果一个指针，它保存了堆内存里面的对象，但是自己又不存放在堆内存里面，那它就是一个 Root 。</p><p>注意</p><p>如果要使用可达性分析算法来判断内存是否可回收，那么分析工作必须在一个能保障一致性的快照中进行。这点不满足的话分析结果的准确性就无法保证。<br>这点也是导致 GC 进行时必须 “Stop The World ”的一个重要原因。即使是号称（几乎）不会发生停顿的 CMS 收集器中，枚举根节点时也是必须要停顿的。<br>对象的 finalization 机制<br>finalize() 方法机制<br>对象销毁前的回调函数：finalize()</p><p>Java 语言提供了对象终止（finalization）机制来允许开发人员提供对象被销毁之前的自定义处理逻辑。<br>当垃圾回收器发现没有引用指向一个对象，即：垃圾回收此对象之前，总会先调用这个对象的 finalize() 方法。<br>finalize() 方法允许在子类中被重写，用于在对象被回收时进行资源释放。通常在这个方法中进行一些资源释放和清理的工作，比如关闭文件、套接字和数据库连接等。<br>Object 类中 finalize() 源码：</p><p>JAVA<br>1<br>2<br>// 等待被重写<br>protected void finalize() throws Throwable { }<br>永远不要主动调用某个对象的 finalize() 方法，应该交给垃圾回收机制调用。理由包括下面三点：<br>在 finalize() 时可能会导致对象复活； - finalize() 方法的执行时间是没有保障的，它完全由 GC 线程决定，极端情况下，若不发生 GC ，则 finalize() 方法将没有执行机会； - 一个糟糕的 finalize() 会严重影响 GC 的性能。比如 finalize 是个死循环。<br>从功能上来说，finalize() 方法与 C++ 中的析构函数比较相似，但是 Java 采用的是基于垃圾回收器的自动内存管理机制，所以 finalize() 方法在本质上不同于 C++ 中的析构函数。<br>finalize() 方法对应了一个 finalize 线程，因为优先级比较低，即使主动调用该方法，也不会因此就直接进行回收。<br>生存还是死亡？<br>由于 finalize() 方法的存在，虚拟机中的对象一般处于三种可能的状态。</p><p>如果从所有的根节点都无法访问到某个对象，说明对象己经不再使用了。一般来说，此对象需要被回收。但事实上，也并非是 “非死不可” 的，这时候它们暂时处于 “缓刑” 阶段。一个无法触及的对象有可能在某一个条件下 “复活” 自己，如果这样，那么对它立即进行回收就是不合理的。为此，定义虚拟机中的对象可能的三种状态。如下：<br>可触及的：从根节点开始，可以到达这个对象。<br>可复活的：对象的所有引用都被释放，但是对象有可能在finalize()中复活。<br>不可触及的：对象的finalize()被调用，并且没有复活，那么就会进入不可触及状态。不可触及的对象不可能被复活，因为 finalize() 只会被调用一次。<br>以上3种状态中，是由于 finalize() 方法的存在进行的区分。只有在对象不可触及时才可以被回收。<br>具体过程<br>判定一个对象 objA 是否可回收，至少要经历两次标记过程：</p><p>如果对象 objA 到 GC Roots 没有引用链，则进行第一次标记。<br>进行筛选，判断此对象是否有必要执行 finalize() 方法<br>如果对象 objA 没有重写 finalize() 方法，或者 finalize() 方法已经被虚拟机调用过，则虚拟机视为“没有必要执行”，objA 被判定为不可触及的。<br>如果对象 objA 重写了 finalize() 方法，且还未执行过，那么 objA 会被插入到 F-Queue 队列中，由一个虚拟机自动创建的、低优先级的 Finalizer 线程触发其finalize() 方法执行。<br>finalize() 方法是对象逃脱死亡的最后机会，稍后 GC 会对 F-Queue 队列中的对象进行第二次标记。如果 objA 在 finalize() 方法中与引用链上的任何一个对象建立了联系，那么在第二次标记时，objA 会被移出 “即将回收” 集合。之后，对象会再次出现没有引用存在的情况。在这个情况下，finalize() 方法不会被再次调用，对象会直接变成不可触及的状态，也就是说，一个对象的 finalize() 方法只会被调用一次。<br>通过 JVisual VM 查看 Finalizer 线程</p><p>代码演示 finalize() 方法可复活对象</p><p>重写 CanReliveObj 类的 finalize()方法，在调用其 finalize()方法时，将 obj 指向当前类对象 this 。</p><pre><code class="bash">/** * 测试Object类中finalize()方法，即对象的finalization机制。 * */public class CanReliveObj &#123;    public static CanReliveObj obj;//类变量，属于 GC Root    //此方法只能被调用一次    @Override    protected void finalize() throws Throwable &#123;        super.finalize();        System.out.println(&quot;调用当前类重写的finalize()方法&quot;);        obj = this;//当前待回收的对象在finalize()方法中与引用链上的一个对象obj建立了联系    &#125;    public static void main(String[] args) &#123;        try &#123;            obj = new CanReliveObj();            // 对象第一次成功拯救自己            obj = null;            System.gc();//调用垃圾回收器            System.out.println(&quot;第1次 gc&quot;);            // 因为Finalizer线程优先级很低，暂停2秒，以等待它            Thread.sleep(2000);            if (obj == null) &#123;                System.out.println(&quot;obj is dead&quot;);            &#125; else &#123;                System.out.println(&quot;obj is still alive&quot;);            &#125;            System.out.println(&quot;第2次 gc&quot;);            // 下面这段代码与上面的完全相同，但是这次自救却失败了            obj = null;            System.gc();            // 因为Finalizer线程优先级很低，暂停2秒，以等待它            Thread.sleep(2000);            if (obj == null) &#123;                System.out.println(&quot;obj is dead&quot;);            &#125; else &#123;                System.out.println(&quot;obj is still alive&quot;);            &#125;        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;    &#125;&#125;</code></pre><blockquote><p>如果注释掉 finalize() 方法</p></blockquote><pre><code class="bash">//此方法只能被调用一次   @Override   protected void finalize() throws Throwable &#123;       super.finalize();       System.out.println(&quot;调用当前类重写的finalize()方法&quot;);       obj = this;//当前待回收的对象在finalize()方法中与引用链上的一个对象obj建立了联系   &#125;</code></pre><blockquote><p>输出结果：</p></blockquote><pre><code class="bash">第1次 gcobj is dead第2次 gcobj is dead</code></pre><blockquote><p>放开 finalize() 方法,输出结果：</p></blockquote><pre><code class="bash">第1次 gc调用当前类重写的finalize()方法obj is still alive第2次 gcobj is dead</code></pre><p>第一次自救成功，但由于 finalize() 方法只会执行一次，所以第二次自救失败。</p><p>JProfiler 的 GC Roots 溯源<br>在实际开发中，很少会查看所有的 GC Roots 。一般都是查看某一个或几个对象的 GC Root 是哪个，这个过程叫 GC Roots 溯源。</p><p>使用 JProfiler 进行 GC Roots 溯源示例代码：</p><pre><code class="bash">public class GCRootsTest &#123;    public static void main(String[] args) &#123;        List&lt;Object&gt; numList = new ArrayList&lt;&gt;();        Date birth = new Date();        for (int i = 0; i &lt; 100; i++) &#123;            numList.add(String.valueOf(i));            try &#123;                Thread.sleep(10);            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;        &#125;        System.out.println(&quot;数据添加完毕，请操作：&quot;);        new Scanner(System.in).next();        numList = null;        birth = null;        System.out.println(&quot;numList、birth已置空，请操作：&quot;);        new Scanner(System.in).next();        System.out.println(&quot;结束&quot;);    &#125;&#125;</code></pre><p>上述代码就是不断的创建一个1M小字节数组，然后让内存溢出。同时限制一下内存大小，使用 HeapDumpOnOutOfMemoryError 将出错时候的 dump 文件输出。</p><pre><code class="bash">-Xms8m -Xmx8m -XX:HeapDumpOnOutOfMemoryError</code></pre><blockquote><p>将生成的 dump 文件打开，然后点击 Biggest Objects 就能够看到超大对象。</p></blockquote><p>之后通过线程，还能够定位到哪里出现 OOM 。</p><p>清除阶段：标记-清除算法<br>垃圾清除阶段</p><p>当成功区分出内存中存活对象和死亡对象后，GC 接下来的任务就是执行垃圾回收，释放掉无用对象所占用的内存空间，以便有足够的可用内存空间为新对象分配内存。目前在 JVM 中比较常见的三种垃圾收集算法是</p><p>标记-清除算法（Mark-Sweep）<br>复制算法（Copying）<br>标记-压缩算法（Mark-Compact）<br>背景</p><p>标记-清除算法（Mark-Sweep）是一种非常基础和常见的垃圾收集算法，该算法被 J.McCarthy 等人在 1960 年提出并并应用于 Lisp 语言。</p><p>执行过程</p><p>当堆中的有效内存空间（available memory）被耗尽的时候，就会停止整个程序（也被称为 stop the world），然后进行两项工作，第一项则是标记，第二项则是清除。</p><p>标记：Collector 从引用根节点开始遍历，标记所有被引用的对象。一般是在对象的 Header 中记录为可达对象。注意：标记的是被引用的对象，也就是可达对象，并非标记的是即将被清除的垃圾对象。<br>清除：Collector 对堆内存从头到尾进行线性的遍历，如果发现某个对象在其 Header 中没有标记为可达对象，则将其回收。<br>什么是清除？</p><p>这里所谓的清除并不是真的置空，而是把需要清除的对象地址保存在空闲的地址列表里。下次有新对象需要加载时，判断垃圾的位置空间是否够，如果够，就存放覆盖原有的地址。</p><p>关于空闲列表在为对象分配内存的时候提过：</p><p>如果内存规整：采用指针碰撞的方式进行内存分配。<br>如果内存不规整：虚拟机需要维护一个列表，空闲列表分配。<br>标记-清除算法的缺点</p><p>标记清除算法的效率不算高；<br>在进行 GC 的时候，需要停止整个应用程序，用户体验较差；<br>这种方式清理出来的空闲内存是不连续的，产生内碎片，需要维护一个空闲列表。<br>清除阶段：复制算法<br>背景</p><p>为了解决标记-清除算法在垃圾收集效率方面的缺陷，M.L.Minsky 于1963年发表了著名的论文， “使用双存储区的 Lisp 语言垃圾收集器 CA LISP Garbage Collector Algorithm Using Serial Secondary Storage）”。M.L.Minsky 在该论文中描述的算法被人们称为复制（Copying）算法，它也被 M.L.Minsky 本人成功地引入到了 Lisp 语言的一个实现版本中。</p><p>核心思想</p><p>将活着的内存空间分为两块，每次只使用其中一块，在垃圾回收时将正在使用的内存中的存活对象复制到未被使用的内存块中，之后清除正在使用的内存块中的所有对象，交换两个内存的角色，最后完成垃圾回收。<br>把可达的对象，直接复制到另外一个区域中复制完成后，A 区就没有用了，里面的对象可以直接清除掉，新生代里面就用到了复制算法，Eden 区和 S0 区存活对象整体复制到 S1 区。</p><p>复制算法的优缺点</p><p>优点</p><p>没有标记和清除过程，实现简单，运行高效；<br>复制过去以后保证空间的连续性，不会出现 “碎片” 问题。<br>缺点</p><p>此算法的缺点也是很明显的，就是需要两倍的内存空间；<br>对于 G1 这种分拆成大量 region 的 GC，复制而不是移动，意味着 GC 需要维护 region 之间对象引用关系，不管是内存占用或者时间开销也不小。<br>复制算法的应用场景</p><p>如果系统中的垃圾对象很多，复制算法需要复制的存活对象数量并不会太大，效率较高；<br>老年代大量的对象存活，那么复制的对象将会有很多，效率会很低；<br>在新生代，对常规应用的垃圾回收，一次通常可以回收 70% - 99% 的内存空间，回收性价比很高，所以现在的商业虚拟机都是用这种收集算法回收新生代。<br>清除阶段：标记-压缩算法<br>背景</p><p>复制算法的高效性是建立在存活对象少、垃圾对象多的前提下的。这种情况在新生代经常发生，但是在老年代，更常见的情况是大部分对象都是存活对象。如果依然使用复制算法，由于存活对象较多，复制的成本也将很高，因此，基于老年代垃圾回收的特性，需要使用其他的算法。<br>标记-清除算法的确可以应用在老年代中，但是该算法不仅执行效率低下，而且在执行完内存回收后还会产生内存碎片，所以 JVM 的设计者需要在此基础之上进行改进。标记-压缩（Mark-Compact）算法由此诞生。<br>1970年前后，G.L.Steele、C.J.Chene 和 D.s.Wise 等研究者发布标记-压缩算法。在许多现代的垃圾收集器中，人们都使用了标记-压缩算法或其改进版本。<br>执行过程</p><p>第一阶段和标记清除算法一样，从根节点开始标记所有被引用对象；<br>第二阶段将所有的存活对象压缩到内存的一端，按顺序排放，之后，清理边界外所有的空间。</p><p>标记-压缩算法与标记-清除算法的比较</p><p>标记-压缩算法的最终效果等同于标记-清除算法执行完成后，再进行一次内存碎片整理，因此，也可以把它称为标记-清除-压缩（Mark-Sweep-Compact）算法。<br>二者的本质差异在于标记-清除算法是一种非移动式的回收算法，标记-压缩是移动式的。是否移动回收后的存活对象是一项优缺点并存的风险决策。<br>可以看到，标记的存活对象将会被整理，按照内存地址依次排列，而未被标记的内存会被清理掉。如此一来，当需要给新对象分配内存时，JVM 只需要持有一个内存的起始地址即可，这比维护一个空闲列表显然少了许多开销。<br>标记-压缩算法的优缺点</p><p>优点</p><p>消除了标记-清除算法当中，内存区域分散的缺点，需要给新对象分配内存时，JVM 只需要持有一个内存的起始地址即可；<br>消除了复制算法当中，内存减半的高额代价。<br>缺点</p><p>从效率上来说，标记-压缩算法要低于复制算法；<br>移动对象的同时，如果对象被其他对象引用，则还需要调整引用的地址（因为 HotSpot 虚拟机采用的不是句柄池的方式，而是直接指针）；<br>移动过程中，需要全程暂停用户应用程序。即：STW 。<br>垃圾回收算法小结<br>对比三种清除阶段的算法</p><p>效率上来说，复制算法是当之无愧的老大，但是却浪费了太多内存；<br>而为了尽量兼顾上面提到的三个指标，标记-压缩算法相对来说更平滑一些，但是效率上不尽如人意，它比复制算法多了一个标记的阶段，比标记-清除多了一个整理内存的阶段。</p><p>分代收集算法<br>Q：难道就没有一种最优的算法吗？<br>A：无，没有最好的算法，只有最合适的算法。</p><p>为什么要使用分代收集算法</p><p>前面所有这些算法中，并没有一种算法可以完全替代其他算法，它们都具有自己独特的优势和特点。分代收集算法应运而生。<br>分代收集算法，是基于这样一个事实：不同的对象的生命周期是不一样的。因此，不同生命周期的对象可以采取不同的收集方式，以便提高回收效率。一般是把 Java 堆分为新生代和老年代，这样就可以根据各个年代的特点使用不同的回收算法，以提高垃圾回收的效率。<br>在 Java 程序运行的过程中，会产生大量的对象，其中有些对象是与业务信息相关：<br>比如 Http 请求中的 Session 对象、线程、Socket 连接，这类对象跟业务直接挂钩，因此生命周期比较长； - 还有一些对象，主要是程序运行过程中生成的临时变量，这些对象生命周期会比较短，比如：String 对象，由于其不变类的特性，系统会产生大量的这些对象，有些对象甚至只用一次即可回收。<br>目前几乎所有的 GC 都采用分代收集算法执行垃圾回收的。</p><p>在 HotSpot 中，基于分代的概念，GC 所使用的内存回收算法必须结合年轻代和老年代各自的特点。</p><p>年轻代（Young Gen）<br>年轻代特点：区域相对老年代较小，对象生命周期短、存活率低，回收频繁。 - 这种情况复制算法的回收整理，速度是最快的。复制算法的效率只和当前存活对象大小有关，因此很适用于年轻代的回收。而复制算法内存利用率不高的问题，通过 hotspot 中的两个survivor 的设计得到缓解。<br>老年代（Tenured Gen）<br>老年代特点：区域较大，对象生命周期长、存活率高，回收不及年轻代频繁。<br>这种情况存在大量存活率高的对象，复制算法明显变得不合适。一般是由标记-清除或者是标记-清除与标记-整理的混合实现。<br>Mark 阶段的开销与存活对象的数量成正比。<br>Sweep 阶段的开销与所管理区域的大小成正相关。<br>Compact 阶段的开销与存活对象的数据成正比。<br>以 HotSpot 中的 CMS 回收器为例，CMS 是基于 Mark-Sweep实现的，对于对象的回收效率很高。对于碎片问题，CMS 采用基于 Mark-Compact 算法的 Serial Old 回收器作为补偿措施：当内存回收不佳（碎片导致的 Concurrent Mode Failure 时），将采用 Serial Old 执行 Full GC 以达到对老年代内存的整理。<br>分代的思想被现有的虚拟机广泛使用。几乎所有的垃圾回收器都区分新生代和老年代。<br>增量收集算法和分区算法<br>增量收集算法<br>上述现有的算法，在垃圾回收过程中，应用软件将处于一种 Stop the World 的状态。在 Stop the World 状态下，应用程序所有的线程都会挂起，暂停一切正常的工作，等待垃圾回收的完成。如果垃圾回收时间过长，应用程序会被挂起很久，将严重影响用户体验或者系统的稳定性。为了解决这个问题，即对实时垃圾收集算法的研究直接导致了增量收集（Incremental Collecting）算法的诞生。</p><p>增量收集算法基本思想</p><p>如果一次性将所有的垃圾进行处理，需要造成系统长时间的停顿，那么就可以让垃圾收集线程和应用程序线程交替执行。每次垃圾收集线程只收集一小片区域的内存空间，接着切换到应用程序线程。依次反复，直到垃圾收集完成。<br>总的来说，增量收集算法的基础仍是传统的标记-清除和复制算法。增量收集算法通过对线程间冲突的妥善处理，允许垃圾收集线程以分阶段的方式完成标记、清理或复制工作。<br>增量收集算法的缺点</p><p>使用这种方式，由于在垃圾回收过程中，间断性地还执行了应用程序代码，所以能减少系统的停顿时间。但是，因为线程切换和上下文转换的消耗，会使得垃圾回收的总体成本上升，造成系统吞吐量的下降。<br>分区算法（主要针对 G1 收集器来说的）<br>一般来说，在相同条件下，堆空间越大，一次 GC 时所需要的时间就越长，有关 GC 产生的停顿也越长。为了更好地控制 GC 产生的停顿时间，将一块大的内存区域分割成多个小块，根据目标的停顿时间，每次合理地回收若干个小区间，而不是整个堆空间，从而减少一次 GC 所产生的停顿。<br>分代算法将按照对象的生命周期长短划分成两个部分，分区算法将整个堆空间划分成连续的不同小区间。每一个小区间都独立使用，独立回收。这种算法的好处是可以控制一次回收多少个小区间。</p>]]></content>
      
      
      <categories>
          
          <category> JVM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Parallel </tag>
            
            <tag> CMS </tag>
            
            <tag> G1 </tag>
            
            <tag> Serial </tag>
            
            <tag> ZGC </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>垃圾回收概述</title>
      <link href="/2020/11/04/jvm/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E6%A6%82%E8%BF%B0/"/>
      <url>/2020/11/04/jvm/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E6%A6%82%E8%BF%B0/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="垃圾回收简介"><a href="#垃圾回收简介" class="headerlink" title="垃圾回收简介"></a>垃圾回收简介</h1><h2 id="什么是垃圾？"><a href="#什么是垃圾？" class="headerlink" title="什么是垃圾？"></a>什么是垃圾？</h2><p>垃圾是指在运行程序中没有任何指针指向的对象，这个对象就是需要被回收的垃圾。</p><p>如果不及时对内存中的垃圾进行清理，那么，这些垃圾对象所占的内存空间会一直保留到应用程序结束，被保留的空间无法被其他对象使用，甚至可能导致内存溢出。</p><h2 id="什么是垃圾回收-？"><a href="#什么是垃圾回收-？" class="headerlink" title="什么是垃圾回收 ？"></a>什么是垃圾回收 ？</h2><p>垃圾回收（Garbage Collection，GC），顾名思义就是释放垃圾占用的空间，防止内存泄露。有效的使用可以使用的内存，对内存堆中已经死亡的或者长时间没有使用的对象进行清除和回收。</p><p>Java 的垃圾收集 Garbage Collection 通常被称为 “GC” ，它诞生于 1960 年 MIT 的 Lisp 语言，经过半个多世纪，目前已经十分成熟了。</p><h2 id="垃圾收集有三个最经典的问题："><a href="#垃圾收集有三个最经典的问题：" class="headerlink" title="垃圾收集有三个最经典的问题："></a>垃圾收集有三个最经典的问题：</h2><ol><li>哪些内存需要回收？（对象是否可以被回收的两种经典算法: 引用计数法和可达性分析算法）</li><li>什么时候回收？（堆的新生代、老年代、永久代的垃圾回收时机，MinorGC和FullGC）</li><li>如何回收？（三种经典垃圾回收算法(标记清除算法、复制算法、标记整理算法)及分代收集算法和七种垃圾收集器)）<br>为什么需要 GC ？<br>对于高级语言来说，如果不进行垃圾回收，内存迟早都会被消耗完，因为不断地分配内存空间而不进行回收，就会将内存耗尽；</li></ol><p>除了释放没用的对象，垃圾回收也可以清除内存里的记录碎片。碎片整理将所占用的堆内存移到堆的一端，以便 JVM 将整理出的内存分配给新的对象；</p><p>随着应用程序所应付的业务越来越庞大、复杂，用户越来越多，没有 GC 就不能保证应用程序的正常进行。而经常造成 STW 的 GC 又跟不上实际的需求，所以才会不断地尝试对 GC 进行优化。</p><h2 id="哪些内存需要回收-？"><a href="#哪些内存需要回收-？" class="headerlink" title="哪些内存需要回收 ？"></a>哪些内存需要回收 ？</h2><p>** 哪些内存需要回收？**<br>由于程序计数器、虚拟机栈、本地方法栈的生命周期都跟随线程的生命周期，当线程销毁了，内存也就回收了，所以这几个区域不用过多地考虑内存回收。由于堆和方法区的内存都是动态分配的，而且是线程共享的，所以内存回收主要关注这部分区域。<br>除此之外，垃圾收集器可以对年轻代回收，也可以对老年代回收，甚至是全栈和方法区的回收。其中，Java 堆是垃圾收集器的工作重点，从次数上讲：</p><p>频繁收集 Young 区<br>较少收集 Old 区<br>基本不收集 Perm 区（元空间）<br>垃圾回收相关概念<br>System.gc () 的理解<br>在默认情况下，通过 System.gc () 或 Runtime.getRuntime ().gc () 的调用，会显式触发 Full GC，同时对老年代和新生代进行回收，尝试释放被丢弃对象占用的内存。然而 System.gc () 调用附带一个免责声明，无法保证对垃圾收集器的调用 (不能确保立即生效)。<br>JVM 实现者可以通过 System.gc () 调用来决定 JVM 的 GC 行为。而一般情况下，垃圾回收应该是自动进行的，无须手动触发，否则就太过于麻烦了。在一些特殊情况下，如我们正在编写一个性能基准，我们可以在运行之间调用 System.gc () 。<br>示例代码：</p><p>public class SystemGCTest {<br>    public static void main(String[] args) {<br>        new SystemGCTest();<br>        System.gc();//提醒jvm的垃圾回收器执行gc,但是不确定是否马上执行gc<br>        //与Runtime.getRuntime().gc();的作用一样。</p><p>//        System.runFinalization();//强制调用使用引用的对象的finalize()方法<br>    }<br>    //如果发生了GC，这个finalize()一定会被调用<br>    @Override<br>    protected void finalize() throws Throwable {<br>        super.finalize();<br>        System.out.println(“SystemGCTest 重写了finalize()”);<br>    }<br>}<br>输出结果不确定：有时候会调用 finalize () 方法，有时候并不会调用。</p><pre><code class="bash">SystemGCTest 重写了finalize()或空</code></pre><blockquote><p>手动 GC 理解不可达对象的回收行为：</p></blockquote><pre><code class="bash">//加上参数：  -XX:+PrintGCDetailspublic class LocalVarGC &#123;    /**     * 触发Minor GC没有回收对象，然后在触发Full GC将该对象存入old区     */    public void localvarGC1() &#123;        byte[] buffer = new byte[10*1024*1024];        System.gc();    &#125;    /**     * 触发YoungGC的时候，已经被回收了，由于 buffer 数组对象没有引用指向它，执行 System.gc() 将被回收     */    public void localvarGC2() &#123;        byte[] buffer = new byte[10*1024*1024];        buffer = null;        System.gc();    &#125;    /**     * 不会被回收，因为它还存放在局部变量表索引为1的槽中     */    public void localvarGC3() &#123;        &#123;            byte[] buffer = new byte[10*1024*1024];        &#125;        System.gc();    &#125;    /**     * 会被回收，因为它还存放在局部变量表索引为1的槽中，但是后面定义的value把这个槽给替换了     */    public void localvarGC4() &#123;        &#123;            byte[] buffer = new byte[10*1024*1024];        &#125;        int value = 10;        System.gc();    &#125;    /**     * localvarGC5中的数组已经被回收     */    public void localvarGC5() &#123;        localvarGC1();        System.gc();    &#125;    public static void main(String[] args) &#123;        LocalVarGC localVarGC = new LocalVarGC();        localVarGC.localvarGC3();    &#125;&#125;</code></pre><p>调用 localvarGC1 () 方法：执行 System.gc () 仅仅是将年轻代的 buffer 数组对象放到了老年代，buffer 对象仍然没有回收。<br>JAVA<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>[GC (System.gc()) [PSYoungGen: 15492K-&gt;10728K(76288K)] 15492K-&gt;11000K(251392K), 0.0066473 secs] [Times: user=0.08 sys=0.02, real=0.01 secs]<br>[Full GC (System.gc()) [PSYoungGen: 10728K-&gt;0K(76288K)] [ParOldGen: 272K-&gt;10911K(175104K)] 11000K-&gt;10911K(251392K), [Metaspace: 3492K-&gt;3492K(1056768K)], 0.0097940 secs] [Times: user=0.00 sys=0.00, real=0.01 secs]<br>Heap<br> PSYoungGen      total 76288K, used 655K [0x00000000fab00000, 0x0000000100000000, 0x0000000100000000)<br>  eden space 65536K, 1% used [0x00000000fab00000,0x00000000faba3ee8,0x00000000feb00000)<br>  from space 10752K, 0% used [0x00000000feb00000,0x00000000feb00000,0x00000000ff580000)<br>  to   space 10752K, 0% used [0x00000000ff580000,0x00000000ff580000,0x0000000100000000)<br> ParOldGen       total 175104K, used 10911K [0x00000000f0000000, 0x00000000fab00000, 0x00000000fab00000)<br>  object space 175104K, 6% used [0x00000000f0000000,0x00000000f0aa7d08,0x00000000fab00000)<br> Metaspace       used 3498K, capacity 4498K, committed 4864K, reserved 1056768K<br>  class space    used 387K, capacity 390K, committed 512K, reserved 1048576K<br>调用 localvarGC2 () 方法：由于 buffer 数组对象没有引用指向它，执行 System.gc () 将被回收。<br>JAVA<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>[GC (System.gc()) [PSYoungGen: 15492K-&gt;808K(76288K)] 15492K-&gt;816K(251392K), 0.0294475 secs] [Times: user=0.00 sys=0.00, real=0.04 secs]<br>[Full GC (System.gc()) [PSYoungGen: 808K-&gt;0K(76288K)] [ParOldGen: 8K-&gt;640K(175104K)] 816K-&gt;640K(251392K), [Metaspace: 3385K-&gt;3385K(1056768K)], 0.0054210 secs] [Times: user=0.00 sys=0.00, real=0.01 secs]<br>Heap<br> PSYoungGen      total 76288K, used 1966K [0x00000000fab00000, 0x0000000100000000, 0x0000000100000000)<br>  eden space 65536K, 3% used [0x00000000fab00000,0x00000000faceb9e0,0x00000000feb00000)<br>  from space 10752K, 0% used [0x00000000feb00000,0x00000000feb00000,0x00000000ff580000)<br>  to   space 10752K, 0% used [0x00000000ff580000,0x00000000ff580000,0x0000000100000000)<br> ParOldGen       total 175104K, used 640K [0x00000000f0000000, 0x00000000fab00000, 0x00000000fab00000)<br>  object space 175104K, 0% used [0x00000000f0000000,0x00000000f00a01a8,0x00000000fab00000)<br> Metaspace       used 3392K, capacity 4496K, committed 4864K, reserved 1056768K<br>  class space    used 379K, capacity 388K, committed 512K, reserved 1048576K</p><blockquote><p>调用 localvarGC3 () 方法：虽然出了代码块的作用域，但是 buffer 数组对象并没有被回收。</p></blockquote><pre><code class="bash">[GC (System.gc()) [PSYoungGen: 15492K-&gt;840K(76288K)] 15492K-&gt;11088K(251392K), 0.0070281 secs] [Times: user=0.08 sys=0.00, real=0.01 secs] [Full GC (System.gc()) [PSYoungGen: 840K-&gt;0K(76288K)] [ParOldGen: 10248K-&gt;10900K(175104K)] 11088K-&gt;10900K(251392K), [Metaspace: 3386K-&gt;3386K(1056768K)], 0.0084464 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] Heap PSYoungGen      total 76288K, used 1966K [0x00000000fab00000, 0x0000000100000000, 0x0000000100000000)  eden space 65536K, 3% used [0x00000000fab00000,0x00000000faceb9e0,0x00000000feb00000)  from space 10752K, 0% used [0x00000000feb00000,0x00000000feb00000,0x00000000ff580000)  to   space 10752K, 0% used [0x00000000ff580000,0x00000000ff580000,0x0000000100000000) ParOldGen       total 175104K, used 10900K [0x00000000f0000000, 0x00000000fab00000, 0x00000000fab00000)  object space 175104K, 6% used [0x00000000f0000000,0x00000000f0aa52e8,0x00000000fab00000) Metaspace       used 3393K, capacity 4496K, committed 4864K, reserved 1056768K  class space    used 379K, capacity 388K, committed 512K, reserved 1048576K</code></pre><blockquote><p>原因：看看字节码，实例方法局部变量表第一个变量肯定是 this 。</p></blockquote><p>但是，有没有看到，局部变量表的大小是 2。但是局部变量表里只有一个索引为 0 的啊？那索引为 1 的是哪个局部变量呢？实际上索引为 1 的位置是 buffer 在占用着，执行 System.gc () 时，栈中还有 buffer 变量指向堆中的字节数组，所以没有进行 GC 。</p><blockquote><p>调用 localvarGC4 () 方法：</p></blockquote><pre><code class="bash">[GC (System.gc()) [PSYoungGen: 15492K-&gt;776K(76288K)] 15492K-&gt;784K(251392K), 0.0009430 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] [Full GC (System.gc()) [PSYoungGen: 776K-&gt;0K(76288K)] [ParOldGen: 8K-&gt;646K(175104K)] 784K-&gt;646K(251392K), [Metaspace: 3485K-&gt;3485K(1056768K)], 0.0065829 secs] [Times: user=0.02 sys=0.00, real=0.01 secs] Heap PSYoungGen      total 76288K, used 1966K [0x00000000fab00000, 0x0000000100000000, 0x0000000100000000)  eden space 65536K, 3% used [0x00000000fab00000,0x00000000faceb9f8,0x00000000feb00000)  from space 10752K, 0% used [0x00000000feb00000,0x00000000feb00000,0x00000000ff580000)  to   space 10752K, 0% used [0x00000000ff580000,0x00000000ff580000,0x0000000100000000) ParOldGen       total 175104K, used 646K [0x00000000f0000000, 0x00000000fab00000, 0x00000000fab00000)  object space 175104K, 0% used [0x00000000f0000000,0x00000000f00a1b88,0x00000000fab00000) Metaspace       used 3498K, capacity 4498K, committed 4864K, reserved 1056768K  class space    used 387K, capacity 390K, committed 512K, reserved 1048576K为什么定义了一个局部变量 value ，就可以把字节数组回收了呢？原因：局部变量表长度为 2 ，这说明了出了代码块时，buffer 就出了其作用域范围，此时没有为 value 开启新的槽，value 变量直接占据了 buffer 变量的槽（Slot），导致堆中的字节数组没有引用再指向它，执行 System.gc () 时被回收。value 位于局部变量表中索引为 1 的位置。value 这个局部变量把原本属于 buffer 的 slot 给占用了，这样栈上就没有 buffer 变量指向 new byte [10 * 1024* 1024] 实例了。</code></pre><p>这点看不懂的可以看前面的文章：虚拟机栈 –&gt; Slot 的重复利用。</p><p>调用 localvarGC5 () 方法：局部变量出了方法范围就是失效了，堆中的字节数组肯定被回收。</p><pre><code class="bash">[GC (System.gc()) [PSYoungGen: 15492K-&gt;840K(76288K)] 15492K-&gt;11088K(251392K), 0.0070281 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] [Full GC (System.gc()) [PSYoungGen: 840K-&gt;0K(76288K)] [ParOldGen: 10248K-&gt;10911K(175104K)] 11088K-&gt;10911K(251392K), [Metaspace: 3492K-&gt;3492K(1056768K)], 0.0082011 secs] [Times: user=0.03 sys=0.03, real=0.01 secs] [GC (System.gc()) [PSYoungGen: 0K-&gt;0K(76288K)] 10911K-&gt;10911K(251392K), 0.0004440 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] [Full GC (System.gc()) [PSYoungGen: 0K-&gt;0K(76288K)] [ParOldGen: 10911K-&gt;671K(175104K)] 10911K-&gt;671K(251392K), [Metaspace: 3492K-&gt;3492K(1056768K)], 0.0108555 secs] [Times: user=0.08 sys=0.02, real=0.01 secs] Heap PSYoungGen      total 76288K, used 655K [0x00000000fab00000, 0x0000000100000000, 0x0000000100000000)  eden space 65536K, 1% used [0x00000000fab00000,0x00000000faba3ee8,0x00000000feb00000)  from space 10752K, 0% used [0x00000000ff580000,0x00000000ff580000,0x0000000100000000)  to   space 10752K, 0% used [0x00000000feb00000,0x00000000feb00000,0x00000000ff580000) ParOldGen       total 175104K, used 671K [0x00000000f0000000, 0x00000000fab00000, 0x00000000fab00000)  object space 175104K, 0% used [0x00000000f0000000,0x00000000f00a7cf8,0x00000000fab00000) Metaspace       used 3499K, capacity 4502K, committed 4864K, reserved 1056768K  class space    used 387K, capacity 390K, committed 512K, reserved 1048576K</code></pre><h2 id="内存溢出与内存泄漏"><a href="#内存溢出与内存泄漏" class="headerlink" title="内存溢出与内存泄漏"></a>内存溢出与内存泄漏</h2><h3 id="内存溢出"><a href="#内存溢出" class="headerlink" title="内存溢出"></a>内存溢出</h3><p>由于 GC 一直在发展，所有一般情况下，除非应用程序占用的内存增长速度非常快，造成垃圾回收已经跟不上内存消耗的速度，否则不太容易出现 OOM 的情况。<br>大多数情况下，GC 会进行各种年龄段的垃圾回收，实在不行了就来一次独占式的 Full GC 操作，这时候会回收大量的内存，供应用程序继续使用。<br>Javadoc 中对 OutofMemoryErro r 的解释是，没有空闲内存，并且垃圾收集器也无法提供更多内存。<br>内存溢出（OOM）原因分析：</p><p>Java 虚拟机的堆内存设置不够。比如：可能存在内存泄漏问题；也很有可能就是堆的大小不合理，比如要处理比较可观的数据量，但是没有显式指定 JVM 堆大小或者指定数值偏小。可以通过参数 - Xms 、-Xmx 来调整。</p><p>代码中创建了大量大对象，并且长时间不能被垃圾收集器收集（存在被引用）。对于老版本的 oracle JDK ，因为永久代的大小是有限的，并且 JVM 对永久代垃圾回收（如常量池回收、卸载不再需要的类型）非常不积极，所以当不断添加新类型的时候，永久代出现 OutOfMemoryError 也非常多见，尤其是在运行时存在大量动态类型生成的场合，类似 intern 字符串缓存占用太多空间，也会导致 OOM 问题。对应的异常信息，会标记出来和永久代相关：“java.lang.OutOfMemoryError:PermGen space” 。而随着元数据区的引入，方法区内存已经不再那么窘迫，所以相应的 OOM 有所改观，出现 OOM 异常信息则变成了：“java.lang.OutofMemoryError:Metaspace” 。直接内存不足，也会导致 OOM 。</p><p>注：在抛出 OutofMemoryError 之前，通常垃圾收集器会被触发，尽其所能去清理出空间。当然，也不是在任何情况下垃圾收集器都会被触发的。比如，去分配一个超大对象，类似一个超大数组超过堆的最大值，JVM 可以判断出垃圾收集并不能解决这个问题，所以直接抛出 OutofMemoryError 。<br>内存泄漏<br>严格来说，只有对象不会再被程序用到了，但是 GC 又不能回收他们的情况，才叫内存泄漏。<br>而实际情况很多时候一些不太好的实践（或疏忽）会导致对象的生命周期变得很长甚至导致 OOM ，也可以叫做宽泛意义上的 “内存泄漏”。<br>尽管内存泄漏并不会立刻引起程序崩溃，但是一旦发生内存泄漏，程序中的可用内存就会被逐步蚕食，直至耗尽所有内存，最终出现 OutofMemory 异常，导致程序崩溃。<br>注意，这里的存储空间并不是指物理内存，而是指虚拟内存大小，这个虚拟内存大小取决于磁盘交换区设定的大小。<br>内存泄露官方例子：</p><p>左边的图：Java 使用可达性分析算法，最上面的数据不可达，就是需要被回收的对象。<br>右边的图：后期有一些对象不用了，按道理应该断开引用，但是存在一些链没有断开（图示中的 Forgotten Reference Memory Leak），从而导致没有办法被回收。<br>常见例子：</p><p>单例模式：单例的生命周期和应用程序是一样长的，所以在单例程序中，如果持有对外部对象的引用的话，那么这个外部对象是不能被回收的，则会导致内存泄漏的产生。<br>一些提供 close () 的资源未关闭导致内存泄漏：数据库连接 dataSourse.getConnection ()，网络连接 socket 和 io 连接必须手动 close ，否则是不能被回收的。<br>Stop the World<br>Stop-the-World，简称 STW ，指的是 GC 事件发生过程中，会产生应用程序的停顿。停顿产生时整个应用程序线程都会被暂停，没有任何响应，有点像卡死的感觉，这个停顿称为 STW 。<br>可达性分析算法中枚举根节点（GC Roots）会导致所有 Java 执行线程停顿，为什么需要停顿所有 Java 执行线程呢？<br>分析工作必须在一个能确保一致性的快照中进行； - 一致性指整个分析期间整个执行系统看起来像被冻结在某个时间点上；<br>如果出现分析过程中对象引用关系还在不断变化，则分析结果的准确性无法保证。<br>被 STW 中断的应用程序线程会在完成 GC 之后恢复，频繁中断会让用户感觉像是网速不快造成电影卡带一样，所以需要减少 STW 的发生。<br>注意：</p><p>STW 事件和采用哪款 GC 无关，所有的 GC 都有这个事件。<br>哪怕是 G1 也不能完全避免 Stop-the-world 情况发生，只能说垃圾回收器越来越优秀，回收效率越来越高，尽可能地缩短了暂停时间。<br>STW 是 JVM 在后台自动发起和自动完成的。在用户不可见的情况下，把用户正常的工作线程全部停掉。<br>开发中不要用 System.gc () ，这会导致 Stop-the-World 的发生。<br>代码示例：</p><pre><code class="bash">public class StopTheWorldDemo &#123;    public static class WorkThread extends Thread &#123;        List&lt;byte[]&gt; list = new ArrayList&lt;byte[]&gt;();        public void run() &#123;            try &#123;                while (true) &#123;                    for(int i = 0;i &lt; 1000;i++)&#123;                        byte[] buffer = new byte[1024];                        list.add(buffer);                    &#125;                    if(list.size() &gt; 10000)&#123;                        list.clear();                        System.gc();//会触发full gc，进而会出现STW事件                                         &#125;                &#125;            &#125; catch (Exception ex) &#123;                ex.printStackTrace();            &#125;        &#125;    &#125;    public static class PrintThread extends Thread &#123;        public final long startTime = System.currentTimeMillis();        public void run() &#123;            try &#123;                while (true) &#123;                    // 每秒打印时间信息                    long t = System.currentTimeMillis() - startTime;                    System.out.println(t / 1000 + &quot;.&quot; + t % 1000);                    Thread.sleep(1000);                &#125;            &#125; catch (Exception ex) &#123;                ex.printStackTrace();            &#125;        &#125;    &#125;    public static void main(String[] args) &#123;        WorkThread w = new WorkThread();        PrintThread p = new PrintThread();        w.start();        p.start();    &#125;&#125;</code></pre><blockquote><p>关闭工作线程 w ，观察输出：当前时间间隔与上次时间间隔基本是每隔 1 秒打印一次。</p></blockquote><pre><code class="bash">0.11.12.23.24.35.36.37.3</code></pre><p>Process finished with exit code -1<br>开启工作线程 w ，观察打印输出：当前时间间隔与上次时间间隔相差 1.3s ，可以明显感受到 Stop the World 的存在。</p><pre><code class="bash">0.11.42.73.84.125.13</code></pre><p>Process finished with exit code -1<br>垃圾回收的并行与并发<br>并发的概念:</p><p>在操作系统中，是指一个时间段中有几个程序都处于已启动运行到运行完毕之间，且这几个程序都是在同一个处理器上运行；<br>并发不是真正意义上的 “同时进行”，只是 CPU 把一个时间段划分成几个时间片段（时间区间），然后在这几个时间区间之间来回切换。由于 CPU 处理的速度非常快，只要时间间隔处理得当，即可让用户感觉是多个应用程序同时在进行。</p><p>并行的概念：</p><p>当系统有一个以上 CPU 时，当一个 CPU 执行一个进程时，另一个 CPU 可以执行另一个进程，两个进程互不抢占 CPU 资源，可以同时进行，我们称之为并行（Parallel）；<br>其实决定并行的因素不是 CPU 的数量，而是 CPU 的核心数量，比如一个 CPU 多个核也可以并行；<br>适合科学计算，后台处理等弱交互场景。</p><p>在这里插入图片描述<br>并发与并行的对比：</p><p>并发，指的是多个事情，在同一时间段内同时发生了。<br>并行，指的是多个事情，在同一时间点上（或者说同一时刻）同时发生了。<br>并发的多个任务之间是互相抢占资源的，并行的多个任务之间是不互相抢占资源的。<br>只有在多 CPU 或者一个 CPU 多核的情况中，才会发生并行。否则，看似同时发生的事情，其实都是并发执行的。<br>垃圾回收的并发与并行</p><p>并行（Parallel）：指多条垃圾收集线程并行工作，但此时用户线程仍处于等待状态。如 ParNew、Parallel Scavenge、Parallel Old 。<br>串行（Serial）：相较于并行的概念，单线程执行。如果内存不够，则程序暂停，启动 JVM 垃圾回收器进行垃圾回收（单线程）。</p><p>并发和并行，在谈论垃圾收集器的上下文语境中，它们可以解释如下：</p><p>并发（Concurrent）：指用户线程与垃圾收集线程同时执行（但不一定是并行的，可能会交替执行），垃圾回收线程在执行时不会停顿用户程序的运行。 比如用户程序在继续运行，而垃圾收集程序线程运行于另一个 CPU 上。</p><p>典型垃圾回收器：CMS、G1 。</p><p>HotSpot 的算法实现细节<br>根节点枚举<br>固定可作为 GC Roots 的节点主要在全局性的引用（例如常量或类静态属性）与执行上下文（例如栈帧中的本地变量表）中，尽管目标明确，但查找过程要做到高效并非一件容易的事情，现在 Java 应用越做越庞大，光是方法区的大小就常有数百上千兆，里面的类、常量等更是恒河沙数，若要逐个检查以这里为起源的引用肯定得消耗不少时间。</p><p>迄今为止，所有收集器在根节点枚举这一步骤时都是必须暂停用户线程的，因此毫无疑问根节点枚举与之前提及的整理内存碎片一样会面临相似的 “Stop The World” 的困扰。现在可达性分析算法耗时最长的查找引用链的过程已经可以做到与用户线程一起并发，但根节点枚举始终还是必须在一个能保障一致性的快照中才得以进行 —— 这里 “一致性” 的意思是整个枚举期间执行子系统看起来就像被冻结在某个时间点上，不会出现分析过程中，根节点集合的对象引用关系还在不断变化的情况，若这点不能满足的话，分析结果准确性也就无法保证。这是导致垃圾收集过程必须停顿所有用户线程的其中一个重要原因，即使是号称停顿时间可控，或者（几乎）不会发生停顿的 CMS、G1、 ZGC 等收集器，枚举根节点时也是必须要停顿的。</p><p>由于目前主流 Java 虚拟机使用的都是准确式垃圾收集，所以当用户线程停顿下来之后，其实并不需要一个不漏地检查完所有执行上下文和全局的引用位置，虚拟机应当是有办法直接得到哪些地方存放着对象引用的。在 HotSpot 的解决方案里，是使用一组称为 OopMap 的数据结构来达到这个目的。一旦类加载动作完成的时候， HotSpot 就会把对象内什么偏移量上是什么类型的数据计算出来，在即时编译过程中，也会在特定的位置记录下栈里和寄存器里哪些位置是引用。这样收集器在扫描时就可以直接得知这些信息了，并不需要真正一个不漏地从方法区等 GC Roots 始查找。</p><p>Exact VM 因它使用准确式内存管理（Exact Memory Management，也可以叫 Non-Con- servative/Accurate Memory Management）而得名。准确式内存管理是指虚拟机可以知道内存中某个位置的数据具体是什么类型。譬如内存中有一个 32bit 的整数 123456，虚拟机将有能力分辨出它到底是一 个指向了 123456 的内存地址的引用类型还是一个数值为 123456 的整数，准确分辨出哪些内存是引用类 型，这也是在垃圾收集时准确判断堆上的数据是否还可能被使用的前提。【这个不是特别重要，了解一下即可】</p><p>常考面试：在 OopMap 的协助下，HotSpot 可以快速准确地完成 GC Roots 枚举.</p><p>安全点与安全区域<br>安全点（Safepoint）<br>程序执行时并非在所有地方都能停顿下来开始 GC ，只有在特定的位置才能停顿下来开始 GC ，这些位置称为 “安全点（Safepoint）” 。<br>Safe Point 的选择很重要，如果太少可能导致 GC 等待的时间太长，如果太频繁可能导致运行时的性能问题。大部分指令的执行时间都非常短暂，通常会根据 “是否具有让程序长时间执行的特征” 为标准。比如：选择一些执行时间较长的指令作为 Safe Point ，如方法调用、循环跳转和异常跳转等。<br>如何在 GC 发生时，检查所有线程都跑到最近的安全点停顿下来呢？</p><p>抢先式中断：（目前没有虚拟机采用了）首先中断所有线程。如果还有线程不在安全点，就恢复线程，让线程跑到安全点；<br>主动式中断：设置一个中断标志，各个线程运行到 Safe Point 的时候主动轮询这个标志，如果中断标志为真，则将自己进行中断挂起。<br>安全区域（Safe Region）<br>线程处于 Sleep 状态或 Blocked 状态，这时候线程无法响应 JVM 的中断请求，“走” 到安全点去中断挂起，JVM 也不太可能等待线程被唤醒。对于这种情况，就需要安全区域（Safe Region）来解决。<br>安全区域是指在一段代码片段中，对象的引用关系不会发生变化，在这个区域中的任何位置开始 GC 都是安全的。也可以把 Safe Region 看做是被扩展了的 Safe point 。<br>安全区域的执行流程：</p><p>当线程运行到 Safe Region 的代码时，首先标识已经进入了 Safe Region，如果这段时间内发生 GC，JVM 会忽略标识为 Safe Region 状态的线程；<br>当线程即将离开 Safe Region 时，会检查 JVM 是否已经完成根节点枚举（即 GC Roots 的枚举），如果完成了，则继续运行，否则线程必须等待直到收到可以安全离开 Safe Region 的信号为止。<br>记忆集与卡表<br>什么是跨代引用？</p><p>一般的垃圾回收算法至少会划分出两个年代，年轻代和老年代。但是单纯的分代理论在垃圾回收的时候存在一个巨大的缺陷：为了找到年轻代中的存活对象，却不得不遍历整个老年代，反过来也是一样的。<br>如果我们从年轻代开始遍历，那么可以断定 N, S, P, Q 都是存活对象。但是，V 却不会被认为是存活对象，其占据的内存会被回收了。这就是一个惊天的大漏洞！因为 U 本身是老年代对象，而且有外部引用指向它，也就是说 U 是存活对象，而 U 指向了 V ，也就是说 V 也应该是存活对象才是！而这都是因为我们只遍历年轻代对象。<br>为了解决这种跨代引用的问题，最笨的办法就是遍历老年代的对象，找出这些跨代引用来。这种方案存在极大的性能浪费。因为从两个分代假说里面，其实隐含了一个推论：跨代引用是极少的。也就是为了找出那么一点点跨代引用，却得遍历整个老年代！从上图来说，很显然的是，根本不必遍历 R。<br>因此，为了避免这种遍历老年代的性能开销，通常的分代垃圾回收器会引入一种称为记忆集的技术。简单来说，记忆集就是用来记录跨代引用的表。<br>记忆集与卡表</p><p>为解决对象跨代引用所带来的问题，垃圾收集器在新生代中建立了名为记忆集（Remembered Set）的数据结构，用以避免把整个老年代加进 GC Roots 扫描范围。事实上并不只是新生代、老年代之间才有跨代引用的问题，所有涉及部分区域收集（Partial GC）行为的垃圾收集器，典型的如 G1、ZGC 和 Shenandoah 收集器，都会面临相同的问题，因此有必要进一步理清记忆集的原理和实现方式，以便在后续章节里介绍几款最新的收集器相关知识时能更好地理解。</p><p>记忆集是一种用于记录从非收集区域指向收集区域的指针集合的抽象数据结构。如果不考虑效率和成本的话，最简单的实现可以用非收集区域中所有含跨代引用的对象数组来实现这个数据结构。</p><p>比如说老年代（非收集区域）和年轻代（收集区域）的对象之间有一条引用链。</p><p>这种记录全部含跨代引用对象的实现方案，无论是空间占用还是维护成本都相当高昂。而在垃圾收集的场景中，收集器只需要通过记忆集判断出某一块非收集区域是否存在有指向了收集区域的指针就可以了，并不需要了解这些跨代指针的全部细节。那设计者在实现记忆集的时候，便可以选择更为粗犷的记录粒度来节省记忆集的存储和维护成本，下面列举了一些可供选择（当然也可以选择这个范 围以外的）的记录精度：</p><ul><li>字长精度：每个记录精确到一个机器字长（就是处理器的寻址位数，如常见的32位或64位，这个 精度决定了机器访问物理内存地址的指针长度），该字长包含跨代指针；</li><li>对象精度：每个记录精确到一个对象，该对象里有字段含有跨代指针；</li><li>卡精度：每个记录精确到一块内存区域，该区域内有对象含有跨代指针。<br>其中，第三种 “卡精度” 所指的是用一种称为 “卡表”（Card Table）的方式去实现记忆集，这也是目前最常用的一种记忆集实现形式，一些资料中甚至直接把它和记忆集混为一谈。前面定义中提到记忆集其实是一种 “抽象” 的数据结构，抽象的意思是只定义了记忆集的行为意图，并没有定义其行为的具体实现。卡表就是记忆集的一种具体实现，它定义了记忆集的记录精度、与堆内存的映射关系等。 关于卡表与记忆集的关系，读者不妨按照 Java 语言中 HashMap 与 Map 的关系来类比理解。 卡表最简单的形式可以只是一个字节数组，而 HotSpot 虚拟机确实也是这样做的。</li></ul><p>引用概述<br>我们希望能描述这样一类对象：当内存空间还足够时，则能保留在内存中；如果内存空间在进行垃圾收集后还是很紧张，则可以抛弃这些对象。</p><p>【既偏门又非常高频的面试题】强引用、软引用、弱引用、虚引用有什么区别？具体使用场景是什么？ 在 JDK1.2 版之后，Java 对引用的概念进行了扩充，将引用分为：</p><p>强引用（Strong Reference）<br>软引用（Soft Reference）<br>弱引用（Weak Reference）<br>虚引用（Phantom Reference）<br>这 4 种引用强度依次逐渐减弱。除强引用外，其他 3 种引用均可以在 java.lang.ref 包中找到它们的身影。如下图，显示了这 3 种引用类型对应的类，开发人员可以在应用程序中直接使用它们。</p><p>Reference 子类中只有终结器引用是包内可见的，其他 3 种引用类型均为 public ，可以在应用程序中直接使用。</p><p>强引用（StrongReference）：最传统的 “引用” 的定义，是指在程序代码之中普遍存在的引用赋值，即类似 “object obj=new Object ()” 这种引用关系。无论任何情况下，只要强引用关系还存在，垃圾收集器就永远不会回收掉被引用的对象。宁可报 OOM ，也不会 GC 强引用。<br>软引用（SoftReference）：在系统将要发生内存溢出之前，将会把这些对象列入回收范围之中进行第二次回收。如果这次回收后还没有足够的内存，才会抛出内存溢出异常。<br>弱引用（WeakReference）：被弱引用关联的对象只能生存到下一次垃圾收集之前。当垃圾收集器工作时，无论内存空间是否足够，都会回收掉被弱引用关联的对象。<br>虚引用（PhantomReference）：一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来获得一个对象的实例。为一个对象设置虚引用关联的唯一目的就是能在这个对象被收集器回收时收到一个系统通知。<br>强引用：不回收<br>在 Java 程序中，最常见的引用类型是强引用（普通系统 99% 以上都是强引用），也就是最常见的普通对象引用，也是默认的引用类型。<br>当在 Java 言中使用 new 操作符创建一个新的对象，并将其赋值给一个变量的时候，这个变量就成为指向该对象的一个强引用。<br>只要强引用的对象是可触及的，垃圾收集器就永远不会回收掉被引用的对象。只要强引用的对象是可达的，jvm 宁可报 OOM ，也不会回收强引用。<br>对于一个普通的对象，如果没有其他的引用关系，只要超过了引用的作用域或者显式地将相应（强）引用赋值为 null ，就是可以当做垃圾被收集了，当然具体回收时机还是要看垃圾收集策略。<br>相对的，软引用、弱引用和虚引用的对象是软可触及、弱可触及和虚可触及的，在一定条件下，都是可以被回收的。所以，强引用是造成 Java 内存泄漏的主要原因之一。<br>强引用代码示例：</p><pre><code class="bash">public class StrongReferenceTest &#123;    public static void main(String[] args) &#123;        StringBuffer str = new StringBuffer (&quot;`Hello,小白`&quot;);        StringBuffer str1 = str;        str = null;        System.gc();        try &#123;            Thread.sleep(3000);        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;        System.out.println(str1);    &#125;&#125;</code></pre><p>输出：</p><pre><code class="bash">Hello,小白局部变量 str 指向 stringBuffer 实例所在堆空间，通过 str 可以操作该实例，那么 str 就是 stringBuffer 实例的强引用对应内存结构：</code></pre><pre><code class="bash">StringBuffer str = new StringBuffer (&quot;`Hello,小白`&quot;);</code></pre><p>在这里插入图片描述</p><p>如果此时，在运行一个赋值语句:</p><pre><code class="bash">StringBuffer str = new StringBuffer (&quot;`Hello,小白`&quot;);StringBuffer str1 = str; </code></pre><p>在这里插入图片描述</p><p>那么将 str = null; 则 原来堆中的对象也不会被回收，因为还有其它对象指向该区域。</p><p>本例中的两个引用，都是强引用，强引用具备以下特点：</p><p>强引用可以直接访问目标对象。<br>强引用所指向的对象在任何时候都不会被系统回收，虚拟机宁愿抛出 OOM 异常，也不会回收强引用所指向对象。<br>强引用可能导致内存泄漏。<br>软引用：内存不足即回收<br>软引用是用来描述一些还有用，但非必需的对象。只被软引用关联着的对象，在系统将要发生内存溢出异常前，会把这些对象列进回收范围之中进行第二次回收，如果这次回收还没有足够的内存，才会抛出内存溢出异常。注意，这里的第一次回收是不可达的对象。<br>软引用通常用来实现内存敏感的缓存。比如：高速缓存就有用到软引用。如果还有空闲内存，就可以暂时保留缓存，当内存不足时清理掉，这样就保证了使用缓存的同时，不会耗尽内存。<br>垃圾回收器在某个时刻决定回收软可达的对象的时候，会清理软引用，并可选地把引用存放到一个引用队列（Reference Queue）。<br>类似弱引用，只不过 Java 虚拟机会尽量让软引用的存活时间长一些，迫不得已才清理。<br>一句话概括：当内存足够时，不会回收软引用可达的对象。内存不够时，回收。<br>在 JDK1.2 版之后提供了 SoftReference 类来实现软引用。</p><pre><code class="bash">Object obj = new Object();// 声明强引用SoftReference&lt;Object&gt; sf = new SoftReference&lt;&gt;(obj);obj = null; //销毁强引用</code></pre><blockquote><p>软引用代码示例：</p></blockquote><pre><code class="bash">//设置参数：-Xms10m -Xmx10mpublic class SoftReferenceTest &#123;    public static class User &#123;        public User(int id, String name) &#123;            this.id = id;            this.name = name;        &#125;        public int id;        public String name;        @Override        public String toString() &#123;            return &quot;[id=&quot; + id + &quot;, name=&quot; + name + &quot;] &quot;;        &#125;    &#125;    public static void main(String[] args) &#123;        //创建对象，建立软引用//        SoftReference&lt;User&gt; userSoftRef = new SoftReference&lt;User&gt;(new User(1, &quot;zc&quot;));        //上面的一行代码，等价于如下的三行代码        User u1 = new User(1,&quot;zc&quot;);        SoftReference&lt;User&gt; userSoftRef = new SoftReference&lt;User&gt;(u1);        u1 = null;//取消强引用        //从软引用中重新获得强引用对象        System.out.println(userSoftRef.get());        System.out.println(&quot;---目前内存还不紧张---&quot;);        System.gc();        System.out.println(&quot;After GC:&quot;);//        //垃圾回收之后获得软引用中的对象        System.out.println(userSoftRef.get());//由于堆空间内存足够，所有不会回收软引用的可达对象。        System.out.println(&quot;---下面开始内存紧张了---&quot;);        try &#123;            //让系统认为内存资源紧张、不够//            byte[] b = new byte[1024 * 1024 * 7];            byte[] b = new byte[1024 * 7168 - 635 * 1024];        &#125; catch (Throwable e) &#123;            e.printStackTrace();        &#125; finally &#123;            //再次从软引用中获取数据            System.out.println(userSoftRef.get());//在报OOM之前，垃圾回收器会回收软引用的可达对象。        &#125;    &#125;&#125;</code></pre><p>在 JVM 内存不足时，会清理软引用对象。输出如下：</p><pre><code class="bash">[id=1, name=zc] ---目前内存还不紧张---After GC:[id=1, name=zc] ---下面开始内存紧张了---nulljava.lang.OutOfMemoryError: Java heap space    at com.heu.gc.SoftReferenceTest.main(SoftReferenceTest.java:48)Process finished with exit code 0</code></pre><h2 id="弱引用：发现即回收"><a href="#弱引用：发现即回收" class="headerlink" title="弱引用：发现即回收"></a>弱引用：发现即回收</h2><p>弱引用也是用来描述那些非必需对象，只被弱引用关联的对象只能生存到下一次垃圾收集发生为止。在系统 GC 时，只要发现弱引用，不管系统堆空间使用是否充足，都会回收掉只被弱引用关联的对象。<br>但是，由于垃圾回收器的线程通常优先级很低，因此，并不一定能很快地发现持有弱引用的对象。在这种情况下，弱引用对象可以存在较长的时间。<br>弱引用和软引用一样，在构造弱引用时，也可以指定一个引用队列，当弱引用对象被回收时，就会加入指定的引用队列，通过这个队列可以跟踪对象的回收情况。<br>软引用、弱引用都非常适合来保存那些可有可无的缓存数据。如果这么做，当系统内存不足时，这些缓存数据会被回收，不会导致内存溢出。而当内存资源充足时，这些缓存数据又可以存在相当长的时间，从而起到加速系统的作用。<br>在 JDK1.2 版之后提供了 WeakReference 类来实现弱引用。</p><pre><code class="bash">// 声明强引用Object obj = new Object();WeakReference&lt;Object&gt; sf = new WeakReference&lt;&gt;(obj);obj = null; //销毁强引用弱引用对象与软引用对象的最大不同就在于，当 GC 在进行回收时，需要通过算法检查是否回收软引用对象，而对于弱引用对象，GC 总是进行回收。弱引用对象更容易、更快被 GC 回收。</code></pre><p>弱引用代码示例：</p><pre><code class="bash">public class WeakReferenceTest &#123;    public static class User &#123;        public User(int id, String name) &#123;            this.id = id;            this.name = name;        &#125;        public int id;        public String name;        @Override        public String toString() &#123;            return &quot;[id=&quot; + id + &quot;, name=&quot; + name + &quot;] &quot;;        &#125;    &#125;    public static void main(String[] args) &#123;        //构造了弱引用        WeakReference&lt;User&gt; userWeakRef = new WeakReference&lt;User&gt;(new User(1, &quot;zc&quot;));        //从弱引用中重新获取对象        System.out.println(userWeakRef.get());        System.gc();        // 不管当前内存空间足够与否，都会回收它的内存        System.out.println(&quot;After GC:&quot;);        //重新尝试从弱引用中获取对象        System.out.println(userWeakRef.get());    &#125;&#125;</code></pre><p>执行垃圾回收后，软引用对象必定被清除：</p><pre><code class="bash">[id=1, name=zc] After GC:null</code></pre><p>Process finished with exit code 0<br>虚引用：对象回收跟踪<br>一个对象是否有虚引用的存在，完全不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它和没有引用几乎是一样的，随时都可能被垃圾回收器回收。<br>它不能单独使用，也无法通过虚引用来获取被引用的对象。当试图通过虚引用的 get () 方法取得对象时，总是 null 。即通过虚引用无法获取到我们的数据。<br>为一个对象设置虚引用关联的唯一目的在于跟踪垃圾回收过程。比如：能在这个对象被收集器回收时收到一个系统通知。<br>虚引用必须和引用队列一起使用。虚引用在创建时必须提供一个引用队列作为参数。当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象后，将这个虚引用加入引用队列，以通知应用程序对象的回收情况。<br>由于虚引用可以跟踪对象的回收时间，因此，也可以将一些资源释放操作放置在虚引用中执行和记录。<br>在 JDK1.2 版之后提供了 PhantomReference 类来实现虚引用。</p><pre><code class="bash">// 声明强引用Object obj = new Object();// 声明引用队列ReferenceQueue phantomQueue = new ReferenceQueue();// 声明虚引用（还需要传入引用队列）PhantomReference&lt;Object&gt; sf = new PhantomReference&lt;&gt;(obj, phantomQueue);obj = null; </code></pre><blockquote><p>虚引用代码示例：</p></blockquote><pre><code class="bash">public class PhantomReferenceTest &#123;    public static PhantomReferenceTest obj;//当前类对象的声明    static ReferenceQueue&lt;PhantomReferenceTest&gt; phantomQueue = null;//引用队列    public static class CheckRefQueue extends Thread &#123;        @Override        public void run() &#123;            while (true) &#123;                if (phantomQueue != null) &#123;                    PhantomReference&lt;PhantomReferenceTest&gt; objt = null;                    try &#123;                        objt = (PhantomReference&lt;PhantomReferenceTest&gt;) phantomQueue.remove();                    &#125; catch (InterruptedException e) &#123;                        e.printStackTrace();                    &#125;                    if (objt != null) &#123;                        System.out.println(&quot;追踪垃圾回收过程：PhantomReferenceTest实例被GC了&quot;);                    &#125;                &#125;            &#125;        &#125;    &#125;    @Override    protected void finalize() throws Throwable &#123; //finalize()方法只能被调用一次！        super.finalize();        System.out.println(&quot;调用当前类的finalize()方法&quot;);        obj = this;    &#125;    public static void main(String[] args) &#123;        Thread t = new CheckRefQueue();        t.setDaemon(true);//设置为守护线程：当程序中没有非守护线程时，守护线程也就执行结束。        t.start();        phantomQueue = new ReferenceQueue&lt;PhantomReferenceTest&gt;();        obj = new PhantomReferenceTest();        //构造了 PhantomReferenceTest 对象的虚引用，并指定了引用队列        PhantomReference&lt;PhantomReferenceTest&gt; phantomRef = new PhantomReference&lt;PhantomReferenceTest&gt;(obj, phantomQueue);        try &#123;            //不可获取虚引用中的对象            System.out.println(phantomRef.get());            System.out.println(&quot;第 1 次 gc&quot;);            //将强引用去除            obj = null;            //第一次进行GC,由于对象可复活，GC无法回收该对象            System.gc();            Thread.sleep(1000);            if (obj == null) &#123;                System.out.println(&quot;obj 是 null&quot;);            &#125; else &#123;                System.out.println(&quot;obj 可用&quot;);            &#125;            System.out.println(&quot;第 2 次 gc&quot;);            obj = null;            System.gc(); //一旦将obj对象回收，就会将此虚引用存放到引用队列中。            Thread.sleep(1000);            if (obj == null) &#123;                System.out.println(&quot;obj 是 null&quot;);            &#125; else &#123;                System.out.println(&quot;obj 可用&quot;);            &#125;        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;    &#125;&#125;</code></pre><p>第一次尝试获取虚引用的值，发现无法获取的，这是因为虚引用是无法直接获取对象的值，然后进行第一次 GC ，因为会调用 finalize 方法，将对象复活了，所以对象没有被回收<br>但是调用第二次 GC 操作的时候，因为 finalize 方法只能执行一次，所以就触发了 GC 操作，将对象回收了，同时将会触发第二个操作就是将待回收的对象存入到引用队列中。<br>输出结果：</p><pre><code class="bash">null第 1 次 gc调用当前类的finalize()方法obj 可用第 2 次 gc追踪垃圾回收过程：PhantomReferenceTest实例被GC了obj 是 null</code></pre><p>Process finished with exit code 0<br>终结器引用（了解）<br>它用于实现对象的 finalize () 方法，也可以称为终结器引用；<br>无需手动编码，其内部配合引用队列使用；<br>在 GC 时，终结器引用入队。由 Finalizer 线程通过终结器引用找到被引用对象调用它的 finalize () 方法，第二次 GC 时才回收被引用的对象。<br>大厂面试题<br>蚂蚁金服</p><p>你知道哪几种垃圾回收器，各自的优缺点，重点讲一下 CMS 和 G1 ？<br>JVM GC 算法有哪些，目前的 JDK 版本采用什么回收算法？<br>G1 回收器讲下回收过程，GC 是什么？为什么要有 GC ？<br>GC 的两种判定方法？CMS 收集器与 G1 收集器的特点？<br>百度</p><p>说一下 GC 算法，分代回收说下；<br>垃圾收集策略和算法。<br>天猫</p><p>JVM GC 原理，JVM 怎么回收内存？<br>CMS 特点，垃圾回收算法有哪些？各自的优缺点，他们共同的缺点是什么？<br>滴滴</p><p>Java 的垃圾回收器都有哪些，说下 G1 的应用场景，平时你是如何搭配使用垃圾回收器的？<br>京东</p><p>你知道哪几种垃圾收集器，各自的优缺点，重点讲下 CMS 和 G1 ， 包括原理，流程，优缺点。垃圾回收算法的实现原理 .<br>阿里</p><p>讲一讲垃圾回收算法。<br>什么情况下触发垃圾回收？<br>如何选择合适的垃圾收集算法？<br>JVM 有哪三种垃圾回收器？<br>字节跳动</p><p>常见的垃圾回收器算法有哪些，各有什么优劣？<br>System.gc () 和 Runtime.gc () 会做什么事情？<br>Java GC 机制？GC Roots 有哪些？<br>Java 对象的回收方式，回收算法。<br>CMS 和 G1 了解么，CMS 解决什么问题，说一下回收的过程。<br>CMS 回收停顿了几次，为什么要停顿两次？<br>需要清楚的问题：</p><p>在 JVM 的哪块内存中发生垃圾回收？<br>哪些对象需要被回收？<br>什么时候回收？<br>怎样回收这些对象？</p>]]></content>
      
      
      <categories>
          
          <category> JVM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 垃圾回收 </tag>
            
            <tag> 引用 </tag>
            
            <tag> 内存泄漏 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>对象的内存布局与访问定位</title>
      <link href="/2020/10/31/jvm/%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%86%85%E5%AD%98%E5%B8%83%E5%B1%80%E4%B8%8E%E8%AE%BF%E9%97%AE%E5%AE%9A%E4%BD%8D/"/>
      <url>/2020/10/31/jvm/%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%86%85%E5%AD%98%E5%B8%83%E5%B1%80%E4%B8%8E%E8%AE%BF%E9%97%AE%E5%AE%9A%E4%BD%8D/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="对象的创建"><a href="#对象的创建" class="headerlink" title="对象的创建"></a>对象的创建</h1><p>面试题</p><p>对象在 JVM 中是怎么存储的？<br>对象头信息里面有哪些东西？<br>Java 对象头有什么？<br>从对象创建的方式和步骤开始：</p><p>对象创建的方式<br>new：最常见的方式、单例类中调用 getInstance 的静态类方法，XXXFactory 的静态方法；<br>Class 的 newInstance 方法：在 JDK9 里面被标记为过时的方法，因为只能调用空参构造器；<br>Constructor 的 newInstance (XXX) ：反射的方式，可以调用空参的，或者带参的构造器；<br>使用 clone ()：不调用任何的构造器，要求当前的类需要实现 Cloneable 接口中的 clone 接口；<br>使用序列化：序列化一般用于 Socket 的网络传输；<br>第三方库 Objenesis。<br>对象创建的步骤<br>从字节码看待对象的创建过程：</p><p>示例代码：</p><pre><code class="bash">public class ObjectTest &#123;    public static void main(String[] args) &#123;        Object obj = new Object();    &#125;&#125;</code></pre><p><strong>字节码：</strong></p><pre><code class="bash"> public static void main(java.lang.String[]);    descriptor: ([Ljava/lang/String;)V    flags: ACC_PUBLIC, ACC_STATIC    Code:      stack=2, locals=2, args_size=1         0: new           #2                  // class java/lang/Object         3: dup                    4: invokespecial #1                  // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V         7: astore_1         8: return      LineNumberTable:        line 9: 0        line 10: 8      LocalVariableTable:        Start  Length  Slot  Name   Signature            0       9     0  args   [Ljava/lang/String;            8       1     1   obj   Ljava/lang/Object;&#125;</code></pre><p>1、判断对象对应的类是否加载、链接、初始化</p><p>虚拟机遇到一条 new 指令，首先去检查这个指令的参数能否在 Metaspace（方法区）的常量池中定位到一个类的符号引用，并已经被加载，解析和初始化。（即判断类元信息是否存在）；<br>如果该类没有加载，那么在双亲委派模式下，使用当前类加载器以 ClassLoader + 包名 + 类名为 key 进行查找对应的 .class 文件，如果没有找到文件，则抛出 ClassNotFoundException 异常，如果找到，则进行类加载，并生成对应的 Class 对象。<br>2、为对象分配内存</p><p>首先计算对象占用空间的大小，接着在堆中划分一块内存给新对象。如果实例成员变量是引用变量，仅分配引用变量空间即可，即 4 个字节大小；<br>如果内存规整：采用指针碰撞分配内存。<br>如果内存是规整的，那么虚拟机将采用的是指针碰撞法（Bump The Point）来为对象分配内存。意思是所有用过的内存在一边，空闲的内存放另外一边，中间放着一个指针作为分界点的指示器，分配内存就仅仅是把指针往空闲内存那边挪动一段与对象大小相等的距离罢了。<br>如果垃圾收集器选择的是 Serial ，ParNew 这种基于压缩算法的，虚拟机采用这种分配方式，一般使用带 Compact（整理）过程的收集器时，使用指针碰撞。<br>标记压缩（整理）算法会整理内存碎片，堆内存一边存对象，另一边为空闲区域。<br>如果内存不规整：空闲列表。<br>如果内存不是规整的，已使用的内存和未使用的内存相互交错，那么虚拟机将采用的是空闲列表来为对象分配内存。意思是虚拟机维护了一个列表，记录上哪些内存块是可用的，在分配的时候从列表中找到一块足够大的空间划分给对象实例，并更新列表上的内容。这种分配方式成为了 “空闲列表（Free List）”。<br>选择哪种分配方式由 Java 堆是否规整所决定，而 Java 堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定。<br>标记清除算法清理过后的堆内存，就会存在很多内存碎片。<br>3、处理并发问题</p><ol><li>采用 CAS + 失败重试保证更新的原子性；</li><li>每个线程预先分配 TLAB ，通过设置 -XX:+UseTLAB 参数来设置（区域加锁机制）； 在 Eden 区给每个线程分配一块区域。<br>4、初始化分配到的空间</li></ol><p>所有属性设置默认值，保证对象实例字段在不赋值可以直接使用。<br>给对象属性赋值的顺序：<br>属性的默认值初始化<br>显示初始化 / 代码块初始化（并列关系，谁先谁后看代码编写的顺序）<br>构造器初始化<br>5、设置对象的对象头</p><p>将对象的所属类（即类的元数据信息）、对象的 HashCode 和对象的 GC 信息、锁信息等数据存储在对象的对象头中。这个过程的具体设置方式取决于 JVM 实现。<br>6、执行 init 方法进行初始化</p><p>在 Java 程序的视角看来，初始化才正式开始。初始化成员变量，执行实例化代码块，调用类的构造方法，并把堆内对象的首地址赋值给引用变量；<br>因此一般来说（由字节码中跟随 invokespecial 指令所决定），new 指令之后会接着就是执行 init 方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完成创建出来。<br>从字节码角度看 init 方法</p><pre><code class="bash">/** * 测试对象实例化的过程 *  ① 加载类元信息 - ② 为对象分配内存 - ③ 处理并发问题  - ④ 属性的默认初始化（零值初始化） *  - ⑤ 设置对象头的信息 - ⑥ 属性的显式初始化、代码块中初始化、构造器中初始化 * * *  给对象的属性赋值的操作： *  ① 属性的默认初始化 - ② 显式初始化 / ③ 代码块中初始化 - ④ 构造器中初始化 */public class Customer&#123;    int id = 1001;    String name;    Account acct;    &#123;        name = &quot;匿名客户&quot;;    &#125;    public Customer()&#123;        acct = new Account();    &#125;&#125;class Account&#123;&#125;</code></pre><blockquote><p>字节码信息：</p></blockquote><pre><code class="bash"> 0 aload_0 1 invokespecial #1 &lt;java/lang/Object.&lt;init&gt;&gt; 4 aload_0 5 sipush 1001 8 putfield #2 &lt;com/atguigu/java/Customer.id&gt;11 aload_012 ldc #3 &lt;匿名客户&gt;14 putfield #4 &lt;com/atguigu/java/Customer.name&gt;17 aload_018 new #5 &lt;com/atguigu/java/Account&gt;21 dup22 invokespecial #6 &lt;com/atguigu/java/Account.&lt;init&gt;&gt;25 putfield #7 &lt;com/atguigu/java/Customer.acct&gt;28 return</code></pre><p>init () 方法的字节码指令：</p><p>属性的默认值初始化：id = 1001;<br>显示初始化 / 代码块初始化：name = “匿名客户”;<br>构造器初始化：acct = new Account ();<br>对象的内存布局</p><p>注：指类型指针指向的其实是方法区中存放的类元信息。</p><p>内存布局总结</p><p>对象的访问定位<br>JVM 是如何通过栈帧中的对象引用访问到其内部的对象实例呢？</p><p>定位，通过栈上 reference 访问</p><p>对象的两种访问方式：句柄访问和直接指针：</p><p>句柄访问</p><p>缺点：在堆空间中开辟了一块空间作为句柄池，句柄池本身也会占用空间；通过两次指针访问才能访问到堆中的对象，效率低。<br>优点：reference 中存储稳定句柄地址，对象被移动（垃圾收集时移动对象很普遍）时只会改变句柄中实例数据指针即可，reference 本身不需要被修改。<br>直接指针（HotSpot 采用）</p><p>特点：直接指针是局部变量表中的引用，直接指向堆中的实例，在对象实例中有类型指针，指向的是方法区中的对象类型数据。<br>缺点：对象被移动（垃圾收集时移动对象很普遍）时需要修改 reference 的值。</p>]]></content>
      
      
      <categories>
          
          <category> JVM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 内存布局 </tag>
            
            <tag> 访问定位 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>字符串常量池</title>
      <link href="/2020/10/27/jvm/%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%B8%B8%E9%87%8F%E6%B1%A0/"/>
      <url>/2020/10/27/jvm/%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%B8%B8%E9%87%8F%E6%B1%A0/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="字符串常量池"><a href="#字符串常量池" class="headerlink" title="字符串常量池"></a>字符串常量池</h1><p>String 的基本特性<br>String：字符串，使用一对 “ “ 引起来表示。<br>JAVA<br>1<br>2<br>String s1 = “hello” ;               // 字面量的定义方式<br>String s2 =  new String(“hello”);   // new 对象的方式<br>String 被声明为 final 的，不可被继承。<br>String 实现了 Serializable 接口：表示字符串是支持序列化的；实现了 Comparable 接口：表示 String 可以比较大小。<br>String 在 jdk8 及以前内部定义了 final char value [] 用于存储字符串数据，jdk9 时改为 byte [] 。<br>为什么 JDK9 改变了 String 的结构？</p><p>官方文档：<a href="http://openjdk.java.net/jeps/254">http://openjdk.java.net/jeps/254</a></p><p>为什么改为 byte [] 存储？</p><p>String 类的当前实现将字符存储在 char 数组中，每个字符使用两个字节 (16 位)。从许多不同的应用程序收集的数据表明，字符串是堆的主要组成部分，而且大多数字符串对象只包含拉丁字符（Latin-1），这些字符只需要一个字节的存储空间，因此这些字符串对象的内部 char 数组中有一半的空间将不会使用，产生了大量浪费；<br>之前 String 类使用 UTF-16 的 char [] 数组存储，现在改为 byte [] 数组外加一个编码标识存储。该编码表示如果你的字符是 ISO-8859-1 或者 Latin-1 ，那么只需要一个字节存储。如果你是其它字符集，比如 UTF-8 ，仍然用两个字节存储，这样 String 再也不用 char [] 来存储了，改成了 byte [] 加上编码标记，节约了一些空间，同时基于 String 的数据结构，例如 StringBuffe r 和 StringBuilder 也同样做了修改。<br>JAVA<br>1<br>2<br>3<br>4<br>// 之前<br>private final char value[];<br>// 之后<br>private final byte[] value<br>基本特性</p><p>String：代表不可变的字符序列，简称：不可变性。</p><ul><li>当对字符串重新赋值时，需要重写指定内存区域赋值，不能使用原有的 value 进行赋值。</li><li>当对现有的字符串进行连接操作时，也需要重新指定内存区域赋值，不能使用原有的 value 进行赋值。</li><li>当调用 String 的 replace() 方法修改指定字符或字符串时，也需要重新指定内存区域赋值，不能使用原有的 value 进行赋值。<br>通过字面量的方式（区别于 new ）给一个字符串赋值，此时的字符串值声明在字符串常量池中。<br>当对字符串重新赋值时，需要重写指定内存区域赋值，不能使用原有的 value 进行赋值。</li></ul><p>示例代码：重新赋值</p><p>JAVA<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>@Test<br>   public void test1() {<br>       String s1 = “abc”;//字面量定义的方式，”abc”存储在字符串常量池中<br>       String s2 = “abc”;<br>       s1 = “hello”;</p><pre><code>   System.out.println(s1 == s2);//判断地址：true  --&gt; false   System.out.println(s1);//   System.out.println(s2);//abc</code></pre><p>   }<br>输出：</p><p>JAVA<br>1<br>2<br>3<br>false<br>hello<br>abc<br>字节码指令：</p><p>取字符串 “abc” 时，使用的是同一个符号引用：#2<br>取字符串 “hello” 时，使用的是另一个符号引用：#3<br>当对现有的字符串进行连接操作时，也需要重新指定内存区域赋值，不能使用原有的 value 进行赋值。</p><p>示例代码：字符串连接</p><p>JAVA<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>@Test<br>   public void test2() {<br>       String s1 = “abc”;<br>       String s2 = “abc”;<br>       s2 += “def”;<br>       System.out.println(s2);//abcdef<br>       System.out.println(s1);//abc<br>   }</p><p>当调用 string 的 replace () 方法修改指定字符或字符串时，也需要重新指定内存区域赋值，不能使用原有的 value 进行赋值。</p><p>示例代码：调用 replace（） 方法</p><p>JAVA<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>@Test<br>public void test3() {<br>    String s1 = “abc”;<br>    String s2 = s1.replace(‘a’, ‘m’);<br>    System.out.println(s1);//abc<br>    System.out.println(s2);//mbc<br>}<br>一道笔试题：</p><p>JAVA<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>public class StringExer {<br>    String str = new String(“good”);<br>    char[] ch = {‘t’, ‘e’, ‘s’, ‘t’};</p><pre><code>public void change(String str, char ch[]) &#123;    str = &quot;test ok&quot;;    ch[0] = &#39;b&#39;;&#125;public static void main(String[] args) &#123;    StringExer ex = new StringExer();    ex.change(ex.str, ex.ch);    System.out.println(ex.str);//输出：good    System.out.println(ex.ch);//输出：best&#125;</code></pre><p>}<br>str 的内容并没有变：“test ok” 位于字符串常量池中的另一个区域（地址），进行赋值操作并没有修改原来 str 指向的引用的内容。<br>String 的底层结构<br>字符串常量池是不会存储相同内容的字符串的。</p><p>String 的 String Pool（字符串常量池）是一个固定大小的 Hashtable ，默认值大小长度是 1009。如果放进 String Pool 的 String 非常多，就会造成 Hash 冲突严重，从而导致链表会很长，而链表长了后直接会造成的影响就是当调用 String.intern () 方法时性能会大幅下降。<br>使用 -XX:StringTablesize 可设置 StringTable 的长度；<br>在 JDK6 中 StringTable 是固定的，就是 1009 的长度，所以如果常量池中的字符串过多就会导致效率下降很快，而 StringTablesize 设置没有要求；<br>在 JDK7 中，StringTable 的长度默认值是 60013 ，StringTablesize 设置没有要求；<br>在 JDK8 中，StringTable 的长度默认值是 60013，StringTable 可以设置的最小值为 1009。<br>JDK8 下：</p><pre><code class="bash">Error: Could not create the Java. Virtual Machine.Error: A fatal exception has occurred. Program will exit.StringTable size of 10 is invalid; must be between 1009 and 1305843009213693951</code></pre><blockquote><p>测试不同 StringTable 长度下程序的性能，示例代码如下：</p></blockquote><pre><code class="bash">/** * 产生10万个长度不超过10的字符串，包含a-z,A-Z */public class GenerateString &#123;    public static void main(String[] args) throws IOException &#123;        FileWriter fw =  new FileWriter(&quot;words.txt&quot;);        for (int i = 0; i &lt; 100000; i++) &#123;            //1 - 10           int length = (int)(Math.random() * (10 - 1 + 1) + 1);            fw.write(getString(length) + &quot;\n&quot;);        &#125;        fw.close();    &#125;    public static String getString(int length)&#123;        String str = &quot;&quot;;        for (int i = 0; i &lt; length; i++) &#123;            //65 - 90, 97-122            int num = (int)(Math.random() * (90 - 65 + 1) + 65) + (int)(Math.random() * 2) * 32;            str += (char)num;        &#125;        return str;    &#125;&#125;</code></pre><pre><code class="bash">public class StringTest2 &#123;    public static void main(String[] args) &#123;        BufferedReader br = null;        try &#123;            br = new BufferedReader(new FileReader(&quot;words.txt&quot;));            long start = System.currentTimeMillis();            String data;            while((data = br.readLine()) != null)&#123;                data.intern(); //如果字符串常量池中没有对应data的字符串的话，则在常量池中生成            &#125;            long end = System.currentTimeMillis();            System.out.println(&quot;花费的时间为：&quot; + (end - start));//1009:143ms  100009:47ms        &#125; catch (IOException e) &#123;            e.printStackTrace();        &#125; finally &#123;            if(br != null)&#123;                try &#123;                    br.close();                &#125; catch (IOException e) &#123;                    e.printStackTrace();                &#125;            &#125;        &#125;    &#125;&#125;</code></pre><p>-XX:StringTableSize=1009 ：程序耗时 505ms.<br>-XX:StringTableSize=100009 ：程序耗时 116ms.<br>String 的内存分配<br>在 Java 语言中有 8 种基本数据类型和一种比较特殊的类型 String 。这些类型为了使它们在运行过程中速度更快、更节省内存，都提供了一种常量池的概念。</p><p>常量池就类似一个 Java 系统级别提供的缓存。8 种基本数据类型的常量池都是系统协调的，String 类型的常量池比较特殊。它的主要使用方法有两种：</p><p>直接使用双引号声明出来的 String 对象会直接存储在常量池中。比如：String info=”atqq.com” ;<br>如果不是用双引号声明的 String 对象，可以使用 String 提供的 intern () 方法。<br>Java 6 及以前，字符串常量池存放在永久代；<br>Java 7 中 将字符串常量池的位置调整到 Java 堆内；<br>所有的字符串都保存在堆（Heap）中，和其他普通对象一样，这样可以在进行调优应用时仅需要调整堆大小就可以了；<br>字符串常量池概念原本使用得比较多，但是这个改动使得需要重新考虑在 Java 7 中使用 String.intern ()；<br>Java 8 元空间，字符串常量在堆。<br>StringTable 为什么要调整？</p><p>官方文档:<a href="https://www.oracle.com/java/technologies/javase/jdk7-relnotes.html#jdk7changes">https://www.oracle.com/java/technologies/javase/jdk7-relnotes.html#jdk7changes</a></p><p>永久代的默认空间大小比较小；<br>永久代垃圾回收频率低，大量的字符串无法及时回收，容易进行 Full GC 产生 STW 或者容易产生 OOM：PermGen Space；<br>堆中空间足够大，字符串可被及时回收。<br>在 JDK 7 中，interned 字符串不再在 Java 堆的永久代中分配，而是在 Java 堆的主要部分（称为年轻代和年老代）中分配，与应用程序创建的其他对象一起分配。此更改将导致驻留在主 Java 堆中的数据更多，驻留在永久生成中的数据更少，因此可能需要调整堆大小。</p><p>示例代码：</p><pre><code class="bash">/** * jdk6中： * -XX:PermSize=6m -XX:MaxPermSize=6m -Xms6m -Xmx6m * * jdk8中： * -XX:MetaspaceSize=6m -XX:MaxMetaspaceSize=6m -Xms6m -Xmx6m */public class StringTest3 &#123;    public static void main(String[] args) &#123;        //使用Set保持着常量池引用，避免full gc回收常量池行为        Set&lt;String&gt; set = new HashSet&lt;String&gt;();        //在short可以取值的范围内足以让6MB的PermSize或heap产生OOM了。        short i = 0;        while(true)&#123;            set.add(String.valueOf(i++).intern());        &#125;    &#125;&#125;</code></pre><p>输出结果：字符串真的在堆中（JDK8）</p><pre><code class="bash">Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: Java heap space    at java.util.HashMap.resize(HashMap.java:703)    at java.util.HashMap.putVal(HashMap.java:662)    at java.util.HashMap.put(HashMap.java:611)    at java.util.HashSet.add(HashSet.java:219)    at com.atguigu.java.StringTest3.main(StringTest3.java:22)Process finished with exit code 1</code></pre><p>String 的基本操作<br>Java 语言规范里要求完全相同的字符串字面量，应该包含同样的 Unicode 字符序列（包含同一份码点序列的常量），并且必须是指向同一个 String 类实例。</p><p>示例 1：</p><pre><code class="bash">public class StringTest4 &#123;    public static void main(String[] args) &#123;        System.out.println();//2293        System.out.println(&quot;1&quot;);//2294        System.out.println(&quot;2&quot;);        System.out.println(&quot;3&quot;);        System.out.println(&quot;4&quot;);        System.out.println(&quot;5&quot;);        System.out.println(&quot;6&quot;);        System.out.println(&quot;7&quot;);        System.out.println(&quot;8&quot;);        System.out.println(&quot;9&quot;);        System.out.println(&quot;10&quot;);//2303        //如下的字符串&quot;1&quot; 到 &quot;10&quot;不会再次加载        System.out.println(&quot;1&quot;);//2304        System.out.println(&quot;2&quot;);//2304        System.out.println(&quot;3&quot;);        System.out.println(&quot;4&quot;);        System.out.println(&quot;5&quot;);        System.out.println(&quot;6&quot;);        System.out.println(&quot;7&quot;);        System.out.println(&quot;8&quot;);        System.out.println(&quot;9&quot;);        System.out.println(&quot;10&quot;);//2304    &#125;&#125;</code></pre><p>结论：加依次载完字符串”1” 到”10” ，后面的字符串”1” 到 “10” 不会再次加载。</p><p>字符串拼接操作</p><p>常量与常量的拼接结果在常量池，原理是编译期优化；<br>常量池中不会存在相同内容的变量；<br>拼接前后，只要其中有一个是变量，结果就在堆中。变量拼接的原理是 StringBuilder ；<br>如果拼接的结果调用 intern () 方法，根据该字符串是否在常量池中存在，分为：<br>        -      如果存在，则返回字符串在常量池中的地址；</p><ul><li>如果字符串常量池中不存在该字符串，则在常量池中创建一份，并返回此对象的地址。<br>常量与常量的拼接结果在常量池，原理是编译期优化。<br>示例代码：</li></ul><pre><code class="bash">@Test    public void test1()&#123;        String s1 = &quot;a&quot; + &quot;b&quot; + &quot;c&quot;;//编译期优化：等同于&quot;abc&quot;        String s2 = &quot;abc&quot;; //&quot;abc&quot;一定是放在字符串常量池中，将此地址赋给s2        /*         * 最终.java编译成.class,再执行.class         * String s1 = &quot;abc&quot;;         * String s2 = &quot;abc&quot;         */        System.out.println(s1 == s2); //true        System.out.println(s1.equals(s2)); //true    &#125;</code></pre><blockquote><p>从字节码指令看出：编译器做了优化，将 “a” + “b” + “c” 优化成了 “abc”。</p></blockquote><pre><code class="bash">0 ldc #2 &lt;abc&gt;2 astore_13 ldc #2 &lt;abc&gt;5 astore_26 getstatic #3 &lt;java/lang/System.out&gt;9 aload_110 aload_211 if_acmpne 18 (+7)14 iconst_115 goto 19 (+4)18 iconst_019 invokevirtual #4 &lt;java/io/PrintStream.println&gt;22 getstatic #3 &lt;java/lang/System.out&gt;25 aload_126 aload_227 invokevirtual #5 &lt;java/lang/String.equals&gt;30 invokevirtual #4 &lt;java/io/PrintStream.println&gt;33 return</code></pre><blockquote><p>拼接前后，只要其中有一个是变量，结果就在堆中。而调用 intern () 方法，则主动将字符串对象存入字符串常量池中，并将其地址返回。</p></blockquote><pre><code class="bash">@Test    public void test2()&#123;        String s1 = &quot;javaEE&quot;;        String s2 = &quot;hadoop&quot;;        String s3 = &quot;javaEEhadoop&quot;;        String s4 = &quot;javaEE&quot; + &quot;hadoop&quot;;//编译期优化        //如果拼接符号的前后出现了变量，则相当于在堆空间中new String()，具体的内容为拼接的结果：javaEEhadoop        String s5 = s1 + &quot;hadoop&quot;;        String s6 = &quot;javaEE&quot; + s2;        String s7 = s1 + s2;        System.out.println(s3 == s4);//true        System.out.println(s3 == s5);//false        System.out.println(s3 == s6);//false        System.out.println(s3 == s7);//false        System.out.println(s5 == s6);//false        System.out.println(s5 == s7);//false        System.out.println(s6 == s7);//false        //intern():判断字符串常量池中是否存在javaEEhadoop值，如果存在，则返回常量池中javaEEhadoop的地址；        //如果字符串常量池中不存在javaEEhadoop，则在常量池中加载一份javaEEhadoop，并返回次对象的地址。        String s8 = s6.intern();        System.out.println(s3 == s8);//true    &#125;</code></pre><blockquote><p>从字节码角度来看：拼接前后有变量，都会使用到 StringBuilder 类。</p></blockquote><pre><code class="bash">0 ldc #6 &lt;javaEE&gt;2 astore_13 ldc #7 &lt;hadoop&gt;5 astore_26 ldc #8 &lt;javaEEhadoop&gt;8 astore_39 ldc #8 &lt;javaEEhadoop&gt;11 astore 413 new #9 &lt;java/lang/StringBuilder&gt;16 dup17 invokespecial #10 &lt;java/lang/StringBuilder.&lt;init&gt;&gt;20 aload_121 invokevirtual #11 &lt;java/lang/StringBuilder.append&gt;24 ldc #7 &lt;hadoop&gt;26 invokevirtual #11 &lt;java/lang/StringBuilder.append&gt;29 invokevirtual #12 &lt;java/lang/StringBuilder.toString&gt;32 astore 534 new #9 &lt;java/lang/StringBuilder&gt;37 dup38 invokespecial #10 &lt;java/lang/StringBuilder.&lt;init&gt;&gt;41 ldc #6 &lt;javaEE&gt;43 invokevirtual #11 &lt;java/lang/StringBuilder.append&gt;46 aload_247 invokevirtual #11 &lt;java/lang/StringBuilder.append&gt;50 invokevirtual #12 &lt;java/lang/StringBuilder.toString&gt;53 astore 655 new #9 &lt;java/lang/StringBuilder&gt;58 dup59 invokespecial #10 &lt;java/lang/StringBuilder.&lt;init&gt;&gt;62 aload_163 invokevirtual #11 &lt;java/lang/StringBuilder.append&gt;66 aload_267 invokevirtual #11 &lt;java/lang/StringBuilder.append&gt;70 invokevirtual #12 &lt;java/lang/StringBuilder.toString&gt;73 astore 775 getstatic #3 &lt;java/lang/System.out&gt;78 aload_379 aload 481 if_acmpne 88 (+7)84 iconst_185 goto 89 (+4)88 iconst_089 invokevirtual #4 &lt;java/io/PrintStream.println&gt;92 getstatic #3 &lt;java/lang/System.out&gt;95 aload_396 aload 598 if_acmpne 105 (+7)101 iconst_1102 goto 106 (+4)105 iconst_0106 invokevirtual #4 &lt;java/io/PrintStream.println&gt;109 getstatic #3 &lt;java/lang/System.out&gt;112 aload_3113 aload 6115 if_acmpne 122 (+7)118 iconst_1119 goto 123 (+4)122 iconst_0123 invokevirtual #4 &lt;java/io/PrintStream.println&gt;126 getstatic #3 &lt;java/lang/System.out&gt;129 aload_3130 aload 7132 if_acmpne 139 (+7)135 iconst_1136 goto 140 (+4)139 iconst_0140 invokevirtual #4 &lt;java/io/PrintStream.println&gt;143 getstatic #3 &lt;java/lang/System.out&gt;146 aload 5148 aload 6150 if_acmpne 157 (+7)153 iconst_1154 goto 158 (+4)157 iconst_0158 invokevirtual #4 &lt;java/io/PrintStream.println&gt;161 getstatic #3 &lt;java/lang/System.out&gt;164 aload 5166 aload 7168 if_acmpne 175 (+7)171 iconst_1172 goto 176 (+4)175 iconst_0176 invokevirtual #4 &lt;java/io/PrintStream.println&gt;179 getstatic #3 &lt;java/lang/System.out&gt;182 aload 6184 aload 7186 if_acmpne 193 (+7)189 iconst_1190 goto 194 (+4)193 iconst_0194 invokevirtual #4 &lt;java/io/PrintStream.println&gt;197 aload 6199 invokevirtual #13 &lt;java/lang/String.intern&gt;202 astore 8204 getstatic #3 &lt;java/lang/System.out&gt;207 aload_3208 aload 8210 if_acmpne 217 (+7)213 iconst_1214 goto 218 (+4)217 iconst_0218 invokevirtual #4 &lt;java/io/PrintStream.println&gt;221 return</code></pre><p>字符串拼接的底层细节示例说明：</p><p>示例 1</p><pre><code class="bash">@Testpublic void test3()&#123;    String s1 = &quot;a&quot;;    String s2 = &quot;b&quot;;    String s3 = &quot;ab&quot;;    /*    如下的 s1 + s2 的执行细节：(变量s是临时定义的）    ① StringBuilder s = new StringBuilder();    ② s.append(&quot;a&quot;)    ③ s.append(&quot;b&quot;)    ④ s.toString()  --&gt; 约等于 new String(&quot;ab&quot;)，但不等价    补充：在jdk5.0之后使用的是StringBuilder,在jdk5.0之前使用的是StringBuffer     */    String s4 = s1 + s2;//    System.out.println(s3 == s4);//false&#125;</code></pre><p>字节码指令如下；</p><pre><code class="bash">0 ldc #14 &lt;a&gt;2 astore_13 ldc #15 &lt;b&gt;5 astore_26 ldc #16 &lt;ab&gt;8 astore_39 new #9 &lt;java/lang/StringBuilder&gt;12 dup13 invokespecial #10 &lt;java/lang/StringBuilder.&lt;init&gt;&gt;16 aload_117 invokevirtual #11 &lt;java/lang/StringBuilder.append&gt;20 aload_221 invokevirtual #11 &lt;java/lang/StringBuilder.append&gt;24 invokevirtual #12 &lt;java/lang/StringBuilder.toString&gt;27 astore 429 getstatic #3 &lt;java/lang/System.out&gt;32 aload_333 aload 435 if_acmpne 42 (+7)38 iconst_139 goto 43 (+4)42 iconst_043 invokevirtual #4 &lt;java/io/PrintStream.println&gt;46 return</code></pre><p>示例 2</p><pre><code class="bash">/*    1. 字符串拼接操作不一定使用的是StringBuilder!       如果拼接符号左右两边都是字符串常量或常量引用，则仍然使用编译期优化，即非StringBuilder的方式。    2. 针对于final修饰类、方法、基本数据类型、引用数据类型的量的结构时，能使用上final的时候建议使用上。     */    @Test    public void test4()&#123;        final String s1 = &quot;a&quot;;        final String s2 = &quot;b&quot;;        String s3 = &quot;ab&quot;;        String s4 = s1 + s2;        System.out.println(s3 == s4);//true    &#125;</code></pre><p>从字节码角度来看：为变量 s4 赋值时，直接使用 #16 符号引用，即字符串常量 “ab”。</p><pre><code class="bash">0 ldc #14 &lt;a&gt;2 astore_13 ldc #15 &lt;b&gt;5 astore_26 ldc #16 &lt;ab&gt;8 astore_39 ldc #16 &lt;ab&gt;11 astore 413 getstatic #3 &lt;java/lang/System.out&gt;16 aload_317 aload 419 if_acmpne 26 (+7)22 iconst_123 goto 27 (+4)26 iconst_027 invokevirtual #4 &lt;java/io/PrintStream.println&gt;30 return</code></pre><p>拼接操作与 append 操作的效率对比：</p><pre><code class="bash">    @Test    public void test6()&#123;        long start = System.currentTimeMillis();//        method1(100000);//4014        method2(100000);//7        long end = System.currentTimeMillis();        System.out.println(&quot;花费的时间为：&quot; + (end - start));    &#125;    public void method1(int highLevel)&#123;        String src = &quot;&quot;;        for(int i = 0;i &lt; highLevel;i++)&#123;            src = src + &quot;a&quot;;//每次循环都会创建一个StringBuilder、String        &#125;//        System.out.println(src);    &#125;    public void method2(int highLevel)&#123;        //只需要创建一个StringBuilder        StringBuilder src = new StringBuilder();        for (int i = 0; i &lt; highLevel; i++) &#123;            src.append(&quot;a&quot;);        &#125;//        System.out.println(src);    &#125;</code></pre><p>体会执行效率：通过 StringBuilder 的 append () 的方式添加字符串的效率要远高于使用 String 的字符串拼接方式！<br>原因：<br>StringBuilder 的 append () 的方式：自始至终中只创建过一个 StringBuilder 的对象；<br>使用 String 的字符串拼接方式：创建过多个 StringBuilder 和 String（调的 toString 方法）的对象，内存占用更大；如果进行 GC ，需要花费额外的时间（在拼接的过程中产生的一些中间字符串可能永远也用不到，会产生大量垃圾字符串）。<br>改进的空间：<br>在实际开发中，如果基本确定要前前后后添加的字符串长度不高于某个限定值 highLevel 的情况下，建议使用构造器实例化；<br>StringBuilder s = new StringBuilder(highLevel); //new char[highLevel]<br>可以避免频繁扩容。<br>intern () 的使用<br>intern () 方法的说明：</p><p>JAVA<br>1<br>public native String intern();<br>intern 是一个 native 方法，调用的是底层 C 的方法；</p><p>字符串常量池最初是空的，由 String 类私有地维护。在调用 intern 方法时，如果池中已经包含了由 equals (object) 方法确定的与该字符串内容相等的字符串，则返回池中的字符串地址。否则，该字符串对象将被添加到池中，并返回对该字符串对象的地址（这是源码里的大概翻译）；</p><p>如果不是用双引号声明的 String 对象，可以使用 String 提供的 intern 方法：intern 方法会从字符串常量池中查询当前字符串是否存在，若不存在就会将当前字符串放入常量池中。比如：</p><p>JAVA<br>1<br>String myInfo = new string(“I love you”).intern();<br>如果在任意字符串上调用 String.intern 方法，那么其返回结果所指向的那个类实例，必须和直接以常量形式出现的字符串实例完全相同。因此，下列表达式的值必定是 true ；<br>JAVA<br>1<br>(“a”+”b”+”c”).intern()==”abc”<br>通俗点讲，interned String 就是确保字符串在内存里只有一份拷贝，这样可以节约内存空间，加快字符串操作任务的执行速度。注意，这个值会被存放在字符串内部池（String Intern Pool）。<br>new String () 的说明<br>new String (“ab”) 会创建几个对象？</p><pre><code class="bash">/** * 题目： * new String(&quot;ab&quot;)会创建几个对象？看字节码，就知道是两个。 *     一个对象是：new关键字在堆空间创建的 *     另一个对象是：字符串常量池中的对象&quot;ab&quot;。 字节码指令：ldc * */public class StringNewTest &#123;    public static void main(String[] args) &#123;        String str = new String(&quot;ab&quot;);    &#125;&#125;</code></pre><p>字节码指令：</p><pre><code class="bash">0 new #2 &lt;java/lang/String&gt;3 dup4 ldc #3 &lt;ab&gt;6 invokespecial #4 &lt;java/lang/String.&lt;init&gt;&gt;9 astore_110 return0 new #2 &lt;java/lang/String&gt;：在堆中创建了一个 String 对象4 ldc #3 ：在字符串常量池中放入 “ab”（如果之前字符串常量池中没有 “ab” 的话）</code></pre><h2 id="new-String-“a”-new-String-“b”-会创建几个对象？"><a href="#new-String-“a”-new-String-“b”-会创建几个对象？" class="headerlink" title="new String (“a”) + new String (“b”) 会创建几个对象？"></a>new String (“a”) + new String (“b”) 会创建几个对象？</h2><pre><code class="bash">/** * 思考： * new String(&quot;a&quot;) + new String(&quot;b&quot;)呢？ *  对象1：new StringBuilder() *  对象2： new String(&quot;a&quot;) *  对象3： 常量池中的&quot;a&quot; *  对象4： new String(&quot;b&quot;) *  对象5： 常量池中的&quot;b&quot; * *  深入剖析： StringBuilder的toString(): *      对象6 ：new String(&quot;ab&quot;) *       强调一下，toString()的调用，在字符串常量池中，没有生成&quot;ab&quot; * */public class StringNewTest &#123;    public static void main(String[] args) &#123;        String str = new String(&quot;a&quot;) + new String(&quot;b&quot;);    &#125;&#125;</code></pre><p>字节码指令：</p><pre><code class="bash">0 new #2 &lt;java/lang/StringBuilder&gt;3 dup4 invokespecial #3 &lt;java/lang/StringBuilder.&lt;init&gt;&gt;7 new #4 &lt;java/lang/String&gt;10 dup11 ldc #5 &lt;a&gt;13 invokespecial #6 &lt;java/lang/String.&lt;init&gt;&gt;16 invokevirtual #7 &lt;java/lang/StringBuilder.append&gt;19 new #4 &lt;java/lang/String&gt;22 dup23 ldc #8 &lt;b&gt;25 invokespecial #6 &lt;java/lang/String.&lt;init&gt;&gt;28 invokevirtual #7 &lt;java/lang/StringBuilder.append&gt;31 invokevirtual #9 &lt;java/lang/StringBuilder.toString&gt;34 astore_135 return</code></pre><p>字节码指令分析：</p><p>0 new #2 &lt;java/lang/StringBuilder&gt; ：拼接字符串会创建一个 StringBuilder 对象；<br>7 new #4 &lt;java/lang/String&gt; ：创建 String 对象，对应于 new String (“a”)；<br>11 ldc #5 ：在字符串常量池中放入 “a”（如果之前字符串常量池中没有 “a” 的话）；<br>19 new #4 &lt;java/lang/String&gt; ：创建 String 对象，对应于 new String (“b”)；<br>23 ldc #8 ：在字符串常量池中放入 “b”（如果之前字符串常量池中没有 “b” 的话）；<br>31 invokevirtual #9 &lt;java/lang/StringBuilder.toString&gt; ：调用 StringBuilder 的 toString () 方法，会生成一个 String 对象。<br>如何保证变量 s 指向的是字符串常量池中的数据呢？</p><pre><code class="bash">** * 如何保证变量s指向的是字符串常量池中的数据呢？ * 有两种方式： * 方式一： String s = &quot;shkstart&quot;;//字面量定义的方式 * 方式二： 调用intern() *         String s = new String(&quot;shkstart&quot;).intern(); *         String s = new StringBuilder(&quot;shkstart&quot;).toString().intern(); * */</code></pre><h2 id="String-对象在不同版本中的内存分析？"><a href="#String-对象在不同版本中的内存分析？" class="headerlink" title="String 对象在不同版本中的内存分析？"></a>String 对象在不同版本中的内存分析？</h2><pre><code class="bash">public class StringIntern &#123;    public static void main(String[] args) &#123;        String s = new String(&quot;1&quot;);//这里在字符串常量池中创建了1        s.intern();        String s2 = &quot;1&quot;;        //这里其实是堆中的对象s与字符串常量池中的s2进行判断        System.out.println(s == s2);//jdk6：false   jdk7/8：false                /*         1、s3变量记录的地址为：new String(&quot;11&quot;)         2、经过上面的分析，已经知道在堆中有了一个new String(&quot;11&quot;)这样的String对象，但是在字符串常量池中没有&quot;11&quot;         3、接着执行s3.intern()，在字符串常量池中生成&quot;11&quot;           3-1、在JDK6的版本中，字符串常量池还在永久代，所以直接在永久代生成&quot;11&quot;,也就有了新的地址           3-2、而在JDK7的后续版本中，字符串常量池被移动到了堆中，此时堆里已经有new String（&quot;11&quot;）了，出于节省空间的目的，直接将堆中的那个字符串的引用地址储存在字符串常量池中。没错，字符串常量池中存的是new String（&quot;11&quot;）在堆中的地址         4、所以在JDK7后续版本中，s3和s4指向的完全是同一个地址。         */        String s3 = new String(&quot;1&quot;) + new String(&quot;1&quot;);//pos_1        s3.intern();                String s4 = &quot;11&quot;;//s4变量记录的地址：使用的是上一行代码代码执行时，在常量池中生成的&quot;11&quot;的地址        System.out.println(s3 == s4);//jdk6：false  jdk7/8：true    &#125;&#125;</code></pre><p>注：intern 方法堆中对象的地址引用！！</p><p>JDK6 中输出：</p><p>JAVA<br>1<br>2<br>false<br>false<br>JDK6 中输出：</p><p>JAVA<br>1<br>2<br>false<br>true<br>为什么输出会不一样呢？</p><p>JDK6 ：</p><p>一个是 new 创建的对象，一个是常量池中的对象，显然不是同一个；<br>new String () 即在堆中；<br>str.intern () 则把字符串放入常量池中。<br>JDK7 之后：</p><p>对 s3 和 s4 来说，因为 s3 变量记录的地址是 new String (“11”) ，然后这段代码执行完以后，常量池中不存在 “11”，然后执行 s3.intern () 后，就会在常量池中生成 “11”，最后 s4 用的就是 s3 的地址。<br>拓展一下：</p><p>JAVA<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>/**</p><ul><li><p>StringIntern.java中练习的拓展：</p></li><li></li><li><p>/<br>public class StringIntern1 {<br>  public static void main(String[] args) {</p><pre><code>  //执行完下一行代码以后，字符串常量池中，是否存在&quot;11&quot;呢？答案：不存在！！  String s3 = new String(&quot;1&quot;) + new String(&quot;1&quot;);//new String(&quot;11&quot;)  //在字符串常量池中生成对象&quot;11&quot;，代码顺序换一下，实打实的在字符串常量池里有一个&quot;11&quot;对象  String s4 = &quot;11&quot;;    String s5 = s3.intern();  // s3 是堆中的 &quot;ab&quot; ，s4 是字符串常量池中的 &quot;ab&quot;  System.out.println(s3 == s4);//false  // s5 是从字符串常量池中取回来的引用，当然和 s4 相等  System.out.println(s5 == s4);//true</code></pre><p>  }<br>}<br>intern () 方法的练习<br>练习 1：</p></li></ul><pre><code class="bash">public class StringExer1 &#123;    public static void main(String[] args) &#123;        String x = &quot;ab&quot;;        String s = new String(&quot;a&quot;) + new String(&quot;b&quot;);//new String(&quot;ab&quot;)        //在上一行代码执行完以后，字符串常量池中并没有&quot;ab&quot;        /*        1、jdk6中：在字符串常量池（此时在永久代）中创建一个字符串&quot;ab&quot;        2、jdk8中：字符串常量池（此时在堆中）中没有创建字符串&quot;ab&quot;,而是创建一个引用，指向new String(&quot;ab&quot;)，将此引用返回        3、详解看上面        */        String s2 = s.intern();        System.out.println(s2 == &quot;ab&quot;);//jdk6:true  jdk8:true        System.out.println(s == &quot;ab&quot;);//jdk6:false  jdk8:true    &#125;&#125;</code></pre><p>JDK7/8：练习 2</p><pre><code class="bash">public class StringExer1 &#123;    public static void main(String[] args) &#123;         String x = &quot;ab&quot;;        String s = new String(&quot;a&quot;) + new String(&quot;b&quot;);//new String(&quot;ab&quot;)        String s2 = s.intern();        System.out.println(s2 == &quot;ab&quot;);//jdk6:true  jdk8:true        System.out.println(s == &quot;ab&quot;);//jdk6:false  jdk8:true    &#125;&#125;</code></pre><p>练习 3</p><pre><code class="bash">public class StringExer2 &#123;    // 对象内存地址可以使用System.identityHashCode(object)方法获取    public static void main(String[] args) &#123;        String s1 = new String(&quot;a&quot;) + new String(&quot;b&quot;);//执行完以后，不会在字符串常量池中会生成&quot;ab&quot;        System.out.println(System.identityHashCode(s1));        s1.intern();        System.out.println(System.identityHashCode(s1));        String s2 = &quot;ab&quot;;        System.out.println(System.identityHashCode(s2));        System.out.println(s1 == s2); // true    &#125;&#125;</code></pre><blockquote><p>输出结果：</p></blockquote><pre><code class="bash">183601924018360192401836019240true</code></pre><h2 id="intern-的效率测试（空间角度）"><a href="#intern-的效率测试（空间角度）" class="headerlink" title="intern () 的效率测试（空间角度）"></a>intern () 的效率测试（空间角度）</h2><p>示例代码：</p><pre><code class="bash">/** - 使用intern()测试执行效率：空间使用上 -  3. 结论：对于程序中大量存在的字符串，尤其其中存在很多重复字符串时，使用intern()可以节省内存空间。 -  */public class StringIntern2 &#123;    static final int MAX_COUNT = 1000 * 10000;    static final String[] arr = new String[MAX_COUNT];    public static void main(String[] args) &#123;        Integer[] data = new Integer[]&#123;1,2,3,4,5,6,7,8,9,10&#125;;        long start = System.currentTimeMillis();        for (int i = 0; i &lt; MAX_COUNT; i++) &#123;//            arr[i] = new String(String.valueOf(data[i % data.length]));            arr[i] = new String(String.valueOf(data[i % data.length])).intern();        &#125;        long end = System.currentTimeMillis();        System.out.println(&quot;花费的时间为：&quot; + (end - start));        try &#123;            Thread.sleep(1000000);        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;        System.gc();    &#125;&#125;</code></pre><p>直接 new String：由于每个 String 对象都是 new 出来的，所以程序需要维护大量存放在堆空间中的 String 实例，程序内存占用也会变高；</p><p>使用 intern () 方法：由于数组中字符串的引用都指向字符串常量池中的字符串，所以程序需要维护的 String 对象更少，内存占用也更低；</p><p>JAVA<br>1<br>2<br>//调用了intern()方法使用了字符串常量池里的字符串，那么前面堆里的字符串便会被GC掉，这也是intern省内存的关键原因<br>arr[i] = new String(String.valueOf(data[i % data.length])).intern();<br>结论：</p><p>对于程序中大量使用存在的字符串时，尤其存在很多已经重复的字符串时，使用 intern () 方法能够节省很大的内存空间。</p><p>大的网站平台，需要内存中存储大量的字符串。比如社交网站，很多人都存储：北京市、海淀区等信息。这时候如果字符串都调用 intern () 方法，就会很明显降低内存的大小。</p><p>StringTable 的垃圾回收<br>示例代码：</p><pre><code class="bash">/** * String的垃圾回收: * -Xms15m -Xmx15m -XX:+PrintStringTableStatistics -XX:+PrintGCDetails */public class StringGCTest &#123;    public static void main(String[] args) &#123;        for (int j = 0; j &lt; 100000; j++) &#123;            String.valueOf(j).intern();        &#125;    &#125;&#125;</code></pre><blockquote><p>输出结果：在 PSYoungGen 区发生了垃圾回收。</p></blockquote><p>G1 中的 String 去重操作</p><p>官方文档：<a href="http://openjdk.java.net/jeps/192">http://openjdk.java.net/jeps/192</a></p><p>String 去重操作的背景</p><p>注意不是字符串常量池的去重操作，字符串常量池本身就没有重复的。</p><p>背景：对许多 Java 应用（有大的也有小的）做的测试得出以下结果：<br>堆存活数据集合里面 String 对象占了 25%；<br>堆存活数据集合里面重复的 String 对象有 13.5%；<br>String 对象的平均长度是 45。<br>许多大规模的 Java 应用的瓶颈在于内存，测试表明，在这些类型的应用里面，Java 堆中存活的数据集合差不多 25% 是 String 对象。更进一步，这里面差不多一半 String 对象是重复的，重复的意思是说：str1.equals (str2)=true。堆上存在重复的 String 对象必然是一种内存的浪费。这个项目将在 G1 垃圾收集器中实现自动持续对重复的 String 对象进行去重，这样就能避免浪费内存。<br>String 去重的的实现：</p><p>当垃圾收集器工作的时候，会访问堆上存活的对象。对每一个访问的对象都会检查是否是候选的要去重的 String 对象；<br>如果是，把这个对象的一个引用插入到队列中等待后续的处理。一个去重的线程在后台运行，处理这个队列。处理队列的一个元素意味着从队列删除这个元素，然后尝试去重它引用的 String 对象；<br>使用一个 Hashtable 来记录所有的被 String 对象使用的不重复的 char 数组。当去重的时候，会查这个 Hashtable ，来看堆上是否已经存在一个一模一样的 char 数组；<br>如果存在，String 对象会被调整引用那个数组，释放对原来的数组的引用，最终会被垃圾收集器回收掉；<br>如果查找失败，char 数组会被插入到 Hashtable ，这样以后的时候就可以共享这个数组了。<br>命令行选项：</p><p>UseStringDeduplication (bool) ：开启 String 去重，默认是不开启的，需要手动开启。<br>PrintStringDeduplicationStatistics (bool) ：打印详细的去重统计信息。<br>stringDeduplicationAgeThreshold (uintx) ：达到这个年龄的 String 对象被认为是去重的候选对象。</p>]]></content>
      
      
      <categories>
          
          <category> JVM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 内存分配 </tag>
            
            <tag> intern </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>本地方法接口与本地方法栈</title>
      <link href="/2020/10/23/jvm/%E6%9C%AC%E5%9C%B0%E6%96%B9%E6%B3%95%E6%8E%A5%E5%8F%A3%E4%B8%8E%E6%9C%AC%E5%9C%B0%E6%96%B9%E6%B3%95%E6%A0%88/"/>
      <url>/2020/10/23/jvm/%E6%9C%AC%E5%9C%B0%E6%96%B9%E6%B3%95%E6%8E%A5%E5%8F%A3%E4%B8%8E%E6%9C%AC%E5%9C%B0%E6%96%B9%E6%B3%95%E6%A0%88/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="本地方法接口"><a href="#本地方法接口" class="headerlink" title="本地方法接口"></a>本地方法接口</h1><ul><li>简单地讲，一个 Native Method 是一个 Java 调用非 Java 代码的接囗。一个 Native Method 是这样一个 Java 方法：该方法的实现由非 Java 语言实现，比如 C 。这个特征并非 Java 所特有，很多其它的编程语言都有这一机制，比如在 C++ 中，你可以用 extern “c” 告知 c++ 编译器去调用一个 c 的函数。 - “A native method is a Java method whose implementation is provided by non-java code.”（本地方法是一个非 Java 的方法，它的具体实现是非 Java 代码的实现）。 - 在定义一个 native method 时，并不提供实现体（有些像定义一个 Java interface ），因为其实现体是由非 java 语言在外面实现的。 - 本地接口的作用是融合不同的编程语言为 Java 所用，它的初衷是融合 C/C++ 程序。<br>代码举例说明 Native 方法是如何编写的：</li></ul><p>public class IhaveNatives {<br>    public native void Native1(int x);<br>    native static public long Native2();<br>    native synchronized private float Native3(Object o);<br>    native void Natives(int[] ary) throws Exception;<br>}<br>需要注意的是：标识符 native 可以与其它 java 标识符连用，但是 abstract 除外。<br>为什么使用 Native Method ？</p><p>Java 使用起来非常方便，然而有些层次的任务用 Java 实现起来不容易，或者我们对程序的效率很在意时，问题就来了。<br>与 Java 环境的交互 ，有时 Java 应用需要与 Java 外面的环境交互，这是本地方法存在的主要原因。可以想想 Java 需要与一些底层系统，如操作系统或某些硬件交换信息时的情况。本地方法正是这样一种交流机制：它为我们提供了一个非常简洁的接口，而且我们无需去了解 Java 应用之外的繁琐的细节。<br>与操作系统的交互，JVM 支持着 Java 语言本身和运行时库，它是 Java 程序赖以生存的平台，它由一个解释器（解释字节码）和一些连接到本地代码的库组成。然而不管怎样，它毕竟不是一个完整的系统，它经常依赖于一底层系统的支持。这些底层系统常常是强大的操作系统。通过使用本地方法，我们得以用 Java 实现了 jre 的与底层系统的交互，甚至 JVM 的一些部分就是用 c 写的。还有，如果我们要使用一些 Java 语言本身没有提供封装的操作系统的特性时，我们也需要使用本地方法。<br>Sun’s Java，Sun 的解释器是用 C 实现的，这使得它能像一些普通的 C 一样与外部交互。jre 大部分是用 Java 实现的，它也通过一些本地方法与外界交互。例如：类 java.lang.Thread 的 setpriority（）方法是用 Java 实现的，但是它实现调用的是该类里的本地方法 setpriorityo（）。这个本地方法是用 C 实现的，并被植入 JVM 内部，在 Windows 95 的平台上，这个本地方法最终将调用 Win32 setpriority（）Api 。一个本地方法的具体实现由 JVM 直接提供，更多的情况是本地方法由外部的动态链接库（external dynamic link library）提供，然后被 JVM 调用。<br>现状</p><p>目前该方法使用的越来越少了，除非是与硬件有关的应用，比如通过 Java 程序驱动打印机或者 Java 系统管理生产设备，在企业级应用中已经比较少见。因为现在的异构领域间的通信很发达，比如可以使用 Socket 通信，也可以使用 Web Service 等等，不多做介绍。<br>本地方法栈<br>Java 虚拟机栈于管理 Java 方法的调用，而本地方法栈用于管理本地方法的调用。<br>本地方法栈，也是线程私有的。<br>允许被实现成固定或者是可动态扩展的内存大小。（在内存溢出方面是相同的）<br>如果线程请求分配的栈容量超过本地方法栈允许的最大容量，Java 虚拟机将会抛出一个 stackoverflowError 异常。<br>如果本地方法栈可以动态扩展，并且在尝试扩展的时候无法申请到足够的内存，或者在创建新的线程时没有足够的内存去创建对应的本地方法栈，那么 Java 虚拟机将会抛出一个 outofMemoryError 异常。<br>本地方法是使用 C 语言实现的。<br>它的具体做法是 Native Method Stack 中登记 native 方法，在 Execution Engine 执行时加载本地方法库。</p><p>当某个线程调用一个本地方法时，它就进入了一个全新的并且不再受虚拟机限制的世界。它和虚拟机拥有同样的权限。<br>本地方法可以通过本地方法接口来访问虚拟机内部的运行时数据区。<br>它甚至可以直接使用本地处理器中的寄存器直接从本地内存的堆中分配任意数量的内存。<br>并不是所有的 JVM 都支持本地方法。因为 Java 虚拟机规范并没有明确要求本地方法栈的使用语言、具体实现方式、数据结构等。如果 JVM 产品不打算支持 native 方法，也可以无需实现本地方法栈。<br>在 Hotspot JVM 中，直接将本地方法栈和虚拟机栈合二为一。</p>]]></content>
      
      
      <categories>
          
          <category> JVM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 本地方法栈 </tag>
            
            <tag> 本地方法接口 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>方法区</title>
      <link href="/2020/10/20/jvm/%E6%96%B9%E6%B3%95%E5%8C%BA/"/>
      <url>/2020/10/20/jvm/%E6%96%B9%E6%B3%95%E5%8C%BA/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="方法区"><a href="#方法区" class="headerlink" title="方法区"></a>方法区</h1><p>方法区概述<br>前言<br>方法区是运行时数据区的最后一个部分。</p><p>从线程共享与否的角度来看：</p><p>栈、堆、方法区的交互关系</p><p>Person 类的 .class 信息存放在方法区中；<br>person 变量存放在 Java 栈的局部变量表中；<br>真正的 person 对象存放在 Java 堆中；<br>在 person 对象中，有个指针指向方法区中的 person 类型数据，表明这个 person 对象是用方法区中的 Person 类 new 出来的。<br>方法区的理解</p><p>官方文档：<a href="https://docs.oracle.com/javase/specs/jvms/se8/html/jvms-2.html#jvms-2.5.4">https://docs.oracle.com/javase/specs/jvms/se8/html/jvms-2.html#jvms-2.5.4</a></p><p>方法区在哪里：</p><p>《Java 虚拟机规范》中明确说明：尽管所有的方法区在逻辑上是属于堆的一部分，但一些简单的实现可能不会选择去进行垃圾收集或者进行压缩。但对于 HotSpot JVM 而言，方法区还有一个别名叫做 Non-Heap（非堆），目的就是要和堆分开。<br>所以，方法区可以看作是一块独立于 Java 堆的内存空间 。<br>方法区的基本理解：** 方法区主要存放的是 Class，而堆中主要存放的是实例化的对象。**<br>方法区（Method Area）与 Java 堆一样，是各个线程共享的内存区域。多个线程同时加载同一个类时，只能有一个线程能加载该类，其他线程只能等等待该线程加载完毕，然后直接使用该类，即类只能加载一次。<br>方法区在 JVM 启动的时候被创建，并且它的实际的物理内存空间中和 Java 堆区一样都可以是不连续的。<br>方法区的大小，跟堆空间一样，可以选择固定大小或者可扩展。<br>方法区的大小决定了系统可以保存多少个类，如果系统定义了太多的类，导致方法区溢出，虚拟机同样会抛出内存溢出错误：java.lang.OutofMemoryError:PermGen space 或者 java.lang.OutOfMemoryError:Metaspace 。以下几种情况会导致内存溢出错误：<br>加载大量的第三方的 jar 包；<br>Tomcat 部署的工程过多（30~50 个）；<br>大量动态的生成反射类。<br>关闭 JVM 就会释放这个区域的内存。<br>举例说明：</p><pre><code class="bash">public class MethodAreaDemo &#123;    public static void main(String[] args) &#123;        System.out.println(&quot;start...&quot;);        try &#123;            Thread.sleep(1000000);        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;        System.out.println(&quot;end...&quot;);    &#125;&#125;</code></pre><p>上面简单的程序，加载了 2000 多个类！！</p><p>HotSpot 方法区演进<br>在 JDK7 及以前，习惯上把方法区，称为永久代。JDK8 开始，使用元空间取代了永久代。我们可以将方法区类比为 Java 中的接口，将永久代或元空间类比为 Java 中具体的实现类；<br>本质上，方法区和永久代并不等价。仅是对 Hotspot 而言的可以看作等价。《Java 虚拟机规范》对如何实现方法区，不做统一要求。例如：BEAJRockit/ IBM J9 中不存在永久代的概念；<br>到了 JDK8，终于完全废弃了永久代的概念，改用与 JRockit、J9 一样在本地内存中实现的元空间（Metaspace）来代替；<br>元空间的本质和永久代类似，都是对 JVM 规范中方法区的实现。不过元空间与永久代最大的区别在于：元空间不在虚拟机设置的内存中，而是使用本地内存；<br>永久代、元空间二者并不只是名字变了，内部结构也调整了；<br>根据《Java 虚拟机规范》的规定，如果方法区无法满足新的内存分配需求时，将抛出 OOM 异常。<br>设置方法区大小<br>方法区的大小不必是固定的，JVM 可以根据应用的需要动态调整。</p><p>JDK7 及以前 (永久代)：</p><p>通过 -XX:Permsize 来设置永久代初始分配空间。默认值是 20.75M；<br>-XX:MaxPermsize 来设定永久代最大可分配空间。32 位机器默认是 64M，64 位机器模式是 82M；<br>当 JVM 加载的类信息容量超过了这个值，会报异常 OutofMemoryError:PermGen space 。</p><p>JDK8 及以后 (元空间)：</p><p>元数据区大小可以使用参数 -XX:MetaspaceSize 和 -XX:MaxMetaspaceSize 指定。<br>默认值依赖于平台，Windows 下，-XX:MetaspaceSize 约为 21M，-XX:MaxMetaspaceSize 的值是 - 1，即没有限制。<br>与永久代不同，如果不指定大小，默认情况下，虚拟机会耗尽所有的可用系统内存。如果元数据区发生溢出，虚拟机一样会抛出异常 OutOfMemoryError:Metaspace。<br>-XX:MetaspaceSize：设置初始的元空间大小。对于一个 64 位 的服务器端 JVM 来说，其默认的 -XX:MetaspaceSize 值为 21MB。这就是初始的高水位线，一旦触及这个水位线，Full GC 将会被触发并卸载没用的类（即这些类对应的类加载器不再存活），然后这个高水位线将会重置。新的高水位线的值取决于 GC 后释放了多少元空间。如果释放的空间不足，那么在不超过 MaxMetaspaceSize 时，适当提高该值。如果释放空间过多，则适当降低该值。<br>如果初始化的高水位线设置过低，上述高水位线调整情况会发生很多次。通过垃圾回收器的日志可以观察到 Full GC 多次调用。为了避免频繁地 GC，建议将 -XX:MetaspaceSize 设置为一个相对较高的值。<br>方法区 OOM<br>代码示例：OOMTest 类继承 ClassLoader 类，获得 defineClass () 方法，可自己进行类的加载。</p><pre><code class="bash">/** * jdk6/7中： * -XX:PermSize=10m -XX:MaxPermSize=10m * * jdk8中： * -XX:MetaspaceSize=10m -XX:MaxMetaspaceSize=10m * */public class OOMTest extends ClassLoader &#123;    public static void main(String[] args) &#123;        int j = 0;        try &#123;            OOMTest test = new OOMTest();            for (int i = 0; i &lt; 10000; i++) &#123;                //创建ClassWriter对象，用于生成类的二进制字节码                ClassWriter classWriter = new ClassWriter(0);                //指明版本号，修饰符，类名，包名，父类，接口                classWriter.visit(Opcodes.V1_8, Opcodes.ACC_PUBLIC, &quot;Class&quot; + i, null, &quot;java/lang/Object&quot;, null);                //返回byte[]                byte[] code = classWriter.toByteArray();                //类的加载                test.defineClass(&quot;Class&quot; + i, code, 0, code.length);//Class对象                j++;            &#125;        &#125; finally &#123;            System.out.println(j);        &#125;    &#125;&#125;</code></pre><blockquote><p>不设置元空间的上限：使用默认的 JVM 参数，元空间不设置上限。输出结果：</p></blockquote><pre><code class="bash">10000</code></pre><blockquote><p>设置元空间的上限：参数：-XX:MetaspaceSize=10m -XX:MaxMetaspaceSize=10m 输出结果：</p></blockquote><pre><code class="bash">8531Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: Metaspace    at java.lang.ClassLoader.defineClass1(Native Method)    at java.lang.ClassLoader.defineClass(ClassLoader.java:763)    at java.lang.ClassLoader.defineClass(ClassLoader.java:642)    at com.heu.method.OOMTest.main(OOMTest.java:29)</code></pre><h2 id="如何解决-OOM"><a href="#如何解决-OOM" class="headerlink" title="如何解决 OOM?"></a>如何解决 OOM?</h2><p>这个属于调优的问题，这里先简单的说一下</p><p>要解决 OOM 异常或 heap space 的异常，一般的手段是首先通过内存映像分析工具（如 Eclipse MemoryAnalyzer）对 dump 出来的堆转储快照进行分析，重点是确认内存中的对象是否是必要的，也就是要先分清楚到底是出现了内存泄漏（Memory Leak）还是内存溢出（Memory Overflow）；<br>内存泄漏就是有大量的引用指向某些对象，但是这些对象以后不会使用了，但是因为它们还和 GC ROOT 有关联，所以导致以后这些对象也不会被回收，这就是内存泄漏的问题；<br>如果是内存泄漏，可进一步通过工具查看泄漏对象到 GC Roots 的引用链。于是就能找到泄漏对象是通过怎样的路径与 GC Roots 相关联并导致垃圾收集器无法自动回收它们的。掌握了泄漏对象的类型信息，以及 GC Roots 引用链的信息，就可以比较准确地定位出泄漏代码的位置。<br>如果不存在内存泄漏，换句话说就是内存中的对象确实都还必须存活着，那就应当检查虚拟机的堆参数（-Xmx 与 - Xms），与机器物理内存对比看是否还可以调大，从代码上检查是否存在某些对象生命周期过长、持有状态时间过长的情况，尝试减少程序运行期的内存消耗。<br>方法区的内部结构<br>方法区存储什么？</p><p>《深入理解 Java 虚拟机》书中对方法区（Method Area）存储内容描述如下：它用于存储已被虚拟机加载的类型信息、常量、静态变量、即时编译器编译后的代码缓存等。</p><p>在这里插入图片描述</p><p>类型信息</p><p>对每个加载的类型（类 class、接口 interface、枚举 enum、注解 annotation），JVM 必须在方法区中存储以下类型信息：</p><p>这个类型的完整有效名称（全名 = 包名。类名）；<br>这个类型直接父类的完整有效名（对于 interface 或是 java.lang.Object，都没有父类）；<br>这个类型的修饰符（public，abstract，final 的某个子集）；<br>这个类型直接接口的一个有序列表。<br>域（Field）信息</p><p>也就是我们常说的成员变量，域信息是比较官方的称呼。</p><p>JVM 必须在方法区中保存类型的所有域的相关信息以及域的声明顺序；<br>域的相关信息包括：域名称，域类型，域修饰符（public，private，protected，static，final，volatile，transient 的某个子集）。<br>方法（Method）信息</p><p>JVM 必须保存所有方法的以下信息，同域信息一样包括声明顺序：</p><p>方法名称；<br>方法的返回类型（包括 void 返回类型），void 在 Java 中对应的为 void.class；<br>方法参数的数量和类型（按顺序）；<br>方法的修饰符（public，private，protected，static，final，synchronized，native，abstract 的一个子集）；<br>方法的字节码（byte codes）、操作数栈、局部变量表及大小（abstract 和 native 方法除外）；<br>异常表（abstract 和 native 方法除外），异常表记录每个异常处理的开始位置、结束位置、代码处理在程序计数器中的偏移地址、被捕获的异常类的常量池索引。<br>举例说明</p><pre><code class="bash">** * 测试方法区的内部构成 */ public class MethodInnerStructTest extends Object implements Comparable&lt;String&gt;,Serializable &#123;    //属性    public int num = 10;    private static String str = &quot;测试方法的内部结构&quot;;        //构造器    //方法    public void test1()&#123;        int count = 20;        System.out.println(&quot;count = &quot; + count);    &#125;    public static int test2(int cal)&#123;        int result = 0;        try &#123;            int value = 30;            result = value / cal;        &#125; catch (Exception e) &#123;            e.printStackTrace();        &#125;        return result;    &#125;    @Override    public int compareTo(String o) &#123;        return 0;    &#125;&#125;</code></pre><pre><code class="bash">javap -v -p MethodInnerStructTest.class &gt; test.txt</code></pre><p>反编译字节码文件，并输出值文本文件中，便于查看。参数 -p 确保能查看 private 权限类型的字段或方法。字节码指令：</p><pre><code class="bash">Classfile  /E:/Projects/JVM/out/production/com/heu/java/MethodInnerStructTest.class  Last modified 2021-3-7; size 1626 bytes  MD5 checksum 0d0fcb54854d4ce183063df985141ad0  Compiled from &quot;MethodInnerStructTest.java&quot;//类型信息      public class com.heu.java.MethodInnerStructTest extends java.lang.Object implements java.lang.Comparable&lt;java.lang.String&gt;, java.io.Serializable  minor version: 0  major version: 52  flags: ACC_PUBLIC, ACC_SUPERConstant pool:   #1 = Methodref          #18.#52        // java/lang/Object.&quot;&lt;init&gt;&quot;:()V   #2 = Fieldref           #17.#53        // com/heu/java/MethodInnerStructTest.num:I   #3 = Fieldref           #54.#55        // java/lang/System.out:Ljava/io/PrintStream;   #4 = Class              #56            // java/lang/StringBuilder   #5 = Methodref          #4.#52         // java/lang/StringBuilder.&quot;&lt;init&gt;&quot;:()V   #6 = String             #57            // count =   #7 = Methodref          #4.#58         // java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder;   #8 = Methodref          #4.#59         // java/lang/StringBuilder.append:(I)Ljava/lang/StringBuilder;   #9 = Methodref          #4.#60         // java/lang/StringBuilder.toString:()Ljava/lang/String;</code></pre><p>类型信息：在运行时方法区中，类信息中记录了哪个加载器加载了该类，同时类加载器也记录了它加载了哪些类。</p><pre><code class="bash">//类型信息      public class com.heu.java.MethodInnerStrucTest extends java.lang.Object implements java.lang.Comparable&lt;java.lang.String&gt;, java.io.Serializable</code></pre><p>域信息：</p><p>descriptor：I 表示字段类型为 Integer；<br>flags：ACC_PUBLIC 表示字段权限修饰符为 public。</p><pre><code class="bash">//域信息  public int num;    descriptor: I    flags: ACC_PUBLIC  private static java.lang.String str;    descriptor: Ljava/lang/String;    flags: ACC_PRIVATE, ACC_STATIC</code></pre><p>方法信息：</p><p>descriptor： () V 表示方法返回值类型为 void；<br>flags：ACC_PUBLIC 表示方法权限修饰符为 public；<br>stack=3 表示操作数栈深度为 3；<br>locals=2 表示局部变量个数为 2 个（实例方法包含 this）；<br>test1 () 方法虽然没有参数，但是其 args_size=1 ，这时因为将 this 作为了参数。</p><pre><code class="bash">public void test1();    descriptor: ()V    flags: ACC_PUBLIC    Code:      stack=3, locals=2, args_size=1         0: bipush        20         2: istore_1         3: getstatic     #3                  // Field java/lang/System.out:Ljava/io/PrintStream;         6: new           #4                  // class java/lang/StringBuilder         9: dup        10: invokespecial #5                  // Method java/lang/StringBuilder.&quot;&lt;init&gt;&quot;:()V        13: ldc           #6                  // String count =        15: invokevirtual #7                  // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder;        18: iload_1        19: invokevirtual #8                  // Method java/lang/StringBuilder.append:(I)Ljava/lang/StringBuilder;        22: invokevirtual #9                  // Method java/lang/StringBuilder.toString:()Ljava/lang/String;        25: invokevirtual #10                 // Method java/io/PrintStream.println:(Ljava/lang/String;)V        28: return      LineNumberTable:        line 17: 0        line 18: 3        line 19: 28      LocalVariableTable:        Start  Length  Slot  Name   Signature            0      29     0  this   Lcom/heu/java/MethodInnerStructTest;            3      26     1 count   I</code></pre><p>non-final 类型的类（静态）变量</p><p>静态变量和类关联在一起，随着类的加载而加载，它们成为类数据在逻辑上的一部分；<br>类变量（静态变量）被类的所有实例共享，即使没有类实例时，也可以访问它。<br>举例说明：</p><p>如下代码所示，即使我们把 order 设置为 null，也不会出现空指针异常；<br>这更加表明了 static 类型的字段和方法随着类的加载而加载，并不属于特定的类实例。</p><pre><code class="bash">public class MethodAreaTest &#123;    public static void main(String[] args) &#123;        Order order = null;        order.hello();        System.out.println(order.count);    &#125;&#125;class Order &#123;    public static int count = 1;    public static final int number = 2;    public static void hello() &#123;        System.out.println(&quot;hello!&quot;);    &#125;&#125;</code></pre><blockquote><p>输出结果：</p></blockquote><pre><code class="bash">hello!1</code></pre><p>全局常量：static final</p><p>全局常量就是使用 static final 进行修饰；<br>被声明为 final 的类变量的处理方法则不同，每个全局常量在编译的时候就会被分配了。<br>举例说明：</p><p>JAVA<br>1<br>2<br>3<br>4<br>5<br>class Order {<br>    public static int count = 1;<br>    public static final int number = 2;<br>    …<br>}<br>查看上面代码的字节码指令：</p><pre><code class="bash">public static int count;    descriptor: I    flags: ACC_PUBLIC, ACC_STATIC  public static final int number;    descriptor: I    flags: ACC_PUBLIC, ACC_STATIC, ACC_FINAL    ConstantValue: int 2</code></pre><blockquote><p>总结：可以发现 staitc 和 final 同时修饰的 number 的值在编译上的时候已经写死在字节码文件中了。</p></blockquote><p>运行时常量池<br>运行时常量池 VS 常量池</p><p>官方文档：<a href="https://docs.oracle.com/javase/specs/jvms/se8/html/jvms-4.html">https://docs.oracle.com/javase/specs/jvms/se8/html/jvms-4.html</a></p><p>方法区，内部包含了运行时常量池；<br>字节码文件，内部包含了常量池。（之前的字节码文件中已经看到了很多 Constant pool 的东西，这个就是常量池）；<br>要弄清楚方法区，需要理解清楚 Class File ，因为加载类的信息都在方法区；<br>要弄清楚方法区的运行时常量池，需要理解清楚 Class File 中的常量池。<br>常量池</p><p>一个有效的字节码文件中除了包含类的版本信息、字段、方法以及接口等描述符信息外。还包含一项信息就是常量池表（Constant Pool Table），包括各种字面量和对类型、域和方法的符号引用；<br>字面量： 10 ， “我是某某” ，这种数字和字符串都是字面量。</p><p>为什么需要常量池？<br>一个 java 源文件中的类、接口，编译后产生一个字节码文件，而 Java 中的字节码需要数据支持，通常这种数据会很大以至于不能直接存到字节码里，因此换另一种方式，可以存到常量池。字节码包含了指向常量池的引用，在动态链接的时候会用到运行时常量池（类的加载过程中有讲）。<br>比如下面代码：</p><pre><code class="bash">public class SimpleClass &#123;    public void sayHello() &#123;        System.out.println(&quot;hello&quot;);    &#125;&#125;</code></pre><p>虽然上述代码很小，但是里面却使用了 String、System、PrintStream 及 Object 等结构；<br>这个文件中有 6 个地方用到了 ”hello” 这个字符串，如果不用常量池，就需要在 6 个地方全写一遍，造成臃肿。可以将 ”hello” 等所需用到的结构信息记录在常量池中，并通过引用的方式，来加载、调用所需的结构；<br>这里的代码量其实很少了，如果代码多的话，引用的结构将会更多，这里就需要用到常量池了。<br>常量池中有什么？</p><p>数量值<br>字符串值<br>类引用<br>字段引用<br>方法引用<br>上面的 MethodInnerStructTest 的 test1 方法的字节码如下：</p><pre><code class="bash"> 0 bipush 20 2 istore_1 3 getstatic #3 &lt;java/lang/System.out&gt; 6 new #4 &lt;java/lang/StringBuilder&gt; 9 dup10 invokespecial #5 &lt;java/lang/StringBuilder.&lt;init&gt;&gt;13 ldc #6 &lt;count = &gt;15 invokevirtual #7 &lt;java/lang/StringBuilder.append&gt;18 iload_119 invokevirtual #8 &lt;java/lang/StringBuilder.append&gt;22 invokevirtual #9 &lt;java/lang/StringBuilder.toString&gt;25 invokevirtual #10 &lt;java/io/PrintStream.println&gt;28 return</code></pre><p>#3，#5 等等这些带# 的，都是引用了常量池。常量池、可以看做是一张表，虚拟机指令根据这张常量表找到要执行的类名、方法名、参数类型、字面量等类型。</p><h2 id="运行时常量池"><a href="#运行时常量池" class="headerlink" title="运行时常量池"></a>运行时常量池</h2><p>运行时常量池（Runtime Constant Pool）是方法区的一部分；<br>常量池表（Constant Pool Table）是 Class 字节码文件的一部分，用于存放编译期生成的各种字面量与符号引用，这部分内容将在类加载后存放到方法区的运行时常量池中。（运行时常量池就是常量池在程序运行时的称呼）；<br>运行时常量池，在加载类和接口到虚拟机后，就会创建对应的运行时常量池；<br>JVM 为每个已加载的类型（类或接口）都维护一个常量池。池中的数据项像数组项一样，是通过索引访问的；<br>运行时常量池中包含多种不同的常量，包括编译期就已经明确的数值字面量，也包括运行期解析后才能够获得的方法或者字段引用。此时不再是常量池中的符号地址了，这里换为真实地址。而运行时常量池，相对于 Class 文件常量池的另一重要特征是：具备动态性；<br>运行时常量池类似于传统编程语言中的符号表（symbol table），但是它所包含的数据却比符号表要更加丰富一些；<br>当创建类或接口的运行时常量池时，如果构造运行时常量池所需的内存空间超过了方法区所能提供的最大值，则 JVM 会抛 OutofMemoryError 异常。<br>方法区的使用举例<br>示例代码：</p><pre><code class="bash">public class MethodAreaDemo &#123;    public static void main(String[] args) &#123;        int x = 500;        int y = 100;        int a = x / y;        int b = 50;        System.out.println(a + b);    &#125;&#125;</code></pre><p>对应字节码：</p><pre><code class="bash">public class com.heu.java.MethodAreaDemo  minor version: 0  major version: 51  flags: ACC_PUBLIC, ACC_SUPERConstant pool:   #1 = Methodref          #5.#24         // java/lang/Object.&quot;&lt;init&gt;&quot;:()V   #2 = Fieldref           #25.#26        // java/lang/System.out:Ljava/io/PrintStream;   #3 = Methodref          #27.#28        // java/io/PrintStream.println:(I)V   #4 = Class              #29            // com/heu/java/MethodAreaDemo   #5 = Class              #30            // java/lang/Object   #6 = Utf8               &lt;init&gt;   #7 = Utf8               ()V   #8 = Utf8               Code   #9 = Utf8               LineNumberTable  #10 = Utf8               LocalVariableTable  #11 = Utf8               this  #12 = Utf8               Lcom/heu/java/MethodAreaDemo;  #13 = Utf8               main  #14 = Utf8               ([Ljava/lang/String;)V  #15 = Utf8               args  #16 = Utf8               [Ljava/lang/String;  #17 = Utf8               x  #18 = Utf8               I  #19 = Utf8               y  #20 = Utf8               a  #21 = Utf8               b  #22 = Utf8               SourceFile  #23 = Utf8               MethodAreaDemo.java  #24 = NameAndType        #6:#7          // &quot;&lt;init&gt;&quot;:()V  #25 = Class              #31            // java/lang/System  #26 = NameAndType        #32:#33        // out:Ljava/io/PrintStream;  #27 = Class              #34            // java/io/PrintStream  #28 = NameAndType        #35:#36        // println:(I)V  #29 = Utf8               com/heu/java/MethodAreaDemo  #30 = Utf8               java/lang/Object  #31 = Utf8               java/lang/System  #32 = Utf8               out  #33 = Utf8               Ljava/io/PrintStream;  #34 = Utf8               java/io/PrintStream  #35 = Utf8               println  #36 = Utf8               (I)V&#123;  public com.heu.java.MethodAreaDemo();    descriptor: ()V    flags: ACC_PUBLIC    Code:      stack=1, locals=1, args_size=1         0: aload_0         1: invokespecial #1                  // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V         4: return      LineNumberTable:        line 7: 0      LocalVariableTable:        Start  Length  Slot  Name   Signature            0       5     0  this   Lcom/heu/java/MethodAreaDemo;  public static void main(java.lang.String[]);    descriptor: ([Ljava/lang/String;)V    flags: ACC_PUBLIC, ACC_STATIC    Code:      stack=3, locals=5, args_size=1         0: sipush        500         3: istore_1         4: bipush        100         6: istore_2         7: iload_1         8: iload_2         9: idiv        10: istore_3        11: bipush        50        13: istore        4        15: getstatic     #2                  // Field java/lang/System.out:Ljava/io/PrintStream;        18: iload_3        19: iload         4        21: iadd        22: invokevirtual #3                  // Method java/io/PrintStream.println:(I)V        25: return      LineNumberTable:        line 9: 0        line 10: 4        line 11: 7        line 12: 11        line 13: 15        line 14: 25      LocalVariableTable:        Start  Length  Slot  Name   Signature            0      26     0  args   [Ljava/lang/String;            4      22     1     x   I            7      19     2     y   I           11      15     3     a   I           15      11     4     b   I&#125;</code></pre><p>SourceFile: “MethodAreaDemo.java”<br>图解字节码指令执行流程：</p><p>1、初始状态；</p><p>2、首先将操作数 500 压入操作数栈中；</p><p>3、然后操作数 500 从操作数栈中取出，存储到局部变量表中索引为 1 的位置；</p><p>4、重复一次，把 100 压如操作数栈中，之后放入局部变量表中，最后再将变量表中的 500 和 100 取出，进行操作；</p><p>5、将 500 和 100 进行一个除法运算，再把结果入栈；</p><p>接着 50 入栈出栈，并将其保存在局部变量 4 中；</p><p>6、将 50 和 5 压入操作数栈，并执行加法操作；</p><p>7、最后调用 invokevirtual（虚方法调用），进行打印，然后返回。<br>返回时：<br>程序计数器始终计算的都是当前代码运行的位置，目的是为了方便记录方法调用后能够正常返回，或者是进行了 CPU 切换后，也能回来到原来的代码进行执行。<br>符号引用 –&gt; 直接引用</p><p>上面代码调用 System.out.println () 方法时，首先需要看看 System 类有没有加载，再看看 PrintStream 类有没有加载；<br>如果没有加载，则执行加载，执行时，将常量池中的符号引用（字面量）转换为运行时常量池的直接引用（真正的地址值）。<br>方法区演进细节与垃圾回收<br>方法区演进细节<br>永久代演进过程：</p><p>首先明确：只有 Hotspot 才有永久代。BEA JRockit、IBMJ9 等来说，是不存在永久代的概念的。原则上如何实现方法区属于虚拟机实现细节，不受《Java 虚拟机规范》管束，并不要求统一。<br>Hotspot 中方法区的变化如下图：</p><p>JDK6 ：方法区由永久代实现，使用 JVM 虚拟机内存（虚拟的内存)。</p><p>JDK7 ：方法区由永久代实现，使用 JVM 虚拟机内存。</p><p>JDK8 ：方法区由元空间实现，使用物理机本地内存。</p><p>永久代为什么要被元空间替代？</p><p>官方文档：<a href="http://openjdk.java.net/jeps/122">http://openjdk.java.net/jeps/122</a></p><p>随着 Java8 的到来，HotSpot VM 中再也见不到永久代了。但是这并不意味着类的元数据信息也消失了，这些数据被移到了一个与堆不相连的本地内存区域，这个区域叫做元空间（Metaspace）。<br>由于类的元数据分配在本地内存中，元空间的最大可分配空间就是系统可用内存空间。<br>这项改动是很有必要的，原因有：<br>为永久代设置空间大小是很难确定的。在某些场景下，如果动态加载类过多，容易产生 Perm 区的 OOM 。比如某个实际 Web 工程中，因为功能点比较多，在运行过程中，要不断动态加载很多类，经常出现致命错误。如：Exception in thread ‘dubbo client x.x connector’ java.lang .OutOfMemoryError:PermGen space，而元空间和永久代之间最大的区别在于：元空间并不在虚拟机中，而是使用本地内存。 因此，默认情况下，元空间的大小仅受本地内存限制。<br>对永久代进行调优是很困难的。方法区的垃圾收集主要回收两部分内容：常量池中废弃的常量和不再用的类型，方法区的调优主要是为了降低 Full GC。<br>字符串常量池</p><p>字符串常量池 StringTable 为什么要调整位置？</p><p>JDK7 中将 StringTable 放到了堆空间中。因为永久代的回收效率很低，在 Full GC 的时候才会执行永久代的垃圾回收，而 Full GC 是老年代的空间不足、永久代不足时才会触发，这就导致 StringTable 回收效率不高，而开发中会有大量的字符串被创建，回收效率低，导致永久代内存不足，放到堆里，能及时回收内存。</p><p>静态变量放在哪里</p><p>对象实体在哪里放着？</p><pre><code class="bash">/** * 结论： * 1、静态引用对应的对象实体(也就是这个new byte[1024 * 1024 * 100])始终都存在堆空间， * 2、只是那个变量(相当于下面的arr变量名)在 JDK6,JDK7,JDK8 存放位置中有所变化 * * jdk7： * -Xms200m -Xmx200m -XX:PermSize=300m -XX:MaxPermSize=300m -XX:+PrintGCDetails * jdk 8： * -Xms200m -Xmx200m -XX:MetaspaceSize=300m -XX:MaxMetaspaceSize=300m -XX:+PrintGCDetails */public class StaticFieldTest &#123;    private static byte[] arr = new byte[1024 * 1024 * 100];//100MB    public static void main(String[] args) &#123;        System.out.println(StaticFieldTest.arr);    &#125;&#125;</code></pre><p>JDK6 环境下：</p><p>JDK7 环境下：</p><p>JDK8 环境下：</p><p>变量 (名) 存放在哪里？用 JHSDB 工具来进行分析：</p><pre><code class="bash">public class StaticObjTest &#123;    static class Test &#123;        static ObjectHolder staticObj = new ObjectHolder();        ObjectHolder instanceObj = new ObjectHolder();        void foo() &#123;            ObjectHolder localObj = new ObjectHolder();            System.out.println(&quot;done&quot;);        &#125;    &#125;    private static class ObjectHolder &#123;    &#125;    public static void main(String[] args) &#123;        Test test = new StaticObjTest.Test();        test.foo();    &#125;&#125;</code></pre><p>JDK6 环境下：</p><p>staticObj 随着 Test 的类型信息存放在方法区；</p><p>instanceObj 随着 Test 的对象实例存放在 Java 堆；</p><p>localObject （局部变量）则是存放在 foo () 方法栈帧的局部变量表中；</p><p>测试发现：三个对象的数据在内存中的地址都落在 Eden 区范围内，所以结论：只要是对象实例必然会在 Java 堆中分配。</p><p>0x00007f32c7800000 (Eden 区的起始地址) —- 0x00007f32c7b50000 (Eden 区的终止地址)，<br>可以发现三个变量都在这个范围内，<br>所以可以得到上面结论。<br>接着，找到了一个引用该 staticObj 对象的地方，是在一个 java.lang.Class 的实例里，并且给出了这个实例的地址，通过 Inspector 查看该对象实例，可以清楚看到这确实是一个 java.lang.Class 类型的对象实例，里面有一个名为 staticobj 的实例字段：</p><p>从《Java 虚拟机规范》所定义的概念模型来看，所有 Class 相关的信息都应该存放在方法区之中，但方法区该如何实现，《Java 虚拟机规范》并未做出规定，这就成了一件允许不同虚拟机自己灵活把握的事情。JDK7 及其以后版本的 HotSpot 虚拟机选择把静态变量与类型在 Java 语言一端的映射 Class 对象存放在一起，存储于 Java 堆之中，从实验中也明确验证了这一点。<br>方法区的垃圾回收<br>有些人认为方法区（如 Hotspot 虚拟机中的元空间或者永久代）是没有垃圾收集行为的，其实不然。《Java 虚拟机规范》对方法区的约束是非常宽松的，提到过可以不要求虚拟机在方法区中实现垃圾收集。事实上也确实有未实现或未能完整实现方法区类型卸载的收集器存在（如 JDK11 时期的 ZGC 收集器就不支持类卸载）。</p><p>一般来说这个区域的回收效果比较难令人满意，尤其是类型的卸载，条件相当苛刻。但是这部分区域的回收有时又确实是必要的。以前 sun 公司的 Bug 列表中，曾出现过的若干个严重的 Bug 就是由于低版本的 HotSpot 虚拟机对此区域未完全回收而导致内存泄漏。</p><p>方法区的垃圾收集主要回收两部分内容：常量池中废弃的常量和不再使用的类型。</p><p>先来说说方法区内常量池之中主要存放的两大类常量：字面量和符号引用。字面量比较接近 Java 语言层次的常量概念，如文本字符串、被声明为 final 的常量值等。而符号引用则属于编译原理方面的概念，包括下面三类常量：</p><p>类和接口的全限定名<br>字段的名称和描述符<br>方法的名称和描述符<br>HotSpot 虚拟机对常量池的回收策略是很明确的，只要常量池中的常量没有被任何地方引用，就可以被回收。</p><p>回收废弃常量与回收 Java 堆中的对象非常类似。（关于常量的回收比较简单，重点是类的回收）</p><p>方法区的类卸载：</p><p>判定一个常量是否 “废弃” 还是相对简单，而要判定一个类型是否属于 “不再被使用的类” 的条件就比较苛刻了。需要同时满足下面三个条件：</p><p>该类所有的实例都已经被回收，也就是 Java 堆中不存在该类及其任何派生子类的实例；<br>加载该类的类加载器已经被回收，这个条件除非是经过精心设计的可替换类加载器的场景，如 OSGi、JSP 的重加载等，否则通常是很难达成的；<br>该类对应的 java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。<br>Java 虚拟机被允许对满足上述三个条件的无用类进行回收，这里说的仅仅是 “被允许”，而并不是和对象一样，没有引用了就必然会回收。关于是否要对类型进行回收，HotSpot 虚拟机提供了”-Xnoclassgc “参数进行控制，还可以使用 -verbose:class 以及 -XX：+TraceClass-Loading、-XX： +TraceClassUnLoading 查看类加载和卸载信息。</p><p>在大量使用反射、动态代理、CGLib 等字节码框架，动态生成 JSP 以及 OSGi 这类频繁自定义类加载器的场景中，通常都需要 Java 虚拟机具备类型卸载的能力，以保证不会对方法区造成过大的内存压力。</p><p>运行时数据区总结</p><p>常见面试题<br>百度</p><p>三面：说一下 JVM 内存模型吧，有哪些区？分别干什么的？<br>蚂蚁金服：</p><p>Java8 的内存分代改进<br>JVM 内存分哪几个区，每个区的作用是什么？<br>一面：JVM 内存分布 / 内存结构？栈和堆的区别？堆的结构？为什么两个 survivor 区？<br>二面：Eden 和 survior 的比例分配。<br>小米：</p><p>jvm 内存分区，为什么要有新生代和老年代？<br>字节跳动：</p><p>二面：Java 的内存分区<br>二面：讲讲 jvm 运行时数据库区。<br>什么时候对象会进入老年代？<br>京东：</p><p>JVM 的内存结构，Eden 和 Survivor 比例。<br>JVM 内存为什么要分成新生代，老年代，持久代。新生代中为什么要分为 Eden 和 survivor。<br>天猫：</p><p>一面：Jvm 内存模型以及分区，需要详细到每个区放什么。<br>一面：JVM 的内存模型，Java8 做了什么改变？<br>拼多多：</p><p>JVM 内存分哪几个区，每个区的作用是什么？<br>美团：</p><p>java 内存分配<br>jvm 的永久代中会发生垃圾回收吗？<br>一面：jvm 内存分区，为什么要有新生代和老年代？</p>]]></content>
      
      
      <categories>
          
          <category> JVM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 垃圾回收 </tag>
            
            <tag> 方法区 </tag>
            
            <tag> 内部结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>堆</title>
      <link href="/2020/10/15/jvm/%E5%A0%86/"/>
      <url>/2020/10/15/jvm/%E5%A0%86/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="堆"><a href="#堆" class="headerlink" title="堆"></a>堆</h2><p>堆的基本概述<br>堆的概念<br>《Java 虚拟机规范》中对 Java 堆的描述是：所有的对象实例以及数组都应当在运行时分配在堆上。（The heap is the run-time data area from which memory for all class instances and arrays is allocated）。</p><p>但从实际使用角度看，“几乎” 所有的对象实例都在这里分配内存。因为还有一些对象是在栈上分配的，而数组和对象可能永远不会存储在栈上，因为栈帧中保存引用，这个引用指向对象或者数组在堆中的位置。</p><p>堆针对一个 JVM 进程来说是唯一的，也就是说一个进程对应着一个 JVM 实例，但是进程包含多个线程，他们是共享同一堆空间的；<br>一个 JVM 实例只存在一个堆内存，堆是 Java 内存管理的核心区域；<br>Java 堆区在 JVM 启动的时候即被创建，其空间大小也就确定了，是 JVM 管理的最大一块内存空间；<br>但堆内存的大小是可以调节的；<br>《Java 虚拟机规范》规定，堆可以处于物理上不连续的内存空间中，但在逻辑上它应该被视为连续的（可类比操作系统）；<br>Java 堆中可以划分线程私有的缓冲区（Thread Local Allocation Buffer，TLAB），也就是说堆中不是所有信息都是线程共享。<br>下面代码对于堆内存进行说明：</p><pre><code class="bash">public class HeapDemo &#123;    public static void main(String[] args) &#123;        System.out.println(&quot;start...&quot;);        try &#123;            Thread.sleep(1000000);        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;        System.out.println(&quot;end...&quot;);    &#125;&#125;</code></pre><p>设置堆大小：</p><p>-Xms10m：最小堆内存<br>-Xmx10m：最大堆内存<br>在这里插入图片描述<br>下图就是使用 Java VisualVM 查看堆空间的内容，通过 VisualVM 中的 GC 插件。</p><p>在方法结束后，堆中的对象不会马上被移除，仅仅在垃圾收集的时候才会被移除也就是触发了 GC 的时候，才会进行回收。</p><p>因为如果堆中对象马上被回收，那么用户线程就会收到影响。</p><p>堆、Java 栈和方法区之间联系：</p><p>在这里插入图片描述</p><p>堆内存细分<br>Java 7 及之前堆内存逻辑上分为三部分：新生区 + 养老区 + 永久区：</p><p>Young Generation Space 新生区 Young/New 又被划分为 Eden 区和 Survivor 区；<br>Tenure generation space 养老区 Old/Tenure；<br>Permanent Space 永久区 Perm。<br>Java 8 及之后堆内存逻辑上分为三部分：新生区 + 养老区 + 元空间：</p><p>Young Generation Space 新生区 Young/New 又被划分为 Eden 区和 Survivor 区；<br>Tenure generation space 养老区 Old/Tenure；<br>Meta Space 元空间 Meta。<br>约定：新生区 -&gt; 新生代 -&gt; 年轻代 、 养老区 -&gt; 老年区 -&gt; 老年代、 永久区 -&gt; 永久代</p><p>堆空间内部结构，JDK1.8 之前从永久代 替换成 元空间！！！</p><p>堆空间逻辑上包括新生代、老年代、元空间，实际上只包括新生代和老年代，元空间也叫方法区！！！</p><p>设置堆内存大小与 OOM<br>Java 堆区用于存储 Java 对象实例，那么堆的大小在 JVM 启动时就已经设定好了，可以通过选项”-Xmx” 和”-Xms” 来进行设置。</p><p>“-Xms” 用于表示堆区的起始内存，等价于 - xx:InitialHeapSize；<br>“-Xmx” 则用于表示堆区的最大内存，等价于 - XX:MaxHeapSize。<br>一旦堆区中的内存大小超过 “-xmx” 所指定的最大内存时，将会抛出 outofMemoryError 异常。<br>通常会将 - Xms 和 - Xmx 两个参数配置相同的值，其目的是为了能够在 Java 垃圾回收机制清理完堆区后不需要重新分隔计算堆区的大小，从而提高性能。<br>默认情况下：</p><p>初始内存大小：物理电脑内存大小 / 64；<br>最大内存大小：物理电脑内存大小 / 4。<br>下面代码测试查看堆内存大小：</p><pre><code class="bash">public class HeapSpaceInitial &#123;    public static void main(String[] args) &#123;        //返回Java虚拟机中的堆内存总量        long initialMemory = Runtime.getRuntime().totalMemory() / 1024 / 1024;        //返回Java虚拟机试图使用的最大堆内存量        long maxMemory = Runtime.getRuntime().maxMemory() / 1024 / 1024;        System.out.println(&quot;-Xms : &quot; + initialMemory + &quot;M&quot;);        System.out.println(&quot;-Xmx : &quot; + maxMemory + &quot;M&quot;);        //System.out.println(&quot;系统内存大小为：&quot; + initialMemory * 64.0 / 1024 + &quot;G&quot;);        //System.out.println(&quot;系统内存大小为：&quot; + maxMemory * 4.0 / 1024 + &quot;G&quot;);        try &#123;            Thread.sleep(1000000);        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;    &#125;&#125;</code></pre><p>输出结果：</p><p>JAVA<br>1<br>2<br>-Xms : 246M<br>-Xmx : 3934M<br>如何查看堆内存的内存分配情况：</p><p>JAVA<br>1<br>jps  -&gt;  jstat -gc 进程id</p><p><img src="https://img-blog.csdnimg.cn/20210220203635951.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMzNjI2OTk2,size_16,color_FFFFFF,t_70"> **OutOfMemory 举例 **：</p><pre><code class="bash">public class OOMTest &#123;    public static void main(String[] args) &#123;        ArrayList&lt;Picture&gt; list = new ArrayList&lt;&gt;();        while(true)&#123;            try &#123;                Thread.sleep(20);            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;            list.add(new Picture(new Random().nextInt(1024 * 1024)));        &#125;    &#125;&#125;class Picture&#123;    private byte[] pixels;    public Picture(int length) &#123;        this.pixels = new byte[length];    &#125;&#125;</code></pre><p>设置启动参数</p><p>JAVA<br>1<br>-Xms500m -Xmx:500m<br>JAVA<br>1<br>2<br>Exception in thread “main” java.lang.OutOfMemoryError: Java heap space<br>    at com.heu.heap.OOMTest.main(OOMTest.java:21)<br>通过 VisualVM 工具查看具体内存占用：</p><p>可以看到当 Used heap 达到 500，就会出现 OOM 异常。</p><p>年轻代与老年代<br>存储在 JVM 中的 Java 对象可以被划分为两类：</p><p>一类是生命周期较短的瞬时对象，这类对象的创建和消亡都非常迅速，生命周期短的，及时回收即可；<br>另一类对象的生命周期却非常长，在某些极端的情况下还能够与 JVM 的生命周期保持一致。<br>Java 堆区进一步细分的话，可以划分为年轻代（YoungGen）和老年代（oldGen）。其中年轻代又可以划分为 Eden 空间、Survivor0 空间和 Survivor1 空间（有时也叫做 from 区、to 区）。</p><p>下面的堆参数开发中一般不会调：</p><p>Eden：From：to -&gt; 8:1:1<br>新生代：老年代 - &gt; 1 : 2<br>配置新生代与老年代在堆结构的占比：</p><p>默认 - XX:NewRatio=2，表示新生代占 1，老年代占 2，新生代占整个堆的 1/3；<br>可以修改 - XX:NewRatio=4，表示新生代占 1，老年代占 4，新生代占整个堆的 1/5；<br>当发现在整个项目中，生命周期长的对象偏多，那么就可以通过调整老年代的大小，来进行调优；<br>在 HotSpot 虚拟机中，Eden 空间和另外两个 survivor 空间缺省所占的比例是 8：1：1 当然开发人员可以通过选项 “-xx:SurvivorRatio” 调整这个空间比例，比如 - xx:SurvivorRatio=8。<br>几乎所有的 Java 对象都是在 Eden 区被 new 出来的，绝大部分（80%）Java 对象的销毁都在新生代进行，（有些大的对象在 Eden 区无法存储时候，将直接进入老年代）。</p><p>可以使用选项”-Xmn” 设置新生代最大内存大小。而这个参数一般使用默认值就可以了。</p><p>对象分配过程<br>概念<br>为新对象分配内存是一件非常严谨和复杂的任务，JVM 的设计者们不仅需要考虑内存如何分配、在哪里分配等问题，并且由于内存分配算法与内存回收算法密切相关，所以还需要考虑 GC 执行完内存回收后是否会在内存空间中产生内存碎片。</p><p>下面几点说明：</p><p>new 的对象先放伊甸园区，此区有大小限制；<br>当伊甸园的空间填满时，程序又需要创建对象，JVM 的垃圾回收器对伊甸园区进行垃圾回（MinorGC），将伊甸园区中的不再被其他对象所引用的对象进行销毁，再加载新的对象放到伊甸园区；<br>然后将伊甸园中的剩余对象移动到幸存者 0 区；<br>如果再次触发垃圾回收，此时上次幸存下来的放到幸存者 0 区的，如果没有回收，就会放到幸存者 1 区（0 区、1 区互相换）；<br>如果再次经历垃圾回收，此时会重新放回幸存者 0 区，接着再去幸存者 1 区。<br>啥时候能去养老区呢？可以设置次数。默认是 15 次；<br>在养老区，相对悠闲。当养老区内存不足时，再次触发 GC：Major GC，进行养老区的内存清理；<br>若养老区执行了 Major GC 之后，发现依然无法进行对象的保存，就会产生 OOM 异常。<br>可以设置参数（次数）：-Xx:MaxTenuringThreshold= N 进行设置。</p><p>对象分配图解过程<br>我们创建的对象，一般都是存放在 Eden 区的，当 Eden 区满了后，就会触发 GC 操作，一般被称为 YGC / Minor GC 操作；</p><p>当我们进行一次垃圾收集后，红色的将会被回收，而绿色的还会被占用着，存放在 S0 (Survivor From) 区。同时给每个对象设置了一个年龄计数器，一次回收后就是 1；</p><p>同时 Eden 区继续存放对象，当 Eden 区再次存满的时候，又会触发一个 MinorGC 操作，此时 GC 将会把 Eden 和 Survivor From 中的对象 进行一次收集，把存活的对象放到 Survivor To 区，同时让年龄 + 1；</p><p>我们继续不断的进行对象生成和垃圾回收，当 Survivor 中的对象的年龄达到 15 的时候，将会触发一次 Promotion 晋升的操作，即将年轻代中的对象晋升到老年代中；</p><p>幸存区区满了后？</p><p>特别注意，在 Eden 区满了的时候，才会触发 MinorGC，而幸存者区满了后，不会触发 MinorGC 操作；<br>如果 Survivor 区满了后，将会触发一些特殊的规则，也就是可能直接晋升老年代。<br>举例：以当兵为例，正常人的晋升可能是 ： 新兵 -&gt; 班长 -&gt; 排长 -&gt; 连长。</p><p>但是也有可能有些人因为做了非常大的贡献，直接从 新兵 -&gt; 排长。</p><p>对象分配的特殊情况</p><p>代码演示对象分配过程</p><p>示例程序：不断的创建大对象添加到 list 中：</p><pre><code class="bash">public class HeapInstanceTest &#123;    byte [] buffer = new byte[new Random().nextInt(1024 * 200)];    public static void main(String[] args) throws InterruptedException &#123;        ArrayList&lt;HeapInstanceTest&gt; list = new ArrayList&lt;&gt;();        while (true) &#123;            list.add(new HeapInstanceTest());            Thread.sleep(10);        &#125;    &#125;&#125;</code></pre><p>然后设置 JVM 参数：</p><pre><code class="bash">-Xms600m -Xmx600m</code></pre><p>之后打开 VisualVM 工具，通过执行上面代码，通过 VisualGC 进行动态化查看： <img src="https://img-blog.csdnimg.cn/20210222210529173.gif"> 最终，在老年代和新生代都满了，就出现 OOM。</p><pre><code class="bash">Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: Java heap space    at com.heu.heap.HeapInstanceTest.&lt;init&gt;(HeapInstanceTest.java:13)    at com.heu.heap.HeapInstanceTest.main(HeapInstanceTest.java:17)</code></pre><p>总结</p><p>针对幸存者 s0，s1 区的总结：复制之后有交换，谁空谁是 to（s0，s1 不固定）；<br>关于垃圾回收：频繁在新生区收集，很少在老年代收集，几乎不在永久代和元空间进行收集；<br>新生代采用复制算法的目的：是为了减少内碎片。<br>Minor GC，MajorGC、Full GC<br>Minor GC：新生代的 GC<br>Major GC：老年代的 GC<br>Full GC：整堆收集，收集整个 Java 堆和方法区的垃圾收集<br>我们都知道，JVM 的调优的一个环节，也就是垃圾收集，我们需要尽量的避免垃圾回收，因为在垃圾回收的过程中，容易出现 STW（stop the word）的问题，而 Major GC 和 Full GC 出现 STW 的时间，是 Minor GC 的 10 倍以上。</p><p>JVM 在进行 GC 时，并非每次都对上面三个内存区域一起回收的，大部分时候回收的都是指新生代。针对 Hotspot VM 的实现，它里面的 GC 按照回收区域又分为两大种类型：一种是部分收集（Partial GC），一种是整堆收集（FullGC）。</p><p>部分收集：不是完整收集整个 Java 堆的垃圾收集。其中又分为：</p><p>新生代收集（MinorGC/YoungGC）：只是新生代的垃圾收集。<br>老年代收集（MajorGC/o1dGC）：只是老年代的圾收集。<br>       - 目前，只有CMS GC会有单独收集老年代的行为；<br>       - 注意，很多时候Major GC会和Full GC混淆使用，需要具体分辨是老年代回收还是整堆回收。<br>混合收集（MixedGC）：收集整个新生代以及部分老年代的垃圾收集。<br>       - 目前，只有G1 GC会有这种行为。<br>整堆收集（FullGC）：收集整个 java 堆和方法区的垃圾收集。</p><p>Minor GC</p><p>当年轻代空间不足时，就会触发 MinorGC，这里的年轻代满指的是 Eden 代满，Survivor 满不会引发 GC，（每次 Minor GC 会清理年轻代的内存）；<br>因为 Java 对象大多都具备 朝生夕灭 的特性，所以 Minor GC 非常频繁，一般回收速度也比较快；<br>Minor GC 会引发 STW（stop the word），暂停其它用户的线程，等垃圾回收结束，用户线程才恢复运行。<br>Major GC</p><p>Majoy GC 指发生在老年代的 GC，对象从老年代消失时，就说 “Major GC” 或 “Full GC” 发生了。</p><p>出现了 Major GC，经常会伴随至少一次的 Minor GC（但非绝对的，在 Paralle1 Scavenge 收集器的收集策略里就有直接进行 Major GC 的策略选择过程），也就是在老年代空间不足时，会先尝试触发 Minor GC。如果之后空间还不足，则触发 Major GC；<br>Major GC 的速度一般会比 MinorGc 慢 10 倍以上，STW 的时间更长，如果 Major GC 后，内存还不足，就报 OOM 了。<br>Full GC</p><p>触发 Full GC 执行的情况有如下五种：</p><p>调用 System.gc（）时，系统建议执行 Full GC，但是不必然执行；<br>老年代空间不足；<br>方法区空间不足；<br>通过 Minor GC 后进入老年代的平均大小大于老年代的可用内存；<br>由 Eden 区、survivor spacee（From Space）区向 survivor spacel（To Space）区复制时，对象大小大于 To Space 可用内存，则把该对象转存到老年代，且老年代的可用内存小于该对象大小（即年轻代、老年代的内存大小装不下该对象）。<br>说明：Full GC 是开发或调优中尽量要避免的。这样暂时时间会短一些。</p><p>GC 举例</p><p>编写一个 OOM 的异常，不断的创建字符串示例:</p><pre><code class="bash">public class GCTest &#123;    public static void main(String[] args) &#123;        int i = 0;        try &#123;            List&lt;String&gt; list = new ArrayList&lt;&gt;();            String a = &quot;mogu blog&quot;;            while(true) &#123;                list.add(a);                a = a + a;                i++;            &#125;        &#125;catch (Exception e) &#123;            e.getStackTrace();        &#125;    &#125;&#125;</code></pre><p>设置 JVM 启动参数：</p><pre><code class="bash">-Xms10m -Xmx10m -XX:+PrintGCDetails</code></pre><p>打印出的日志：</p><pre><code class="bash">[GC (Allocation Failure) [PSYoungGen: 2038K-&gt;500K(2560K)] 2038K-&gt;797K(9728K), 0.3532002 secs] [Times: user=0.01 sys=0.00, real=0.36 secs] [GC (Allocation Failure) [PSYoungGen: 2108K-&gt;480K(2560K)] 2405K-&gt;1565K(9728K), 0.0014069 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] [Full GC (Ergonomics) [PSYoungGen: 2288K-&gt;0K(2560K)] [ParOldGen: 6845K-&gt;5281K(7168K)] 9133K-&gt;5281K(9728K), [Metaspace: 3482K-&gt;3482K(1056768K)], 0.0058675 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] [GC (Allocation Failure) [PSYoungGen: 0K-&gt;0K(2560K)] 5281K-&gt;5281K(9728K), 0.0002857 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] [Full GC (Allocation Failure) [PSYoungGen: 0K-&gt;0K(2560K)] [ParOldGen: 5281K-&gt;5263K(7168K)] 5281K-&gt;5263K(9728K), [Metaspace: 3482K-&gt;3482K(1056768K)], 0.0058564 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] Heap PSYoungGen      total 2560K, used 60K [0x00000000ffd00000, 0x0000000100000000, 0x0000000100000000)  eden space 2048K, 2% used [0x00000000ffd00000,0x00000000ffd0f138,0x00000000fff00000)  from space 512K, 0% used [0x00000000fff00000,0x00000000fff00000,0x00000000fff80000)  to   space 512K, 0% used [0x00000000fff80000,0x00000000fff80000,0x0000000100000000) ParOldGen       total 7168K, used 5263K [0x00000000ff600000, 0x00000000ffd00000, 0x00000000ffd00000)  object space 7168K, 73% used [0x00000000ff600000,0x00000000ffb23cf0,0x00000000ffd00000) Metaspace       used 3514K, capacity 4498K, committed 4864K, reserved 1056768K  class space    used 388K, capacity 390K, committed 512K, reserved 1048576K    Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: Java heap space    at java.util.Arrays.copyOfRange(Arrays.java:3664)    at java.lang.String.&lt;init&gt;(String.java:207)    at java.lang.StringBuilder.toString(StringBuilder.java:407)    at com.heu.heap.GCTest.main(GCTest.java:20)</code></pre><pre><code class="bash">[GC (Allocation Failure) [PSYoungGen: 2038K-&gt;500K(2560K)] 2038K-&gt;797K(9728K), 0.3532002 secs] [PSYoungGen: 2038K-&gt;500K (2560K)]：年轻代总空间为 2560K ，当前占用 2038K ，经过垃圾回收后剩余 500K；2038K-&gt;797K (9728K)：堆内存总空间为 9728K ，当前占用 2038K ，经过垃圾回收后剩余 797K。</code></pre><blockquote><p>触发 OOM 的时候，一定是进行了一次 Full GC，因为只有在老年代空间不足时候，才会爆出 OOM 异常。</p></blockquote><h1 id="堆空间分代思想"><a href="#堆空间分代思想" class="headerlink" title="堆空间分代思想"></a>堆空间分代思想</h1><p>为什么要把 Java 堆分代？不分代就不能正常工作了吗？</p><p>经研究，不同对象的生命周期不同。70%-99% 的对象是临时对象。</p><p>新生代：有 Eden、两块大小相同的 survivor（又称为 from/to 或 s0/s1）构成，to 总为空。<br>老年代：存放新生代中经历多次 GC 仍然存活的对象。<br>其实不分代完全可以，分代的唯一理由就是优化 GC 性能。</p><p>如果没有分代，那所有的对象都在一块，就如同把一个学校的人都关在一个教室。GC 的时候要找到哪些对象没用，这样就会对堆的所有区域进行扫描。（性能低）<br>而很多对象都是朝生夕死的，如果分代的话，把新创建的对象放到某一地方，当 GC 的时候先把这块存储 “朝生夕死” 对象的区域进行回收，这样就会腾出很大的空间出来。（多回收新生代，少回收老年代，性能会提高很多）<br>对象内存分配策略<br>如果对象在 Eden 区出生并经过第一次 Minor GC 后仍然存活，并且能被 Survivor 容纳的话，将被移动到 Survivor 空间中，并将对象年龄设为 1。<br>对象在 Survivor 区中每熬过一次 Minor GC，年龄就增加 1 岁，当它的年龄增加到一定程度（默认为 15 岁，其实每个 JVM、每个 GC 都有所不同）时，就会被晋升到老年代。<br>对象晋升老年代的年龄阀值，可以通过选项 <strong>-XX:MaxTenuringThreshold</strong> 来设置。<br>针对不同年龄段的对象分配原则如下所示：</p><p>优先分配到 Eden：开发中比较长的字符串或者数组，会直接存在老年代，但是因为新创建的对象都是朝生夕死的，所以这个大对象可能也很快被回收，但是因为老年代触发 Major GC 的次数比 Minor GC 要更少，因此可能回收起来就会比较慢。<br>大对象直接分配到老年代：尽量避免程序中出现过多的大对象。<br>长期存活的对象分配到老年代。<br>动态对象年龄判断：如果 Survivor 区中相同年龄的所有对象大小的总和大于 Survivor 空间的一半，年龄大于或等于该年龄的对象可以直接进入老年代，无须等到 MaxTenuringThreshold 中要求的年龄。<br>空间分配担保： -XX:HandlePromotionFailure 。<br>TLAB 为对象分配内存<br>为什么要有 TLAB？<br>堆区是线程共享区域，任何线程都可以访问到堆区中的共享数据；<br>由于对象实例的创建在 JVM 中非常频繁，因此在并发环境下从堆区中划分内存空间是线程不安全的；<br>为避免多个线程操作同一地址，需要使用加锁等机制，进而影响分配速度。<br>什么是 TLAB？<br>TLAB（Thread Local Allocation Buffer）：</p><p>从内存模型而不是垃圾收集的角度，对 Eden 区域继续进行划分，JVM 为每个线程分配了一个私有缓存区域（栈中提到），它包含在 Eden 空间内；<br>多线程同时分配内存时，使用 TLAB 可以避免一系列的非线程安全问题，同时还能够提升内存分配的吞吐量，因此可以将这种内存分配方式称之为快速分配策略；<br>目前所知，所有 OpenJDK 衍生出来的 JVM 都提供了 TLAB 的设计。</p><p>每个线程都有一个 TLAB 空间；<br>当一个线程的 TLAB 存满时，可以使用公共区域（蓝色）的。<br>说明</p><p>尽管不是所有的对象实例都能够在 TLAB 中成功分配内存，但 JVM 确实是将 TLAB 作为内存分配的首选。</p><p>在程序中，开发人员可以通过选项 -XX:UseTLAB 设置是否开启 TLAB 空间。</p><p>默认情况下，TLAB 空间的内存非常小，仅占有整个 Eden 空间的 1%，当然我们可以通过选项 -XX:TLABWasteTargetPercent 设置 TLAB 空间所占用 Eden 空间的百分比大小。</p><p>一旦对象在 TLAB 空间分配内存失败时，JVM 就会尝试着通过使用加锁机制确保数据操作的原子性，从而直接在 Eden 空间中分配内存。</p><p>注： 哪个线程要分配内存，就在哪个线程的本地缓冲区中分配，只有本地缓冲区用完 了，分配新的缓存区时才需要同步锁定 —《深入理解 JVM》第三版 。</p><p>代码演示</p><p>代码示例：</p><pre><code class="bash">//-XX:UseTLAB参数是否开启的情况:默认情况是开启的public class TLABArgsTest &#123;    public static void main(String[] args) &#123;        System.out.println(&quot;我只是来打个酱油~&quot;);        try &#123;            Thread.sleep(1000000);        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;    &#125;&#125;</code></pre><p>终端输入 jsp，查看 TLABArgsTest 进程 id;<br>jinfo -flag UseTLAB 36732（进程 id），输出 - XX:+UseTLAB，证明 TLAB 默认是开启的.<br>image-20210815093435986<br>TLAB 分配过程</p><p>在这里插入图片描述</p><p>堆空间的参数设置</p><pre><code class="bash">-XX:PrintFlagsInitial: 查看所有参数的默认初始值-XX:PrintFlagsFinal：查看所有的参数的最终值（可能会存在修改，不再是初始值）具体查看某个参数的指令：      - jps：查看当前运行中的进程;      - jinfo -flag SurvivorRatio 进程id： 查看新生代中Eden和S0/S1空间的比例.-Xms: 初始堆空间内存（默认为物理内存的1/64）-Xmx: 最大堆空间内存（默认为物理内存的1/4）-Xmn: 设置新生代大小（初始值及最大值）-XX:NewRatio: 配置新生代与老年代在堆结构的占比-XX:SurvivorRatio：设置新生代中Eden和S0/S1空间的比例-XX:MaxTenuringThreshold：设置新生代垃圾的最大年龄(默认15)-XX:+PrintGCDetails：输出详细的GC处理日志        打印gc简要信息：① -XX:+PrintGC   ② -verbose:gc-XX:HandlePromotionFailure：是否设置空间分配担保</code></pre><p>说明<br>在发生 Minor Gc 之前，虚拟机会检查老年代最大可用的连续空间是否大于新生代所有对象的总空间。</p><p>如果大于，则此次 Minor GC 是安全的；<br>如果小于，则虚拟机会查看 - XX:HandlePromotionFailure 设置值是否允许担保失败。如果 HandlePromotionFailure=true, 那么会继续检查老年代最大可用连续空间是否大于历次晋升到老年代的对象的平均大小。</p><ul><li> 如果大于，则尝试进行一次Minor GC，但这次Minor GC依然是有风险的；</li><li> 如果小于，则改为进行一次Full GC。</li><li> 如果HandlePromotionFailure=false,则改为进行一次Full GC。<br>历史版本:</li></ul><p>在 JDK6 Update 24 之后，HandlePromotionFailure 参数不会再影响到虚拟机的空间分配担保策略，观察 openJDK 中的源码变化，虽然源码中还定义了 HandlePromotionFailure 参数，但是在代码中已经不会再使用它。<br>JDK6 Update 24 之后的规则变为只要老年代的连续空间大于新生代对象总大小或者历次晋升的平均大小就会进行 Minor GC，否则将进行 Full GC。即 HandlePromotionFailure=true.<br>逃逸分析<br>堆是分配对象的唯一选择么？</p><p>在《深入理解 Java 虚拟机》中关于 Java 堆内存有这样一段描述：</p><p>随着 JIT 编译器的发展与逃逸分析技术逐渐成熟，栈上分配、标量替换优化技术将会导致一些微妙的变化，所有的对象都分配到堆上也渐渐变得不那么 “绝对” 了。<br>在 Java 虚拟机中，对象是在 Java 堆中分配内存的，这是一个普遍的常识。但是，有一种特殊情况，那就是如果经过逃逸分析（Escape Analysis）后发现，一个对象并没有逃逸出方法的话，那么就可能被优化成栈上分配。这样就无需在堆上分配内存，也无须进行垃圾回收了。这也是最常见的堆外存储技术。<br>此外，基于 OpenJDK 深度定制的 TaoBao VM，其中创新的 GCIH（GC invisible heap）技术实现 off-heap，将生命周期较长的 Java 对象从 heap 中移至 heap 外，并且 GC 不能管理 GCIH 内部的 Java 对象，以此达到降低 GC 的回收频率和提升 GC 的回收效率的目的。<br>逃逸分析<br>如何将堆上的对象分配到栈，需要使用逃逸分析手段。<br>这是一种可以有效减少 Java 程序中同步负载和内存堆分配压力的跨函数全局数据流分析算法。<br>通过逃逸分析，Java Hotspot 编译器能够分析出一个新对象的引用的使用范围从而决定是否要将这个对象分配到堆上。<br>逃逸分析的基本行为就是分析对象动态作用域：<br>当一个对象在方法中被定义后，对象只在方法内部使用，则认为没有发生逃逸。<br>当一个对象在方法中被定义后，它被外部方法所引用，则认为发生逃逸。例如作为调用参数传递到其他地方中。<br>逃逸分析举例</p><p>没有发生逃逸的对象，则可以分配到栈（无线程安全问题）上，随着方法执行的结束，栈空间就被移除（也就无需 GC）；<br>JAVA<br>1<br>2<br>3<br>4<br>5<br>6<br>public void my_method() {<br>    V v = new V();<br>    // use v<br>    // ….<br>    v = null;<br>}<br>下面代码中的 StringBuffer sb 发生了逃逸，不能在栈上分配。<br>JAVA<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>public static StringBuffer createStringBuffer(String s1, String s2) {<br>    StringBuffer sb = new StringBuffer();<br>    sb.append(s1);<br>    sb.append(s2);<br>    //sb可以被外部方法引用<br>    return sb;<br>}<br>如果想要 StringBuffer sb 不发生逃逸，可以这样写。<br>JAVA<br>1<br>2<br>3<br>4<br>5<br>6<br>public static String createStringBuffer(String s1, String s2) {<br>    StringBuffer sb = new StringBuffer();<br>    sb.append(s1);<br>    sb.append(s2);<br>    return sb.toString();<br>}</p><pre><code class="bash">/** * 逃逸分析 * *  如何快速的判断是否发生了逃逸分析，就看new的对象实体是否有可能在方法外被调用。 */public class EscapeAnalysis &#123;    public EscapeAnalysis obj;    /*    方法返回EscapeAnalysis对象，发生逃逸，同上sb     */    public EscapeAnalysis getInstance()&#123;        return obj == null? new EscapeAnalysis() : obj;    &#125;    /*    为成员属性赋值，发生逃逸     */    public void setObj()&#123;        this.obj = new EscapeAnalysis();    &#125;    //思考：如果当前的obj引用声明为static的？仍然会发生逃逸。    /*    对象的作用域仅在当前方法中有效，没有发生逃逸     */    public void useEscapeAnalysis()&#123;        EscapeAnalysis e = new EscapeAnalysis();    &#125;    /*    引用成员变量的值，发生逃逸     */    public void useEscapeAnalysis1()&#123;        EscapeAnalysis e = getInstance();        //getInstance().xxx()同样会发生逃逸    &#125;&#125;</code></pre><p>逃逸分析参数设置<br>在 JDK 1.7 版本之后，HotSpot 中默认就已经开启了逃逸分析；<br>如果使用的是较早的版本，开发人员则可以通过：选项” -XX:+DoEscapeAnalysis“显式开启逃逸分析，通过选项 “-XX:+PrintEscapeAnalysis” 查看逃逸分析的筛选结果。<br>开发中能使用局部变量的，就不要在方法外定义。</p><p>代码优化<br>使用逃逸分析，编译器可以对代码做如下优化：</p><p>栈上分配：将堆分配转化为栈分配。如果一个对象在子程序中被分配，要使指向该对象的指针永远不会发生逃逸，对象可能是栈上分配的候选，而不是堆上分配。<br>同步省略：如果一个对象被发现只有一个线程被访问到，那么对于这个对象的操作可以不考虑同步。<br>分离对象或标量替换：有的对象可能不需要作为一个连续的内存结构存在也可以被访问到，那么对象的部分（或全部）可以不存储在内存，而是存储在 CPU 寄存器中。<br>栈上分配<br>JIT 编译器在编译期间根据逃逸分析的结果，发现如果一个对象并没有逃逸出方法的话，就可能被优化成栈上分配。分配完成后，继续在调用栈内执行，最后线程结束，栈空间被回收，局部变量对象也被回收，这样就无须进行垃圾回收了。<br>常见的栈上分配的场景：在逃逸分析中，已经说明了，分别是给成员变量赋值、方法返回值、实例引用传递。<br>栈上分配举例：</p><pre><code class="bash">/** *  * 栈上分配测试 *  * -Xmx128m -Xms128m -XX:-DoEscapeAnalysis -XX:+PrintGCDetails *  */public class StackAllocation &#123;    public static void main(String[] args) &#123;        long start = System.currentTimeMillis();        for (int i = 0; i &lt; 10000000; i++) &#123;            alloc();        &#125;        // 查看执行时间        long end = System.currentTimeMillis();        System.out.println(&quot;花费的时间为： &quot; + (end - start) + &quot; ms&quot;);        // 为了方便查看堆内存中对象个数，线程sleep        try &#123;            Thread.sleep(1000000);        &#125; catch (InterruptedException e1) &#123;            e1.printStackTrace();        &#125;    &#125;    private static void alloc() &#123;        User user = new User();//未发生逃逸    &#125;    static class User &#123;    &#125;&#125;</code></pre><p>输出结果：</p><p>JVM 参数设置</p><pre><code class="bash">-Xmx128m -Xms128m -XX:-DoEscapeAnalysis -XX:+PrintGCDetails</code></pre><p>日志打印：发生了 GC ，耗时 44ms。</p><p>开启逃逸分析的情况，输出结果：</p><p>JVM 参数设置<br>JAVA<br>1<br>-Xmx128m -Xms128m -XX:+DoEscapeAnalysis -XX:+PrintGCDetails<br>日志打印：发生了 GC ，耗时 44ms。<br>同步省略（同步消除）<br>线程同步的代价是相当高的，同步的后果是降低并发性和性能。<br>在动态编译同步块的时候，JIT 编译器可以借助逃逸分析来判断同步块所使用的锁对象是否只能够被一个线程访问而没有被发布到其他线程。<br>如果没有，那么 JIT 编译器在编译这个同步块的时候就会取消对这部分代码的同步。这样就能大大提高并发性和性能。这个取消同步的过程就叫同步省略，也叫锁消除。<br>示例代码：</p><pre><code class="bash">public void f() &#123;    Object hollis = new Object();    synchronized(hollis) &#123;        System.out.println(hollis);    &#125;&#125;</code></pre><p>代码中对 hollis 这个对象加锁，但是 hollis 对象的生命周期只在 f () 方法中，并不会被其他线程所访问到，所以在 JIT 编译阶段就会被优化掉，优化成：</p><pre><code class="bash">public void f() &#123;    Object hellis = new Object();    System.out.println(hellis);&#125;</code></pre><p>字节码分析上面第一个程序发现：</p><pre><code class="bash"> 0 new #2 &lt;java/lang/Object&gt; 3 dup 4 invokespecial #1 &lt;java/lang/Object.&lt;init&gt;&gt; 7 astore_1 8 aload_1 9 dup10 astore_211 monitorenter12 getstatic #3 &lt;java/lang/System.out&gt;15 aload_116 invokevirtual #4 &lt;java/io/PrintStream.println&gt;19 aload_220 monitorexit21 goto 29 (+8)24 astore_325 aload_226 monitorexit27 aload_328 athrow29 return</code></pre><p>注意：字节码文件中并没有进行优化，可以看到加锁和释放锁的操作依然存在，同步省略操作是在解释运行时发生的！</p><p>标量替换<br>分离对象或标量替换：</p><p>标量（scalar）是指一个无法再分解成更小的数据的数据。Java 中的原始数据类型就是标量。<br>相对的，那些还可以分解的数据叫做聚合量（Aggregate），Java 中的对象就是聚合量，因为他可以分解成其他聚合量和标量。<br>在 JIT 阶段，如果经过逃逸分析，发现一个对象不会被外界访问的话，那么经过 JIT 优化，就会把这个对象拆解成若干个其中包含的若干个成员变量来代替，这个过程就是标量替换。<br>标量替换代码示例：</p><p>JAVA<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>public static void main(String args[]) {<br>    alloc();<br>}<br>private static void alloc() {<br>    Point point = new Point(1,2);<br>    System.out.println(“point.x” + point.x + “;point.y” + point.y);<br>}<br>class Point {<br>    private int x;<br>    private int y;<br>}<br>以上代码，经过标量替换后，就会变成：</p><p>JAVA<br>1<br>2<br>3<br>4<br>5<br>private static void alloc() {<br>    int x = 1;<br>    int y = 2;<br>    System.out.println(“point.x = “ + x + “; point.y=” + y);<br>}<br>可以看到，Point 这个聚合量经过逃逸分析后，发现他并没有逃逸，就被替换成两个聚合量了。<br>那么标量替换有什么好处呢？就是可以大大减少堆内存的占用。因为一旦不需要创建对象了，那么就不再需要分配堆内存了。<br>标量替换为栈上分配提供了很好的基础。<br>标量替换参数设置：</p><p>参数 -XX:+ElimilnateAllocations：开启了标量替换（默认打开），允许将对象打散分配在栈上。</p><p>代码示例：</p><p>未开启标量替换：</p><p>JVM 参数<br>JAVA<br>1<br>-Xmx100m -Xms100m -XX:+DoEscapeAnalysis -XX:+PrintGC -XX:-EliminateAllocations</p><ol><li>输出：</li></ol><p>开启标量替换：</p><p>JVM 参数</p><p>JAVA<br>1<br>-Xmx100m -Xms100m -XX:+DoEscapeAnalysis -XX:+PrintGC -XX:+EliminateAllocations<br>输出：时间减少很多，且无 GC。</p><p>上述代码在主函数中调用了 1 亿次 alloc () 方法，进行对象创建由于 User 对象实例需要占据约 16 字节的空间，因此累计分配空间达到将近 1.5GB。如果堆空间小于这个值，就必然会发生 GC。使用如下参数运行上述代码：</p><p>JAVA<br>1<br>-server -Xmx100m -Xms100m -XX:+DoEscapeAnalysis -XX:+PrintGC -XX:+EliminateAllocations<br>这里设置参数如下：</p><p>参数 -server：启动 Server 模式，因为在 server 模式下，才可以启用逃逸分析。</p><p>参数 -XX:+DoEscapeAnalysis：启用逃逸分析。</p><p>参数 -Xmx10m：指定了堆空间最大为 10MB。</p><p>参数 -XX:+PrintGC：将打印 GC 日志。</p><p>参数 - XX:+EliminateAllocations：开启了标量替换（默认打开），允许将对象打散分配在栈上，比如对象拥有 id 和 name 两个字段，那么这两个字段将会被视为两个独立的局部变量进行分配。</p><p>逃逸分析的不足<br>关于逃逸分析的论文在 1999 年就已经发表了，但直到 JDK1.6 才有实现，而且这项技术到如今也并不是十分成熟的。<br>其根本原因就是无法保证逃逸分析的性能消耗一定能高于他的消耗。虽然经过逃逸分析可以做标量替换、栈上分配、和锁消除，但是逃逸分析自身也是需要进行一系列复杂的分析的，这其实也是一个相对耗时的过程。<br>一个极端的例子，就是经过逃逸分析之后，发现没有一个对象是不逃逸的。那这个逃逸分析的过程就白白浪费掉了。<br>虽然这项技术并不十分成熟，但是它也是即时编译器优化技术中一个十分重要的手段。<br>注意到有一些观点，认为通过逃逸分析，JVM 会在栈上分配那些不会逃逸的对象，这在理论上是可行的，但是取决于 JVM 设计者的选择。据我所知，Oracle Hotspot JVM 中并未这么做（刚刚演示的效果，是因为 HotSpot 实现了标量替换），这一点在逃逸分析相关的文档里已经说明，所以可以明确在 HotSpot 虚拟机上，所有的对象实例都是创建在堆上。<br>堆是分配对象的唯一选择么？ （不是！）</p><p>小结<br>年轻代是对象的诞生、成长、消亡的区域，一个对象在这里产生、应用，最后被垃圾回收器收集、结束生命。<br>老年代放置长生命周期的对象，通常都是从 Survivor 区域筛选拷贝过来的 Java 对象。<br>当然，也有特殊情况，我们知道普通的对象可能会被分配在 TLAB 上。<br>如果对象较大，无法分配在 TLAB 上，则 JVM 会试图直接分配在 Eden 其他位置上。<br>如果对象太大，完全无法在新生代找到足够长的连续空闲空间，JVM 就会直接分配到老年代。<br>当 GC 只发生在年轻代中，回收年轻代对象的行为被称为 Minor GC。<br>当 GC 发生在老年代时则被称为 Major GC 或者 Full GC。<br>一般的，Minor GC 的发生频率要比 Major GC 高很多，即老年代中垃圾回收发生的频率将大大低于年轻代。</p>]]></content>
      
      
      <categories>
          
          <category> JVM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 堆 </tag>
            
            <tag> 对象分配过程 </tag>
            
            <tag> TLAB </tag>
            
            <tag> 逃逸分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL 高级 — 常用工具、日志、复制、综合案例</title>
      <link href="/2020/10/07/sql/MySQL%20%E9%AB%98%E7%BA%A7%20%E2%80%94%20%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7%E3%80%81%E6%97%A5%E5%BF%97%E3%80%81%E5%A4%8D%E5%88%B6%E3%80%81%E7%BB%BC%E5%90%88%E6%A1%88%E4%BE%8B/"/>
      <url>/2020/10/07/sql/MySQL%20%E9%AB%98%E7%BA%A7%20%E2%80%94%20%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7%E3%80%81%E6%97%A5%E5%BF%97%E3%80%81%E5%A4%8D%E5%88%B6%E3%80%81%E7%BB%BC%E5%90%88%E6%A1%88%E4%BE%8B/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>MySQL 中常用工具<br>mysql<br>该 mysql 不是指 mysql 服务，而是指 mysql 的客户端工具。语法 ：</p><p>SHELL<br>1<br>mysql [options] [database]<br>连接选项<br>SHELL<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>参数 ：<br>    -u, –user=name            指定用户名<br>    -p, –password[=name]    指定密码<br>    -h, –host=name            指定服务器IP或域名<br>    -P, –port=#            指定连接端口</p><p>示例 ：<br>    mysql -h 127.0.0.1 -P 3306 -u root -p</p><pre><code>mysql -h127.0.0.1 -P3306 -uroot -p123456</code></pre><p>执行选项<br>CODE<br>1<br>-e, –execute=name        执行SQL语句并退出<br>此选项可以在 MySQL 客户端执行 SQL 语句，而不用连接到 MySQL 数据库再执行，对于一些批处理脚本，这种方式尤其方便。</p><p>SHELL<br>1<br>示例：mysql -uroot -p123456 test -e “select * from tb_book”;</p><p>image-20210519192733031<br>mysqladmin<br>mysqladmin 是一个执行管理操作的客户端程序。可以用它来检查服务器的配置和当前状态、创建并删除数据库等。</p><p>可以通过 ： mysqladmin –help 指令查看帮助文档 。</p><p>SHELL<br>1<br>2<br>3<br>4<br>5<br>示例 ：<br>    mysqladmin -uroot -p123456 create ‘test01’;<br>    mysqladmin -uroot -p123456 drop ‘test01’;<br>    mysqladmin -uroot -p123456 version;</p><p>image-20210519193244305<br>mysqlbinlog<br>由于服务器生成的二进制日志文件以二进制格式保存，所以如果想要检查这些文本的文本格式，就会使用到 mysqlbinlog 日志管理工具。</p><p>语法 ：</p><p>SHELL<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>mysqlbinlog [options]  log-files1 log-files2 …</p><p>选项：</p><pre><code>-d, --database=name : 指定数据库名称，只列出指定的数据库相关操作。-o, --offset=# : 忽略掉日志中的前n行命令。-r,--result-file=name : 将输出的文本格式日志输出到指定文件。-s, --short-form : 显示简单格式， 省略掉一些信息。--start-datatime=date1  --stop-datetime=date2 : 指定日期间隔内的所有日志。--start-position=pos1 --stop-position=pos2 : 指定位置间隔内的所有日志。</code></pre><p>mysqldump<br>mysqldump 客户端工具用来备份数据库或在不同数据库之间进行数据迁移。备份内容包含创建表，及插入表的 SQL 语句。</p><p>语法 ：</p><p>SHELL<br>1<br>2<br>3<br>4<br>5<br>mysqldump [options] db_name [tables]</p><p>mysqldump [options] –database/-B db1 [db2 db3…]</p><p>mysqldump [options] –all-databases/-A<br>连接选项<br>CODE<br>1<br>2<br>3<br>4<br>5<br>参数 ：<br>    -u, –user=name            指定用户名<br>    -p, –password[=name]    指定密码<br>    -h, –host=name            指定服务器IP或域名<br>    -P, –port=#            指定连接端口<br>输出内容选项<br>CODE<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>参数：<br>    –add-drop-database        在每个数据库创建语句前加上 Drop database 语句<br>    –add-drop-table        在每个表创建语句前加上 Drop table 语句 , 默认开启 ; 不开启 (–skip-add-drop-table)</p><pre><code>-n, --no-create-db        不包含数据库的创建语句-t, --no-create-info    不包含数据表的创建语句-d --no-data            不包含数据 -T, --tab=name            自动生成两个文件：一个.sql文件，创建表结构的语句；                         一个.txt文件，数据文件，相当于select into outfile  </code></pre><p>SHELL<br>1<br>2<br>3<br>4<br>示例 ：<br>    mysqldump -uroot -p123456 test tb_book –add-drop-database –add-drop-table &gt; a</p><pre><code>mysqldump -uroot -p123456 -T /tmp test city</code></pre><p>mysqlimport/source<br>mysqlimport 是客户端数据导入工具，用来导入 mysqldump 加 -T 参数后导出的文本文件。</p><p>语法：</p><p>SHELL<br>1<br>mysqlimport [options]  db_name  textfile1  [textfile2…]<br>SHELL<br>1<br>示例：mysqlimport -uroot -p123456 test /tmp/city.txt<br>如果需要导入 sql 文件，可以使用 mysql 中的 source 指令 :</p><p>SH<br>1<br>source /root/tb_book.sql<br>mysqlshow<br>mysqlshow 客户端对象查找工具，用来很快地查找存在哪些数据库、数据库中的表、表中的列或者索引。</p><p>语法：</p><p>CODE<br>1<br>mysqlshow [options] [db_name [table_name [col_name]]]<br>参数：</p><p>CODE<br>1<br>2<br>3<br>–count        显示数据库及表的统计信息（数据库，表 均可以不指定）</p><p>-i            显示指定数据库或者指定表的状态信息<br>示例：</p><p>SHELL<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>#查询每个数据库的表的数量及表中记录的数量<br>mysqlshow -uroot -p123456 –count</p><p>#查询test库中每个表中的字段书，及行数<br>mysqlshow -uroot -p123456 test –count</p><p>#查询test库中book表的详细情况<br>mysqlshow -uroot -p123456 test book –count</p><p>image-20210519192733031</p><p>image-20210519192627476<br>MySQL 日志<br>在任何一种数据库中，都会有各种各样的日志，记录着数据库工作的方方面面，以帮助数据库管理员追踪数据库曾经发生过的各种事件。MySQL 也不例外，在 MySQL 中，有 4 种不同的日志，分别是错误日志、二进制日志（BINLOG 日志）、查询日志和慢查询日志，这些日志记录着数据库在不同方面的踪迹。</p><p>错误日志<br>错误日志是 MySQL 中最重要的日志之一，它记录了当 mysqld 启动和停止时，以及服务器在运行过程中发生任何严重错误时的相关信息。当数据库出现任何故障导致无法正常使用时，可以首先查看此日志。该日志是默认开启的 ， 默认存放目录为 mysql 的数据目录，默认的日志文件名为 hostname.err（hostname 是主机名）。</p><p>查看日志位置指令 ：</p><p>SQL<br>1<br>show variables like ‘log_error%’;<br>SQL<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>mysql&gt; show variables like ‘log_error%’;<br>+———————+———————–+<br>| Variable_name       | Value                 |<br>+———————+———————–+<br>| log_error           | .\LAPTOP-6SEJGOUJ.err |<br>| log_error_verbosity | 3                     |<br>+———————+———————–+<br>2 rows in set (0.09 sec)<br>二进制日志<br>概述<br>二进制日志（BINLOG）记录了所有的 DDL（数据定义语言）语句和 DML（数据操纵语言）语句，但是不包括数据查询语句。此日志对于灾难时的数据恢复起着极其重要的作用，MySQL 的主从复制， 就是通过该 binlog 实现的。二进制日志，默认情况下是没有开启的，需要到 MySQL 的配置文件中开启，并配置 MySQL 日志的格式。</p><p>配置文件位置：配置时，给定了文件名但是没有指定路径，日志默认写入 MySQL 的数据目录：</p><p>Windows：C:\ProgramData\MySQL\MySQL Server 5.7\my.ini</p><p>Linux：/usr/my.cnf</p><p>XML<br>1<br>2<br>3<br>4<br>5<br>#配置开启binlog日志， 日志的文件前缀为 mysqlbin —–&gt; 生成的文件名如 : mysqlbin.000001,mysqlbin.000002<br>log_bin=mysqlbin</p><p>#配置二进制日志的格式<br>binlog_format=STATEMENT<br>日志格式<br>STATEMENT</p><p>该日志格式在日志文件中记录的都是 SQL 语句（statement），每一条对数据进行修改的 SQL 都会记录在日志文件中，通过 MySQL 提供的 mysqlbinlog 工具，可以清晰的查看到每条语句的文本。主从复制的时候，从库（slave）会将日志解析为原文本，并在从库重新执行一次。</p><p>ROW</p><p>该日志格式在日志文件中记录的是每一行的数据变更，而不是记录 SQL 语句。比如，执行 SQL 语句 ： update tb_book set status=’1’ , 如果是 STATEMENT 日志格式，在日志中会记录一行 SQL 文件； 如果是 ROW，由于是对全表进行更新，也就是每一行记录都会发生变更，ROW 格式的日志中会记录每一行的数据变更。</p><p>MIXED</p><p>这是目前 MySQL 默认的日志格式，即混合了 STATEMENT 和 ROW 两种格式。默认情况下采用 STATEMENT，但是在一些特殊情况下采用 ROW 来进行记录。MIXED 格式能尽量利用两种模式的优点，而避开他们的缺点。</p><p>日志读取<br>由于日志以二进制方式存储，不能直接读取，需要用 mysqlbinlog 工具来查看，语法如下 ：</p><p>SHELL<br>1<br>mysqlbinlog log-file；<br>查看 STATEMENT 格式日志</p><p>执行插入语句 ：</p><p>SQL<br>1<br>insert into tb_book values(null,’Lucene’,’2088-05-01’,’0’);<br>查看日志文件 ：</p><p>image-20210519192007729<br>mysqlbin.index : 该文件是日志索引文件 ， 记录日志的文件名；而 mysqlbing.000001 ：日志文件。</p><p>查看日志内容 ：</p><p>SHELL<br>1<br>mysqlbinlog mysqlbing.000001;</p><p>1554080016778<br>查看 ROW 格式日志</p><p>配置 :</p><p>CODE<br>1<br>2<br>3<br>4<br>5<br>#配置开启binlog日志， 日志的文件前缀为 mysqlbin —–&gt; 生成的文件名如 : mysqlbin.000001,mysqlbin.000002<br>log_bin=mysqlbin</p><p>#配置二进制日志的格式<br>binlog_format=ROW<br>插入数据 :</p><p>SQL<br>1<br>insert into tb_book values(null,’SpringCloud实战’,’2088-05-05’,’0’);<br>如果日志格式是 ROW , 直接查看数据，是看不懂的；可以在 mysqlbinlog 后面加上参数 -vv</p><p>SQL<br>1<br>mysqlbinlog -vv mysqlbin.000002 </p><p>1554095452022<br>日志删除<br>对于比较繁忙的系统，由于每天生成日志量大 ，这些日志如果长时间不清楚，将会占用大量的磁盘空间。下面我们将会讲解几种删除日志的常见方法 ：</p><p>方式一</p><p>通过 Reset Master 指令删除全部 binlog 日志，删除之后，日志编号，将从 xxxx.000001 重新开始 。</p><p>执行删除日志指令：</p><p>SHELL<br>1<br>Reset Master<br>方式二</p><p>执行指令 purge master logs to ‘mysqlbin.******’ ，该命令将删除 ****** 编号之前的所有日志。</p><p>方式三</p><p>执行指令 purge master logs before ‘yyyy-mm-dd hh24:mi:ss’ ，该命令将删除日志为 “yyyy-mm-dd hh24:mi:ss” 之前产生的所有日志 。</p><p>方式四</p><p>设置参数 –expire_logs_days=# ，此参数的含义是设置日志的过期天数， 过了指定的天数后日志将会被自动删除，这样将有利于减少 DBA 管理日志的工作量。</p><p>配置如下 ：</p><p>XML<br>1<br>2<br>3<br>4<br>5<br>log_bin=mysqlbin</p><p>binlog_format=ROW</p><p>expire_logs_days=3<br>查询日志<br>查询日志中记录了客户端的所有操作语句，而二进制日志不包含查询数据的 SQL 语句。默认情况下， 查询日志是未开启的。如果需要开启查询日志，可以设置以下配置 ：</p><p>XML<br>1<br>2<br>3<br>4<br>5<br>#该选项用来开启查询日志 ， 可选值 ： 0 或者 1 ； 0 代表关闭， 1 代表开启<br>general_log=1</p><p>#设置日志的文件名 ， 如果没有指定， 默认的文件名为 host_name.log<br>general_log_file=file_name<br>在 mysql 的配置文件中配置如下内容 ：</p><p>XML<br>1<br>2<br>3<br>4<br>5<br>#开启查询日志<br>general-log=1</p><p>#配置查询日志的文件名<br>general_log_file=”mysql_query.log”<br>配置完毕之后，在数据库执行以下操作 ：</p><p>SQL<br>1<br>2<br>3<br>4<br>select * from tb_book;<br>select * from tb_book where id = 1;<br>update tb_book set name = ‘lucene入门指南’ where id = 5;<br>select * from tb_book where id &lt; 8;<br>执行完毕之后， 再次来查询日志文件 ：</p><p>CODE<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>C:\Program Files\MySQL\MySQL Server 5.7\bin\mysqld.exe, Version: 5.7.32-log (MySQL Community Server (GPL)). started with:<br>TCP Port: 3306, Named Pipe: (null)<br>Time                 Id Command    Argument<br>2021-05-19T12:19:36.603915Z        2 Connect    root@localhost on test using TCP/IP<br>2021-05-19T12:19:36.604924Z        2 Query    SET NAMES utf8mb4<br>2021-05-19T12:19:36.605342Z        2 Init DB    test<br>2021-05-19T12:19:36.607604Z        2 Query    select * from tb_book<br>2021-05-19T12:19:36.779978Z        2 Init DB    test<br>2021-05-19T12:19:36.780489Z        2 Query    select * from tb_book where id = 1<br>2021-05-19T12:19:36.919822Z        2 Init DB    test<br>2021-05-19T12:19:36.956204Z        2 Query    update tb_book set name = ‘lucene入门指南’ where id = 5<br>2021-05-19T12:19:37.017167Z        2 Init DB    test<br>2021-05-19T12:19:37.017970Z        2 Query    select * from tb_book where id &lt; 8<br>慢查询日志<br>慢查询日志记录了所有执行时间超过参数 long_query_time 设置值并且扫描记录数不小于 min_examined_row_limit 的所有的 SQL 语句的日志。long_query_time 默认为 10 秒，最小为 0， 精度可以到微秒。</p><p>文件位置和格式<br>慢查询日志默认是关闭的 。可以通过两个参数来控制慢查询日志 ：</p><p>XML<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8</p><h1 id="该参数用来控制慢查询日志是否开启，-可取值：-1-和-0-，-1-代表开启，-0-代表关闭"><a href="#该参数用来控制慢查询日志是否开启，-可取值：-1-和-0-，-1-代表开启，-0-代表关闭" class="headerlink" title="该参数用来控制慢查询日志是否开启， 可取值： 1 和 0 ， 1 代表开启， 0 代表关闭"></a>该参数用来控制慢查询日志是否开启， 可取值： 1 和 0 ， 1 代表开启， 0 代表关闭</h1><p>slow_query_log=1 </p><h1 id="该参数用来指定慢查询日志的文件名"><a href="#该参数用来指定慢查询日志的文件名" class="headerlink" title="该参数用来指定慢查询日志的文件名"></a>该参数用来指定慢查询日志的文件名</h1><p>slow_query_log_file=slow_query.log</p><h1 id="该选项用来配置查询的时间限制，-超过这个时间将认为值慢查询，-将需要进行日志记录，-默认10s"><a href="#该选项用来配置查询的时间限制，-超过这个时间将认为值慢查询，-将需要进行日志记录，-默认10s" class="headerlink" title="该选项用来配置查询的时间限制， 超过这个时间将认为值慢查询， 将需要进行日志记录， 默认10s"></a>该选项用来配置查询的时间限制， 超过这个时间将认为值慢查询， 将需要进行日志记录， 默认10s</h1><p>long_query_time=10<br>日志的读取<br>和错误日志、查询日志一样，慢查询日志记录的格式也是纯文本，可以被直接读取。</p><p>1） 查询 long_query_time 的值。</p><p>SQL<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>mysql&gt; show variables like ‘long%’;<br>+—————–+———–+<br>| Variable_name   | Value     |<br>+—————–+———–+<br>| long_query_time | 10.000000 |<br>+—————–+———–+<br>1 row in set (0.13 sec)<br>2） 执行查询操作</p><p>SQL<br>1<br>select * from tb_item where id = 1;<br>由于该语句执行时间很短，为 0s ， 所以不会记录在慢查询日志中。</p><p>SQL<br>1<br>select * from tb_item where title like ‘%阿尔卡特 (OT-927) 炭黑 联通3G手机 双卡双待165454%’ ;</p><p>1554130532577<br>该 SQL 语句 ， 执行时长为 26.77s ，超过 10s ， 所以会记录在慢查询日志文件中。</p><p>3） 查看慢查询日志文件</p><p>直接查询该日志文件 ：</p><p>image-20210519203330362<br>如果慢查询日志内容很多， 直接查看文件，比较麻烦， 这个时候可以借助于 mysql 自带的 mysqldumpslow 工具， 来对慢查询日志进行分类汇总。</p><p>image-20210519203426832<br>MySQL 复制<br>复制概述<br>复制是指将主数据库的 DDL 和 DML 操作通过二进制日志传到从库服务器中，然后在从库上对这些日志重新执行（也叫重做），从而使得从库和主库的数据保持同步。</p><p>MySQL 支持一台主库同时向多台从库进行复制， 从库同时也可以作为其他从服务器的主库，实现链状复制。</p><p>复制原理<br>MySQL 的主从复制原理如下。</p><p>image-20210519203834829<br>从上层来看，复制分成三步：</p><p>Master 主库在事务提交时，会把数据变更作为时间 Events 记录在二进制日志文件 Binlog 中。</p><p>主库推送二进制日志文件 Binlog 中的日志事件到从库的中继日志 Relay Log 。</p><p>slave 重做中继日志中的事件，将改变反映给它自己的数据。</p><p>复制优势<br>MySQL 复制的优点主要包含以下三个方面：</p><p>主库出现问题，可以快速切换到从库提供服务。</p><p>可以在从库上执行查询操作，从主库中更新，实现读写分离，降低主库的访问压力。</p><p>可以在从库中执行备份，以避免备份期间影响主库的服务。</p><p>搭建步骤<br>master<br>1） 在 master 的配置文件（/usr/my.cnf 或者 my.ini）中，配置如下内容：</p><p>PROPERTIES<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>26<br>#mysql 服务ID,保证整个集群环境中唯一<br>server-id=1</p><p>#mysql binlog 日志的存储路径和文件名 下面以Linux系统为例<br>log-bin=/var/lib/mysql/mysqlbin </p><p>#错误日志,默认已经开启<br>#log-err</p><p>#mysql的安装目录<br>#basedir</p><p>#mysql的临时目录<br>#tmpdir</p><p>#mysql的数据存放目录<br>#datadir</p><p>#是否只读,1 代表只读, 0 代表读写<br>read-only=0</p><p>#忽略的数据, 指不需要同步的数据库<br>binlog-ignore-db=mysql</p><p>#指定同步的数据库<br>#binlog-do-db=db01<br>2） 执行完毕之后，需要重启 Mysql：</p><p>CODE<br>1<br>service mysql restart ;<br>3） 创建同步数据的账户，并且进行授权操作：</p><p>SQL<br>1<br>2<br>3<br>grant replication slave on <em>.</em> to ‘mysql‘@’192.168.192.131’ identified by ‘mysql’;    </p><p>flush privileges;<br>4） 查看 master 状态：</p><p>SQL<br>1<br>show master status;</p><p>1554477759735<br>字段含义：</p><p>CODE<br>1<br>2<br>3<br>File : 从哪个日志文件开始推送日志文件<br>Position ： 从哪个位置开始推送日志<br>Binlog_Ignore_DB : 指定不需要同步的数据库<br>slave<br>1） 在 slave 端配置文件中，配置如下内容：</p><p>PROPERTIES<br>1<br>2<br>3<br>4<br>5<br>#mysql服务端ID,唯一<br>server-id=2</p><p>#指定binlog日志<br>log-bin=/var/lib/mysql/mysqlbin<br>2） 执行完毕之后，需要重启 Mysql：</p><p>CODE<br>1<br>service mysql restart;<br>3） 执行如下指令 ：</p><p>SQL<br>1<br>change master to master_host= ‘192.168.192.130’, master_user=’mysql’, master_password=’123456’, master_log_file=’mysqlbin.000001’, master_log_pos=413;<br>指定当前从库对应的主库的 IP 地址，用户名，密码，从哪个日志文件开始的那个位置开始同步推送日志。</p><p>4） 开启同步操作</p><p>CODE<br>1<br>2<br>3<br>start slave;</p><p>show slave status;</p><p>image-20210519204321826<br>5） 停止同步操作</p><p>CODE<br>1<br>stop slave;<br>验证同步操作<br>1） 在主库中创建数据库，创建表，并插入数据 ：</p><p>SQL<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>create database db01;</p><p>user db01;</p><p>create table user(<br>    id int(11) not null auto_increment,<br>    name varchar(50) not null,<br>    sex varchar(1),<br>    primary key (id)<br>)engine=innodb default charset=utf8;</p><p>insert into user(id,name,sex) values(null,’Tom’,’1’);<br>insert into user(id,name,sex) values(null,’Trigger’,’0’);<br>insert into user(id,name,sex) values(null,’Dawn’,’1’);<br>2） 在从库中查询数据，进行验证 ：</p><p>在从库中，可以查看到刚才创建的数据库：</p><p>1554544658640<br>在该数据库中，查询 user 表中的数据：</p><p>1554544679538<br>综合案例<br>需求分析<br>在业务系统中，需要记录当前业务系统的访问日志，该访问日志包含：操作人，操作时间，访问类，访问方法，请求参数，请求结果，请求结果类型，请求时长 等信息。记录详细的系统访问日志，主要便于对系统中的用户请求进行追踪，并且在系统 的管理后台可以查看到用户的访问记录。</p><p>记录系统中的日志信息，可以通过 Spring 框架的 AOP 来实现。具体的请求处理流程，如下：</p><p>image-20210523213639350</p><p>搭建案例环境<br>数据库表<br>SQL<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>26<br>27<br>28<br>29<br>30<br>31<br>32<br>33<br>34<br>35<br>36<br>37<br>38<br>39<br>40<br>41<br>42<br>43<br>44<br>45<br>46<br>47<br>48<br>49<br>50<br>51<br>52<br>53<br>CREATE DATABASE mysql_demo DEFAULT CHARACTER SET utf8mb4 ；</p><p>CREATE TABLE <code>brand</code> (<br>  <code>id</code> bigint(20) NOT NULL AUTO_INCREMENT,<br>  <code>name</code> varchar(255) DEFAULT NULL COMMENT ‘品牌名称’,<br>  <code>first_char</code> varchar(1) DEFAULT NULL COMMENT ‘品牌首字母’,<br>  PRIMARY KEY (<code>id</code>)<br>) ENGINE=InnoDB DEFAULT CHARSET=utf8;</p><p>CREATE TABLE <code>item</code> (<br>  <code>id</code> int(11) NOT NULL AUTO_INCREMENT COMMENT ‘商品id’,<br>  <code>title</code> varchar(100) NOT NULL COMMENT ‘商品标题’,<br>  <code>price</code> double(10,2) NOT NULL COMMENT ‘商品价格，单位为：元’,<br>  <code>num</code> int(10) NOT NULL COMMENT ‘库存数量’,<br>  <code>categoryid</code> bigint(10) NOT NULL COMMENT ‘所属类目，叶子类目’,<br>  <code>status</code> varchar(1) DEFAULT NULL COMMENT ‘商品状态，1-正常，2-下架，3-删除’,<br>  <code>sellerid</code> varchar(50) DEFAULT NULL COMMENT ‘商家ID’,<br>  <code>createtime</code> datetime DEFAULT NULL COMMENT ‘创建时间’,<br>  <code>updatetime</code> datetime DEFAULT NULL COMMENT ‘更新时间’,<br>  PRIMARY KEY (<code>id</code>)<br>) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT=’商品表’;</p><p>CREATE TABLE <code>user</code> (<br>  <code>id</code> int(11) NOT NULL AUTO_INCREMENT,<br>  <code>username</code> varchar(45) NOT NULL,<br>  <code>password</code> varchar(96) NOT NULL,<br>  <code>name</code> varchar(45) NOT NULL,<br>  <code>birthday</code> datetime DEFAULT NULL,<br>  <code>sex</code> char(1) DEFAULT NULL,<br>  <code>email</code> varchar(45) DEFAULT NULL,<br>  <code>phone</code> varchar(45) DEFAULT NULL,<br>  <code>qq</code> varchar(32) DEFAULT NULL,<br>  PRIMARY KEY (<code>id</code>)<br>) ENGINE=InnoDB DEFAULT CHARSET=utf8;</p><p>CREATE TABLE <code>operation_log</code> (<br>  <code>id</code> bigint(20) NOT NULL AUTO_INCREMENT COMMENT ‘ID’,<br>  <code>operate_class</code> varchar(200) DEFAULT NULL COMMENT ‘操作类’,<br>  <code>operate_method</code> varchar(200) DEFAULT NULL COMMENT ‘操作方法’,<br>  <code>return_class</code> varchar(200) DEFAULT NULL COMMENT ‘返回值类型’,<br>  <code>operate_user</code> varchar(20) DEFAULT NULL COMMENT ‘操作用户’,<br>  <code>operate_time</code> varchar(20) DEFAULT NULL COMMENT ‘操作时间’,<br>  <code>param_and_value</code> varchar(500) DEFAULT NULL COMMENT ‘请求参数名及参数值’,<br>  <code>cost_time</code> bigint(20) DEFAULT NULL COMMENT ‘执行方法耗时, 单位 ms’,<br>  <code>return_value</code> varchar(200) DEFAULT NULL COMMENT ‘返回值’,<br>  PRIMARY KEY (<code>id</code>)<br>) ENGINE=InnoDB  DEFAULT CHARSET=utf8mb4;</p><pre><code class="bash">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;       xmlns:mvc=&quot;http://www.springframework.org/schema/mvc&quot;       xmlns:context=&quot;http://www.springframework.org/schema/context&quot;       xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot;       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans            http://www.springframework.org/schema/beans/spring-beans.xsd            http://www.springframework.org/schema/mvc            http://www.springframework.org/schema/mvc/spring-mvc.xsd            http://www.springframework.org/schema/aop            http://www.springframework.org/schema/aop/spring-aop.xsd            http://www.springframework.org/schema/context            http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt;    &lt;context:component-scan base-package=&quot;cn.itcast.controller&quot;&gt;&lt;/context:component-scan&gt;    &lt;mvc:annotation-driven&gt;&lt;/mvc:annotation-driven&gt;    &lt;aop:aspectj-autoproxy /&gt;&lt;/beans&gt;</code></pre><p>导入基础工程</p><p>image-20210523213609159</p><p>通过 AOP 记录操作日志<br>自定义注解<br>通过自定义注解，来标示方法需不需要进行记录日志，如果该方法在访问时需要记录日志，则在该方法上标示该注解既可。</p><pre><code>@Inherited@Documented@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)public @interface OperateLog &#123;&#125;</code></pre><p>定义通知类</p><pre><code class="bash">@Component@Aspectpublic class OperateAdvice &#123;      private static Logger log = Logger.getLogger(OperateAdvice.class);      @Autowired   private OperationLogService operationLogService;      @Around(&quot;execution(* cn.itcast.controller.*.*(..)) &amp;&amp; @annotation(operateLog)&quot;)   public Object insertLogAround(ProceedingJoinPoint pjp , OperateLog operateLog) throws Throwable&#123;      System.out.println(&quot; ************************ 记录日志 [start]  ****************************** &quot;);            OperationLog op = new OperationLog();            DateFormat sdf = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;);      op.setOperateTime(sdf.format(new Date()));      op.setOperateUser(DataUtils.getRandStr(8));            op.setOperateClass(pjp.getTarget().getClass().getName());      op.setOperateMethod(pjp.getSignature().getName());            //获取方法调用时传递的参数      Object[] args = pjp.getArgs();      op.setParamAndValue(Arrays.toString(args));      long start_time = System.currentTimeMillis();      //放行      Object object = pjp.proceed();      long end_time = System.currentTimeMillis();      op.setCostTime(end_time - start_time);      if(object != null)&#123;         op.setReturnClass(object.getClass().getName());         op.setReturnValue(object.toString());      &#125;else&#123;         op.setReturnClass(&quot;java.lang.Object&quot;);         op.setParamAndValue(&quot;void&quot;);      &#125;      log.error(JsonUtils.obj2JsonString(op));      operationLogService.insert(op);            System.out.println(&quot; ************************** 记录日志 [end]  *************************** &quot;);            return object;   &#125;   &#125;</code></pre><p>方法上加注解<br>在需要记录日志的方法上加上注解 @OperateLog。</p><pre><code class="bash">@OperateLog@RequestMapping(&quot;/insert&quot;)public Result insert(@RequestBody Brand brand)&#123;    try &#123;        brandService.insert(brand);        return new Result(true,&quot;操作成功&quot;);    &#125; catch (Exception e) &#123;        e.printStackTrace();        return new Result(false,&quot;操作失败&quot;);    &#125;&#125;</code></pre><p>日志查询后端代码实现<br>Mapper 接口</p><pre><code class="bash">public interface OperationLogMapper &#123;    public void insert(OperationLog operationLog);    public List&lt;OperationLog&gt; selectListByCondition(Map dataMap);    public Long countByCondition(Map dataMap);&#125;</code></pre><p>Mapper.xml 映射配置文件</p><pre><code class="bash">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot; &gt;&lt;mapper namespace=&quot;cn.itcast.mapper.OperationLogMapper&quot; &gt;    &lt;insert id=&quot;insert&quot; parameterType=&quot;operationLog&quot;&gt;        INSERT INTO operation_log(id,return_value,return_class,operate_user,operate_time,param_and_value,        operate_class,operate_method,cost_time)      VALUES(NULL,#&#123;returnValue&#125;,#&#123;returnClass&#125;,#&#123;operateUser&#125;,#&#123;operateTime&#125;,#&#123;paramAndValue&#125;,        #&#123;operateClass&#125;,#&#123;operateMethod&#125;,#&#123;costTime&#125;)    &lt;/insert&gt;    &lt;select id=&quot;selectListByCondition&quot; parameterType=&quot;map&quot; resultType=&quot;operationLog&quot;&gt;      select        id ,        operate_class as operateClass ,        operate_method as operateMethod,        return_class as returnClass,        operate_user as operateUser,        operate_time as operateTime,        param_and_value as paramAndValue,        cost_time as costTime,        return_value as returnValue      from operation_log      &lt;include refid=&quot;oplog_where&quot;/&gt;      limit #&#123;start&#125;,#&#123;size&#125;    &lt;/select&gt;    &lt;select id=&quot;countByCondition&quot; resultType=&quot;long&quot; parameterType=&quot;map&quot;&gt;        select count(*) from operation_log        &lt;include refid=&quot;oplog_where&quot;/&gt;    &lt;/select&gt;    &lt;sql id=&quot;oplog_where&quot;&gt;        &lt;where&gt;            &lt;if test=&quot;operateClass != null and operateClass != &#39;&#39; &quot;&gt;                and operate_class = #&#123;operateClass&#125;            &lt;/if&gt;            &lt;if test=&quot;operateMethod != null and operateMethod != &#39;&#39; &quot;&gt;                and operate_method = #&#123;operateMethod&#125;            &lt;/if&gt;            &lt;if test=&quot;returnClass != null and returnClass != &#39;&#39; &quot;&gt;                and return_class = #&#123;returnClass&#125;            &lt;/if&gt;            &lt;if test=&quot;costTime != null&quot;&gt;                and cost_time =  #&#123;costTime&#125;            &lt;/if&gt;        &lt;/where&gt;    &lt;/sql&gt;&lt;/mapper&gt;</code></pre><p>Service</p><pre><code class="bash">@Service@Transactionalpublic class OperationLogService &#123;    //private static Logger logger = Logger.getLogger(OperationLogService.class);    @Autowired    private OperationLogMapper operationLogMapper;    //插入数据    public void insert(OperationLog operationLog)&#123;        operationLogMapper.insert(operationLog);    &#125;    //根据条件查询    public PageResult selectListByCondition(Map dataMap, Integer pageNum , Integer pageSize)&#123;       if(paramMap ==null)&#123;            paramMap = new HashMap();        &#125;        paramMap.put(&quot;start&quot; , (pageNum-1)*rows);        paramMap.put(&quot;rows&quot;,rows);        Object costTime = paramMap.get(&quot;costTime&quot;);        if(costTime != null)&#123;            if(&quot;&quot;.equals(costTime.toString()))&#123;                paramMap.put(&quot;costTime&quot;,null);            &#125;else&#123;                paramMap.put(&quot;costTime&quot;,new Long(paramMap.get(&quot;costTime&quot;).toString()));            &#125;        &#125;        System.out.println(dataMap);        long countStart = System.currentTimeMillis();        Long count = operationLogMapper.countByCondition(dataMap);        long countEnd = System.currentTimeMillis();        System.out.println(&quot;Count Cost Time : &quot; + (countEnd-countStart)+&quot; ms&quot;);        List&lt;OperationLog&gt; list = operationLogMapper.selectListByCondition(dataMap);        long queryEnd = System.currentTimeMillis();        System.out.println(&quot;Query Cost Time : &quot; + (queryEnd-countEnd)+&quot; ms&quot;);        return new PageResult(count,list);    &#125;&#125;</code></pre><p>Controller</p><pre><code class="bash">@RestController@RequestMapping(&quot;/operationLog&quot;)public class OperationLogController &#123;    @Autowired    private OperationLogService operationLogService;    @RequestMapping(&quot;/findList&quot;)    public PageResult findList(@RequestBody Map dataMap, Integer pageNum , Integer pageSize)&#123;        PageResult page = operationLogService.selectListByCondition(dataMap, pageNum, pageSize);        return page;    &#125;&#125;日志查询前端代码实现前端代码使用 BootStrap + AdminLTE 进行布局， 使用 Vuejs 进行视图层展示。```bash&lt;script&gt;   var vm = new Vue(&#123;       el: &#39;#app&#39;,       data: &#123;           dataList:[],           searchEntity:&#123;               operateClass:&#39;&#39;,               operateMethod:&#39;&#39;,               returnClass:&#39;&#39;,               costTime:&#39;&#39;           &#125;,           page: 1,  //显示的是哪一页           pageSize: 10, //每一页显示的数据条数           total: 150, //记录总数           maxPage:8  //最大页数       &#125;,       methods: &#123;           pageHandler: function (page) &#123;               this.page = page;               this.search();           &#125;,           search: function () &#123;               var _this = this;               this.showLoading();               axios.post(&#39;/operationLog/findList.do?pageNum=&#39; + _this.page + &quot;&amp;pageSize=&quot; + _this.pageSize, _this.searchEntity).then(function (response) &#123;                   if (response) &#123;                       _this.dataList = response.data.dataList;                       _this.total = response.data.total;                       _this.hideLoading();                   &#125;               &#125;)           &#125;,           showLoading: function () &#123;               $(&#39;#loadingModal&#39;).modal(&#123;backdrop: &#39;static&#39;, keyboard: false&#125;);           &#125;,           hideLoading: function () &#123;               $(&#39;#loadingModal&#39;).modal(&#39;hide&#39;);           &#125;,       &#125;,       created:function()&#123;           this.pageHandler(1);       &#125;   &#125;);&lt;/script&gt;</code></pre><p>列表数据展示</p><pre><code class="bash">&lt;tr v-for=&quot;item in dataList&quot;&gt;    &lt;td&gt;&lt;input name=&quot;ids&quot; type=&quot;checkbox&quot;&gt;&lt;/td&gt;    &lt;td&gt;&#123;&#123;item.id&#125;&#125;&lt;/td&gt;    &lt;td&gt;&#123;&#123;item.operateClass&#125;&#125;&lt;/td&gt;    &lt;td&gt;&#123;&#123;item.operateMethod&#125;&#125;&lt;/td&gt;    &lt;td&gt;&#123;&#123;item.returnClass&#125;&#125;&lt;/td&gt;    &lt;td&gt;&#123;&#123;item.returnValue&#125;&#125;&lt;/td&gt;    &lt;td&gt;&#123;&#123;item.operateUser&#125;&#125;&lt;/td&gt;    &lt;td&gt;&#123;&#123;item.operateTime&#125;&#125;&lt;/td&gt;    &lt;td&gt;&#123;&#123;item.costTime&#125;&#125;&lt;/td&gt;    &lt;td class=&quot;text-center&quot;&gt;        &lt;button type=&quot;button&quot; class=&quot;btn bg-olive btn-xs&quot;&gt;详情&lt;/button&gt;        &lt;button type=&quot;button&quot; class=&quot;btn bg-olive btn-xs&quot;&gt;删除&lt;/button&gt;    &lt;/td&gt;&lt;/tr&gt;</code></pre><p>分页插件</p><pre><code class="bash">&lt;div class=&quot;wrap&quot; id=&quot;wrap&quot;&gt;    &lt;zpagenav v-bind:page=&quot;page&quot; v-bind:page-size=&quot;pageSize&quot; v-bind:total=&quot;total&quot;              v-bind:max-page=&quot;maxPage&quot;  v-on:pagehandler=&quot;pageHandler&quot;&gt;    &lt;/zpagenav&gt;&lt;/div&gt;</code></pre><p>联调测试<br>可以通过 postman 来访问业务系统，再查看数据库中的日志信息，验证能不能将用户的访问日志记录下来。</p><p>image-20210523213448735</p><p>分析性能问题<br>系统中用户访问日志的数据量，随着时间的推移，这张表的数据量会越来越大，因此我们需要根据业务需求，来对日志查询模块的性能进行优化。</p><p>1） 分页查询优化：由于在进行日志查询时，是进行分页查询，那也就意味着，在查看时，至少需要查询两次：</p><p>查询符合条件的总记录数。–&gt; count 操作</p><p>查询符合条件的列表数据。–&gt; 分页查询 limit 操作</p><p>通常来说，count () 都需要扫描大量的行（意味着需要访问大量的数据）才能获得精确的结果，因此是很难对该 SQL 进行优化操作的。如果需要对 count 进行优化，可以采用另外一种思路，可以增加汇总表，或者 redis 缓存来专门记录该表对应的记录数，这样的话，就可以很轻松的实现汇总数据的查询，而且效率很高，但是这种统计并不能保证百分之百的准确 。对于数据库的操作，“快速、精确、实现简单”，三者永远只能满足其二，必须舍掉其中一个。</p><p>2） 条件查询优化：针对于条件查询，需要对查询条件，及排序字段建立索引。</p><p>3） 读写分离：通过主从复制集群，来完成读写分离，使写操作走主节点， 而读操作，走从节点。</p><p>4） MySQL 服务器优化</p><p>5） 应用优化</p><p>性能优化 - 分页<br>优化 count<br>创建一张表用来记录日志表的总数据量：</p><pre><code class="bash">create table log_counter(    logcount bigint not null)engine = innodb default CHARSET = utf8;</code></pre><p>在每次插入数据之后，更新该表 ：</p><pre><code class="bash">&lt;update id=&quot;updateLogCounter&quot; &gt;    update log_counter set logcount = logcount + 1&lt;/update&gt;在进行分页查询时，获取总记录数，从该表中查询既可。</code></pre><pre><code class="bash">&lt;select id=&quot;countLogFromCounter&quot; resultType=&quot;long&quot;&gt;    select logcount from log_counter limit 1&lt;/select&gt;</code></pre><h2 id="优化-limit"><a href="#优化-limit" class="headerlink" title="优化 limit"></a>优化 limit</h2><p>在进行分页时，一般通过创建覆盖索引，能够比较好的提高性能。一个非常常见，而又非常头疼的分页场景就是 “limit 1000000,10” ，此时 MySQL 需要搜索出前 1000010 条记录后，仅仅需要返回第 1000001 到 1000010 条记录，前 1000000 记录会被抛弃，查询代价非常大。</p><p>image-20210523213403564</p><p>当点击比较靠后的页码时，就会出现这个问题，查询效率非常慢。</p><p>优化 SQL：</p><p>SQL<br>1<br>select * from operation_log limit 3000000 , 10;<br>将上述 SQL 优化为 :</p><pre><code class="bash">SQLselect * from operation_log t , (select id from operation_log order by id limit 3000000,10) b where t.id = b.id ;</code></pre><pre><code class="bash">&lt;select id=&quot;selectListByCondition&quot; parameterType=&quot;map&quot; resultType=&quot;operationLog&quot;&gt;  select    id ,    operate_class as operateClass ,    operate_method as operateMethod,    return_class as returnClass,    operate_user as operateUser,    operate_time as operateTime,    param_and_value as paramAndValue,    cost_time as costTime,    return_value as returnValue  from operation_log t,      (select id from operation_log   &lt;where&gt;    &lt;include refid=&quot;oplog_where&quot;/&gt;  &lt;/where&gt;  order by id limit #&#123;start&#125;,#&#123;rows&#125;) b  where t.id = b.id  &lt;/select&gt;</code></pre><h2 id="性能优化-索引"><a href="#性能优化-索引" class="headerlink" title="性能优化 - 索引"></a>性能优化 - 索引</h2><p>image-20210523213331621</p><p>当根据操作人进行查询时， 查询的效率很低，耗时比较长。原因就是因为在创建数据库表结构时，并没有针对于 操作人 字段建立索引。</p><pre><code class="bash">CREATE INDEX idx_user_method_return_cost ON operation_log(operate_user,operate_method,return_class,cost_time);</code></pre><p>同上 ， 为了查询效率高，我们也需要对 操作方法、返回值类型、操作耗时 等字段进行创建索引，以提高查询效率。</p><pre><code class="bash">CREATE INDEX idx_optlog_method_return_cost ON operation_log(operate_method,return_class,cost_time);CREATE INDEX idx_optlog_return_cost ON operation_log(return_class,cost_time);CREATE INDEX idx_optlog_cost ON operation_log(cost_time);</code></pre><p>性能优化 - 排序<br>在查询数据时，如果业务需求中需要我们对结果内容进行了排序处理，这个时候，我们还需要对排序的字段建立适当的索引，来提高排序的效率 。</p><p>性能优化 - 读写分离<br>概述<br>在 MySQL 主从复制的基础上，可以使用读写分离来降低单台 MySQL 节点的压力，从而来提高访问效率，读写分离的架构如下：</p><p>image-20210523213306954</p><p>对于读写分离的实现，可以通过 Spring AOP 来进行动态的切换数据源，进行操作 ：</p><p>实现方式<br>db.properties：</p><p>PROPERTIES<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>jdbc.write.driver=com.mysql.jdbc.Driver<br>jdbc.write.url=jdbc:mysql://192.168.142.128:3306/mysql_demo<br>jdbc.write.username=root<br>jdbc.write.password=itcast</p><p>jdbc.read.driver=com.mysql.jdbc.Driver<br>jdbc.read.url=jdbc:mysql://192.168.142.129:3306/mysql_demo<br>jdbc.read.username=root<br>jdbc.read.password=itcast<br>applicationContext-datasource.xml：</p><pre><code class="bash">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;       xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot;       xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot;       xmlns:context=&quot;http://www.springframework.org/schema/context&quot;       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd        http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd        http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd        http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt;    &lt;!-- 配置数据源 - Read --&gt;    &lt;bean id=&quot;readDataSource&quot; class=&quot;com.mchange.v2.c3p0.ComboPooledDataSource&quot; destroy-method=&quot;close&quot;  lazy-init=&quot;true&quot;&gt;        &lt;property name=&quot;driverClass&quot; value=&quot;$&#123;jdbc.read.driver&#125;&quot;&gt;&lt;/property&gt;        &lt;property name=&quot;jdbcUrl&quot; value=&quot;$&#123;jdbc.read.url&#125;&quot;&gt;&lt;/property&gt;        &lt;property name=&quot;user&quot; value=&quot;$&#123;jdbc.read.username&#125;&quot;&gt;&lt;/property&gt;        &lt;property name=&quot;password&quot; value=&quot;$&#123;jdbc.read.password&#125;&quot;&gt;&lt;/property&gt;    &lt;/bean&gt;    &lt;!-- 配置数据源 - Write --&gt;    &lt;bean id=&quot;writeDataSource&quot; class=&quot;com.mchange.v2.c3p0.ComboPooledDataSource&quot;  destroy-method=&quot;close&quot;  lazy-init=&quot;true&quot;&gt;        &lt;property name=&quot;driverClass&quot; value=&quot;$&#123;jdbc.write.driver&#125;&quot;&gt;&lt;/property&gt;        &lt;property name=&quot;jdbcUrl&quot; value=&quot;$&#123;jdbc.write.url&#125;&quot;&gt;&lt;/property&gt;        &lt;property name=&quot;user&quot; value=&quot;$&#123;jdbc.write.username&#125;&quot;&gt;&lt;/property&gt;        &lt;property name=&quot;password&quot; value=&quot;$&#123;jdbc.write.password&#125;&quot;&gt;&lt;/property&gt;    &lt;/bean&gt;    &lt;!-- 配置动态分配的读写 数据源 --&gt;    &lt;bean id=&quot;dataSource&quot; class=&quot;cn.itcast.aop.datasource.ChooseDataSource&quot; lazy-init=&quot;true&quot;&gt;        &lt;property name=&quot;targetDataSources&quot;&gt;            &lt;map key-type=&quot;java.lang.String&quot; value-type=&quot;javax.sql.DataSource&quot;&gt;                &lt;entry key=&quot;write&quot; value-ref=&quot;writeDataSource&quot;/&gt;                &lt;entry key=&quot;read&quot; value-ref=&quot;readDataSource&quot;/&gt;            &lt;/map&gt;        &lt;/property&gt;        &lt;property name=&quot;defaultTargetDataSource&quot; ref=&quot;writeDataSource&quot;/&gt;        &lt;property name=&quot;methodType&quot;&gt;            &lt;map key-type=&quot;java.lang.String&quot;&gt;                &lt;entry key=&quot;read&quot; value=&quot;,get,select,count,list,query,find&quot;/&gt;                &lt;entry key=&quot;write&quot; value=&quot;,add,create,update,delete,remove,insert&quot;/&gt;            &lt;/map&gt;        &lt;/property&gt;    &lt;/bean&gt;&lt;/beans&gt;</code></pre><p>ChooseDataSource：</p><pre><code class="bash">public class ChooseDataSource extends AbstractRoutingDataSource &#123;    public static Map&lt;String, List&lt;String&gt;&gt; METHOD_TYPE_MAP = new HashMap&lt;String, List&lt;String&gt;&gt;();    /**     * 实现父类中的抽象方法，获取数据源名称     * @return     */    protected Object determineCurrentLookupKey() &#123;        return DataSourceHandler.getDataSource();    &#125;    // 设置方法名前缀对应的数据源    public void setMethodType(Map&lt;String, String&gt; map) &#123;        for (String key : map.keySet()) &#123;            List&lt;String&gt; v = new ArrayList&lt;String&gt;();            String[] types = map.get(key).split(&quot;,&quot;);            for (String type : types) &#123;                if (!StringUtils.isEmpty(type)) &#123;                    v.add(type);                &#125;            &#125;            METHOD_TYPE_MAP.put(key, v);        &#125;        System.out.println(&quot;METHOD_TYPE_MAP : &quot;+METHOD_TYPE_MAP);    &#125;&#125;</code></pre><p>DataSourceHandler：</p><pre><code class="bash">public class DataSourceHandler &#123;    // 数据源名称    public static final ThreadLocal&lt;String&gt; holder = new ThreadLocal&lt;String&gt;();    /**     * 在项目启动的时候将配置的读、写数据源加到holder中     */    public static void putDataSource(String datasource) &#123;        holder.set(datasource);    &#125;    /**     * 从holer中获取数据源字符串     */    public static String getDataSource() &#123;        return holder.get();    &#125;&#125;</code></pre><p>DataSourceAspect：</p><pre><code class="bash">@Aspect@Component@Order(-9999)@EnableAspectJAutoProxy(proxyTargetClass = true)public class DataSourceAspect &#123;    protected Logger logger = LoggerFactory.getLogger(this.getClass());    /**     * 配置前置通知,使用在方法aspect()上注册的切入点     */    @Before(&quot;execution(* cn.itcast.service.*.*(..))&quot;)    @Order(-9999)    public void before(JoinPoint point) &#123;                String className = point.getTarget().getClass().getName();        String method = point.getSignature().getName();        logger.info(className + &quot;.&quot; + method + &quot;(&quot; + Arrays.asList(point.getArgs())+ &quot;)&quot;);        try &#123;            for (String key : ChooseDataSource.METHOD_TYPE_MAP.keySet()) &#123;                for (String type : ChooseDataSource.METHOD_TYPE_MAP.get(key)) &#123;                    if (method.startsWith(type)) &#123;                        System.out.println(&quot;key : &quot; + key);                        DataSourceHandler.putDataSource(key);                        break;                    &#125;                &#125;            &#125;        &#125; catch (Exception e) &#123;            e.printStackTrace();        &#125;    &#125;&#125;</code></pre><p>通过 @Order (-9999) 注解来控制事务管理器，与该通知类的加载顺序，需要让通知类，先加载，来判定使用哪个数据源 。</p><p>验证<br>在主库和从库中，执行如下 SQL 语句，来查看是否读的时候， 从从库中读取； 写入操作的时候，是否写入到主库。</p><p>SQL<br>1<br>show status like ‘Innodb_rows_%’ ;</p><p>image-20210523213147982</p><p>原理</p><p>image-20210523213121482</p><p>性能优化 - 应用优化<br>缓存<br>可以在业务系统中使用 redis 来做缓存，缓存一些基础性的数据，来降低关系型数据库的压力，提高访问效率。</p><p>全文检索<br>如果业务系统中的数据量比较大（达到千万级别），这个时候，如果再对数据库进行查询，特别是进行分页查询，速度将变得很慢（因为在分页时首先需要 count 求合计数），为了提高访问效率，这个时候，可以考虑加入 Solr 或者 ElasticSearch 全文检索服务，来提高访问效率。</p><p>非关系数据库<br>也可以考虑将非核心（重要）数据，存在 MongoDB 中，这样可以提高插入以及查询的效率。</p>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL 高级 — 索引、视图、触发器</title>
      <link href="/2020/10/01/sql/MySQL%20%E9%AB%98%E7%BA%A7%20%E2%80%94%20%E7%B4%A2%E5%BC%95%E3%80%81%E8%A7%86%E5%9B%BE%E3%80%81%E8%A7%A6%E5%8F%91%E5%99%A8/"/>
      <url>/2020/10/01/sql/MySQL%20%E9%AB%98%E7%BA%A7%20%E2%80%94%20%E7%B4%A2%E5%BC%95%E3%80%81%E8%A7%86%E5%9B%BE%E3%80%81%E8%A7%A6%E5%8F%91%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>索引<br>索引概述<br>索引用于快速找出在某个列中有一特定值的行。不使用索引，MySQL 必须从第 1 条记录开始读完整个表，直到找出相关的行。表越大，查询数据所花费的时间越多。如果表中查询的列有一个索引，MySQL 能快速到达某个位置去搜寻数据文件，而不必查看所有数据。</p><p>MySQL 官方对索引的定义为：索引（index）是帮助 MySQL 高效获取数据的数据结构（有序）。在数据之外，数据库系统还维护者满足特定查找算法的数据结构，这些数据结构以某种方式引用（指向）数据， 这样就可以在这些数据结构上实现高级查找算法，这种数据结构就是索引。如下面的示意图所示 :</p><p>img</p><p>左边是数据表，一共有两列七条记录，最左边的是数据记录的物理地址（注意逻辑上相邻的记录在磁盘上也并不是一定物理相邻的）。为了加快 Col2 的查找，可以维护一个右边所示的二叉查找树，每个节点分别包含索引键值和一个指向对应数据记录物理地址的指针，这样就可以运用二叉查找快速获取到相应数据。</p><p>一般来说索引本身也很大，不可能全部存储在内存中，因此索引往往以索引文件的形式存储在磁盘上。索引是数据库中用来提高性能的最常用的工具。</p><p>索引优势劣势<br>优势</p><p>通过创建唯一索引，可以保证数据库表中每一行数据的唯一 性。</p><p>可以大大加快数据的查询速度，这也是创建索引的最主要的原因。</p><p>在实现数据的参考完整性方面，可以加速表和表之间的连接。</p><p>在使用分组和排序子句进行数据查询时，也可以显著减少查询中分组和排序的时间。</p><p>通过索引列对数据进行排序，降低数据排序的成本，降低 CPU 的消耗。</p><p>劣势</p><p>创建索引和维护索引要耗费时间，并且随着数据量的增加所耗费的时间也会增加。而实际上索引也是一张表，该表中保存了主键与索引字段，并指向实体类的记录，所以索引列也是要占用空间的。</p><p>虽然索引大大提高了查询效率，同时却也降低更新表的速度，如对表进行 INSERT、UPDATE、DELETE。因为更新表时，MySQL 不仅要保存数据，还要保存一下索引文件每次更新添加了索引列的字段，都会调整因为更新所带来的键值变化后的索引信息。</p><p>索引结构<br>索引是在 MySQL 的存储引擎层中实现的，而不是在服务器层实现的。所以每种存储引擎的索引都不一定完全相同，也不是所有的存储引擎都支持所有的索引类型的。MySQL 目前提供了以下 4 种索引：</p><p>BTREE 索引 ： 最常见的索引类型，大部分索引都支持 B 树索引。<br>HASH 索引：只有 Memory 引擎支持 ， 使用场景简单 。<br>R-tree 索引（空间索引）：空间索引是 MyISAM 引擎的一个特殊索引类型，主要用于地理空间数据类型，通常使用较少，不做特别介绍。<br>Full-text （全文索引） ：全文索引也是 MyISAM 的一个特殊索引类型，主要用于全文索引，InnoDB 从 Mysql5.6 版本开始支持全文索引。<br>MyISAM、InnoDB、Memory 三种存储引擎对各种索引类型的支持<br>索引    InnoDB 引擎    MyISAM 引擎    Memory 引擎<br>BTREE 索引    支持    支持    支持<br>HASH 索引    不支持    不支持    支持<br>R-tree 索引    不支持    支持    不支持<br>Full-text    5.6 版本之后支持    支持    不支持<br>我们平常所说的索引，如果没有特别指明，都是指 B + 树（多路搜索树，并不一定是二叉的）结构组织的索引。其中聚集索引、复合索引、前缀索引、唯一索引默认都是使用 B+tree 索引，统称为 索引。</p><p>BTREE 结构<br>BTree 又叫多路平衡搜索树，一颗 m 叉的 BTree 特性如下：</p><p>树中每个节点最多包含 m 个孩子。<br>除根节点与叶子节点外，每个节点至少有 [ceil (m/2)] 个孩子。<br>若根节点不是叶子节点，则至少有两个孩子。<br>所有的叶子节点都在同一层。<br>每个非叶子节点由 n 个 key 与 n+1 个指针组成，其中 [ceil (m/2)-1] &lt;= n &lt;= m-1<br>以 5 叉 BTree 为例，key 的数量：公式推导 [ceil (m/2)-1] &lt;= n &lt;= m-1。所以 2 &lt;= n &lt;=4 。当 n&gt;4 时，中间节点分裂到父节点，两边节点分裂。</p><p>插入 C N G A H E K Q M F W L T Z D P R X Y S 数据为例。</p><p>演变过程如下：</p><p>1). 插入前 4 个字母 C N G A</p><p>image-20210509150725663</p><p>2). 插入 H，n&gt;4，中间元素 G 字母向上分裂到新的节点</p><p>image-20210509151445248</p><p>3). 插入 E，K，Q 不需要分裂</p><p>image-20210509151405735</p><p>4). 插入 M，中间元素 M 字母向上分裂到父节点 G</p><p>image-20210509151524511</p><p>5). 插入 F，W，L，T 不需要分裂</p><p>image-20210509151610632</p><p>6). 插入 Z，中间元素 T 向上分裂到父节点中</p><p>image-20210509151637065</p><p>7). 插入 D，中间元素 D 向上分裂到父节点中。然后插入 P，R，X，Y 不需要分裂</p><p>image-20210509151704163</p><p>8). 最后插入 S，NPQR 节点 n&gt;5，中间节点 Q 向上分裂，但分裂后父节点 DGMT 的 n&gt;5，中间节点 M 向上分裂</p><p>image-20210509151732707</p><p>到此，该 BTREE 树就已经构建完成了， BTREE 树和二叉树 相比， 查询数据的效率更高， 因为对于相同的数据量来说，BTREE 的层级结构比二叉树小，因此搜索速度快。</p><p>B+TREE 结构<br>B+Tree 为 BTree 的变种，B+Tree 与 BTree 的区别为：</p><p>n 叉 B+Tree 最多含有 n 个 key，而 BTree 最多含有 n-1 个 key。</p><p>B+Tree 的叶子节点保存所有的 key 信息，依 key 大小顺序排列。</p><p>所有的非叶子节点都可以看作是 key 的索引部分。</p><p>image-20210509152053832</p><p>由于 B+Tree 只有叶子节点保存 key 信息，查询任何 key 都要从 root 走到叶子。所以 B+Tree 的查询效率更加稳定。</p><p>MySQL 中的 B+Tree<br>MySQL 索引数据结构对经典的 B+Tree 进行了优化。在原 B+Tree 的基础上，增加一个指向相邻叶子节点的链表指针，就形成了带有顺序指针的 B+Tree，提高区间访问的性能。</p><p>MySQL 中的 B+Tree 索引结构示意图:</p><p>image-20210509152148351</p><p>索引分类<br>单值索引 ：即一个索引只包含单个列，一个表可以有多个单列索引。</p><p>唯一索引 ：索引列的值必须唯一，但允许有空值。</p><p>复合索引 ：即一个索引包含多个列。</p><p>全文索引：在定义索引的列上支持值的全文查找，允许在这些索引列插入重复值和空值。</p><p>索引语法<br>索引在创建表的时候，可以同时创建， 也可以随时增加新的索引。</p><p>准备环境:</p><p>SQL<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>26<br>27<br>create database demo_01 default charset=utf8mb4;</p><p>use demo_01;</p><p>CREATE TABLE <code>city</code> (<br>  <code>city_id</code> int(11) NOT NULL AUTO_INCREMENT,<br>  <code>city_name</code> varchar(50) NOT NULL,<br>  <code>country_id</code> int(11) NOT NULL,<br>  PRIMARY KEY (<code>city_id</code>)<br>) ENGINE=InnoDB DEFAULT CHARSET=utf8;</p><p>CREATE TABLE <code>country</code> (<br>  <code>country_id</code> int(11) NOT NULL AUTO_INCREMENT,<br>  <code>country_name</code> varchar(100) NOT NULL,<br>  PRIMARY KEY (<code>country_id</code>)<br>) ENGINE=InnoDB DEFAULT CHARSET=utf8;</p><p>insert into <code>city</code> (<code>city_id</code>, <code>city_name</code>, <code>country_id</code>) values(1,’西安’,1);<br>insert into <code>city</code> (<code>city_id</code>, <code>city_name</code>, <code>country_id</code>) values(2,’上海’,2);<br>insert into <code>city</code> (<code>city_id</code>, <code>city_name</code>, <code>country_id</code>) values(3,’北京’,1);<br>insert into <code>city</code> (<code>city_id</code>, <code>city_name</code>, <code>country_id</code>) values(4,’上海’,1);</p><p>insert into <code>country</code> (<code>country_id</code>, <code>country_name</code>) values(1,’China’);<br>insert into <code>country</code> (<code>country_id</code>, <code>country_name</code>) values(2,’America’);<br>insert into <code>country</code> (<code>country_id</code>, <code>country_name</code>) values(3,’Japan’);<br>insert into <code>country</code> (<code>country_id</code>, <code>country_name</code>) values(4,’UK’);<br>创建索引<br>语法 ：</p><p>SQL<br>1<br>2<br>3<br>4<br>5<br>6<br>CREATE     [UNIQUE|FULLTEXT|SPATIAL]  INDEX index_name<br>[USING  index_type]<br>ON tbl_name(index_col_name,…)</p><p>index_col_name : column_name[(length)][ASC | DESC]<br>示例 ： 为 city 表中的 city_name 字段创建索引 ；</p><p>SQL<br>1<br>2<br>3<br>mysql&gt; create index idx_city_name on city(city_name);<br>Query OK, 0 rows affected (0.07 sec)<br>Records: 0  Duplicates: 0  Warnings: 0<br>查看索引<br>语法：</p><p>SQL<br>1<br>show index  from  table_name;<br>示例：查看 city 表中的索引信息；</p><p>SQL<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>mysql&gt; show index from city;<br>+——-+————+—————+————–+————-+———–+————-+———-+——–+——+————+———+—————+<br>| Table | Non_unique | Key_name      | Seq_in_index | Column_name | Collation | Cardinality | Sub_part | Packed | Null | Index_type | Comment | Index_comment |<br>+——-+————+—————+————–+————-+———–+————-+———-+——–+——+————+———+—————+<br>| city  |          0 | PRIMARY       |            1 | city_id     | A         |           4 | NULL     | NULL   |      | BTREE      |         |               |<br>| city  |          1 | idx_city_name |            1 | city_name   | A         |           3 | NULL     | NULL   |      | BTREE      |         |               |<br>+——-+————+—————+————–+————-+———–+————-+———-+——–+——+————+———+—————+<br>2 rows in set (0.14 sec)<br>删除索引<br>语法 ：</p><p>SQL<br>1<br>DROP  INDEX  index_name  ON  tbl_name;<br>示例 ： 想要删除 city 表上的索引 idx_city_name，可以操作如下：</p><p>SQL<br>1<br>2<br>3<br>mysql&gt; drop index idx_city_name on city;<br>Query OK, 0 rows affected (0.05 sec)<br>Records: 0  Duplicates: 0  Warnings: 0<br>ALTER 命令<br>SQL<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15</p><ol><li><p>alter  table  tb_name  add  primary  key(column_list); </p><p> 该语句添加一个主键，这意味着索引值必须是唯一的，且不能为NULL</p></li><li><p>alter  table  tb_name  add  unique index_name(column_list);</p><p> 这条语句创建索引的值必须是唯一的（除了NULL外，NULL可能会出现多次）</p></li><li><p>alter  table  tb_name  add  index index_name(column_list);</p><p> 添加普通索引， 索引值可以出现多次。</p></li><li><p>alter  table  tb_name  add  fulltext  index_name(column_list);</p><p> 该语句指定了索引为FULLTEXT， 用于全文索引<br>索引设计原则<br>​ 索引的设计可以遵循一些已有的原则，创建索引的时候请尽量考虑符合这些原则，便于提升索引的使用效率，更高效的使用索引。</p></li></ol><p>对查询频次较高，且数据量比较大的表建立索引。</p><p>索引字段的选择，最佳候选列应当从 where 子句的条件中提取，如果 where 子句中的组合比较多，那么应当挑选最常用、过滤效果最好的列的组合。</p><p>使用唯一索引，区分度越高，使用索引的效率越高。</p><p>索引可以有效的提升查询数据的效率，但索引数量不是多多益善，索引越多，维护索引的代价自然也就水涨船高。对于插入、更新、删除等 DML 操作比较频繁的表来说，索引过多，会引入相当高的维护代价，降低 DML 操作的效率，增加相应操作的时间消耗。另外索引过多的话，MySQL 也会犯选择困难病，虽然最终仍然会找到一个可用的索引，但无疑提高了选择的代价。</p><p>使用短索引，索引创建之后也是使用硬盘来存储的，因此提升索引访问的 I/O 效率，也可以提升总体的访问效率。假如构成索引的字段总长度比较短，那么在给定大小的存储块内可以存储更多的索引值，相应的可以有效的提升 MySQL 访问索引的 I/O 效率。</p><p>利用最左前缀，N 个列组合而成的组合索引，那么相当于是创建了 N 个索引，如果查询时 where 子句中使用了组成该索引的前几个字段，那么这条查询 SQL 可以利用组合索引来提升查询效率。</p><p>SQL<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>创建复合索引:</p><pre><code>CREATE INDEX idx_name_email_status ON tb_seller(NAME,email,STATUS);</code></pre><p>就相当于<br>    对name 创建索引 ;<br>    对name , email 创建了索引 ;<br>    对name , email, status 创建了索引 ;<br>视图<br>视图概述<br>视图（View）是一种虚拟存在的表。视图并不在数据库中实际存在，行和列数据来自定义视图的查询中使用的表，并且是在使用视图时动态生成的。通俗的讲，视图就是一条 SELECT 语句执行后返回的结果集。所以我们在创建视图的时候，主要的工作就落在创建这条 SQL 查询语句上。</p><p>视图相对于普通的表的优势主要包括以下几项。</p><p>简单：使用视图的用户完全不需要关心后面对应的表的结构、关联条件和筛选条件，对用户来说已经是过滤好的复合条件的结果集。<br>安全：使用视图的用户只能访问他们被允许查询的结果集，对表的权限管理并不能限制到某个行某个列，但是通过视图就可以简单的实现。<br>数据独立：一旦视图的结构确定了，可以屏蔽表结构变化对用户的影响，源表增加列对视图没有影响；源表修改列名，则可以通过修改视图来解决，不会造成对访问者的影响。<br>创建或者修改视图<br>创建视图的语法为：</p><p>SQL<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>CREATE [OR REPLACE] [ALGORITHM = {UNDEFINED | MERGE | TEMPTABLE}]</p><p>VIEW view_name [(column_list)]</p><p>AS select_statement</p><p>[WITH [CASCADED | LOCAL] CHECK OPTION]<br>修改视图的语法为：</p><p>SQL<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>ALTER [ALGORITHM = {UNDEFINED | MERGE | TEMPTABLE}]</p><p>VIEW view_name [(column_list)]</p><p>AS select_statement</p><p>[WITH [CASCADED | LOCAL] CHECK OPTION]<br>SQL<br>1<br>2<br>3<br>4<br>5<br>选项 :<br>    WITH [CASCADED | LOCAL] CHECK OPTION 决定了是否允许更新数据使记录不再满足视图的条件。</p><pre><code>LOCAL ： 只要满足本视图的条件就可以更新。CASCADED ： 必须满足所有针对该视图的所有视图的条件才可以更新。 默认值.</code></pre><p>示例，创建 city_country_view 视图，执行如下 SQL :</p><p>SQL<br>1<br>2<br>3<br>4<br>create or replace view city_country_view<br>as<br>select t.*,c.country_name from country c , city t where c.country_id = t.country_id;</p><p>查询视图 :</p><p>SQL<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>mysql&gt;  select * from city_country_view;<br>+———+———–+————+————–+<br>| city_id | city_name | country_id | country_name |<br>+———+———–+————+————–+<br>|       1 | 西安      |          1 | China        |<br>|       3 | 北京      |          1 | China        |<br>|       4 | 上海      |          1 | China        |<br>|       2 | 上海      |          2 | America      |<br>+———+———–+————+————–+<br>4 rows in set (0.17 sec)<br>查看视图<br>从 MySQL 5.1 版本开始，使用 SHOW TABLES 命令的时候不仅显示表的名字，同时也会显示视图的名字，而不存在单独显示视图的 SHOW VIEWS 命令。</p><p>SQL<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>mysql&gt; show tables;<br>+——————-+<br>| Tables_in_test    |<br>+——————-+<br>| accout            |<br>| book              |<br>| books             |<br>| city              |<br>| city_country_view |<br>| country           |<br>| customers         |<br>同样，在使用 SHOW TABLE STATUS 命令的时候，不但可以显示表的信息，同时也可以显示视图的信息。</p><p>SQL<br>1<br>2<br>3<br>4<br>mysql&gt; show table status;<br> Name              | Engine | Version | Row_format | Rows | Avg_row_length | Data_length | Max_data_length | Index_length | Data_free | Auto_increment | Create_time         | Update_time         | Check_time | Collation       | Checksum | Create_options | Comment |</p><p> city_country_view | NULL   | NULL    | NULL       | NULL | NULL           | NULL        | NULL            | NULL         | NULL      | NULL<br>如果需要查询某个视图的定义，可以使用 SHOW CREATE VIEW 命令进行查看 ：</p><p>SQL<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>mysql&gt; show create view city_country_view;;</p><p>| View              | Create View                                                                                                                                                                                                                                                                                                                    | character_set_client | collation_connection |<br>+——————-+——————————————————————————————————————————————————————————————————————————————————————————————————————————–+———————-+———————-+<br>| city_country_view | CREATE ALGORITHM=UNDEFINED DEFINER=<code>root</code>@<code>localhost</code> SQL SECURITY DEFINER VIEW <code>city_country_view</code> AS select <code>t</code>.<code>city_id</code> AS <code>city_id</code>,<code>t</code>.<code>city_name</code> AS <code>city_name</code>,<code>t</code>.<code>country_id</code> AS <code>country_id</code>,<code>c</code>.<code>country_name</code> AS <code>country_name</code> from (<code>country</code> <code>c</code> join <code>city</code> <code>t</code>) where (<code>c</code>.<code>country_id</code> = <code>t</code>.<code>country_id</code>) | utf8mb4              | utf8mb4_general_ci   |<br>+——————-+——————————————————————————————————————————————————————————————————————————————————————————————————————————–+———————-+———————-+<br>1 row in set (0.15 sec)<br>删除视图<br>语法 :</p><p>SQL<br>1<br>DROP VIEW [IF EXISTS] view_name [, view_name] …[RESTRICT | CASCADE]    ;<br>示例，删除视图 city_country_view :</p><p>SQL<br>1<br>DROP VIEW city_country_view ;<br>触发器<br>介绍<br>触发器是与表有关的数据库对象，指在 insert/update/delete 之前或之后，触发并执行触发器中定义的 SQL 语句集合。触发器的这种特性可以协助应用在数据库端确保数据的完整性，日志记录，数据校验等操作 。</p><p>使用别名 OLD 和 NEW 来引用触发器中发生变化的记录内容，这与其他的数据库是相似的。现在触发器还只支持行级触发，不支持语句级触发。</p><p>触发器类型    NEW 和 OLD 的使用<br>INSERT 型触发器    NEW 表示将要或者已经新增的数据<br>UPDATE 型触发器    OLD 表示修改之前的数据，NEW 表示将要或已经修改后的数据<br>DELETE 型触发器    OLD 表示将要或者已经删除的数据<br>创建触发器<br>语法结构 :</p><p>SQL<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>create trigger trigger_name </p><p>before/after insert/update/delete</p><p>on tbl_name </p><p>[ for each row ]  – 行级触发器</p><p>begin</p><pre><code>trigger_stmt ;</code></pre><p>end;<br>示例需求:</p><p>CODE<br>1<br>通过触发器记录 emp 表的数据变更日志 , 包含增加, 修改 , 删除 ;<br>首先创建一张日志表 :</p><p>SQL<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>create table emp_logs(<br>  id int(11) not null auto_increment,<br>  operation varchar(20) not null comment ‘操作类型, insert/update/delete’,<br>  operate_time datetime not null comment ‘操作时间’,<br>  operate_id int(11) not null comment ‘操作表的ID’,<br>  operate_params varchar(500) comment ‘操作参数’,<br>  primary key(<code>id</code>)<br>)engine=innodb default charset=utf8;<br>创建 insert 型触发器，完成插入数据时的日志记录 :</p><p>SQL<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>DELIMITER $</p><p>create trigger emp_logs_insert_trigger<br>after insert<br>on emp<br>for each row<br>begin<br>  insert into emp_logs (id,operation,operate_time,operate_id,operate_params) values(null,’insert’,now(),new.id,concat(‘插入后(id:’,new.id,’, name:’,new.name,’, age:’,new.age,’, salary:’,new.salary,’)’));<br>end $</p><p>DELIMITER ;<br>创建 update 型触发器，完成更新数据时的日志记录 :</p><p>SQL<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>DELIMITER $</p><p>create trigger emp_logs_update_trigger<br>after update<br>on emp<br>for each row<br>begin<br>  insert into emp_logs (id,operation,operate_time,operate_id,operate_params) values(null,’update’,now(),new.id,concat(‘修改前(id:’,old.id,’, name:’,old.name,’, age:’,old.age,’, salary:’,old.salary,’) , 修改后(id’,new.id, ‘name:’,new.name,’, age:’,new.age,’, salary:’,new.salary,’)’));<br>end $</p><p>DELIMITER ;<br>创建 delete 行的触发器，完成删除数据时的日志记录 :</p><p>SQL<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>DELIMITER $</p><p>create trigger emp_logs_delete_trigger<br>after delete<br>on emp<br>for each row<br>begin<br>  insert into emp_logs (id,operation,operate_time,operate_id,operate_params) values(null,’delete’,now(),old.id,concat(‘删除前(id:’,old.id,’, name:’,old.name,’, age:’,old.age,’, salary:’,old.salary,’)’));<br>end $</p><p>DELIMITER ;<br>测试：</p><p>SQL<br>1<br>2<br>3<br>4<br>5<br>6<br>insert into emp(id,name,age,salary) values(null, ‘光明左使’,30,3500);<br>insert into emp(id,name,age,salary) values(null, ‘光明右使’,33,3200);</p><p>update emp set age = 39 where id = 3;</p><p>delete from emp where id = 5;<br>删除触发器<br>语法结构 :</p><p>SQL<br>1<br>drop trigger [schema_name.]trigger_name;<br>如果没有指定 schema_name，默认为当前数据库 。</p><p>查看触发器<br>可以通过执行 SHOW TRIGGERS 命令查看触发器的状态、语法等信息。</p><p>语法结构 ：</p><p>SQL<br>1<br>show triggers ;<br>触发器注意<br>在使用触发器的时候需要注意，对于相同的表，相同的事件只能创建一个触发器。</p><p>及时删除不再需要的触发器。</p>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL 高级 — 相关优化、锁、使用技巧</title>
      <link href="/2020/09/28/sql/MySQL%20%E9%AB%98%E7%BA%A7%20%E2%80%94%20%E7%9B%B8%E5%85%B3%E4%BC%98%E5%8C%96%E3%80%81%E9%94%81%E3%80%81%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7/"/>
      <url>/2020/09/28/sql/MySQL%20%E9%AB%98%E7%BA%A7%20%E2%80%94%20%E7%9B%B8%E5%85%B3%E4%BC%98%E5%8C%96%E3%80%81%E9%94%81%E3%80%81%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>应用优化<br>前面章节，介绍了很多数据库的优化措施。但是在实际生产环境中，由于数据库本身的性能局限，就必须要对前台的应用进行一些优化，来降低数据库的访问压力。</p><p>使用连接池<br>对于访问数据库来说，建立连接的代价是比较昂贵的，因为频繁的创建关闭连接，是比较耗费资源的，我们有必要建立数据库连接池，以提高访问的性能。</p><p>减少对 MySQL 的访问<br>避免对数据进行重复检索<br>在编写应用代码时，需要能够理清对数据库的访问逻辑。能够一次连接就获取到结果的，就不用两次连接，这样可以大大减少对数据库无用的重复请求。比如 ，需要获取书籍的 id 和 name 字段 ， 则查询如下：</p><p>SQL<br>1<br>select id , name from tb_book;<br>之后，在业务逻辑中有需要获取到书籍状态信息， 则查询如下：</p><p>SQL<br>1<br>select id , status from tb_book;<br>这样，就需要向数据库提交两次请求，数据库就要做两次查询操作。其实完全可以用一条 SQL 语句得到想要的结果。</p><p>SQL<br>1<br>select id, name , status from tb_book;<br>增加 cache 层<br>在应用中，我们可以在应用中增加缓存层来达到减轻数据库负担的目的。缓存层有很多种，也有很多实现方式，只要能达到降低数据库的负担又能满足应用需求就可以。因此可以部分数据从数据库中抽取出来放到应用端以文本方式存储， 或者使用框架 (Mybatis, Hibernate) 提供的一级缓存 / 二级缓存，或者使用 redis 数据库来缓存数据 。</p><p>负载均衡<br>负载均衡是应用中使用非常普遍的一种优化方法，它的机制就是利用某种均衡算法，将固定的负载量分布到不同的服务器上， 以此来降低单台服务器的负载，达到优化的效果。</p><p>利用 MySQL 复制分流查询<br>通过 MySQL 的主从复制，实现读写分离，使增删改操作走主节点，查询操作走从节点，从而可以降低单台服务器的读写压力。</p><p>1<br>采用分布式数据库架构<br>分布式数据库架构适合大数据量、负载高的情况，它有良好的拓展性和高可用性。通过在多台服务器之间分布数据，可以实现在多台服务器之间的负载均衡，提高访问效率。</p><p>MySQL 中查询缓存优化<br>概述<br>开启 MySQL 的查询缓存，当执行完全相同的 SQL 语句的时候，服务器就会直接从缓存中读取结果，当数据被修改，之前的缓存会失效，修改比较频繁的表不适合做查询缓存。</p><p>注：MySQL8 取消了查询缓存。</p><p>操作流程</p><p>20180919131632347<br>客户端发送一条查询给服务器；</p><p>服务器先会检查查询缓存，如果命中了缓存，则立即返回存储在缓存中的结果。否则进入下一阶段；</p><p>服务器端进行 SQL 解析、预处理，再由优化器生成对应的执行计划；</p><p>MySQL 根据优化器生成的执行计划，调用存储引擎的 API 来执行查询；</p><p>将结果返回给客户端。</p><p>查询缓存配置<br>查看当前的 MySQL 数据库是否支持查询缓存：</p><p>SQL<br>1<br>SHOW VARIABLES LIKE ‘have_query_cache’;<br>SQL<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>mysql&gt; show variables like ‘have_query_cache’;<br>+——————+——-+<br>| Variable_name    | Value |<br>+——————+——-+<br>| have_query_cache | YES   |<br>+——————+——-+<br>1 row in set (0.04 sec)<br>查看当前 MySQL 是否开启了查询缓存 ：</p><p>SQL<br>1<br>SHOW VARIABLES LIKE ‘query_cache_type’;<br>SQL<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>mysql&gt; show variables like ‘query_cache_type’;<br>+——————+——-+<br>| Variable_name    | Value |<br>+——————+——-+<br>| query_cache_type | OFF   |<br>+——————+——-+<br>1 row in set (0.06 sec)<br>查看查询缓存的占用大小 ：</p><p>SQL<br>1<br>SHOW VARIABLES LIKE ‘query_cache_size’;<br>SQL<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>mysql&gt; show variables like ‘query_cache_size’;<br>+——————+———+<br>| Variable_name    | Value   |<br>+——————+———+<br>| query_cache_size | 1048576 |<br>+——————+———+<br>1 row in set (0.07 sec)<br>查看查询缓存的状态变量：</p><p>SQL<br>1<br>SHOW STATUS LIKE ‘Qcache%’;<br>SQL<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>mysql&gt; show status like ‘Qcache%’;<br>+————————-+———+<br>| Variable_name           | Value   |<br>+————————-+———+<br>| Qcache_free_blocks      | 1       |<br>| Qcache_free_memory      | 1031872 |<br>| Qcache_hits             | 0       |<br>| Qcache_inserts          | 0       |<br>| Qcache_lowmem_prunes    | 0       |<br>| Qcache_not_cached       | 1       |<br>| Qcache_queries_in_cache | 0       |<br>| Qcache_total_blocks     | 1       |<br>+————————-+———+<br>8 rows in set (0.09 sec)<br>各个变量的含义如下：</p><p>参数    含义<br>Qcache_free_blocks    查询缓存中的可用内存块数<br>Qcache_free_memory    查询缓存的可用内存量<br>Qcache_hits    查询缓存命中数<br>Qcache_inserts    添加到查询缓存的查询数<br>Qcache_lowmen_prunes    由于内存不足而从查询缓存中删除的查询数<br>Qcache_not_cached    非缓存查询的数量（由于 query_cache_type 设置而无法缓存或未缓存）<br>Qcache_queries_in_cache    查询缓存中注册的查询数<br>Qcache_total_blocks    查询缓存中的块总数<br>开启查询缓存<br>MySQL 的查询缓存默认是关闭的，需要手动配置参数 query_cache_type ， 来开启查询缓存。query_cache_type 该参数的可取值有三个 ：</p><p>值    含义<br>OFF 或 0    查询缓存功能关闭<br>ON 或 1    查询缓存功能打开，SELECT 的结果符合缓存条件即会缓存，否则，不予缓存，显式指定 SQL_NO_CACHE，不予缓存<br>DEMAND 或 2    查询缓存功能按需进行，显式指定 SQL_CACHE 的 SELECT 语句才会缓存；其它均不予缓存<br>在如下配置文件中，增加以下配置 ：</p><p>image-20210518191941302<br>CODE<br>1<br>query_cache_type=1<br>配置完毕之后，重启服务既可生效 ；之后就可以在命令行执行 SQL 语句进行验证 ，执行一条比较耗时的 SQL 语句，然后再多执行几次，查看后面几次的执行时间；获取通过查看查询缓存的缓存命中数，来判定是否走查询缓存。</p><pre><code class="bash">mysql&gt; select count(*) from tb_user_2;+----------+| count(*) |+----------+|  1000000 |+----------+1 row in set (0.91 sec)mysql&gt; select count(*) from tb_user_2;+----------+| count(*) |+----------+|  1000000 |+----------+1 row in set (0.05 sec)mysql&gt; show status like &#39;Qcache%&#39;;+-------------------------+--------+| Variable_name           | Value  |+-------------------------+--------+| Qcache_free_blocks      | 1      || Qcache_free_memory      | 875448 || Qcache_hits             | 1      || Qcache_inserts          | 2      || Qcache_lowmem_prunes    | 0      || Qcache_not_cached       | 5      || Qcache_queries_in_cache | 2      || Qcache_total_blocks     | 6      |+-------------------------+--------+8 rows in set (0.08 sec)</code></pre><p>从上面的结果可知，第二次查询已经走了查询缓存，并且命中次数也已经增加。</p><p>查询缓存 SELECT 选项<br>可以在 SELECT 语句中指定两个与查询缓存相关的选项 ：</p><p>SQL_CACHE : 如果查询结果是可缓存的，并且 query_cache_type 系统变量的值为 ON 或 DEMAND ，则缓存查询结果 。</p><p>SQL_NO_CACHE : 服务器不使用查询缓存。它既不检查查询缓存，也不检查结果是否已缓存，也不缓存查询结果。</p><p>例子：</p><p>SQL<br>1<br>2<br>SELECT SQL_CACHE city_id, city_name FROM city;<br>SELECT SQL_NO_CACHE city_id, city_name FROM city;<br>​</p><p>查询缓存失效的情况<br>1） SQL 语句不一致的情况， 要想命中查询缓存，查询的 SQL 语句必须一致，大小写也必须一致。</p><p>SQL<br>1<br>2<br>SQL1 : select count(<em>) from tb_user;<br>SQL2 : Select count(</em>) from tb_user;<br>2） 当查询语句中有一些不确定的属性，则不会缓存。如 ： now () , current_date () , curdate () , curtime () , rand () , uuid () , user () , database () 。如下：</p><p>SQL<br>1<br>2<br>3<br>SQL1 : select * from tb_item where updatetime &lt; now() limit 1;<br>SQL2 : select user();<br>SQL3 : select database();<br>3） 不使用任何表查询语句。</p><p>SQL<br>1<br>select ‘A’;<br>4） 查询 mysql， information_schema 或 performance_schema 数据库中的表时，不会走查询缓存。</p><p>SQL<br>1<br>select * from information_schema.engines;<br>5） 在存储的函数，触发器或事件的主体内执行的查询。</p><p>6） 如果表更改，则使用该表的所有高速缓存查询都将变为无效并从高速缓存中删除。这包括使用 MERGE 映射到已更改表的表的查询。一个表可以被许多类型的语句改变，如被 INSERT， UPDATE， DELETE， TRUNCATE TABLE， ALTER TABLE， DROP TABLE，或 DROP DATABASE 改变。</p><p>MySQL 内存管理及优化<br>内存优化原则<br>尽量多的将内存分配给 MySQL 做缓存，但要给操作系统和其他程序预留足够内存。</p><p>MyISAM 存储引擎的数据文件读取依赖于操作系统自身的 IO 缓存，因此，如果有 MyISAM 表，就要预留更多的内存给操作系统做 IO 缓存。</p><p>排序区、连接区等缓存是分配给每个数据库会话（session）专用的，其默认值的设置要根据最大连接数合理分配，如果设置太大，不但浪费资源，而且在并发连接较高时会导致物理内存耗尽。</p><p>MyISAM 内存优化<br>myisam 存储引擎使用 key_buffer 缓存索引块，加速 myisam 索引的读写速度。对于 myisam 表的数据块，mysql 没有特别的缓存机制，完全依赖于操作系统的 IO 缓存。</p><p>key_buffer_size<br>key_buffer_size 决定 MyISAM 索引块缓存区的大小，直接影响到 MyISAM 表的存取效率。可以在 MySQL 参数文件中设置 key_buffer_size 的值，对于一般 MyISAM 数据库，建议至少将 1/4 可用内存分配给 key_buffer_size。</p><p>在上图所示的 my 配置文件中做如下配置：</p><p>XML<br>1<br>key_buffer_size=512M<br>read_buffer_size<br>如果需要经常顺序扫描 myisam 表，可以通过增大 read_buffer_size 的值来改善性能。但需要注意的是 read_buffer_size 是每个 session 独占的，如果默认值设置太大，就会造成内存浪费。</p><p>read_rn_buffer_size<br>对于需要做排序的 myisam 表的查询，如带有 order by 子句的 sql，适当增加 read_rnd_buffer_size 的值，可以改善此类的 sql 性能。但需要注意的是 read_rnd_buffer_size 是每个 session 独占的，如果默认值设置太大，就会造成内存浪费。</p><p>InnoDB 内存优化<br>innodb 用一块内存区做 IO 缓存池，该缓存池不仅用来缓存 innodb 的索引块，而且也用来缓存 innodb 的数据块。</p><p>innodb_buffer_pool_size<br>该变量决定了 innodb 存储引擎表数据和索引数据的最大缓存区大小。在保证操作系统及其他程序有足够内存可用的情况下，innodb_buffer_pool_size 的值越大，缓存命中率越高，访问 InnoDB 表需要的磁盘 I/O 就越少，性能也就越高。</p><p>XML<br>1<br>innodb_buffer_pool_size=512M<br>innodb_log_buffer_size<br>决定了 innodb 重做日志缓存的大小，对于可能产生大量更新记录的大事务，增加 innodb_log_buffer_size 的大小，可以避免 innodb 在事务提交前就执行不必要的日志写入磁盘操作。</p><p>XML<br>1<br>innodb_log_buffer_size=10M<br>MySQL 并发参数调整<br>从实现上来说，MySQL Server 是多线程结构，包括后台线程和客户服务线程。多线程可以有效利用服务器资源，提高数据库的并发性能。在 MySQL 中，控制并发连接和线程的主要参数包括 max_connections、back_log、thread_cache_size、table_open_cahce。</p><p>max_connections<br>采用 max_connections 控制允许连接到 MySQL 数据库的最大数量，默认值是 151。如果状态变量 connection_errors_max_connections 不为零，并且一直增长，则说明不断有连接请求因数据库连接数已达到允许最大值而失败，这是可以考虑增大 max_connections 的值。</p><p>MySQL 最大可支持的连接数，取决于很多因素，包括给定操作系统平台的线程库的质量、内存大小、每个连接的负荷、CPU 的处理速度，期望的响应时间等。在 Linux 平台下，性能好的服务器，支持 500-1000 个连接不是难事，需要根据服务器性能进行评估设定。</p><p>back_log<br>back_log 参数控制 MySQL 监听 TCP 端口时设置的积压请求栈大小。如果 MySQL 的连接数达到 max_connections 时，新来的请求将会被存在堆栈中，以等待某一连接释放资源，该堆栈的数量即 back_log，如果等待连接的数量超过 back_log，将不被授予连接资源，将会报错。5.6.6 版本之前默认值为 50 ， 之后的版本默认为 50 + （max_connections / 5）， 但最大不超过 900。如果需要数据库在较短的时间内处理大量连接请求， 可以考虑适当增大 back_log 的值。</p><p>table_open_cache<br>该参数用来控制所有 SQL 语句执行线程可打开表缓存的数量， 而在执行 SQL 语句时，每一个 SQL 执行线程至少要打开 1 个表缓存。该参数的值应该根据设置的最大连接数 max_connections 以及每个连接执行关联查询中涉及的表的最大数量来设定 ：</p><p>XML<br>1<br>max_connections x N ;<br>thread_cache_size<br>为了加快连接数据库的速度，MySQL 会缓存一定数量的客户服务线程以备重用，通过参数 thread_cache_size 可控制 MySQL 缓存客户服务线程的数量。</p><p>innodb_lock_wait_timeout<br>该参数是用来设置 InnoDB 事务等待行锁的时间，默认值是 50ms ， 可以根据需要进行动态设置。对于需要快速反馈的业务系统来说，可以将行锁的等待时间调小，以避免事务长时间挂起； 对于后台运行的批量处理程序来说， 可以将行锁的等待时间调大， 以避免发生大的回滚操作。</p><p>MySQL 锁问题<br>锁概述及分类<br>锁是计算机协调多个进程或线程并发访问某一资源的机制（避免争抢）。在数据库中，除传统的计算资源（如 CPU、RAM、I/O 等）的争用以外，数据也是一种供许多用户共享的资源。如何保证数据并发访问的一致性、有效性是所有数据库必须解决的一个问题，锁冲突也是影响数据库并发访问性能的一个重要因素。从这个角度来说，锁对数据库而言显得尤其重要，也更加复杂。</p><p>从对数据操作的粒度分 ：</p><p>表锁：操作时，会锁定整个表。</p><p>行锁：操作时，会锁定当前操作行。</p><p>从对数据操作的类型分：</p><p>读锁（共享锁）：针对同一份数据，多个读操作可以同时进行而不会互相影响。</p><p>写锁（排它锁）：当前操作没有完成之前，它会阻断其他写锁和读锁。</p><p>MySQL 锁<br>相对其他数据库而言，MySQL 的锁机制比较简单，其最显著的特点是不同的存储引擎支持不同的锁机制。下表中列出了各存储引擎对锁的支持情况：<br>| 存储引擎 | 表级锁 | 行级锁 | 页面锁 |<br>| ——– | —— | —— | —— |<br>| MyISAM | 支持 | 不支持 | 不支持 |<br>| InnoDB | 支持 | 支持 | 不支持 |<br>| MEMORY | 支持 | 不支持 | 不支持 |<br>| BDB | 支持 | 不支持 | 支持 |</p><p>MySQL 这 3 种锁的特性可大致归纳如下 ：</p><p>锁类型    特点<br>表级锁    偏向 MyISAM 存储引擎，开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低。<br>行级锁    偏向 InnoDB 存储引擎，开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。<br>页面锁    开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般。<br>从上述特点可见，很难笼统地说哪种锁更好，只能就具体应用的特点来说哪种锁更合适！仅从锁的角度来说：表级锁更适合于以查询为主，只有少量按索引条件更新数据的应用，如 Web 应用；而行级锁则更适合于有大量按索引条件并发更新少量不同数据，同时又有并查询的应用，如一些在线事务处理（OLTP）系统。</p><p>MyISAM 表锁<br>MyISAM 存储引擎只支持表锁，这也是 MySQL 开始几个版本中唯一支持的锁类型。</p><p>如何加表锁<br>MyISAM 在执行查询语句（SELECT）前，会自动给涉及的所有表加读锁，在执行更新操作（UPDATE、DELETE、INSERT 等）前，会自动给涉及的表加写锁，这个过程并不需要用户干预，因此，用户一般不需要直接用 LOCK TABLE 命令给 MyISAM 表显式加锁。</p><p>显示加表锁语法：</p><p>SQL<br>1<br>2<br>3<br>加读锁 ： lock table table_name read;</p><p>加写锁 ： lock table table_name write；<br>读锁案例<br>准备环境：</p><pre><code class="bash">CREATE TABLE `tb_book` (  `id` INT(11) auto_increment,  `name` VARCHAR(50) DEFAULT NULL,  `publish_time` DATE DEFAULT NULL,  `status` CHAR(1) DEFAULT NULL,  PRIMARY KEY (`id`)) ENGINE=myisam DEFAULT CHARSET=utf8 ;INSERT INTO tb_book (id, name, publish_time, status) VALUES(NULL,&#39;java编程思想&#39;,&#39;2088-08-01&#39;,&#39;1&#39;);INSERT INTO tb_book (id, name, publish_time, status) VALUES(NULL,&#39;solr编程思想&#39;,&#39;2088-08-08&#39;,&#39;0&#39;);CREATE TABLE `tb_user` (  `id` INT(11) auto_increment,  `name` VARCHAR(50) DEFAULT NULL,  PRIMARY KEY (`id`)) ENGINE=myisam DEFAULT CHARSET=utf8 ;INSERT INTO tb_user (id, name) VALUES(NULL,&#39;令狐冲&#39;);INSERT INTO tb_user (id, name) VALUES(NULL,&#39;田伯光&#39;);</code></pre><p>客户端 一 ：</p><p>1）获得 tb_book 表的读锁</p><p>SQL<br>1<br>lock table tb_book read;<br>2） 执行查询操作</p><p>SQL<br>1<br>select * from tb_book;<br>SQL<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8</p><p>mysql&gt; select * from tb_book;<br>+—-+————–+————–+——–+<br>| id | name         | publish_time | status |<br>+—-+————–+————–+——–+<br>|  1 | java编程思想 | 2088-08-01   | 1      |<br>|  2 | solr编程思想 | 2088-08-08   | 0      |<br>+—-+————–+————–+——–+<br>可以正常执行 ， 查询出数据。</p><p>客户端 二 ：</p><p>3） 执行查询操作</p><p>SQL<br>1<br>select * from tb_book;<br>SQL<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>mysql&gt; select * from tb_book;<br>+—-+————–+————–+——–+<br>| id | name         | publish_time | status |<br>+—-+————–+————–+——–+<br>|  1 | java编程思想 | 2088-08-01   | 1      |<br>|  2 | solr编程思想 | 2088-08-08   | 0      |<br>+—-+————–+————–+——–+<br>2 rows in set (0.05 sec)<br>客户端 一 ：</p><p>4）查询未锁定的表</p><p>SQL<br>1<br>select name from tb_seller;<br>SQL<br>1<br>2<br>mysql&gt; select name from tb_seller;<br>1100 - Table ‘tb_seller’ was not locked with LOCK TABLES<br>客户端 二 ：</p><p>5）查询未锁定的表</p><p>SQL<br>1<br>select name from tb_seller;<br>SQL<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>mysql&gt; select name from tb_seller;<br>+————————–+<br>| name                     |<br>+————————–+<br>| OPPO科技有限公司         |<br>| 传智播客教育科技有限公司 |<br>| 千度科技                 |<br>| 华为科技有限公司         |<br>| 宜家家居                 |<br>| 小米科技                 |<br>| 掌趣科技股份有限公司     |<br>| 新浪科技有限公司         |<br>| 百度科技有限公司         |<br>| 罗技科技有限公司         |<br>| 阿里巴巴                 |<br>| 黑马程序员               |<br>+————————–+<br>可以正常查询出未锁定的表；</p><p>客户端 一 ：</p><p>6） 执行插入操作</p><p>SQL<br>1<br>insert into tb_book values(null,’Mysql高级’,’2088-01-01’,’1’);<br>SQL<br>1<br>2<br>mysql&gt; insert into tb_book values(null,’Mysql高级’,’2088-01-01’,’1’);<br>1099 - Table ‘tb_book’ was locked with a READ lock and can’t be updated<br>执行插入， 直接报错 ， 由于当前 tb_book 获得的是读锁， 不能执行更新操作。</p><p>客户端 二 ：</p><p>7） 执行插入操作</p><p>SQL<br>1<br>insert into tb_book values(null,’Mysql高级’,’2088-01-01’,’1’);</p><p>image-20210518201017343<br>当在客户端一中释放锁指令 unlock tables 后 ， 客户端二中的 inesrt 语句 ， 立即执行 ：</p><p>SQL<br>1<br>2<br>mysql&gt; insert into tb_book values(null,’Mysql高级’,’2088-01-01’,’1’);<br>Query OK, 1 row affected (86.41 sec)<br>写锁案例<br>客户端 一 :</p><p>1）获得 tb_book 表的写锁</p><p>SQL<br>1<br>lock table tb_book write ;<br>2）执行查询操作</p><p>SQL<br>1<br>select * from tb_book ;<br>SQL<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>mysql&gt; select * from tb_book ;<br>+—-+————–+————–+——–+<br>| id | name         | publish_time | status |<br>+—-+————–+————–+——–+<br>|  1 | java编程思想 | 2088-08-01   | 1      |<br>|  2 | solr编程思想 | 2088-08-08   | 0      |<br>|  3 | Mysql高级    | 2088-01-01   | 1      |<br>+—-+————–+————–+——–+<br>3 rows in set (0.10 sec)<br>查询操作执行成功；</p><p>3）执行更新操作</p><p>SQL<br>1<br>update tb_book set name = ‘java编程思想（第二版）’ where id = 1;<br>SQL<br>1<br>2<br>3<br>mysql&gt; update tb_book set name = ‘java编程思想（第二版）’ where id = 1;<br>Query OK, 1 row affected (0.04 sec)<br>Rows matched: 1  Changed: 1  Warnings: 0<br>更新操作执行成功 。</p><p>客户端 二 :</p><p>4）执行查询操作</p><p>CODE<br>1<br>select * from tb_book ;</p><p>image-20210518201427139<br>当在客户端一中释放锁指令 unlock tables 后 ， 客户端二中的 select 语句 ， 立即执行 ；</p><p>image-20210518201459651<br>结论<br>锁模式的相互兼容性如表中所示：</p><p>img<br>由上表可见：</p><p>​ 1. 对 MyISAM 表的读操作，不会阻塞其他用户对同一表的读请求，但会阻塞对同一表的写请求；</p><p>​ 2. 对 MyISAM 表的写操作，则会阻塞其他用户对同一表的读和写操作。</p><p>CODE<br>1<br>简而言之，就是读锁会阻塞写，但是不会阻塞读。而写锁，则既会阻塞读，又会阻塞写。<br>此外，MyISAM 的读写锁调度是写优先，这也是 MyISAM 不适合做写为主的表的存储引擎的原因。因为写锁后，其他线程不能做任何操作，大量的更新会使查询很难得到锁，从而造成永远阻塞。</p><p>查看锁的争用情况<br>SQL<br>1<br>show open tables;</p><p>image-20210518202136787<br>In_user : 表当前被查询使用的次数。如果该数为零，则表是打开的，但是当前没有被使用。</p><p>Name_locked：表名称是否被锁定。名称锁定用于取消表或对表进行重命名等操作。</p><p>SQL<br>1<br>show status like ‘Table_locks%’;<br>SQL<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>mysql&gt; show status like ‘Table_locks%’;<br>+———————–+——-+<br>| Variable_name         | Value |<br>+———————–+——-+<br>| Table_locks_immediate | 114   |<br>| Table_locks_waited    | 0     |<br>+———————–+——-+<br>2 rows in set (0.15 sec)<br>Table_locks_immediate ： 指的是能够立即获得表级锁的次数，每立即获取锁，值加 1。</p><p>Table_locks_waited ： 指的是不能立即获取表级锁而需要等待的次数，每等待一次，该值加 1，此值高说明存在着较为严重的表级锁争用情况。</p><p>InnoDB 行锁<br>行锁介绍<br>行锁特点 ：偏向 InnoDB 存储引擎，开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。</p><p>InnoDB 与 MyISAM 的最大不同有两点：一是支持事务；二是采用了行级锁。</p><p>背景知识<br>事务的 ACID 属性</p><p>ACID 属性    含义<br>原子性（Atomicity）    事务是一个原子操作单元，其对数据的修改，要么全部成功，要么全部失败。<br>一致性（Consistent）    在事务开始和完成时，数据都必须保持一致状态。<br>隔离性（Isolation）    数据库系统提供一定的隔离机制，保证事务在不受外部并发操作影响的 “独立” 环境下运行。<br>持久性（Durable）    事务完成之后，对于数据的修改是永久的。<br>并发事务处理带来的问题</p><p>问题    含义<br>丢失更新（Lost Update）    当两个或多个事务选择同一行，最初的事务修改的值，会被后面的事务修改的值覆盖。<br>脏读（Dirty Reads）    当一个事务正在访问数据，并且对数据进行了修改，而这种修改还没有提交到数据库中，这时，另外一个事务也访问这个数据，然后使用了这个数据。<br>不可重复读（Non-Repeatable Reads）    一个事务在读取某些数据后的某个时间，再次读取以前读过的数据，却发现和以前读出的数据不一致。<br>幻读（Phantom Reads）    一个事务按照相同的查询条件重新读取以前查询过的数据，却发现其他事务插入了满足其查询条件的新数据。<br>事务隔离级别</p><p>为了解决上述提到的事务并发问题，数据库提供一定的事务隔离机制来解决这个问题。数据库的事务隔离越严格，并发副作用越小，但付出的代价也就越大，因为事务隔离实质上就是使事务在一定程度上 “串行化” 进行，这显然与 “并发” 是矛盾的。</p><p>数据库的隔离级别有 4 个，由低到高依次为 Read uncommitted、Read committed、Repeatable read、Serializable，这四个级别可以逐个解决脏写、脏读、不可重复读、幻读这几类问题。</p><p>隔离级别    丢失更新    脏读    不可重复读    幻读<br>Read uncommitted    ×    √    √    √<br>Read committed    ×    ×    √    √<br>Repeatable read（默认）    ×    ×    ×    √<br>Serializable    ×    ×    ×    ×<br>备注 ： √ 代表可能出现 ， × 代表不会出现 。</p><p>MySQL 的数据库的默认隔离级别为 Repeatable read ， 查看方式：</p><p>SQL<br>1<br>show variables like ‘tx_isolation’;<br>SQL<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>mysql&gt; show variables like ‘tx_isolation’;<br>+—————+—————–+<br>| Variable_name | Value           |<br>+—————+—————–+<br>| tx_isolation  | REPEATABLE-READ |<br>+—————+—————–+<br>1 row in set (0.12 sec)<br>InnoDB 的行锁模式<br>InnoDB 实现了以下两种类型的行锁。</p><p>共享锁（S）：又称为读锁，简称 S 锁，共享锁就是多个事务对于同一数据可以共享一把锁，都能访问到数据，但是只能读不能修改。</p><p>排他锁（X）：又称为写锁，简称 X 锁，排他锁就是不能与其他锁并存，如一个事务获取了一个数据行的排他锁，其他事务就不能再获取该行的其他锁，包括共享锁和排他锁，但是获取排他锁的事务是可以对数据就行读取和修改。</p><p>对于 UPDATE、DELETE 和 INSERT 语句，InnoDB 会自动给涉及数据集加排他锁（X)；</p><p>对于普通 SELECT 语句，InnoDB 不会加任何锁。</p><p>可以通过以下语句显示给记录集加共享锁或排他锁 。</p><p>CODE<br>1<br>2<br>3<br>共享锁（S）：SELECT * FROM table_name WHERE … LOCK IN SHARE MODE</p><p>排他锁（X) ：SELECT * FROM table_name WHERE … FOR UPDATE<br>案例准备工作<br>SQL<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>create table test_innodb_lock(<br>    id int(11),<br>    name varchar(16),<br>    sex varchar(1)<br>)engine = innodb default charset=utf8;</p><p>insert into test_innodb_lock values(1,’100’,’1’);<br>insert into test_innodb_lock values(3,’3’,’1’);<br>insert into test_innodb_lock values(4,’400’,’0’);<br>insert into test_innodb_lock values(5,’500’,’1’);<br>insert into test_innodb_lock values(6,’600’,’0’);<br>insert into test_innodb_lock values(7,’700’,’0’);<br>insert into test_innodb_lock values(8,’800’,’1’);<br>insert into test_innodb_lock values(9,’900’,’1’);<br>insert into test_innodb_lock values(1,’200’,’0’);</p><p>create index idx_test_innodb_lock_id on test_innodb_lock(id);<br>create index idx_test_innodb_lock_name on test_innodb_lock(name);<br>行锁基本演示<br>Session-1    Session-2</p><p>image-20210518210156129</p><p>关闭自动提交功能<br>image-20210518210219856</p><p>关闭自动提交功能</p><p>image-20210518210332599</p><p>可以正常的查询出全部的数据<br>image-20210518210349824</p><p>可以正常的查询出全部的数据</p><p>image-20210518210426841<br>查询 id 为 3 的数据 ；<br>image-20210518210436934<br>获取 id 为 3 的数据 ；</p><p>image-20210518210554412<br>更新 id 为 3 的数据，但是不提交；<br>image-20210518213328713<br>更新 id 为 3 的数据， 处于等待状态</p><p>image-20210518211809494<br>通过 commit， 提交事务<br>image-20210518210717517<br>解除阻塞，更新正常进行<br>以上， 操作的都是同一行的数据，接下来，演示不同行的数据 ：    </p><p>image-20210518210801669<br>更新 id 为 3 数据，正常的获取到行锁 ， 执行更新 ；<br>image-20210518210831154<br>由于与 Session-1 操作不是同一行，获取当前行锁，执行更新；<br>无索引行锁升级为表锁<br>如果不通过索引条件检索数据，那么 InnoDB 将对表中的所有记录加锁，实际效果跟表锁一样。</p><p>查看当前表的索引 ： show index from test_innodb_lock ;</p><p>image-20210518211018083<br>Session-1    Session-2<br>关闭事务的自动提交<br>image-20210518210156129<br>关闭事务的自动提交</p><p>image-20210518210156129<br>执行更新语句 ：<br>image-20210518211639732<br>执行更新语句， 但处于阻塞状态：<br>image-20210518211748011<br>提交事务：<br>image-20210518211809494<br>解除阻塞，执行更新成功 ：<br>image-20210518211826968<br>执行提交操作 ：<br>image-20210518211949350<br>由于 执行更新时 ， name 字段本来为 varchar 类型， 这里是作为数组类型使用，存在类型转换，索引失效，最终行锁变为表锁 ；</p><p>间隙锁危害<br>当用范围条件，而不是使用相等条件检索数据，并请求共享或排他锁时，InnoDB 会给符合条件的已有数据进行加锁； 对于键值在条件范围内但并不存在的记录，叫做 “间隙（GAP）” ， InnoDB 也会对这个 “间隙” 加锁，这种锁机制就是所谓的 间隙锁（Next-Key 锁） 。</p><p>InnoDB 行锁争用情况<br>SQL<br>1<br>show  status like ‘innodb_row_lock%’;</p><p>image-20210518211525007<br>XML<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>Innodb_row_lock_current_waits: 当前正在等待锁定的数量</p><p>Innodb_row_lock_time: 从系统启动到现在锁定总时间长度</p><p>Innodb_row_lock_time_avg:每次等待所花平均时长</p><p>Innodb_row_lock_time_max:从系统启动到现在等待最长的一次所花的时间</p><p>Innodb_row_lock_waits: 系统启动后到现在总共等待的次数</p><p>当等待的次数很高，而且每次等待的时长也不小的时候，我们就需要分析系统中为什么会有如此多的等待，然后根据分析结果着手制定优化计划。</p><p>总结<br>InnoDB 存储引擎由于实现了行级锁定，虽然在锁定机制的实现方面带来了性能损耗可能比表锁会更高一些，但是在整体并发处理能力方面要远远由于 MyISAM 的表锁的。当系统并发量较高的时候，InnoDB 的整体性能和 MyISAM 相比就会有比较明显的优势。但是，InnoDB 的行级锁同样也有其脆弱的一面，当我们使用不当的时候，可能会让 InnoDB 的整体性能表现不仅不能比 MyISAM 高，甚至可能会更差。</p><p>优化建议：</p><p>尽可能让所有数据检索都能通过索引来完成，避免无索引行锁升级为表锁。<br>合理设计索引，尽量缩小锁的范围。<br>尽可能减少索引条件，及索引范围，避免间隙锁。<br>尽量控制事务大小，减少锁定资源量和时间长度。<br>尽可使用低级别事务隔离（但是需要业务层面满足需求）。<br>常用 SQL 技巧<br>SQL 执行顺序<br>编写顺序：</p><p>SQL<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>SELECT DISTINCT<br>    <select list><br>FROM<br>    <left_table> <join_type><br>JOIN<br>    <right_table> ON <join_condition><br>WHERE<br>    <where_condition><br>GROUP BY<br>    <group_by_list><br>HAVING<br>    <having_condition><br>ORDER BY<br>    <order_by_condition><br>LIMIT<br>    <limit_params><br>执行顺序：</p><p>SQL<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>FROM    <left_table></p><p>ON         <join_condition></p><p><join_type>        JOIN    <right_table></p><p>WHERE        <where_condition></p><p>GROUP BY     <group_by_list></p><p>HAVING        <having_condition></p><p>SELECT DISTINCT        <select list></p><p>ORDER BY    <order_by_condition></p><p>LIMIT        <limit_params><br>正则表达式使用<br>正则表达式（Regular Expression）是指一个用来描述或者匹配一系列符合某个句法规则的字符串的单个字符串。</p><p>符号    含义<br>^    在字符串开始处进行匹配<br>$    在字符串末尾处进行匹配<br>.    匹配任意单个字符，包括换行符<br>[…]    匹配出括号内的任意字符<br>[^…]    匹配不出括号内的任意字符<br>a*    匹配零个或者多个 a (包括空串)<br>a+    匹配一个或者多个 a (不包括空串)<br>a?    匹配零个或者一个 a<br>a1|a2    匹配 a1 或 a2<br>a(m)    匹配 m 个 a<br>a(m,)    至少匹配 m 个 a<br>a(m,n)    匹配 m 个 a 到 n 个 a<br>a(,n)    匹配 0 到 n 个 a<br>(…)    将模式元素组成单一元素<br>CODE<br>1<br>2<br>3<br>4<br>5<br>select * from emp where name regexp ‘^T’;</p><p>select * from emp where name regexp ‘2$’;</p><p>select * from emp where name regexp ‘[uvw]’;<br>MySQL 常用函数<br>数字函数：</p><p>函数名称    作 用<br>ABS    求绝对值<br>SQRT    求二次方根<br>MOD    求余数<br>CEIL 和 CEILING    两个函数功能相同，都是返回不小于参数的最小整数，即向上取整<br>FLOOR    向下取整，返回值转化为一个 BIGINT<br>RAND    生成一个 0~1 之间的随机数，传入整数参数是，用来产生重复序列<br>ROUND    对所传参数进行四舍五入<br>SIGN    返回参数的符号<br>POW 和 POWER    两个函数的功能相同，都是所传参数的次方的结果值<br>SIN    求正弦值<br>ASIN    求反正弦值，与函数 SIN 互为反函数<br>COS    求余弦值<br>ACOS    求反余弦值，与函数 COS 互为反函数<br>TAN    求正切值<br>ATAN    求反正切值，与函数 TAN 互为反函数<br>COT    求余切值<br>字符串函数：</p><p>函数名称    作 用<br>LENGTH    计算字符串长度函数，返回字符串的字节长度<br>CONCAT    合并字符串函数，返回结果为连接参数产生的字符串，参数可以使一个或多个<br>INSERT    替换字符串函数<br>LOWER    将字符串中的字母转换为小写<br>UPPER    将字符串中的字母转换为大写<br>LEFT    从左侧字截取符串，返回字符串左边的若干个字符<br>RIGHT    从右侧字截取符串，返回字符串右边的若干个字符<br>TRIM    删除字符串左右两侧的空格<br>REPLACE    字符串替换函数，返回替换后的新字符串<br>SUBSTRING    截取字符串，返回从指定位置开始的指定长度的字符换<br>REVERSE    字符串反转（逆序）函数，返回与原始字符串顺序相反的字符串<br>日期函数：</p><p>函数名称    作 用<br>CURDATE 和 CURRENT_DATE    两个函数作用相同，返回当前系统的日期值<br>CURTIME 和 CURRENT_TIME    两个函数作用相同，返回当前系统的时间值<br>NOW 和 SYSDATE    两个函数作用相同，返回当前系统的日期和时间值<br>MONTH    获取指定日期中的月份<br>MONTHNAME    获取指定日期中的月份英文名称<br>DAYNAME    获取指定曰期对应的星期几的英文名称<br>DAYOFWEEK    获取指定日期对应的一周的索引位置值<br>WEEK    获取指定日期是一年中的第几周，返回值的范围是否为 0〜52 或 1〜53<br>DAYOFYEAR    获取指定曰期是一年中的第几天，返回值范围是 1<del>366<br>DAYOFMONTH    获取指定日期是一个月中是第几天，返回值范围是 1</del>31<br>YEAR    获取年份，返回值范围是 1970〜2069<br>TIME_TO_SEC    将时间参数转换为秒数<br>SEC_TO_TIME    将秒数转换为时间，与 TIME_TO_SEC 互为反函数<br>DATE_ADD 和 ADDDATE    两个函数功能相同，都是向日期添加指定的时间间隔<br>DATE_SUB 和 SUBDATE    两个函数功能相同，都是向日期减去指定的时间间隔<br>ADDTIME    时间加法运算，在原始时间上添加指定的时间<br>SUBTIME    时间减法运算，在原始时间上减去指定的时间<br>DATEDIFF    获取两个日期之间间隔，返回参数 1 减去参数 2 的值<br>DATE_FORMAT    格式化指定的日期，根据参数返回指定格式的值<br>WEEKDAY    获取指定日期在一周内的对应的工作日索引<br>聚合函数：</p><p>函数名称    作用<br>MAX    查询指定列的最大值<br>MIN    查询指定列的最小值<br>COUNT    统计查询结果的行数<br>SUM    求和，返回指定列的总和<br>AVG    求平均值，返回指定列数据的平均值</p>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>多线程与高并发 —JUC 之 AQS、ReentrantLock、读写锁原理等</title>
      <link href="/2020/09/20/thread/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E9%AB%98%E5%B9%B6%E5%8F%91%20%E2%80%94JUC%20%E4%B9%8B%20AQS%E3%80%81ReentrantLock%E3%80%81%E8%AF%BB%E5%86%99%E9%94%81%E5%8E%9F%E7%90%86%E7%AD%89/"/>
      <url>/2020/09/20/thread/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E9%AB%98%E5%B9%B6%E5%8F%91%20%E2%80%94JUC%20%E4%B9%8B%20AQS%E3%80%81ReentrantLock%E3%80%81%E8%AF%BB%E5%86%99%E9%94%81%E5%8E%9F%E7%90%86%E7%AD%89/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="AQS"><a href="#AQS" class="headerlink" title="AQS"></a>AQS</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>全称是 AbstractQueuedSynchronizer，是阻塞式锁和相关的同步器工具的框架。</p><h2 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h2><ul><li><p>用 state 属性来表示资源的状态（分独占模式和共享模式），子类需要定义如何维护这个状态，控制如何获取锁和释放锁：</p><ul><li>getState：获取 state 状态。</li><li>setState：设置 state 状态。</li><li>compareAndSetState：cas 机制设置 state 状态。</li><li>独占模式只有一个线程能够访问资源，而共享模式可以允许多个线程访问资源。</li></ul></li><li><p>提供了基于 FIFO 的等待队列，类似于 Monitor 的 EntryList。</p></li><li><p>条件变量来实现等待、唤醒机制，支持多个条件变量，类似于 Monitor 的 WaitSet。</p></li></ul><blockquote><p>子类主要实现这样一些方法（默认抛出 UnsupportedOperationException）：</p></blockquote><ul><li>tryAcquire</li><li>tryRelease</li><li>tryAcquireShared</li><li>tryReleaseShared</li><li>isHeldExclusively</li></ul><pre><code>// 获取锁的姿势// 如果获取锁失败if (!tryAcquire(arg)) &#123; // 入队, 可以选择阻塞当前线程 park unpark&#125;// 释放锁的姿势// 如果释放锁成功if (tryRelease(arg)) &#123; // 让阻塞线程恢复运行&#125;</code></pre><h2 id="自定义同步器"><a href="#自定义同步器" class="headerlink" title="自定义同步器"></a>自定义同步器</h2><p>下面实现一个不可重入的阻塞式锁：使用 AbstractQueuedSynchronizer 自定义一个同步器来实现自定义锁，代码如下：</p><pre><code>public class UnRepeatLock &#123;    public static void main(String[] args) &#123;        MyLock myLock = new MyLock();        new Thread(() -&gt; &#123;            myLock.lock();            log.info(&quot;lock ... &quot;);            // 测试是否不可重入            myLock.lock();            try &#123;                log.info(&quot;starting...&quot;);                Thread.sleep(1000);            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125; finally &#123;                log.info(&quot;unlock ... &quot;);                myLock.unlock();            &#125;        &#125;,&quot;t1&quot;).start();    &#125;&#125;class MyLock implements Lock &#123;    class MySync extends AbstractQueuedSynchronizer &#123;        @Override        protected boolean tryAcquire(int arg) &#123;            if (compareAndSetState(0, 1)) &#123;                setExclusiveOwnerThread(Thread.currentThread());                return true;            &#125;            return false;        &#125;        @Override        protected boolean tryRelease(int arg) &#123;            if (compareAndSetState(1, 0)) &#123;                setExclusiveOwnerThread(null);                setState(0);                return true;            &#125;            return false;        &#125;        @Override        protected boolean isHeldExclusively() &#123;            return getState() == 1;        &#125;        public Condition newCondition() &#123;            return new ConditionObject();        &#125;    &#125;    private MySync mySync = new MySync();    //加锁    @Override    public void lock() &#123;        mySync.acquire(1);    &#125;    // 可中断的锁    @Override    public void lockInterruptibly() throws InterruptedException &#123;        mySync.acquireInterruptibly(1);    &#125;    // 只会尝试一次加锁    @Override    public boolean tryLock() &#123;        return mySync.tryAcquire(1);    &#125;    // 带超时时间的    @Override    public boolean tryLock(long time, TimeUnit unit) throws InterruptedException &#123;        return mySync.tryAcquireNanos(1,unit.toNanos(time));    &#125;    // 解锁    @Override    public void unlock() &#123;        mySync.release(1);    &#125;    // 创建条件变量    @Override    public Condition newCondition() &#123;        return mySync.newCondition();    &#125;&#125;</code></pre><p>输出：</p><pre><code class="bash">19:35:34.374 [t1] INFO com.heu.test.UnRepeatLock - lock ... 一直等待。。。</code></pre><h2 id="AQS-要实现的功能目标"><a href="#AQS-要实现的功能目标" class="headerlink" title="AQS 要实现的功能目标"></a>AQS 要实现的功能目标</h2><ol><li>阻塞版本获取锁 acquire 和非阻塞的版本尝试获取锁 tryAcquire</li><li>获取锁超时机制</li><li>通过打断取消机制</li><li>独占机制及共享机制</li><li>条件不满足时的等待机制</li></ol><h2 id="AQS-设计"><a href="#AQS-设计" class="headerlink" title="AQS 设计"></a>AQS 设计</h2><p><strong>获取锁的逻辑：</strong></p><pre><code>while(state 状态不允许获取) &#123;     if(队列中还没有此线程) &#123;     // 入队并阻塞     &#125;&#125;// 当前线程出队</code></pre><p><strong>释放锁的逻辑：</strong></p><pre><code>if(state 状态允许了) &#123;     恢复阻塞的线程(s)  &#125;</code></pre><p><strong>要点：</strong></p><ul><li>原子维护 state 状态</li><li>阻塞及恢复线程</li><li>维护队列</li></ul><p><strong>state 设计</strong></p><ul><li>state 使用 volatile 配合 cas 保证其修改时的原子性。</li><li>state 使用了 32bit int 来维护同步状态，因为当时使用 long 在很多平台下测试的结果并不理想。</li></ul><p><strong>阻塞恢复设计</strong></p><ul><li><p>早期的控制线程暂停和恢复的 api 有 suspend 和 resume，但它们是不可用的，因为如果先调用的 resume ，那么 suspend 将感知不到。</p></li><li><p>解决方法是使用 park &amp; unpark 来实现线程的暂停和恢复，具体原理在之前讲过了，先 unpark 再 park 也没问题。</p></li><li><p>park &amp; unpark 是针对线程的，而不是针对同步器的，因此控制粒度更为精细。</p></li><li><p>park &amp; unpark 是针对线程的，而不是针对同步器的，因此控制粒度更为精细。<br>park 线程还可以通过 interrupt 打断。</p></li></ul><p><strong>队列设计</strong></p><ul><li><p>使用了 FIFO 先入先出队列，并不支持优先级队列。</p></li><li><p>设计时借鉴了 CLH 队列，它是一种单向无锁队列。</p></li></ul><p><img src="https://cdn.jsdelivr.net/gh/junian455/pic@master/img/image-20210616201035669.png"></p><p><img src="https://cdn.jsdelivr.net/gh/junian455/pic@master/img/image-20210616201054697.png"></p><blockquote><p>队列中有 head 和 tail 两个指针节点，都用 volatile 修饰配合 cas 使用，每个节点有 state 维护节点状态。</p></blockquote><h2 id="主要用到-AQS-的并发工具类"><a href="#主要用到-AQS-的并发工具类" class="headerlink" title="主要用到 AQS 的并发工具类"></a>主要用到 AQS 的并发工具类</h2><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210616202126371.png"></p><h1 id="ReentrantLock-原理"><a href="#ReentrantLock-原理" class="headerlink" title="ReentrantLock 原理"></a>ReentrantLock 原理</h1><p>可以看到 ReentrantLock 提供了两个同步器，实现公平锁和非公平锁，默认是非公平锁！</p><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210616194522522.png"></p><h2 id="非公平锁实现原理"><a href="#非公平锁实现原理" class="headerlink" title="非公平锁实现原理"></a>非公平锁实现原理</h2><h3 id="加锁流程"><a href="#加锁流程" class="headerlink" title="加锁流程"></a>加锁流程</h3><p>先从构造器开始看，默认为非公平锁实现。</p><pre><code class="bash">public ReentrantLock() &#123;        sync = new NonfairSync();    &#125;</code></pre><p>NonfairSync 继承自 AQS，在没有线程竞争时：</p><pre><code class="bash">final void lock() &#123;    // 没有竞争时, 直接加锁 (CAS)    if (compareAndSetState(0, 1))        // 设置持有锁的线程        setExclusiveOwnerThread(Thread.currentThread());    else        // 有竞争, 会调用这个方法        acquire(1);&#125;</code></pre><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210616195628434.png"></p><p>第一个竞争出现时：</p><pre><code>public final void acquire(int arg) &#123;    // 再次尝试加锁失败，则创建一个 Node 节点对象加入到等待队列中去.    if (!tryAcquire(arg) &amp;&amp;        acquireQueued(addWaiter(Node.EXCLUSIVE), arg))        selfInterrupt();&#125;</code></pre><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210616200052450.png"></p><p>Thread-1 执行了：</p><ol><li>lock 方法中 CAS，尝试将 state 由 0 改为 1，结果失败；</li><li>lock 方法中进一步调用 acquire 方法，进入 tryAcquire 逻辑，这里认为此时 state 已经是 1，结果仍然失败；</li><li>接下来进入 acquire 方法的 addWaiter 逻辑，构造 Node 队列：<ul><li>图中黄色三角表示该 Node 的 waitStatus 状态，其中 0 为默认正常状态；</li><li>Node 的创建是懒惰的；</li><li>其中第一个 Node 称为 Dummy（哑元）或哨兵，用来占位，并不关联线程。</li></ul></li></ol><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210616202800247.png"></p><p>之后当前线程进入 acquire 方法的 acquireQueued 逻辑：</p><ol><li>acquireQueued 会在一个死循环中不断尝试获得锁，失败后进入 park 阻塞；</li><li>如果自己是紧邻着 head（排第二位），那么再次 tryAcquire 尝试获取锁，这里设置此时 state 仍为 1，失败；</li><li>进入 shouldParkAfterFailedAcquire 逻辑，将前驱 node，即 head 的 waitStatus 改为 -1，这次返回 false；</li></ol><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210616203601530.png"></p><ol><li><p>shouldParkAfterFailedAcquire 执行完毕回到 acquireQueued ，再次 tryAcquire 尝试获取锁，当然这时 state 仍为 1，失败；</p></li><li><p>当再次进入 shouldParkAfterFailedAcquire 时，这时因为其前驱 node 的 waitStatus 已经是 -1，这次返回 true；</p></li><li><p>进入 parkAndCheckInterrupt， Thread-1 park（灰色表示已经阻塞）。</p></li></ol><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210616204249004.png"></p><p>如果再次有多个线程经历上述过程竞争失败，变成这个样子：</p><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210616204842320.png"></p><p><strong>加锁源码：</strong></p><pre><code class="bash">// Sync 继承自 AQSstatic final class NonfairSync extends Sync &#123;    private static final long serialVersionUID = 7316153563782823691L;     // 加锁实现    final void lock() &#123;        // 首先用 cas 尝试（仅尝试一次）将 state 从 0 改为 1, 如果成功表示获得了独占锁        if (compareAndSetState(0, 1))            setExclusiveOwnerThread(Thread.currentThread());        else            // 如果尝试失败，进入 ㈠            acquire(1);    &#125;    // ㈠ AQS 继承过来的方法, 方便阅读, 放在此处    public final void acquire(int arg) &#123;        // ㈡ tryAcquire        if (            !tryAcquire(arg) &amp;&amp;            // 当 tryAcquire 返回为 false 时, 先调用 addWaiter ㈣, 接着 acquireQueued ㈤            acquireQueued(addWaiter(Node.EXCLUSIVE), arg)        ) &#123;            selfInterrupt();        &#125;    &#125;    // ㈡ 进入 ㈢    protected final boolean tryAcquire(int acquires) &#123;        return nonfairTryAcquire(acquires);    &#125;    // ㈢ Sync 继承过来的方法, 方便阅读, 放在此处    final boolean nonfairTryAcquire(int acquires) &#123;        final Thread current = Thread.currentThread();        int c = getState();        // 如果还没有获得锁        if (c == 0) &#123;            // 尝试用 cas 获得, 这里体现了非公平性: 不去检查 AQS 队列            if (compareAndSetState(0, acquires)) &#123;                setExclusiveOwnerThread(current);                return true;            &#125;        &#125;        // 如果已经获得了锁, 线程还是当前线程, 表示发生了锁重入        else if (current == getExclusiveOwnerThread()) &#123;            // state++            int nextc = c + acquires;            if (nextc &lt; 0) // overflow                throw new Error(&quot;Maximum lock count exceeded&quot;);            setState(nextc);            return true;        &#125;        // 获取失败, 回到调用处        return false;    &#125;    // ㈣ AQS 继承过来的方法, 方便阅读, 放在此处    private Node addWaiter(Node mode) &#123;   // 将当前线程关联到一个 Node 对象上, 模式为独占模式，新建的Node的waitstatus默认为0，因为waitstatus是成员变量，默认被初始化为0        Node node = new Node(Thread.currentThread(), mode);        // 如果 tail 不为 null, cas 尝试将 Node 对象加入 AQS 队列尾部        Node pred = tail;        if (pred != null) &#123;            node.prev = pred;            if (compareAndSetTail(pred, node)) &#123;                // 双向链表                pred.next = node;                return node;            &#125;        &#125;        //如果tail为null，尝试将 Node 加入 AQS, 进入 ㈥        enq(node);        return node;    &#125;    // ㈥ AQS 继承过来的方法, 方便阅读, 放在此处    private Node enq(final Node node) &#123;        for (;;) &#123;            Node t = tail;            if (t == null) &#123;                // 还没有, 设置 head 为哨兵节点（不对应线程，状态为 0）                if (compareAndSetHead(new Node())) &#123;                    tail = head;                &#125;            &#125; else &#123;                // cas 尝试将 Node 对象加入 AQS 队列尾部                node.prev = t;                if (compareAndSetTail(t, node)) &#123;                    t.next = node;                    return t;                &#125;            &#125;        &#125;    &#125;    // ㈤ AQS 继承过来的方法, 方便阅读, 放在此处    final boolean acquireQueued(final Node node, int arg) &#123;        boolean failed = true;        try &#123;            boolean interrupted = false;            for (;;) &#123;                final Node p = node.predecessor();                // 上一个节点是 head, 表示轮到自己（当前线程对应的 node）了, 尝试获取                if (p == head &amp;&amp; tryAcquire(arg)) &#123;                    // 获取成功, 设置自己（当前线程对应的 node）为 head                    setHead(node);                    // 上一个节点 help GC                    p.next = null;                    failed = false;                    // 返回中断标记 false                    return interrupted;                &#125;                if (                    // 判断是否应当 park, 进入 ㈦                    shouldParkAfterFailedAcquire(p, node) &amp;&amp;                    // park 等待, 此时 Node 的状态被置为 Node.SIGNAL ㈧                    parkAndCheckInterrupt()                ) &#123;                    interrupted = true;                &#125;            &#125;        &#125; finally &#123;            if (failed)                cancelAcquire(node);        &#125;    &#125;    // ㈦ AQS 继承过来的方法, 方便阅读, 放在此处    private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123;        // 获取上一个节点的状态        int ws = pred.waitStatus;        if (ws == Node.SIGNAL) &#123;            // 上一个节点都在阻塞, 那么自己也阻塞好了            return true;        &#125;        // &gt; 0 表示取消状态        if (ws &gt; 0) &#123;            // 上一个节点取消, 那么重构删除前面所有取消的节点, 返回到外层循环重试            do &#123;                node.prev = pred = pred.prev;            &#125; while (pred.waitStatus &gt; 0);            pred.next = node;        &#125; else &#123;            // 这次还没有阻塞            // 但下次如果重试不成功, 则需要阻塞，这时需要设置上一个节点状态为 Node.SIGNAL            compareAndSetWaitStatus(pred, ws, Node.SIGNAL);        &#125;        return false;    &#125;    // ㈧ 阻塞当前线程    private final boolean parkAndCheckInterrupt() &#123;        LockSupport.park(this);        return Thread.interrupted();    &#125;&#125;</code></pre><h3 id="解锁流程"><a href="#解锁流程" class="headerlink" title="解锁流程"></a>解锁流程</h3><p>Thread-0 释放锁，进入 tryRelease 流程，如果成功：</p><ul><li>设置 exclusiveOwnerThread 为 null</li><li>state = 0</li></ul><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210616205036686.png"></p><p>如果当前队列不为 null，并且 head 的 waitStatus = -1，进入 unparkSuccessor 流程：</p><p>unparkSuccessor 中会找到队列中离 head 最近的一个 Node（没取消的），unpark 恢复其运行，本例中即为 Thread-1.</p><p>回到 Thread-1 的 acquireQueued 流程：</p><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210616205303644.png"></p><blockquote><p>如果加锁成功（没有竞争），会设置 （acquireQueued 方法中）：</p></blockquote><ul><li>exclusiveOwnerThread 为 Thread-1，state = 1；</li><li>head 指向刚刚 Thread-1 所在的 Node，该 Node 清空 Thread；</li><li>原本的 head 因为从链表断开，而可被垃圾回收。</li></ul><blockquote><p>如果这时候有其它线程来竞争（非公平的体现），例如这时有 Thread-4 来了：</p></blockquote><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210616205711587.png"></p><p>如果不巧又被 Thread-4 占了先：</p><ul><li>Thread-4 被设置为 exclusiveOwnerThread，state = 1；</li><li>Thread-1 再次进入 acquireQueued 流程，获取锁失败，重新进入 park 阻塞。</li></ul><p><strong>解锁源码：</strong></p><pre><code>// Sync 继承自 AQSstatic final class NonfairSync extends Sync &#123;    // 解锁实现    public void unlock() &#123;        sync.release(1);    &#125;    // AQS 继承过来的方法, 方便阅读, 放在此处    public final boolean release(int arg) &#123;        // 尝试释放锁, 进入 ㈠        if (tryRelease(arg)) &#123;            // 队列头节点 unpark            Node h = head;            if (                // 队列不为 null                h != null &amp;&amp;                // waitStatus == Node.SIGNAL 才需要 unpark                h.waitStatus != 0            ) &#123;                // unpark AQS 中等待的线程, 进入 ㈡                unparkSuccessor(h);            &#125;            return true;        &#125;        return false;    &#125;    // ㈠ Sync 继承过来的方法, 方便阅读, 放在此处    protected final boolean tryRelease(int releases) &#123;        // state--        int c = getState() - releases;        if (Thread.currentThread() != getExclusiveOwnerThread())            throw new IllegalMonitorStateException();        boolean free = false;        // 支持锁重入, 只有 state 减为 0, 才释放成功        if (c == 0) &#123;            free = true;            setExclusiveOwnerThread(null);        &#125;        setState(c);        return free;    &#125;    // ㈡ AQS 继承过来的方法, 方便阅读, 放在此处    private void unparkSuccessor(Node node) &#123;        // 如果状态为 Node.SIGNAL 尝试重置状态为 0, 如果线程获取到了锁那么后来头结点会被抛弃掉        // 不成功也可以        int ws = node.waitStatus;        if (ws &lt; 0) &#123;            compareAndSetWaitStatus(node, ws, 0);        &#125;        // 找到需要 unpark 的节点, 但本节点从 AQS 队列中脱离, 是由唤醒节点完成的        Node s = node.next;        // 不考虑已取消的节点, 从 AQS 队列从后至前找到队列最前面需要 unpark 的节点        if (s == null || s.waitStatus &gt; 0) &#123;            s = null;            for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev)                if (t.waitStatus &lt;= 0)                    s = t;        &#125;        if (s != null)            LockSupport.unpark(s.thread);    &#125;&#125;</code></pre><h2 id="锁重入原理"><a href="#锁重入原理" class="headerlink" title="锁重入原理"></a>锁重入原理</h2><pre><code class="bash">static final class NonfairSync extends Sync &#123;    // Sync 继承过来的方法, 方便阅读, 放在此处    final boolean nonfairTryAcquire(int acquires) &#123;        final Thread current = Thread.currentThread();        int c = getState();        if (c == 0) &#123;            if (compareAndSetState(0, acquires)) &#123;                setExclusiveOwnerThread(current);                return true;            &#125;        &#125;        // 如果已经获得了锁, 线程还是当前线程, 表示发生了锁重入        else if (current == getExclusiveOwnerThread()) &#123;            // state++            int nextc = c + acquires;            if (nextc &lt; 0) // overflow                throw new Error(&quot;Maximum lock count exceeded&quot;);            setState(nextc);            return true;        &#125;        return false;    &#125;    //解锁    // Sync 继承过来的方法, 方便阅读, 放在此处    protected final boolean tryRelease(int releases) &#123;        // state--        int c = getState() - releases;        if (Thread.currentThread() != getExclusiveOwnerThread())            throw new IllegalMonitorStateException();        boolean free = false;        // 支持锁重入, 只有 state 减为 0, 才释放成功        if (c == 0) &#123;            free = true;            setExclusiveOwnerThread(null);        &#125;        setState(c);        return free;    &#125;&#125;</code></pre><h2 id="可打断原理"><a href="#可打断原理" class="headerlink" title="可打断原理"></a>可打断原理</h2><p><strong>不可打断模式</strong>：在此模式下，即使它被打断，仍会驻留在 AQS 队列中，一直要等到获得锁后方能得知自己被打断了。</p><pre><code>// Sync 继承自 AQSstatic final class NonfairSync extends Sync &#123;    // ...    private final boolean parkAndCheckInterrupt() &#123;        // 如果打断标记已经是 true, 则 park 会失效        LockSupport.park(this);        // interrupted 会清除打断标记        return Thread.interrupted();    &#125;    final boolean acquireQueued(final Node node, int arg) &#123;        boolean failed = true;        try &#123;            boolean interrupted = false;            for (;;) &#123;                final Node p = node.predecessor();                if (p == head &amp;&amp; tryAcquire(arg)) &#123;                    setHead(node);                    p.next = null;                    failed = false;                    // 还是需要获得锁后, 才能返回打断状态                    return interrupted;                &#125;                if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;                                parkAndCheckInterrupt()                ) &#123;                    // 如果是因为 interrupt 被唤醒, 返回打断状态为 true                    interrupted = true;                &#125;            &#125;        &#125;          finally &#123;               if (failed)                cancelAcquire(node);            &#125;    &#125;    public final void acquire(int arg) &#123;        if (!tryAcquire(arg) &amp;&amp;                        acquireQueued(addWaiter(Node.EXCLUSIVE), arg)        ) &#123;            // 如果打断状态为 true            selfInterrupt();        &#125;    &#125;    static void selfInterrupt() &#123;        // 重新产生一次中断，这时候线程是如果正常运行的状态，那么不是出于sleep等状态，interrupt方法就不会报错        Thread.currentThread().interrupt();    &#125;&#125;</code></pre><p><strong>可打断模式：</strong></p><pre><code>static final class NonfairSync extends Sync &#123;    public final void acquireInterruptibly(int arg) throws InterruptedException &#123;        if (Thread.interrupted())            throw new InterruptedException();        // 如果没有获得到锁, 进入 ㈠        if (!tryAcquire(arg))            doAcquireInterruptibly(arg);    &#125;    // ㈠ 可打断的获取锁流程    private void doAcquireInterruptibly(int arg) throws InterruptedException &#123;        final Node node = addWaiter(Node.EXCLUSIVE);        boolean failed = true;        try &#123;            for (;;) &#123;                final Node p = node.predecessor();                if (p == head &amp;&amp; tryAcquire(arg)) &#123;                    setHead(node);                    p.next = null; // help GC                    failed = false;                    return;                &#125;                if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;                        parkAndCheckInterrupt()) &#123;                    // 在 park 过程中如果被 interrupt 会进入此                    // 这时候抛出异常, 而不会再次进入 for (;;)                    throw new InterruptedException();                &#125;            &#125;        &#125; finally &#123;            if (failed)                cancelAcquire(node);        &#125;    &#125;&#125;</code></pre><h2 id="公平锁原理"><a href="#公平锁原理" class="headerlink" title="公平锁原理"></a>公平锁原理</h2><pre><code class="bash">static final class FairSync extends Sync &#123;    private static final long serialVersionUID = -3000897897090466540L;    final void lock() &#123;        acquire(1);    &#125;    // AQS 继承过来的方法, 方便阅读, 放在此处    public final void acquire(int arg) &#123;        if (            !tryAcquire(arg) &amp;&amp;                acquireQueued(addWaiter(Node.EXCLUSIVE), arg)        ) &#123;            selfInterrupt();        &#125;    &#125;    // 与非公平锁主要区别在于 tryAcquire 方法的实现    protected final boolean tryAcquire(int acquires) &#123;        final Thread current = Thread.currentThread();        int c = getState();        if (c == 0) &#123;            // 先检查 AQS 队列中是否有前驱节点, 没有才去竞争            if (!hasQueuedPredecessors() &amp;&amp;                    compareAndSetState(0, acquires)) &#123;                setExclusiveOwnerThread(current);                return true;            &#125;        &#125;        else if (current == getExclusiveOwnerThread()) &#123;            int nextc = c + acquires;            if (nextc &lt; 0)                throw new Error(&quot;Maximum lock count exceeded&quot;);            setState(nextc);            return true;        &#125;        return false;    &#125;    // ㈠ AQS 继承过来的方法, 方便阅读, 放在此处    public final boolean hasQueuedPredecessors() &#123;        Node t = tail;        Node h = head;        Node s;        // h != t 时表示队列中有 Node        return h != t &amp;&amp;(                    // (s = h.next) == null 表示队列中还有没有老二或者队列中老二线程不是此线程                    (s = h.next) == null ||                     s.thread != Thread.currentThread()        );    &#125;&#125;</code></pre><h2 id="条件变量实现原理"><a href="#条件变量实现原理" class="headerlink" title="条件变量实现原理"></a>条件变量实现原理</h2><p>每个条件变量其实就对应着一个等待队列，其实现类是 <code>ConditionObject</code>。</p><h3 id="await-流程"><a href="#await-流程" class="headerlink" title="await 流程"></a>await 流程</h3><ol><li>开始时 Thread-0 持有锁，调用 await 方法，进入 ConditionObject 的 addConditionWaiter 流程，创建新的 Node 节点，状态为 - 2（Node.CONDITION），关联 Thread-0，加入等待队列尾部。</li></ol><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210617095324574.png"></p><ol start="2"><li>接下来进入 AQS 的 fullyRelease 流程，释放同步器上的锁：</li></ol><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210617095417259.png"></p><ol start="3"><li>unpark AQS 队列中的下一个节点，竞争锁，假设没有其他竞争线程竞争，那么 Thread-1 竞争成功：</li></ol><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210617095612679.png"></p><ol start="4"><li>park 阻塞 Thread-0：</li></ol><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210617095650506.png"></p><h3 id="signal-流程"><a href="#signal-流程" class="headerlink" title="signal 流程"></a>signal 流程</h3><ol><li>假设 Thread-1 要来唤醒 Thread-0：</li></ol><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210617095807467.png"></p><ol start="2"><li>进入 ConditionObject 的 doSignal 流程，取得等待队列中第一个 Node，即 Thread-0 所在 Node：</li></ol><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210617100008910.png"></p><ol start="3"><li>执行 transferForSignal 流程，将该 Node 加入 AQS 队列尾部，将 Thread-0 的 waitStatus 改为 0，Thread-3 的 waitStatus 改为 -1：</li></ol><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210617100149481.png"></p><ol start="4"><li>之后 Thread-1 释放锁，进入 unlock 流程。</li></ol><h3 id="源码分析"><a href="#源码分析" class="headerlink" title="源码分析"></a>源码分析</h3><pre><code class="bash">public class ConditionObject implements Condition, java.io.Serializable &#123;    private static final long serialVersionUID = 1173984872572414699L;    // 第一个等待节点    private transient Node firstWaiter;    // 最后一个等待节点    private transient Node lastWaiter;    public ConditionObject() &#123; &#125;    // ㈠ 添加一个 Node 至等待队列    private Node addConditionWaiter() &#123;        Node t = lastWaiter;        // 所有已取消的 Node 从队列链表删除, 见 ㈡        if (t != null &amp;&amp; t.waitStatus != Node.CONDITION) &#123;            unlinkCancelledWaiters();            t = lastWaiter;        &#125;        // 创建一个关联当前线程的新 Node, 添加至队列尾部        Node node = new Node(Thread.currentThread(), Node.CONDITION);        if (t == null)            firstWaiter = node;        else            t.nextWaiter = node;        lastWaiter = node;        return node;    &#125;    // 唤醒 - 将没取消的第一个节点转移至 AQS 队列    private void doSignal(Node first) &#123;        do &#123;            // 已经是尾节点了            if ( (firstWaiter = first.nextWaiter) == null) &#123;                lastWaiter = null;            &#125;            first.nextWaiter = null;        &#125; while (            // 将等待队列中的 Node 转移至 AQS 队列, 不成功且还有节点则继续循环 ㈢                !transferForSignal(first) &amp;&amp;                        // 队列还有节点                        (first = firstWaiter) != null        );    &#125;    // 外部类方法, 方便阅读, 放在此处    // ㈢ 如果节点状态是取消, 返回 false 表示转移失败, 否则转移成功    final boolean transferForSignal(Node node) &#123;        // 设置当前node状态为0（因为处在队列末尾），如果状态已经不是 Node.CONDITION, 说明被取消了        if (!compareAndSetWaitStatus(node, Node.CONDITION, 0))            return false;        // 加入 AQS 队列尾部        Node p = enq(node);        int ws = p.waitStatus;        if (            // 插入节点的上一个节点被取消                ws &gt; 0 ||                        // 插入节点的上一个节点不能设置状态为 Node.SIGNAL                        !compareAndSetWaitStatus(p, ws, Node.SIGNAL)        ) &#123;            // unpark 取消阻塞, 让线程重新同步状态            LockSupport.unpark(node.thread);        &#125;        return true;    &#125;// 全部唤醒 - 等待队列的所有节点转移至 AQS 队列private void doSignalAll(Node first) &#123;    lastWaiter = firstWaiter = null;    do &#123;        Node next = first.nextWaiter;        first.nextWaiter = null;        transferForSignal(first);        first = next;    &#125; while (first != null);&#125;    // ㈡    private void unlinkCancelledWaiters() &#123;        // ...    &#125;    // 唤醒 - 必须持有锁才能唤醒, 因此 doSignal 内无需考虑加锁    public final void signal() &#123;        // 如果没有持有锁，会抛出异常        if (!isHeldExclusively())            throw new IllegalMonitorStateException();        Node first = firstWaiter;        if (first != null)            doSignal(first);    &#125;    // 全部唤醒 - 必须持有锁才能唤醒, 因此 doSignalAll 内无需考虑加锁    public final void signalAll() &#123;        if (!isHeldExclusively())            throw new IllegalMonitorStateException();        Node first = firstWaiter;        if (first != null)            doSignalAll(first);    &#125;    // 不可打断等待 - 直到被唤醒    public final void awaitUninterruptibly() &#123;        // 添加一个 Node 至等待队列, 见 ㈠        Node node = addConditionWaiter();        // 释放节点持有的锁, 见 ㈣        int savedState = fullyRelease(node);        boolean interrupted = false;        // 如果该节点还没有转移至 AQS 队列, 阻塞        while (!isOnSyncQueue(node)) &#123;            // park 阻塞            LockSupport.park(this);            // 如果被打断, 仅设置打断状态            if (Thread.interrupted())                interrupted = true;        &#125;        // 唤醒后, 尝试竞争锁, 如果失败进入 AQS 队列        if (acquireQueued(node, savedState) || interrupted)            selfInterrupt();    &#125;    // 外部类方法, 方便阅读, 放在此处    // ㈣ 因为某线程可能重入，需要将 state 全部释放，获取state，然后把它全部减掉，以全部释放    final int fullyRelease(Node node) &#123;        boolean failed = true;        try &#123;            int savedState = getState();            // 唤醒等待队列队列中的下一个节点            if (release(savedState)) &#123;                failed = false;                return savedState;            &#125; else &#123;                throw new IllegalMonitorStateException();            &#125;        &#125; finally &#123;            if (failed)                node.waitStatus = Node.CANCELLED;        &#125;    &#125;    // 打断模式 - 在退出等待时重新设置打断状态    private static final int REINTERRUPT = 1;    // 打断模式 - 在退出等待时抛出异常    private static final int THROW_IE = -1;    // 判断打断模式    private int checkInterruptWhileWaiting(Node node) &#123;        return Thread.interrupted() ?                (transferAfterCancelledWait(node) ? THROW_IE : REINTERRUPT) :                0;    &#125;    // ㈤ 应用打断模式    private void reportInterruptAfterWait(int interruptMode)            throws InterruptedException &#123;        if (interruptMode == THROW_IE)            throw new InterruptedException();        else if (interruptMode == REINTERRUPT)            selfInterrupt();    &#125;    // 等待 - 直到被唤醒或打断    public final void await() throws InterruptedException &#123;        if (Thread.interrupted()) &#123;            throw new InterruptedException();        &#125;        // 添加一个 Node 至等待队列, 见 ㈠        Node node = addConditionWaiter();        // 释放节点持有的锁        int savedState = fullyRelease(node);        int interruptMode = 0;        // 如果该节点还没有转移至 AQS 队列, 阻塞        while (!isOnSyncQueue(node)) &#123;            // park 阻塞                          LockSupport.park(this);            // 如果被打断, 退出等待队列            if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)                break;        &#125;        // 退出等待队列后, 还需要获得 AQS 队列的锁        if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE)            interruptMode = REINTERRUPT;        // 所有已取消的 Node 从队列链表删除, 见 ㈡        if (node.nextWaiter != null)            unlinkCancelledWaiters();        // 应用打断模式, 见 ㈤        if (interruptMode != 0)            reportInterruptAfterWait(interruptMode);    &#125;    // 等待 - 直到被唤醒或打断或超时    public final long awaitNanos(long nanosTimeout) throws InterruptedException &#123;        if (Thread.interrupted()) &#123;            throw new InterruptedException();        &#125;        // 添加一个 Node 至等待队列, 见 ㈠        Node node = addConditionWaiter();        // 释放节点持有的锁        int savedState = fullyRelease(node);        // 获得最后期限        final long deadline = System.nanoTime() + nanosTimeout;        int interruptMode = 0;        // 如果该节点还没有转移至 AQS 队列, 阻塞        while (!isOnSyncQueue(node)) &#123;            // 已超时, 退出等待队列            if (nanosTimeout &lt;= 0L) &#123;                transferAfterCancelledWait(node);                break;            &#125;            // park 阻塞一定时间, spinForTimeoutThreshold 为 1000 ns            if (nanosTimeout &gt;= spinForTimeoutThreshold)                LockSupport.parkNanos(this, nanosTimeout);            // 如果被打断, 退出等待队列            if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)                break;            nanosTimeout = deadline - System.nanoTime();        &#125;        // 退出等待队列后, 还需要获得 AQS 队列的锁        if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE)            interruptMode = REINTERRUPT;        // 所有已取消的 Node 从队列链表删除, 见 ㈡        if (node.nextWaiter != null)            unlinkCancelledWaiters();        // 应用打断模式, 见 ㈤        if (interruptMode != 0)            reportInterruptAfterWait(interruptMode);        return deadline - System.nanoTime();    &#125;    // 等待 - 直到被唤醒或打断或超时, 逻辑类似于 awaitNanos    public final boolean awaitUntil(Date deadline) throws InterruptedException &#123;        // ...    &#125;    // 等待 - 直到被唤醒或打断或超时, 逻辑类似于 awaitNanos    public final boolean await(long time, TimeUnit unit) throws InterruptedException &#123;        // ...    &#125;    // 工具方法 省略 ...&#125;</code></pre><h1 id="读写锁原理"><a href="#读写锁原理" class="headerlink" title="读写锁原理"></a>读写锁原理</h1><h2 id="ReentrantReadWriteLock"><a href="#ReentrantReadWriteLock" class="headerlink" title="ReentrantReadWriteLock"></a>ReentrantReadWriteLock</h2><blockquote><p>当读操作远远高于写操作时，这时候使用读写锁让读 - 读可以并发，提高性能。读 - 写，写 - 写都是相互互斥的！提供一个数据容器类，内部分别使用读锁保护数据的 read () 方法，写锁保护数据的 write () 方法 。实现代码如下：</p></blockquote><pre><code class="bash">@Slf4jpublic class ReadWriteLockTest &#123;    public static void main(String[] args) &#123;        DataContainer dataContainer = new DataContainer();        new Thread(() -&gt; &#123;            dataContainer.read();            dataContainer.write();        &#125;,&quot;t1&quot;).start();        new Thread(() -&gt; &#123;            dataContainer.write();        &#125;,&quot;t2&quot;).start();    &#125;&#125;@Slf4jclass DataContainer &#123;    private Object object = new Object();    private ReentrantReadWriteLock readWriteLock = new ReentrantReadWriteLock();    private ReentrantReadWriteLock.ReadLock readLock = readWriteLock.readLock();    private ReentrantReadWriteLock.WriteLock writeLock = readWriteLock.writeLock();    public Object read() &#123;        readLock.lock();        log.info(&quot;拿到读锁&quot;);        try &#123;            log.info(&quot;读取操作&quot;);            TimeUnit.SECONDS.sleep(1);        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125; finally &#123;            readLock.unlock();            log.info(&quot;释放读锁&quot;);        &#125;        return object;    &#125;    public  void write() &#123;        writeLock.lock();        log.info(&quot;拿到写锁&quot;);        try &#123;            log.info(&quot;写操作&quot;);        &#125;finally &#123;            writeLock.unlock();            log.info(&quot;释放写锁&quot;);        &#125;    &#125;&#125;</code></pre><p><strong>输出：读读并发，读写阻塞</strong></p><pre><code class="bash">11:01:47.856 [t1] INFO com.heu.test.DataContainer - 拿到读锁11:01:47.865 [t1] INFO com.heu.test.DataContainer - 读取操作11:01:47.856 [t2] INFO com.heu.test.DataContainer - 拿到读锁11:01:47.867 [t2] INFO com.heu.test.DataContainer - 读取操作11:01:48.872 [t1] INFO com.heu.test.DataContainer - 释放读锁11:01:48.872 [t2] INFO com.heu.test.DataContainer - 释放读锁11:01:48.872 [t1] INFO com.heu.test.DataContainer - 拿到写锁11:01:48.872 [t1] INFO com.heu.test.DataContainer - 写操作11:01:48.872 [t1] INFO com.heu.test.DataContainer - 释放写锁</code></pre><p><strong>注意事项：</strong></p><ol><li>读锁不支持条件变量。</li><li>重入时升级不支持：即持有读锁的情况下去获取写锁，会导致获取写锁永久等待。</li></ol><pre><code class="bash">r.lock();     try &#123;         // ...         w.lock();         try &#123;             // ...         &#125; finally&#123;             w.unlock();         &#125;     &#125; finally&#123;         r.unlock();     &#125;//写锁永久等待</code></pre><ol><li>重入时降级支持：即持有写锁的情况下去获取读锁：</li></ol><pre><code class="bash">class CachedData &#123;    Object data;    // 是否有效，如果失效，需要重新计算 data    volatile boolean cacheValid;    final ReentrantReadWriteLock rwl = new ReentrantReadWriteLock();    void processCachedData() &#123;        rwl.readLock().lock();        if (!cacheValid) &#123;            // 获取写锁前必须释放读锁            rwl.readLock().unlock();            rwl.writeLock().lock();            try &#123;                // 判断是否有其它线程已经获取了写锁、更新了缓存, 避免重复更新                if (!cacheValid) &#123;                    data = ...                    cacheValid = true;                &#125;                // 降级为读锁, 释放写锁, 这样能够让其它线程读取缓存                rwl.readLock().lock();            &#125; finally &#123;                rwl.writeLock().unlock();            &#125;        &#125;        // 自己用完数据, 释放读锁        try &#123;            use(data);        &#125; finally &#123;            rwl.readLock().unlock();        &#125;    &#125;&#125;</code></pre><h2 id="读写锁原理-1"><a href="#读写锁原理-1" class="headerlink" title="读写锁原理"></a>读写锁原理</h2><p><strong>读写锁</strong>用的是同一个 Sync 同步器，因此**等待队列、state **等也是同一个。</p><p><strong>下面执行：t1 w.lock，t2 r.lock 情况：</strong></p><ol><li><p>t1 成功上锁，流程与 ReentrantLock 加锁相比没有特殊之处，不同是写锁状态占了 state 的低 16 位，读锁使用的是 state 的高 16 位。<br>​<br><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210617141553828.png"></p></li><li><p>t2 执行 r.lock，这时进入读锁的 sync.acquireShared (1) 流程，首先会进入 tryAcquireShared 流程。如果有写锁占据，那么 tryAcquireShared 返回 -1 表示失败。tryAcquireShared 返回值表示：</p><ul><li>-1 表示失败。</li><li>0 表示成功，但后继节点不会继续唤醒。</li><li>正数表示成功，而且数值是还有几个后继节点需要唤醒，这里的读写锁返回 1。</li></ul></li></ol><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210617141820347.png"></p><ol start="2"><li>这时会进入 sync.doAcquireShared (1) 流程，首先也是调用 addWaiter 添加节点，不同之处在于节点被设置为 Node.SHARED 模式而非 Node.EXCLUSIVE 模式，注意此时 t2 仍处于活跃状态。</li></ol><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210617142341800.png"></p><ol start="3"><li><p>t2 会看看自己的节点是不是老二，如果是，还会再次调用 tryAcquireShared (1) 来尝试获取锁。</p></li><li><p>如果没有成功，在 doAcquireShared 内 for 循环一次，把前驱节点的 waitStatus 改为 -1，再 for 循环一 次尝试 tryAcquireShared (1) 如果还不成功，那么在 parkAndCheckInterrupt () 处 park。</p></li></ol><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210617142418723.png"></p><ol start="5"><li><strong>又继续执行 ：t3 r.lock，t4 w.lock。</strong>在这种状态下，假设又有 t3 加读锁和 t4 加写锁，这期间 t1 仍然持有锁，就变成了下面的样子：</li></ol><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210617144002185.png"></p><ol start="6"><li>**继续执行 t1 w.unlock,**这时会走到写锁的 sync.release (1) 流程，调用 sync.tryRelease (1) 成功，变成下面的样子：</li></ol><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210617144632809.png"></p><ol start="7"><li>接下来执行唤醒流程 sync.unparkSuccessor，即让老二恢复运行。这时 t2 在 doAcquireShared 内 parkAndCheckInterrupt () 处恢复运行，图中的 t2 从黑色变成了蓝色（注意这里只是恢复运行而已，并没有获取到锁！） 这回再来一次 for (;;) 执行 tryAcquireShared 成功，让读锁计数加一。</li></ol><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210617144832160.png"></p><ol start="8"><li>这时 t2 已经恢复运行，接下来 t2 调用 setHeadAndPropagate (node, 1)，它原本所在节点被置为头节点。</li></ol><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210617144926677.png"></p><ol start="9"><li>事情还没完，在 setHeadAndPropagate 方法内还会检查下一个节点是否是 shared，如果是，则调用 doReleaseShared () 将 head 的状态从 -1 改为 0 并唤醒老二，这时 t3 在 doAcquireShared 内 parkAndCheckInterrupt () 处恢复运行。</li></ol><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210617145201826.png"></p><ol start="10"><li>这回再来一次 for (;;) ，执行 tryAcquireShared 成功则让读锁计数加一。</li></ol><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210617145259018.png"></p><ol start="11"><li>这时 t3 已经恢复运行，接下来 t3 调用 setHeadAndPropagate (node, 1)，它原本所在节点被置为头节点。</li></ol><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210617145411846.png"></p><ol start="12"><li> 再继续执行 t2 r.unlock，t3 r.unlock t2，进入 sync.releaseShared (1) 中，调用 tryReleaseShared (1) 让计数减一。</li></ol><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210617145742494.png"></p><ol start="13"><li>但由于计数还不为零，t3 进入 sync.releaseShared (1) 中，调用 tryReleaseShared (1) 让计数减一，这回计数为零了，进入 doReleaseShared () 将头节点从 -1 改为 0 并唤醒老二，即：</li></ol><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210617150145779.png"></p><ol start="14"><li>之后 t4 线程 在 acquireQueued 中 parkAndCheckInterrupt 处恢复运行，再次 执行 for (;;) 循环， 这次自己是老二，并且没有其他线程竞争，tryAcquire (1) 成功，修改头结点，流程结束。</li></ol><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210617150310448.png"></p><h2 id="源码分析-1"><a href="#源码分析-1" class="headerlink" title="源码分析"></a>源码分析</h2><h3 id="写锁源码分析"><a href="#写锁源码分析" class="headerlink" title="写锁源码分析"></a>写锁源码分析</h3><h3 id="写锁上锁流程："><a href="#写锁上锁流程：" class="headerlink" title="写锁上锁流程："></a>写锁上锁流程：</h3><pre><code class="bash">static final class NonfairSync extends Sync &#123;    // ... 省略无关代码    // 外部类 WriteLock 方法, 方便阅读, 放在此处    public void lock() &#123;        sync.acquire(1);    &#125;    // AQS 继承过来的方法, 方便阅读, 放在此处    public final void acquire(int arg) &#123;        if (            // 尝试获得写锁失败                !tryAcquire(arg) &amp;&amp;                        // 将当前线程关联到一个 Node 对象上, 模式为独占模式                        // 进入 AQS 队列阻塞                        acquireQueued(addWaiter(Node.EXCLUSIVE), arg)        ) &#123;            selfInterrupt();        &#125;    &#125;    // Sync 继承过来的方法, 方便阅读, 放在此处    protected final boolean tryAcquire(int acquires) &#123;        // 获得低 16 位, 代表写锁的 state 计数        Thread current = Thread.currentThread();        int c = getState();        int w = exclusiveCount(c);        if (c != 0) &#123;            if (                // c != 0 and w == 0 表示有读锁返回错误，读锁不支持锁升级, 或者                    w == 0 ||                            // c != 0 and w == 0 表示有写，如果 exclusiveOwnerThread 不是自己                            current != getExclusiveOwnerThread()            ) &#123;                // 获得锁失败                return false;            &#125;            // 写锁计数超过低 16 位, 报异常            if (w + exclusiveCount(acquires) &gt; MAX_COUNT)                throw new Error(&quot;Maximum lock count exceeded&quot;);            // 写锁重入, 获得锁成功            setState(c + acquires);            return true;        &#125;        if (            // 判断写锁是否该阻塞这里返回false, 或者                writerShouldBlock() ||                        // 尝试更改计数失败                        !compareAndSetState(c, c + acquires)        ) &#123;            // 获得锁失败            return false;        &#125;        // 获得锁成功        setExclusiveOwnerThread(current);        return true;    &#125;    // 非公平锁 writerShouldBlock 总是返回 false, 无需阻塞    final boolean writerShouldBlock() &#123;        return false;    &#125;&#125;</code></pre><blockquote><p>写锁释放流程：</p></blockquote><pre><code class="bash">static final class NonfairSync extends Sync &#123;    // ... 省略无关代码    // WriteLock 方法, 方便阅读, 放在此处    public void unlock() &#123;        sync.release(1);    &#125;    // AQS 继承过来的方法, 方便阅读, 放在此处    public final boolean release(int arg) &#123;        // 尝试释放写锁成功        if (tryRelease(arg)) &#123;            // unpark AQS 中等待的线程            Node h = head;            if (h != null &amp;&amp; h.waitStatus != 0)                unparkSuccessor(h);            return true;        &#125;        return false;    &#125;    // Sync 继承过来的方法, 方便阅读, 放在此处    protected final boolean tryRelease(int releases) &#123;        if (!isHeldExclusively())            throw new IllegalMonitorStateException();        int nextc = getState() - releases;        // 因为可重入的原因, 写锁计数为 0, 才算释放成功        boolean free = exclusiveCount(nextc) == 0;        if (free) &#123;            setExclusiveOwnerThread(null);        &#125;        setState(nextc);        return free;    &#125;&#125;</code></pre><h3 id="读锁上锁流程："><a href="#读锁上锁流程：" class="headerlink" title="读锁上锁流程："></a>读锁上锁流程：</h3><pre><code class="bash">static final class NonfairSync extends Sync &#123;    // ReadLock 方法, 方便阅读, 放在此处    public void lock() &#123;        sync.acquireShared(1);    &#125;    // AQS 继承过来的方法, 方便阅读, 放在此处    public final void acquireShared(int arg) &#123;        // tryAcquireShared 返回负数, 表示获取读锁失败        if (tryAcquireShared(arg) &lt; 0) &#123;            doAcquireShared(arg);        &#125;    &#125;    // Sync 继承过来的方法, 方便阅读, 放在此处    protected final int tryAcquireShared(int unused) &#123;        Thread current = Thread.currentThread();        int c = getState();        // 如果是其它线程持有写锁, 获取读锁失败        if (                exclusiveCount(c) != 0 &amp;&amp;                        getExclusiveOwnerThread() != current        ) &#123;            return -1;        &#125;        int r = sharedCount(c);        if (            // 读锁不该阻塞(如果老二是写锁，读锁该阻塞), 并且                !readerShouldBlock() &amp;&amp;                        // 小于读锁计数, 并且                        r &lt; MAX_COUNT &amp;&amp;                        // 尝试增加计数成功                        compareAndSetState(c, c + SHARED_UNIT)        ) &#123;            // ... 省略不重要的代码            return 1;        &#125;        return fullTryAcquireShared(current);    &#125;    // 非公平锁 readerShouldBlock 看 AQS 队列中第一个节点是否是写锁    // true 则该阻塞, false 则不阻塞    final boolean readerShouldBlock() &#123;        return apparentlyFirstQueuedIsExclusive();    &#125;    // AQS 继承过来的方法, 方便阅读, 放在此处    // 与 tryAcquireShared 功能类似, 但会不断尝试 for (;;) 获取读锁, 执行过程中无阻塞    final int fullTryAcquireShared(Thread current) &#123;        HoldCounter rh = null;        for (;;) &#123;            int c = getState();            if (exclusiveCount(c) != 0) &#123;                if (getExclusiveOwnerThread() != current)                    return -1;            &#125; else if (readerShouldBlock()) &#123;                // ... 省略不重要的代码            &#125;            if (sharedCount(c) == MAX_COUNT)                throw new Error(&quot;Maximum lock count exceeded&quot;);            if (compareAndSetState(c, c + SHARED_UNIT)) &#123;                // ... 省略不重要的代码                return 1;            &#125;        &#125;    &#125;    // AQS 继承过来的方法, 方便阅读, 放在此处    private void doAcquireShared(int arg) &#123;        // 将当前线程关联到一个 Node 对象上, 模式为共享模式        final Node node = addWaiter(Node.SHARED);        boolean failed = true;        try &#123;            boolean interrupted = false;            for (;;) &#123;                final Node p = node.predecessor();                if (p == head) &#123;                    // 再一次尝试获取读锁                    int r = tryAcquireShared(arg);                    // 成功                    if (r &gt;= 0) &#123;                        // ㈠                        // r 表示可用资源数, 在这里总是 1 允许传播                        //（唤醒 AQS 中下一个 Share 节点）                        setHeadAndPropagate(node, r);                        p.next = null; // help GC                        if (interrupted)                            selfInterrupt();                        failed = false;                        return;                    &#125;                &#125;                if (                    // 是否在获取读锁失败时阻塞（前一个阶段 waitStatus == Node.SIGNAL）                        shouldParkAfterFailedAcquire(p, node) &amp;&amp;                                // park 当前线程                                parkAndCheckInterrupt()                ) &#123;                    interrupted = true;                &#125;            &#125;        &#125; finally &#123;            if (failed)                cancelAcquire(node);        &#125;    &#125;    // ㈠ AQS 继承过来的方法, 方便阅读, 放在此处    private void setHeadAndPropagate(Node node, int propagate) &#123;        Node h = head; // Record old head for check below        // 设置自己为 head        setHead(node);        // propagate 表示有共享资源（例如共享读锁或信号量）        // 原 head waitStatus == Node.SIGNAL 或 Node.PROPAGATE        // 现在 head waitStatus == Node.SIGNAL 或 Node.PROPAGATE        if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0 ||                (h = head) == null || h.waitStatus &lt; 0) &#123;            Node s = node.next;            // 如果是最后一个节点或者是等待共享读锁的节点            if (s == null || s.isShared()) &#123;                // 进入 ㈡                doReleaseShared();            &#125;        &#125;    &#125;    // ㈡ AQS 继承过来的方法, 方便阅读, 放在此处    private void doReleaseShared() &#123;        // 如果 head.waitStatus == Node.SIGNAL ==&gt; 0 成功, 下一个节点 unpark        // 如果 head.waitStatus == 0 ==&gt; Node.PROPAGATE        for (;;) &#123;            Node h = head;            // 队列还有节点            if (h != null &amp;&amp; h != tail) &#123;                int ws = h.waitStatus;                if (ws == Node.SIGNAL) &#123;                    if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0))                        continue; // loop to recheck cases                    // 下一个节点 unpark 如果成功获取读锁                    // 并且下下个节点还是 shared, 继续 doReleaseShared                    unparkSuccessor(h);                &#125;                else if (ws == 0 &amp;&amp;                        !compareAndSetWaitStatus(h, 0, Node.PROPAGATE))                    continue; // loop on failed CAS            &#125;            if (h == head) // loop if head changed                break;        &#125;    &#125;&#125;</code></pre><blockquote><p>读锁释放流程：</p></blockquote><pre><code class="bash">static final class NonfairSync extends Sync &#123;    // ReadLock 方法, 方便阅读, 放在此处    public void unlock() &#123;        sync.releaseShared(1);    &#125;    // AQS 继承过来的方法, 方便阅读, 放在此处    public final boolean releaseShared(int arg) &#123;        if (tryReleaseShared(arg)) &#123;            doReleaseShared();            return true;        &#125;        return false;    &#125;    // Sync 继承过来的方法, 方便阅读, 放在此处    protected final boolean tryReleaseShared(int unused) &#123;        // ... 省略不重要的代码        for (;;) &#123;            int c = getState();            int nextc = c - SHARED_UNIT;            if (compareAndSetState(c, nextc)) &#123;                // 读锁的计数不会影响其它获取读锁线程, 但会影响其它获取写锁线程                // 计数为 0 才是真正释放                return nextc == 0;            &#125;        &#125;    &#125;    // AQS 继承过来的方法, 方便阅读, 放在此处    private void doReleaseShared() &#123;        // 如果 head.waitStatus == Node.SIGNAL ==&gt; 0 成功, 下一个节点 unpark        // 如果 head.waitStatus == 0 ==&gt; Node.PROPAGATE        for (;;) &#123;            Node h = head;            if (h != null &amp;&amp; h != tail) &#123;                int ws = h.waitStatus;                // 如果有其它线程也在释放读锁，那么需要将 waitStatus 先改为 0                // 防止 unparkSuccessor 被多次执行                if (ws == Node.SIGNAL) &#123;                    if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0))                        continue; // loop to recheck cases                    unparkSuccessor(h);                &#125;                // 如果已经是 0 了，改为 -3，用来解决传播性，见后文信号量 bug 分析                else if (ws == 0 &amp;&amp;                        !compareAndSetWaitStatus(h, 0, Node.PROPAGATE))                    continue; // loop on failed CAS            &#125;            if (h == head) // loop if head changed                break;        &#125;    &#125;&#125;</code></pre><h2 id="StampedLock"><a href="#StampedLock" class="headerlink" title="StampedLock"></a>StampedLock</h2><p>该类自 JDK 8 加入，是为了进一步优化读性能，它的特点是在使用读锁、写锁时都必须配合【戳】使用。</p><blockquote><p>加解读锁</p></blockquote><pre><code class="bash">long stamp = lock.readLock();lock.unlockRead(stamp);</code></pre><blockquote><p>加解写锁</p></blockquote><pre><code class="bash">long stamp = lock.writeLock();lock.unlockWrite(stamp);</code></pre><p>StampedLock 支持 tryOptimisticRead () 方法（乐观读），读取完毕后需要做一次戳校验，如果校验通过，表示这期间确实没有写操作，数据可以安全使用，如果校验没通过，需要重新获取读锁，保证数据安全。</p><pre><code class="bash">long stamp = lock.tryOptimisticRead();// 验戳if(!lock.validate(stamp))&#123; // 锁升级&#125;</code></pre><blockquote><p>示例：提供一个数据容器类内部分别使用读锁保护数据的 read () 方法，写锁保护数据的 write () 方法。代码实现：</p></blockquote><pre><code class="bash">@Slf4jpublic class StampedLockTest &#123;    public static void main(String[] args) throws InterruptedException &#123;        StampedLockDataContainer dataContainer = new StampedLockDataContainer(1);        Thread t1 = new Thread(() -&gt; &#123;            try &#123;                System.out.println(dataContainer.read(1));            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;        &#125;, &quot;t1&quot;);        t1.start();        TimeUnit.MILLISECONDS.sleep(500);        Thread t2 = new Thread(() -&gt; &#123;            dataContainer.write(10);        &#125;, &quot;t2&quot;);        t2.start();    &#125;&#125;@Slf4jclass StampedLockDataContainer &#123;    private int data;    private StampedLock stampedLock = new StampedLock();    public StampedLockDataContainer(int data) &#123;        this.data = data;    &#125;    public int read(int readTime) throws InterruptedException &#123;        long stamp = stampedLock.tryOptimisticRead();        log.info(&quot;optimistic read locking ...&#123;&#125;&quot;, stamp);        Thread.sleep(readTime * 1000);        if (stampedLock.validate(stamp)) &#123;            log.info(&quot;read finish... &#123;&#125;&quot;, stamp);            return data;        &#125;        // 锁升级 - 读锁        log.info(&quot;update to read lock ...&quot;);        try &#123;            stamp = stampedLock.readLock();            log.info(&quot;read lock &#123;&#125;&quot;, stamp);            Thread.sleep(readTime * 1000);            log.info(&quot;read finish ... &#123;&#125;&quot;, stamp);            return data;        &#125;finally &#123;            stampedLock.unlockRead(stamp);        &#125;    &#125;    public void write(int newData) &#123;        long stamp = stampedLock.writeLock();        try &#123;            log.info(&quot;write lock &#123;&#125;&quot;, stamp);            this.data = newData;            try &#123;                TimeUnit.SECONDS.sleep(1);            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;            log.info(&quot;write finish ... &#123;&#125;&quot;, stamp);            log.info(&quot;write newData ... &#123;&#125;&quot;, this.data);        &#125; finally &#123;            stampedLock.unlockWrite(stamp);        &#125;    &#125;&#125;</code></pre><p><em>输出：</em></p><pre><code>16:30:13.011 [t1] INFO com.heu.test.StampedLockDataContainer - optimistic read locking ...25616:30:13.519 [t2] INFO com.heu.test.StampedLockDataContainer - write lock 38416:30:14.031 [t1] INFO com.heu.test.StampedLockDataContainer - update to read lock ...16:30:14.523 [t2] INFO com.heu.test.StampedLockDataContainer - write finish ... 38416:30:14.524 [t2] INFO com.heu.test.StampedLockDataContainer - write newData ... 1016:30:14.525 [t1] INFO com.heu.test.StampedLockDataContainer - read lock 51316:30:15.533 [t1] INFO com.heu.test.StampedLockDataContainer - read finish ... 51310</code></pre><blockquote><p>注意：</p></blockquote><ol><li>StampedLock 不支持条件变量</li><li>StampedLock 不支持可重入</li></ol><h1 id="Semaphore"><a href="#Semaphore" class="headerlink" title="Semaphore"></a>Semaphore</h1><h2 id="基本使用"><a href="#基本使用" class="headerlink" title="基本使用"></a>基本使用</h2><p><strong>信号量</strong>，用来限制能同时访问共享资源的线程上限。示例：</p><pre><code>@Slf4jpublic class SemaphoreTest &#123;    public static void main(String[] args) &#123;        //1.创建一个对象        Semaphore semaphore = new Semaphore(3);        //2.开10个线程        for (int i = 0; i &lt; 10; i++) &#123;            new Thread(() -&gt; &#123;                //获取一个许可                try &#123;                    semaphore.acquire();                &#125; catch (InterruptedException e) &#123;                    e.printStackTrace();                &#125;                try &#123;                    log.info(&quot;start...&quot;);                    Thread.sleep(1000);                    log.info(&quot;end...&quot;);                &#125; catch (InterruptedException e) &#123;                    e.printStackTrace();                &#125;finally &#123;                    semaphore.release();                &#125;            &#125;,&quot;t&quot;+(i+1)).start();        &#125;    &#125;&#125;</code></pre><p><strong>输出：</strong></p><pre><code class="bash">16:43:36.143 [t2] INFO com.heu.test.SemaphoreTest - start...16:43:36.143 [t3] INFO com.heu.test.SemaphoreTest - start...16:43:36.143 [t1] INFO com.heu.test.SemaphoreTest - start...16:43:37.154 [t1] INFO com.heu.test.SemaphoreTest - end...16:43:37.154 [t3] INFO com.heu.test.SemaphoreTest - end...16:43:37.155 [t2] INFO com.heu.test.SemaphoreTest - end...16:43:37.156 [t4] INFO com.heu.test.SemaphoreTest - start...16:43:37.155 [t10] INFO com.heu.test.SemaphoreTest - start...16:43:37.156 [t6] INFO com.heu.test.SemaphoreTest - start...16:43:38.162 [t4] INFO com.heu.test.SemaphoreTest - end...16:43:38.162 [t6] INFO com.heu.test.SemaphoreTest - end...16:43:38.162 [t10] INFO com.heu.test.SemaphoreTest - end...16:43:38.162 [t9] INFO com.heu.test.SemaphoreTest - start...16:43:38.163 [t7] INFO com.heu.test.SemaphoreTest - start...16:43:38.163 [t8] INFO com.heu.test.SemaphoreTest - start...16:43:39.174 [t9] INFO com.heu.test.SemaphoreTest - end...16:43:39.174 [t7] INFO com.heu.test.SemaphoreTest - end...16:43:39.174 [t5] INFO com.heu.test.SemaphoreTest - start...16:43:39.174 [t8] INFO com.heu.test.SemaphoreTest - end...16:43:40.181 [t5] INFO com.heu.test.SemaphoreTest - end...</code></pre><h2 id="Semaphore-原理"><a href="#Semaphore-原理" class="headerlink" title="Semaphore 原理"></a>Semaphore 原理</h2><p><strong>Semaphore</strong> 有点像一个停车场，permits 就好像停车位数量，当线程获得了 permits 就像是获得了停车位，然后停车场显示空余车位减一。如下示例：刚开始 permits（state）为 3，这时 5 个线程来获取资源：</p><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210617164935238.png"></p><ol><li>假设其中 Thread-1，Thread-2，Thread-4 cas 竞争成功，而 Thread-0 和 Thread-3 竞争失败，进入 AQS 队列 park 阻塞。</li></ol><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210617165100987.png"></p><ol start="2"><li>这时 Thread-4 释放了 permits，状态如下：</li></ol><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210617165142832.png"></p><ol start="3"><li>接下来 Thread-0 竞争成功，permits 再次设置为 0，设置自己为 head 节点，断开原来的 head 节点，unpark 接下来的 Thread-3 节点，但由于 permits 是 0，因此 Thread-3 在尝试不成功后再次进入 park 状态。</li></ol><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210617165256132.png"></p><h2 id="源码分析-2"><a href="#源码分析-2" class="headerlink" title="源码分析"></a>源码分析</h2><pre><code class="bash">static final class NonfairSync extends Sync &#123;    private static final long serialVersionUID = -2694183684443567898L;    NonfairSync(int permits) &#123;        // permits 即 state        super(permits);    &#125;    // Semaphore 方法, 方便阅读, 放在此处    public void acquire() throws InterruptedException &#123;        sync.acquireSharedInterruptibly(1);    &#125;    // AQS 继承过来的方法, 方便阅读, 放在此处    public final void acquireSharedInterruptibly(int arg)            throws InterruptedException &#123;        if (Thread.interrupted())            throw new InterruptedException();        if (tryAcquireShared(arg) &lt; 0)            doAcquireSharedInterruptibly(arg);    &#125;    // 尝试获得共享锁    protected int tryAcquireShared(int acquires) &#123;        return nonfairTryAcquireShared(acquires);    &#125;    // Sync 继承过来的方法, 方便阅读, 放在此处    final int nonfairTryAcquireShared(int acquires) &#123;        for (;;) &#123;            int available = getState();            int remaining = available - acquires;            if (                   // 如果许可已经用完, 返回负数, 表示获取失败, 进入 doAcquireSharedInterruptibly                    remaining &lt; 0 ||                            // 如果 cas 重试成功, 返回正数, 表示获取成功                            compareAndSetState(available, remaining)            ) &#123;                return remaining;            &#125;        &#125;    &#125;    // AQS 继承过来的方法, 方便阅读, 放在此处    private void doAcquireSharedInterruptibly(int arg) throws InterruptedException &#123;        final Node node = addWaiter(Node.SHARED);        boolean failed = true;        try &#123;            for (;;) &#123;                final Node p = node.predecessor();                if (p == head) &#123;                    // 再次尝试获取许可                    int r = tryAcquireShared(arg);                    if (r &gt;= 0) &#123;                        // 成功后本线程出队（AQS）, 所在 Node设置为 head                        // 如果 head.waitStatus == Node.SIGNAL ==&gt; 0 成功, 下一个节点 unpark                        // 如果 head.waitStatus == 0 ==&gt; Node.PROPAGATE                      // r 表示可用资源数, 为 0 则不会继续传播                        setHeadAndPropagate(node, r);                        p.next = null; // help GC                        failed = false;                        return;                    &#125;                &#125;                // 不成功, 设置上一个节点 waitStatus = Node.SIGNAL, 下轮进入 park 阻塞                if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;                        parkAndCheckInterrupt())                    throw new InterruptedException();            &#125;        &#125; finally &#123;            if (failed)                cancelAcquire(node);        &#125;    &#125;    // Semaphore 方法, 方便阅读, 放在此处    public void release() &#123;        sync.releaseShared(1);    &#125;    // AQS 继承过来的方法, 方便阅读, 放在此处    public final boolean releaseShared(int arg) &#123;        if (tryReleaseShared(arg)) &#123;            doReleaseShared();            return true;        &#125;        return false;    &#125;    // Sync 继承过来的方法, 方便阅读, 放在此处    protected final boolean tryReleaseShared(int releases) &#123;        for (;;) &#123;            int current = getState();            int next = current + releases;            if (next &lt; current) // overflow                throw new Error(&quot;Maximum permit count exceeded&quot;);            if (compareAndSetState(current, next))                return true;        &#125;    &#125;&#125;</code></pre><h1 id="CountdownLatch"><a href="#CountdownLatch" class="headerlink" title="CountdownLatch"></a>CountdownLatch</h1><p><strong>CountDownLatch</strong> 允许多线程阻塞在一个地方，直至所有线程的任务都执行完毕。在 Java 并发中，countdownlatch 的概念是一个常见的面试题，所以一定要确保很好的理解了它。</p><ol><li><p>CountDownLatch 是共享锁的一种实现，它默认构造 AQS 的 state 值为 count。当线程使用 countDown 方法时，其实使用了 tryReleaseShared 方法以 CAS 的操作来减少 state，当 state 为 0， 就代表所有的线程都调用了 countDown 方法。</p></li><li><p>当调用 await 方法的时候，如果 state 不为 0，就代表仍然有线程没有调用 countDown0 方法，那么就把已经调用过 countDown 的线程都放入阻塞队列 Park ，并自旋 CAS 判断 state == 0，直至最后一个线程调用了 countDown ，使得 state == 0，于是阻塞的线程便判断成功，全部往下执行。</p></li></ol><p>用来进行线程同步协作，等待所有线程完成倒计时。 其中构造参数用来初始化等待计数值，await () 用来等待计数归零，countDown () 用来让计数减一。</p><pre><code class="bash">@Slf4j@SuppressWarnings(&quot;all&quot;)public class CountDownLatchTest &#123;    public static void main(String[] args) throws InterruptedException &#123;         method3();    &#125;    public static void method1() throws InterruptedException &#123;        CountDownLatch countDownLatch = new CountDownLatch(3);        new Thread(() -&gt; &#123;            log.info(&quot;t1 start ...&quot;);            try &#123;                Thread.sleep(1000);            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;            log.info(&quot;t1 end ...&quot;);            countDownLatch.countDown();        &#125;,&quot;t1&quot;).start();        new Thread(() -&gt; &#123;            log.info(&quot;t2 start ...&quot;);            try &#123;                Thread.sleep(2000);            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;            log.info(&quot;t2 end ...&quot;);            countDownLatch.countDown();        &#125;, &quot;t2&quot;).start();        new Thread(() -&gt; &#123;            log.info(&quot;t3 start ...&quot;);            try &#123;                Thread.sleep(1500);            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;            log.info(&quot;t3 end ...&quot;);            countDownLatch.countDown();        &#125;, &quot;t3&quot;).start();        log.info(&quot;main wait ...&quot;);        countDownLatch.await();        log.info(&quot;main wait end ...&quot;);    &#125;    public static void method2() &#123;        CountDownLatch countDownLatch = new CountDownLatch(3);        ExecutorService executorService = Executors.newFixedThreadPool(4);        executorService.submit(() -&gt; &#123;            log.info(&quot;t1 start ...&quot;);            try &#123;                Thread.sleep(1000);            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;            countDownLatch.countDown();            log.info(&quot;t1 end ...&#123;&#125;&quot;, countDownLatch.getCount());        &#125;);        executorService.submit(() -&gt; &#123;            log.info(&quot;t2 start ...&quot;);            try &#123;                Thread.sleep(2000);            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;            log.info(&quot;t2 end ...&#123;&#125;&quot;, countDownLatch.getCount());            countDownLatch.countDown();        &#125;);        executorService.submit(() -&gt; &#123;            log.info(&quot;t3 start ...&quot;);            try &#123;                Thread.sleep(1500);            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;            log.info(&quot;t3 end ...&#123;&#125;&quot;, countDownLatch.getCount());            countDownLatch.countDown();        &#125;);        executorService.submit(() -&gt; &#123;            log.info(&quot;main wait...&quot;);            try &#123;                countDownLatch.await();            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;            log.info(&quot;main wait end ...&quot;);            executorService.shutdown();        &#125;);    &#125;    public static void method3() throws InterruptedException &#123;        CountDownLatch countDownLatch = new CountDownLatch(10);        ExecutorService executorService = Executors.newFixedThreadPool(10);        String[] all = new String[10];        Random random = new Random();        for (int i = 0; i &lt; 10; i++) &#123;            int id = i;            executorService.submit(() -&gt; &#123;                for (int j = 0; j &lt;= 100; j++) &#123;                    try &#123;                        Thread.sleep(random.nextInt(100));                    &#125; catch (InterruptedException e) &#123;                        e.printStackTrace();                    &#125;                    all[id] = j + &quot;%&quot;;                    System.out.print(&quot;\r&quot; + Arrays.toString(all));                &#125;                countDownLatch.countDown();            &#125;);        &#125;        countDownLatch.await();        System.out.println();        System.out.println(&quot;游戏开始&quot;);        executorService.shutdown();    &#125;&#125;</code></pre><blockquote><p>method1 输出：</p></blockquote><pre><code class="bash">17:18:12.575 [main] INFO com.heu.test.CountDownLatchTest - main wait ...17:18:12.575 [t2] INFO com.heu.test.CountDownLatchTest - t2 start ...17:18:12.575 [t1] INFO com.heu.test.CountDownLatchTest - t1 start ...17:18:12.575 [t3] INFO com.heu.test.CountDownLatchTest - t3 start ...17:18:13.592 [t1] INFO com.heu.test.CountDownLatchTest - t1 end ...17:18:14.098 [t3] INFO com.heu.test.CountDownLatchTest - t3 end ...17:18:14.590 [t2] INFO com.heu.test.CountDownLatchTest - t2 end ...17:18:14.590 [main] INFO com.heu.test.CountDownLatchTest - main wait end ...</code></pre><blockquote><p>method2 输出：</p></blockquote><pre><code class="bash">17:23:07.829 [pool-1-thread-4] INFO com.heu.test.CountDownLatchTest - main wait...17:23:07.829 [pool-1-thread-2] INFO com.heu.test.CountDownLatchTest - t2 start ...17:23:07.829 [pool-1-thread-3] INFO com.heu.test.CountDownLatchTest - t3 start ...17:23:07.829 [pool-1-thread-1] INFO com.heu.test.CountDownLatchTest - t1 start ...17:23:08.854 [pool-1-thread-1] INFO com.heu.test.CountDownLatchTest - t1 end ...217:23:09.344 [pool-1-thread-3] INFO com.heu.test.CountDownLatchTest - t3 end ...217:23:09.851 [pool-1-thread-2] INFO com.heu.test.CountDownLatchTest - t2 end ...117:23:09.851 [pool-1-thread-4] INFO com.heu.test.CountDownLatchTest - main wait end ...&gt; method3 输出：当所有线程全部加载完毕，输出游戏开始，类似王者荣耀！```bash[100%, 100%, 100%, 100%, 100%, 100%, 100%, 100%, 100%, 100%]游戏开始</code></pre><h1 id="CyclicBarrier"><a href="#CyclicBarrier" class="headerlink" title="CyclicBarrier"></a>CyclicBarrier</h1><p><strong>CyclicBarr 循环栅栏</strong>，用来进行线程协作，等待线程满足某个计数。构造时设置『计数个数』，每个线程执行到某个需要 “同步” 的时刻调用 await () 方法进行等待，当等待的线程数满足『计数个数』时，继续执行。跟 CountdownLatch 一样，但这个可以重用。</p><pre><code class="bash">public static void main(String[] args) &#123;       ExecutorService executorService = Executors.newFixedThreadPool(2);       CyclicBarrier cyclicBarrier = new CyclicBarrier(2, () -&gt; &#123;           log.info(&quot;task2 finish ...&quot;);       &#125;);       for(int i = 0; i &lt; 3; i++) &#123;           executorService.submit(() -&gt; &#123;               log.info(&quot;task1 begin ...&quot;);               try &#123;                   Thread.sleep(1000);                   cyclicBarrier.await();               &#125; catch (InterruptedException | BrokenBarrierException e) &#123;                   e.printStackTrace();               &#125;           &#125;);           executorService.submit(() -&gt; &#123;               log.info(&quot;task2 begin ...&quot;);               try &#123;                   Thread.sleep(2000);                   cyclicBarrier.await();               &#125; catch (InterruptedException | BrokenBarrierException e) &#123;                   e.printStackTrace();               &#125;           &#125;);       &#125;       executorService.shutdown();   &#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> 多线程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ReentrantLock 原理 </tag>
            
            <tag> AQS 原理 </tag>
            
            <tag> 读写锁原理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>多线程与高并发 —JMM、Volatile、CAS</title>
      <link href="/2020/09/15/thread/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E9%AB%98%E5%B9%B6%E5%8F%91%20%E2%80%94JMM%E3%80%81Volatile%E3%80%81CAS/"/>
      <url>/2020/09/15/thread/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E9%AB%98%E5%B9%B6%E5%8F%91%20%E2%80%94JMM%E3%80%81Volatile%E3%80%81CAS/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="共享模型之内存"><a href="#共享模型之内存" class="headerlink" title="共享模型之内存"></a>共享模型之内存</h1><h2 id="Java-内存模型（JMM）"><a href="#Java-内存模型（JMM）" class="headerlink" title="Java 内存模型（JMM）"></a>Java 内存模型（JMM）</h2><p>JMM 即 Java Memory Model，它定义了主存（共享内存）、工作内存（线程私有）的抽象概念，底层对应着 CPU 寄存器、缓存、硬件内存、 CPU 指令优化等。</p><p>JMM 体现在以下几个方面：</p><ul><li>原子性 - 保证指令不会受到线程上下文切换的影响。</li><li>可见性 - 保证指令不会受 cpu 缓存的影响。</li><li>有序性 - 保证指令不会受 cpu 指令并行优化的影响。</li></ul><h2 id="可见性"><a href="#可见性" class="headerlink" title="可见性"></a>可见性</h2><h3 id="退不出的循环"><a href="#退不出的循环" class="headerlink" title="退不出的循环"></a>退不出的循环</h3><p>先来看一个现象，main 线程对 run 变量的修改对于 t 线程不可见，导致了 t 线程无法停止：</p><pre><code>public static boolean run = true;    public static void main(String[] args) &#123;        Thread t1 = new Thread(() -&gt; &#123;            while(run) &#123;            &#125;        &#125;, &quot;t1&quot;);        t1.start();        try &#123;            Thread.sleep(1000);        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;        log.info(&quot;t1 Stop&quot;);        run = false;    &#125;</code></pre><p>为什么呢？分析一下：</p><ol><li><p>初始状态， t 线程刚开始从主内存读取了 run 的值到工作内存。</p></li><li><p>因为 t 线程要频繁从主内存中读取 run 的值，JIT 编译器会将 run 的值缓存至自己工作内存中的高速缓存中，减少对主存中 run 的访问，提高效率。</p></li><li><p>1 秒之后，main 线程修改了 run 的值，并同步至主存，而 t 是从自己工作内存中的高速缓存中读取这个变量的值，结果永远是旧值。分析如下：</p></li></ol><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210608104021476.png"><br><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210608104045387.png"></p><p><strong>解决方法</strong></p><ul><li><p>使用 volatile （易变关键字）</p></li><li><p>它可以用来修饰成员变量和静态成员变量（放在主存中的变量），可以避免线程从自己的工作缓存中查找变量的值，而必须到主存中获取它的值，线程操作 volatile 变量都是直接操作主存。</p></li></ul><h3 id="可见性-vs-原子性"><a href="#可见性-vs-原子性" class="headerlink" title="可见性 vs 原子性"></a>可见性 vs 原子性</h3><p>上面例子体现的实际上就是可见性，它保证的是在多个线程之间，一个线程对 volatile 变量的修改对另一个线程可见，但不能保证原子性，仅用在一个写线程，多个读线程的情况。</p><ul><li><p>synchronized 语句块既可以保证代码块的原子性，也同时保证代码块内变量的可见性。但缺点是 synchronized 是属于重量级操作，性能相对更低。</p></li><li><p>如果在前面示例的死循环中加入 System.out.println () 会发现即使不加 volatile 修饰符，线程 t 也能正确看到 对 run 变量的修改了。因为 printIn () 方法使用了 synchronized 同步代码块，可以保证原子性与可见性，它是 PrintStream 类的方法。</p></li></ul><h2 id="CPU-缓存结构原理"><a href="#CPU-缓存结构原理" class="headerlink" title="CPU 缓存结构原理"></a>CPU 缓存结构原理</h2><h3 id="CPU-缓存结构"><a href="#CPU-缓存结构" class="headerlink" title="CPU 缓存结构"></a>CPU 缓存结构</h3><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210608110939298.png"></p><p><strong>速度比较</strong></p><table><thead><tr><th>从 cpu 到</th><th align="right">大约需要的时钟周期</th></tr></thead><tbody><tr><td>寄存器</td><td align="right">1 cycle</td></tr><tr><td>L1</td><td align="right">3~4 cycle</td></tr><tr><td>L2</td><td align="right">10~20 cycle</td></tr><tr><td>L3</td><td align="right">40~45 cycle</td></tr><tr><td>内存</td><td align="right">20~240 cycle</td></tr></tbody></table><p><strong>cpu 拿到的内存地址格式是这样的</strong></p><pre><code>[高位组标记][低位索引][偏移量]</code></pre><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210608111443605.png"></p><h3 id="CPU-缓存读"><a href="#CPU-缓存读" class="headerlink" title="CPU 缓存读"></a>CPU 缓存读</h3><p>读取数据流程如下：</p><ul><li>根据低位，计算在缓存中的索引；</li><li>判断是否有效：<ul><li>0 去内存读取新数据更新缓存行；</li><li>1 再对比高位组标记是否一致：<ul><li>一致，根据偏移量返回缓存数据；</li><li>不一致，去内存读取新数据更新缓存行。</li></ul></li></ul></li></ul><h3 id="内存屏障"><a href="#内存屏障" class="headerlink" title="内存屏障"></a>内存屏障</h3><ul><li><p>可见性</p><ul><li>写屏障（sfence）保证在该屏障之前的，对共享变量的改动，都同步到主存当中。</li><li>而读屏障（lfence）保证在该屏障之后，对共享变量的读取，加载的是主存中最新数据。</li></ul></li><li><p>有序性</p><ul><li>写屏障会确保指令重排序时，不会将写屏障之前的代码排在写屏障之后。</li><li>读屏障会确保指令重排序时，不会将读屏障之后的代码排在读屏障之前。</li></ul></li></ul><h2 id="模式之两阶段终止"><a href="#模式之两阶段终止" class="headerlink" title="模式之两阶段终止"></a>模式之两阶段终止</h2><p>使用 volatile 关键字来实现两阶段终止模式：</p><pre><code>public class Test &#123;    public static void main(String[] args) throws InterruptedException &#123;        Monitor monitor = new Monitor();        monitor.start();        Thread.sleep(3500);        monitor.stop();    &#125;&#125;class Monitor &#123;    Thread monitor;    // 设置标记，用于判断是否被终止了    private volatile boolean stop = false;    /**     * 启动监控器线程     */    public void start() &#123;        // 设置线控器线程，用于监控线程状态        monitor = new Thread() &#123;            @Override            public void run() &#123;                // 开始不停的监控                while (true) &#123;                    if(stop) &#123;                        System.out.println(&quot;处理后续任务&quot;);                        break;                    &#125;                    System.out.println(&quot;监控器运行中...&quot;);                    try &#123;                        // 线程休眠                        Thread.sleep(1000);                    &#125; catch (InterruptedException e) &#123;                        System.out.println(&quot;被打断了&quot;);                    &#125;                &#125;            &#125;        &#125;;        monitor.start();    &#125;    /**     *     用于停止监控器线程     */    public void stop() &#123;        // 修改标记        stop = true;        // 打断线程        monitor.interrupt();            &#125;&#125;</code></pre><h2 id="同步模式之-Balking"><a href="#同步模式之-Balking" class="headerlink" title="同步模式之 Balking"></a>同步模式之 Balking</h2><p>Balking （犹豫）模式用在一个线程发现另一个线程或本线程已经做了某一件相同的事，那么本线程就无需再做 了，直接结束返回，有点类似单例。</p><ul><li>用一个标记来判断该任务是否已经被执行过了；</li><li>需要避免线程安全问题；</li><li>加锁的代码块要尽量的小，以保证性能。</li></ul><pre><code>public class TestBalking &#123;    public static void main(String[] args) throws InterruptedException &#123;        Monitor monitor = new Monitor();        monitor.start();        monitor.start();        Thread.sleep(3500);        monitor.stop();    &#125;&#125;class Monitor &#123;    Thread monitor;    private volatile boolean stop = false;    private boolean starting = false;    public void start() &#123;        synchronized (this) &#123;            if (starting) &#123;                return;            &#125;            starting = true;        &#125;        monitor = new Thread() &#123;            @Override            public void run() &#123;                while (true) &#123;                    if (stop) &#123;                        System.out.println(&quot;处理后续任务&quot;);                        break;                    &#125;                    System.out.println(&quot;监控运行中&quot;);                    try &#123;                        Thread.sleep(1000);                    &#125; catch (InterruptedException e) &#123;                        System.out.println(&quot;被打断了&quot;);                    &#125;                &#125;            &#125;        &#125;;        monitor.start();    &#125;    public void stop() &#123;        monitor.interrupt();        stop = true;    &#125;&#125;</code></pre><p>输出：</p><pre><code>监控运行中监控运行中监控运行中监控运行中被打断了处理后续任务</code></pre><h2 id="有序性"><a href="#有序性" class="headerlink" title="有序性"></a>有序性</h2><p><strong>指令重排</strong></p><p>JVM 会在不影响正确性的前提下，可以调整语句的执行顺序，思考下面一段代码：</p><pre><code>static int i;static int j;// 在某个线程内执行如下赋值操作i = ...; j = ...;</code></pre><p>可以看到，至于是先执行 i 还是 先执行 j ，对最终的结果不会产生影响。所以，上面代码真正执行时，既可以是：</p><pre><code>i = ...; j = ...;</code></pre><p>也可以是：</p><pre><code>j = ...;i = ...; </code></pre><p>这种特性称之为『指令重排』，多线程下『指令重排』会影响正确性。</p><p>下面看一段代码：</p><pre><code>int num = 0;// volatile 修饰的变量，可以禁用指令重排 volatile boolean ready = false; 可以防止变量之前的代码被重排序boolean ready = false; // 线程1 执行此方法public void actor1(I_Result r) &#123; if(ready) &#123;     r.r1 = num + num; &#125;  else &#123;     r.r1 = 1; &#125;&#125;// 线程2 执行此方法public void actor2(I_Result r) &#123; num = 2; ready = true;&#125;</code></pre><p>在多线程环境下，以上的代码 r1 的值有三种情况：</p><ul><li>第一种：线程 2 先执行，然后线程 1 后执行，r1 的结果为 4；</li><li>第二种：线程 1 先执行，然后线程 2 后执行，r1 的结果为 1；</li><li>第三种：线程 2 先执行，但是发生了指令重排，num = 2 与 ready = true 这两行代码语序发生交换，然后执行 ready = true 后，线程 1 运行了，那么 r1 的结果是为 0。</li></ul><p><strong>解决方法</strong></p><p>volatile 修饰的变量，可以禁用指令重排。</p><h1 id="volatile-原理"><a href="#volatile-原理" class="headerlink" title="volatile 原理"></a>volatile 原理</h1><p>volatile 的底层实现原理是<strong>内存屏障</strong>，Memory Barrier（Memory Fence）</p><ul><li>对 volatile 变量的写指令后会加入写屏障。</li><li>对 volatile 变量的读指令前会加入读屏障。</li></ul><h3 id="如何保证可见性"><a href="#如何保证可见性" class="headerlink" title="如何保证可见性"></a>如何保证可见性</h3><ul><li>写屏障（sfence）保证在该屏障之前的，对共享变量的改动，都同步到主存中。</li></ul><pre><code>public void actor2(I_Result r) &#123;     num = 2;     ready = true; // ready 是被 volatile 修饰的，赋值带写屏障     // 写屏障&#125;</code></pre><ul><li>而读屏障（lfence）保证在该屏障之后，对共享变量的读取，加载的是主存中最新数据。</li></ul><pre><code>public void actor1(I_Result r) &#123; // 读屏障 // ready是被 volatile 修饰的，读取值带读屏障     if(ready) &#123;     r.r1 = num + num;     &#125; else &#123;         r.r1 = 1;     &#125;&#125;</code></pre><p>分析如图：</p><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/20210202154154463.png"></p><h3 id="如何保证有序性"><a href="#如何保证有序性" class="headerlink" title="如何保证有序性"></a>如何保证有序性</h3><ul><li>写屏障会确保指令重排时，不会将写屏障之前的代码排在写屏障之后。</li><li>读屏障会确保指令重排时，不会将读屏障之后的代码排在读屏障之前。</li></ul><p>volatile 不能解决指令交错，写屏障仅仅是保证之后的读能够读到最新的结果，但不能保证其它线程的读跑到它前面去。<br>而有序性的保证也只是保证了本线程内相关代码不被重排序。</p><h3 id="double-checked-locking-问题"><a href="#double-checked-locking-问题" class="headerlink" title="double-checked locking 问题"></a>double-checked locking 问题</h3><pre><code>   // 最开始的单例模式是这样的   public final class Singleton &#123;       private Singleton() &#123;        &#125;       private static Singleton INSTANCE = null;              public static Singleton getInstance() &#123;                 // 首次访问会同步，而之后的使用不用进入synchronized           synchronized(Singleton.class) &#123;               if (INSTANCE == null) &#123; // t1                   INSTANCE = new Singleton();               &#125;           &#125;         return INSTANCE;       &#125;   &#125;    // 但是上面的代码块的效率是有问题的，因为即使已经产生了单实例之后，之后调用了getInstance()方法之后还是会加锁，这会严重影响     性能！因此就有了模式如下double-checked locking    public final class Singleton &#123;        private Singleton() &#123;         &#125;        private static Singleton INSTANCE = null;                public static Singleton getInstance() &#123;            if(INSTANCE == null) &#123; // t2                // 首次访问会同步，而之后的使用没有 synchronized                synchronized(Singleton.class) &#123;                    if (INSTANCE == null) &#123; // t1                        INSTANCE = new Singleton();                    &#125;                &#125;            &#125;            return INSTANCE;        &#125;    &#125;//但是上面的if(INSTANCE == null)判断代码没有在同步代码块synchronized中，不能享有synchronized保证的原子性，可见性。</code></pre><p>以上的实现特点是：</p><ul><li>懒惰实例化</li><li>首次使用 getInstance () 才使用 synchronized 加锁，后续使用时无需加锁。</li><li>有隐含的，但很关键的一点：第一个 if 使用了 INSTANCE 变量，是在同步块之外。</li></ul><p>但在多线程环境下，上面的代码是有问题的，getInstance 方法对应的字节码为：</p><pre><code>0: getstatic #2 // Field INSTANCE:com/heu/n5/Singleton;3: ifnonnull 37// ldc是获得类对象6: ldc #3 // class com/heu/n5/Singleton// 复制操作数栈栈顶的值放入栈顶, 将类对象的引用地址复制了一份8: dup// 操作数栈栈顶的值弹出，即将对象的引用地址存到局部变量表中// 将类对象的引用地址存储了一份，是为了将来解锁用9: astore_010: monitorenter11: getstatic #2 // Field INSTANCE:com/heu/n5/Singleton;14: ifnonnull 27// 新建一个实例17: new #3 // class com/heu/n5/Singleton// 复制了一个实例的引用20: dup// 通过这个复制的引用调用它的构造方法21: invokespecial #4 // Method &quot;&lt;init&gt;&quot;:()V// 最开始的这个引用用来进行赋值操作24: putstatic #2 // Field INSTANCE:com/heu/n5/Singleton;27: aload_028: monitorexit29: goto 3732: astore_133: aload_034: monitorexit35: aload_136: athrow37: getstatic #2 // Field INSTANCE:com/heu/n5/Singleton;40: areturn</code></pre><p>其中：</p><ul><li>17 表示创建对象，将对象引用入栈 //new Singleton。</li><li>20 表示复制一份对象引用 // 复制了引用地址。</li><li>21 表示利用一个对象引用，调用构造方法 // 根据复制的引用地址调用构造方法。</li><li>24 表示利用一个对象引用，赋值给 static INSTANCE。</li></ul><p>也许 jvm 会优化为：先执行 24，再执行 21。如果两个线程 t1，t2 按如下时间序列执行：</p><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/20210202172322592.png"></p><p>关键在于 0: getstatic 这行代码在 monitor 控制之外，可以越过 monitor 读取 INSTANCE 变量的值，这时 t1 还未完全将构造方法执行完毕，如果在构造方法中要执行很多初始化操作，那么 t2 拿到的将是一个未初始化完毕的单例，解决方法是对 INSTANCE 使用 volatile 修饰即可，可以禁用指令重排，但要注意在 JDK 5 以上的版本的 volatile 才会真正有效。</p><h3 id="double-checked-locking-解决"><a href="#double-checked-locking-解决" class="headerlink" title="double-checked locking 解决"></a>double-checked locking 解决</h3><p><strong>加上 volatile 就行了</strong></p><pre><code>public final class Singleton &#123;        private Singleton() &#123; &#125;        private static volatile Singleton INSTANCE = null;        public static Singleton getInstance() &#123;            // 实例没创建，才会进入内部的 synchronized代码块            if (INSTANCE == null) &#123;                synchronized (Singleton.class) &#123; // t2                    // 也许有其它线程已经创建实例，所以再判断一次                    if (INSTANCE == null) &#123; // t1                        INSTANCE = new Singleton();                    &#125;                &#125;            &#125;            return INSTANCE;        &#125;    &#125;</code></pre><p>如上面的注释内容所示，读写 volatile 变量操作（即 getstatic 操作和 putstatic 操作）时会加入内存屏障（Memory Barrier（Memory Fence）），保证下面两点：</p><ol><li>可见性</li></ol><ul><li>写屏障（sfence）保证在该屏障之前的 t1 对共享变量的改动，都同步到主存当中。</li><li>而读屏障（lfence）保证在该屏障之后 t2 对共享变量的读取，加载的是主存中最新数据。</li></ul><ol start="2"><li>有序性</li></ol><ul><li>写屏障会确保指令重排序时，不会将写屏障之前的代码排在写屏障之后。</li><li>读屏障会确保指令重排序时，不会将读屏障之后的代码排在读屏障之前。</li></ul><h2 id="happens-before"><a href="#happens-before" class="headerlink" title="happens-before"></a>happens-before</h2><p>下面说的变量都是指成员变量或静态成员变量。</p><ol><li>线程解锁 m 之前对变量的写，对于接下来对 m 加锁的其它线程对该变量的读可见。</li></ol><pre><code>static int x;static Object m = new Object();new Thread(()-&gt;&#123;    synchronized(m) &#123;        x = 10;    &#125;&#125;,&quot;t1&quot;).start();new Thread(()-&gt;&#123;    synchronized(m) &#123;        System.out.println(x);    &#125;&#125;,&quot;t2&quot;).start();</code></pre><ol start="2"><li>线程对 volatile 变量的写，对接下来其它线程对该变量的读可见。</li></ol><pre><code>volatile static int x;new Thread(()-&gt;&#123; x = 10;&#125;,&quot;t1&quot;).start();new Thread(()-&gt;&#123; System.out.println(x);&#125;,&quot;t2&quot;).start();</code></pre><ol start="3"><li>线程 start 前对变量的写，对该线程开始后对该变量的读可见。</li></ol><pre><code>static int x;x = 10;new Thread(()-&gt;&#123; System.out.println(x);&#125;,&quot;t2&quot;).start();</code></pre><ol start="4"><li>线程结束前对变量的写，对其它线程得知它结束后的读可见（比如其它线程调用 t1.isAlive () 或 t1.join () 等待它结束）。</li></ol><pre><code>static int x;Thread t1 = new Thread(()-&gt;&#123; x = 10;&#125;,&quot;t1&quot;);t1.start();t1.join();System.out.println(x);</code></pre><ol start="5"><li>线程 t1 打断 t2（interrupt）前对变量的写，对于其他线程得知 t2 被打断后对变量的读可见（通过 t2.interrupted 或 t2.isInterrupted）。</li></ol><pre><code>static int x;    public static void main(String[] args) &#123;        Thread t2 = new Thread(()-&gt;&#123;            while(true) &#123;                if(Thread.currentThread().isInterrupted()) &#123;                    System.out.println(x);                    break;                &#125;            &#125;        &#125;,&quot;t2&quot;);        t2.start();        new Thread(()-&gt;&#123;            sleep(1);            x = 10;            t2.interrupt();        &#125;,&quot;t1&quot;).start();        while(!t2.isInterrupted()) &#123;            Thread.yield();        &#125;        System.out.println(x);    &#125;</code></pre><ol start="6"><li><p>对变量默认值（0，false，null）的写，对其它线程对该变量的读可见。</p></li><li><p>具有传递性，如果 x hb-&gt; y 并且 y hb-&gt; z 那么有 x hb-&gt; z ，配合 volatile 的防指令重排，有下面的例子：</p></li></ol><pre><code>volatile static int x;     static int y;     new Thread(() -&gt; &#123;         y = 10;         x = 20;     &#125;,&quot;t1&quot;).start();         new Thread(() -&gt; &#123;         // x=20 对 t2 可见, 同时 y=10 也对 t2 可见         System.out.println(x);     &#125;,&quot;t2&quot;).start(); </code></pre><h2 id="练习"><a href="#练习" class="headerlink" title="练习"></a>练习</h2><h3 id="balking-模式习题"><a href="#balking-模式习题" class="headerlink" title="balking 模式习题"></a>balking 模式习题</h3><p>希望 doInit () 方法仅被调用一次，下面的实现是否有问题，为什么？</p><pre><code>public class TestVolatile &#123;    volatile boolean initialized = false;    void init() &#123;        if (initialized) &#123;            return;        &#125;        doInit();        initialized = true;    &#125;    private void doInit() &#123;    &#125;&#125; </code></pre><p><strong>结论：volatile 可以保存线程的可见性，有序性，但是不能保证原子性，doInit 方法没加锁，可能会被调用多次。</strong></p><h3 id="线程安全单例习题"><a href="#线程安全单例习题" class="headerlink" title="线程安全单例习题"></a>线程安全单例习题</h3><p>单例模式有很多实现方法，饿汉、懒汉、静态内部类、枚举类，试着分析每种实现下获取单例对象（即调用 getInstance）时的线程安全，并思考注释中的问题。</p><ul><li>饿汉式：类加载就会导致该单实例对象被创建。</li><li>懒汉式：类加载不会导致该单实例对象被创建，而是首次使用该对象时才会创建。</li></ul><p><strong>实现 1： 饿汉式</strong></p><pre><code>// 问题1：为什么加 final，防止子类继承后更改// 问题2：如果实现了序列化接口, 还要做什么来防止反序列化破坏单例，如果进行反序列化的时候会生成新的对象，这样跟单例模式生成的对象是不同的。要解决直接加上readResolve()方法就行了，如下所示public final class Singleton implements Serializable &#123;    // 问题3：为什么设置为私有? 防止其它类中使用new生成新的实例，是否能防止反射创建新的实例?不能。    private Singleton() &#123;&#125;    // 问题4：这样初始化是否能保证单例对象创建时的线程安全?没有，这是类变量，是jvm在类加载阶段就进行了初始化，jvm保证了此操作的线程安全性    private static final Singleton INSTANCE = new Singleton();    // 问题5：为什么提供静态方法而不是直接将 INSTANCE 设置为 public, 说出你知道的理由。    //1.提供更好的封装性；2.提供范型的支持    public static Singleton getInstance() &#123;        return INSTANCE;    &#125;    public Object readResolve() &#123;        return INSTANCE;    &#125;&#125;</code></pre><h3 id="实现-2：-饿汉式"><a href="#实现-2：-饿汉式" class="headerlink" title="实现 2： 饿汉式"></a>实现 2： 饿汉式</h3><pre><code>// 问题1：枚举单例是如何限制实例个数的：创建枚举类的时候就已经定义好了，每个枚举常量其实就是枚举类的一个静态成员变量// 问题2：枚举单例在创建时是否有并发问题：没有，这是静态成员变量// 问题3：枚举单例能否被反射破坏单例：不能// 问题4：枚举单例能否被反序列化破坏单例：枚举类默认实现了序列化接口，枚举类已经考虑到此问题，无需担心破坏单例// 问题5：枚举单例属于懒汉式还是饿汉式：饿汉式// 问题6：枚举单例如果希望加入一些单例创建时的初始化逻辑该如何做：加构造方法就行了enum Singleton &#123; INSTANCE;&#125;</code></pre><p><strong>实现 3：懒汉式</strong></p><pre><code>public final class Singleton &#123;    private Singleton() &#123; &#125;    private static Singleton INSTANCE = null;    // 分析这里的线程安全, 并说明有什么缺点：synchronized加载静态方法上，可以保证线程安全。缺点就是锁的范围过大，每次访问都会加锁，性能比较低。    public static synchronized Singleton getInstance() &#123;        if( INSTANCE != null )&#123;            return INSTANCE;        &#125;        INSTANCE = new Singleton();        return INSTANCE;    &#125;&#125;</code></pre><p><strong>实现 4：DCL 懒汉式</strong></p><pre><code>public final class Singleton &#123;    private Singleton() &#123; &#125;    // 问题1：解释为什么要加 volatile ?为了防止重排序问题    private static volatile Singleton INSTANCE = null;    // 问题2：对比实现3, 说出这样做的意义：提高了效率    public static Singleton getInstance() &#123;        if (INSTANCE != null) &#123;            return INSTANCE;        &#125;        synchronized (Singleton.class) &#123;            // 问题3：为什么还要在这里加为空判断, 之前不是判断过了吗？这是为了第一次判断时的并发问题。            if (INSTANCE != null) &#123; // t2                return INSTANCE;            &#125;            INSTANCE = new Singleton();            return INSTANCE;        &#125;    &#125;&#125;</code></pre><p><strong>实现 5：静态内部类懒汉式</strong></p><pre><code>public final class Singleton &#123;    private Singleton() &#123; &#125;    // 问题1：属于懒汉式还是饿汉式：懒汉式，这是一个静态内部类。类加载本身就是懒惰的，在没有调用getInstance方法时是没有执行       //LazyHolder内部类的类加载操作的。    private static class LazyHolder &#123;        static final Singleton INSTANCE = new Singleton();    &#125;    // 问题2：在创建时是否有并发问题，这是线程安全的，类加载时，jvm保证类加载操作的线程安全    public static Singleton getInstance() &#123;        return LazyHolder.INSTANCE;    &#125;&#125;</code></pre><h1 id="共享模型之无锁"><a href="#共享模型之无锁" class="headerlink" title="共享模型之无锁"></a>共享模型之无锁</h1><h2 id="无锁解决线程安全问题"><a href="#无锁解决线程安全问题" class="headerlink" title="无锁解决线程安全问题"></a>无锁解决线程安全问题</h2><h3 id="问题提出"><a href="#问题提出" class="headerlink" title="问题提出"></a>问题提出</h3><p>有如下需求，保证 account.withdraw 取款方法的线程安全，先看一个线程不安全的情况：</p><pre><code>public class TestCAS &#123;    public static void main(String[] args) &#123;        Account.demo(new AccountUnsafe(10000));    &#125;&#125;interface Account&#123;    //获取余额    Integer getBalance();    //取款    void withdraw(Integer amount);    /**     * 方法内会启动 1000 个线程，每个线程做 -10 元 的操作     * 如果初始余额为 10000 那么正确的结果应当是 0     */    static void demo(Account account) &#123;        List&lt;Thread&gt; ts = new ArrayList&lt;&gt;();        long start = System.nanoTime();        for (int i = 0; i &lt; 1000; i++) &#123;            ts.add(new Thread(()-&gt;&#123;                account.withdraw(10);            &#125;));        &#125;        ts.forEach(Thread::start);        ts.forEach(t-&gt;&#123;            try &#123;                t.join();            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;        &#125;);        long end = System.nanoTime();        System.out.println(account.getBalance()                + &quot; cost: &quot; + (end-start)/1000_000 + &quot; ms&quot;);    &#125;&#125;class AccountUnsafe implements Account &#123;    private Integer balance;    public AccountUnsafe(Integer balance) &#123;        this.balance = balance;    &#125;    @Override    public Integer getBalance() &#123;        return balance;    &#125;    @Override    public void withdraw(Integer amount) &#123;        balance -= amount;    &#125;&#125;</code></pre><p><em>某次执行结果：</em></p><pre><code>420 cost: 151 ms</code></pre><p><strong>为什么不安全</strong></p><p>执行 withdraw 方法对应的字节码：</p><pre><code>ALOAD 0                                                     // &lt;- thisALOAD 0GETFIELD com/heu/AccountUnsafe.balance : Ljava/lang/Integer; // &lt;- this.balanceINVOKEVIRTUAL java/lang/Integer.intValue ()I                 // 拆箱ALOAD 1                                                     // &lt;- amountINVOKEVIRTUAL java/lang/Integer.intValue ()I                // 拆箱ISUB                                                         // 减法INVOKESTATIC java/lang/Integer.valueOf (I)Ljava/lang/Integer; // 结果装箱PUTFIELD com/heu/AccountUnsafe.balance : Ljava/lang/Integer;     // -&gt; this.balance</code></pre><ul><li><p>单核的指令交错</p></li><li><p>多核的指令交错</p></li></ul><h3 id="解决思路-—-锁"><a href="#解决思路-—-锁" class="headerlink" title="解决思路 — 锁"></a>解决思路 — 锁</h3><p>首先想到的是给 Account 对象加锁：</p><pre><code>class AccountUnsafe implements Account &#123;    private Integer balance;    public AccountUnsafe(Integer balance) &#123;        this.balance = balance;    &#125;    @Override    public synchronized Integer getBalance() &#123;        return balance;    &#125;    @Override    public synchronized void withdraw(Integer amount) &#123;        balance -= amount;    &#125;&#125;</code></pre><p>结果为：</p><pre><code>0 cost: 231 ms</code></pre><p>如上代码加锁会造成线程堵塞，堵塞的时间取决于临界区代码执行的时间，这使用加锁的性能不高，因此可以使用无锁来解决此问题。</p><h3 id="解决思路-—-无锁"><a href="#解决思路-—-无锁" class="headerlink" title="解决思路 — 无锁"></a>解决思路 — 无锁</h3><pre><code>class AccountUnsafe implements Account &#123;    AtomicInteger atomicInteger;    public AccountUnsafe(Integer balance) &#123;        this.atomicInteger = new AtomicInteger(balance);    &#125;    @Override    public Integer getBalance() &#123;        return atomicInteger.get();    &#125;    @Override    public void withdraw(Integer amount) &#123;        while (true) &#123;            Integer pre = getBalance();            int next = pre - amount;            //如果当前值等于参数给定的期望值，则将值设置为参数中的传递值。该函数返回一个布尔值，该布尔值使我们了解更新是否完成.            //compareAndSet方法实际上是做了两步操作，第一步是比较，第二步是把value的值更新，这两步是原子操作，在没有多线程锁的情况下，借助cpu锁保证数据安全。            if (atomicInteger.compareAndSet(pre, next)) &#123;                break;            &#125;        &#125;    &#125;&#125;</code></pre><p>输出：</p><pre><code>0 cost: 213 ms</code></pre><h2 id="CAS-与-volatile"><a href="#CAS-与-volatile" class="headerlink" title="CAS 与 volatile"></a>CAS 与 volatile</h2><h3 id="CAS"><a href="#CAS" class="headerlink" title="CAS"></a>CAS</h3><p>前面看到的 AtomicInteger 的解决方法，内部并没有用锁来保护共享变量的线程安全。那么它是如何实现的呢？</p><pre><code>public void withdraw(Integer amount) &#123;        // 需要不断尝试，直到成功为止        while (true) &#123;            // 比如拿到了旧值 1000            Integer pre = getBalance();            // 在这个基础上 1000-10 = 990            int next = pre - amount;           /*             compareAndSet 正是做这个检查，在 set 前，先比较 prev 与当前值：             - 不一致了，next 作废，返回 false 表示失败比如，别的线程已经做了减法，当前值已经被减成了 990，那么本线程的这次             990 就作废了，进入 while 下次循环重试；            - 一致，以 next 设置为新值，返回 true 表示成功 。           */            if (atomicInteger.compareAndSet(pre, next)) &#123;                break;            &#125;        &#125;    &#125;</code></pre><p>其中的关键是 compareAndSet，它的简称就是 CAS （也有 Compare And Swap 的说法），它必须是原子操作。</p><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/20210202215325496.png"></p><p>当一个线程要去修改 Account 对象中的值时，先获取值 preVal（调用 get 方法），然后再将其设置为新的值 nextVal（调用 cas 方法）。在调用 cas 方法时，会将 pre 与 Account 中的余额进行比较：</p><ul><li>如果两者相等，就说明该值还未被其他线程修改，此时便可以进行修改操作。</li><li>如果两者不相等，就不设置值，重新获取值 preVal（调用 get 方法），然后再将其设置为新的值 nextVal（调用 cas 方法），直到修改成功为止。</li></ul><p><strong>注意：</strong></p><ul><li><p>CAS 的底层是 lock cmpxchg 指令（X86 架构），在单核 CPU 和多核 CPU 下都能够保证【比较 - 交换】的原子性。</p></li><li><p>在多核状态下，某个核执行到带 lock 的指令时，CPU 会让总线锁住，当这个核把此指令执行完毕，再开启总线。这个过程中不会被线程的调度机制所打断，保证了多个线程对内存操作的准确性，是原子的 。</p></li></ul><h3 id="volatile"><a href="#volatile" class="headerlink" title="volatile"></a>volatile</h3><ul><li><p>获取共享变量时，为了保证该变量的可见性，需要使用 volatile 修饰。</p></li><li><p>它可以用来修饰成员变量和静态成员变量，可以避免线程从自己的工作缓存中查找变量的值，保证其必须到主存中获取变量的值。</p></li><li><p>线程操作 volatile 变量都是直接操作主存。即一个线程对 volatile 变量的修改，对另一个线程可见。</p></li><li><p>volatile 仅仅保证了共享变量的可见性，让其它线程能够看到新值，但不能解决指令交错问题（不能保证原子性）。</p></li><li><p>CAS 是原子性操作借助 volatile 读取到共享变量的新值来实现【比较并交换】的效果。</p></li></ul><h3 id="为什么无锁效率高"><a href="#为什么无锁效率高" class="headerlink" title="为什么无锁效率高"></a>为什么无锁效率高</h3><ul><li><p>无锁情况下，即使重试失败，线程始终在高速运行，没有停歇，而 synchronized 会让线程在没有获得锁的时候，发生上下文切换，进入阻塞。</p></li><li><p>打个比喻：线程就好像高速跑道上的赛车，高速运行时，速度超快，一旦发生上下文切换，就好比赛车要减速、熄火，等被唤醒又得重新打火、启动、加速… 恢复到高速运行，代价比较大。</p></li><li><p>但无锁情况下，因为线程要保持运行，需要额外 CPU 的支持，CPU 在这里就好比高速跑道，没有额外的跑道，线程想高速运行也无从谈起，虽然不会进入阻塞，但由于没有分到时间片，仍然会进入可运行状态，还是会导致上下文切换。</p></li></ul><h3 id="CAS-的特点"><a href="#CAS-的特点" class="headerlink" title="CAS 的特点"></a>CAS 的特点</h3><p>结合 CAS 和 volatile 可以实现无锁并发，适用于线程数少、多核 CPU 的场景下。</p><ul><li><p>CAS 是基于乐观锁的思想：最乐观的估计，不怕别的线程来修改共享变量，就算改了也没关系，吃亏点再重试呗。</p></li><li><p>synchronized 是基于悲观锁的思想：最悲观的估计，得防着其它线程来修改共享变量，我上了锁你们都别想改，我改完了解开锁，你们才有机会。</p></li><li><p>CAS 体现的是无锁并发、无阻塞并发，请仔细体会这两句话的意思。</p><ul><li>因为没有使用 synchronized，所以线程不会陷入阻塞，这是效率提升的因素之一。</li><li>但如果竞争激烈 (写操作多)，可以想到重试必然频繁发生，反而效率会受影响。</li></ul></li></ul><h2 id="原子整数"><a href="#原子整数" class="headerlink" title="原子整数"></a>原子整数</h2><p>java.util.concurrent.atomic 并发包提供了一些并发工具类，这里把它分成五类，分别是：</p><ul><li>原子类<ul><li>AtomicInteger：整型原子类</li><li>AtomicLong：长整型原子类</li><li>AtomicBoolean ：布尔型原子类</li></ul></li><li>原子引用</li><li>原子数组</li><li>字段更新器</li><li>原子累加器</li></ul><p>下面先讨论原子整数类，以 AtomicInteger 为例讨论它的 api 接口：通过观察源码可以发现，AtomicInteger 内部是通过 cas 的原理来实现的。上面三个原子类提供的方法几乎相同，所以我们将以 AtomicInteger 为例子进行说明：</p><pre><code>public static void main(String[] args) &#123;        AtomicInteger i = new AtomicInteger(0);        // 获取并自增（i = 0, 结果 i = 1, 返回 0），类似于 i++        System.out.println(i.getAndIncrement());        // 自增并获取（i = 1, 结果 i = 2, 返回 2），类似于 ++i        System.out.println(i.incrementAndGet());        // 自减并获取（i = 2, 结果 i = 1, 返回 1），类似于 --i        System.out.println(i.decrementAndGet());        // 获取并自减（i = 1, 结果 i = 0, 返回 1），类似于 i--        System.out.println(i.getAndDecrement());        // 获取并加值（i = 0, 结果 i = 5, 返回 0）        System.out.println(i.getAndAdd(5));        // 加值并获取（i = 5, 结果 i = 0, 返回 0）        System.out.println(i.addAndGet(-5));        // 获取并更新（i = 0, p 为 i 的当前值, 结果 i = -2, 返回 0）        // 函数式编程接口，其中函数中的操作能保证原子，但函数需要无副作用        System.out.println(i.getAndUpdate(p -&gt; p - 2));        // 更新并获取（i = -2, p 为 i 的当前值, 结果 i = 0, 返回 0）        // 函数式编程接口，其中函数中的操作能保证原子，但函数需要无副作用        System.out.println(i.updateAndGet(p -&gt; p + 2));        // 获取并计算（i = 0, p 为 i 的当前值, x 为参数1, 结果 i = 10, 返回 0）        // 函数式编程接口，其中函数中的操作能保证原子，但函数需要无副作用        // getAndUpdate 如果在 lambda 中引用了外部的局部变量，要保证该局部变量是 final 的        // getAndAccumulate 可以通过 参数1 来引用外部的局部变量，但因为其不在 lambda 中因此不必是 final        System.out.println(i.getAndAccumulate(10, (p, x) -&gt; p + x));        // 计算并获取（i = 10, p 为 i 的当前值, x 为参数1值, 结果 i = 0, 返回 0）        // 函数式编程接口，其中函数中的操作能保证原子，但函数需要无副作用        System.out.println(i.accumulateAndGet(-10, (p, x) -&gt; p + x));    &#125;</code></pre><h2 id="原子引用"><a href="#原子引用" class="headerlink" title="原子引用"></a>原子引用</h2><p><strong>为什么需要原子引用类型？</strong></p><p>保证引用类型的共享变量是线程安全的（确保这个原子引用没有引用过别人）。基本类型原子类只能更新一个变量，如果需要原子更新多个变量，需要使用引用类型原子类。</p><p>原子引用：</p><ul><li><p>AtomicReference：引用类型原子类。</p></li><li><p>AtomicStampedReference：原子更新带有版本号的引用类型，该类将整数值与引用关联起来，可以解决使用 CAS 进行原子更新时可能出现的 ABA 问题。</p></li><li><p>AtomicMarkableReference ：原子更新带有标记的引用类型。该类将 boolean 标记与引用关联起来。</p></li></ul><h3 id="AtomicReference"><a href="#AtomicReference" class="headerlink" title="AtomicReference"></a>AtomicReference</h3><p>还是上面取款的案例，试着提供不同的 DecimalAccount 实现，实现安全的取款操作。</p><p><strong>不安全实现</strong></p><pre><code>class DecimalAccountUnsafe implements DecimalAccount &#123;    BigDecimal balance;    public DecimalAccountUnsafe(BigDecimal balance) &#123;        this.balance = balance;    &#125;    @Override    public BigDecimal getBalance() &#123;        return balance;    &#125;    // 取款任务    @Override    public void withdraw(BigDecimal amount) &#123;        BigDecimal balance = this.getBalance();        this.balance = balance.subtract(amount);    &#125;&#125;</code></pre><p>当执行 withdraw 方法时，可能会有线程安全问题，我们可以加锁解决或者是使用无锁的方式 CAS 来解决，这里的解决方式是用 AtomicReference 原子引用解决。</p><pre><code>class DecimalAccountCas implements DecimalAccount &#123;    private AtomicReference&lt;BigDecimal&gt; balance;    public DecimalAccountCas(BigDecimal balance) &#123;        this.balance = new AtomicReference&lt;&gt;(balance);    &#125;    @Override    public BigDecimal getBalance() &#123;        return balance.get();    &#125;    @Override    public void withdraw(BigDecimal amount) &#123;        while (true) &#123;            BigDecimal preVal = balance.get();            BigDecimal nextVal = preVal.subtract(amount);            if(balance.compareAndSet(preVal, nextVal)) &#123;                break;            &#125;        &#125;    &#125;&#125;</code></pre><h3 id="ABA-问题"><a href="#ABA-问题" class="headerlink" title="ABA 问题"></a>ABA 问题</h3><pre><code>public static AtomicReference&lt;String&gt; ref = new AtomicReference&lt;&gt;(&quot;A&quot;);    public static void main(String[] args) throws InterruptedException &#123;        log.debug(&quot;main start...&quot;);        String preVal = ref.get();        other();        TimeUnit.SECONDS.sleep(1);        log.debug(&quot;change A-&gt;C &#123;&#125;&quot;, ref.compareAndSet(preVal, &quot;C&quot;));    &#125;    private static void other() throws InterruptedException &#123;        new Thread(() -&gt; &#123;            log.debug(&quot;change A-&gt;B &#123;&#125;&quot;, ref.compareAndSet(ref.get(), &quot;B&quot;));        &#125;, &quot;t1&quot;).start();        TimeUnit.SECONDS.sleep(1);        new Thread(() -&gt; &#123;            log.debug(&quot;change B-&gt;A &#123;&#125;&quot;, ref.compareAndSet(ref.get(), &quot;A&quot;));        &#125;, &quot;t2&quot;).start();    &#125;</code></pre><blockquote><p>主线程仅能判断出共享变量的值与最初值 A 是否相同，不能感知到这种从 A 改为 B 又改回 A 的情况，如果主线程希望只要有其它线程【动过了】共享变量，那么自己的 cas 就算失败的话，这时，仅比较值是不够的，需要再加一个版本号。使用 AtomicStampedReference 来解决。</p></blockquote><h3 id="AtomicStampedReference"><a href="#AtomicStampedReference" class="headerlink" title="AtomicStampedReference"></a>AtomicStampedReference</h3><blockquote><p>使用 AtomicStampedReference 加 stamp （版本号或者时间戳）的方式解决 ABA 问题。代码如下：</p></blockquote><pre><code>public class TestAtomicStampedReference &#123;    public static AtomicStampedReference&lt;String&gt; ref = new AtomicStampedReference&lt;&gt;(&quot;A&quot;, 0);    public static void main(String[] args) throws InterruptedException &#123;        log.debug(&quot;main start...&quot;);        String preVal = ref.getReference();        int stamp = ref.getStamp();        log.info(&quot;main 拿到的版本号 &#123;&#125;&quot;,stamp);        other();        TimeUnit.SECONDS.sleep(1);        log.info(&quot;修改后的版本号 &#123;&#125;&quot;,ref.getStamp());        log.info(&quot;change A-&gt;C:&#123;&#125;&quot;, ref.compareAndSet(preVal, &quot;C&quot;, stamp, stamp + 1));    &#125;    private static void other() throws InterruptedException &#123;        new Thread(() -&gt; &#123;            int stamp = ref.getStamp();            log.info(&quot;&#123;&#125;&quot;,stamp);            log.info(&quot;change A-&gt;B:&#123;&#125;&quot;, ref.compareAndSet(ref.getReference(), &quot;B&quot;, stamp, stamp + 1));        &#125;).start();        TimeUnit.SECONDS.sleep(1);        new Thread(() -&gt; &#123;            int stamp = ref.getStamp();            log.info(&quot;&#123;&#125;&quot;,stamp);            log.debug(&quot;change B-&gt;A:&#123;&#125;&quot;, ref.compareAndSet(ref.getReference(), &quot;A&quot;,stamp,stamp + 1));        &#125;).start();    &#125;&#125;</code></pre><p>输出：</p><pre><code>16:48:22.772 [main] DEBUG com.heu.test.TestAtomicStampedReference - main start...16:48:22.782 [main] INFO com.heu.test.TestAtomicStampedReference - main 拿到的版本号 016:48:22.788 [Thread-0] INFO com.heu.test.TestAtomicStampedReference - 016:48:22.788 [Thread-0] INFO com.heu.test.TestAtomicStampedReference - change A-&gt;B:true16:48:23.792 [Thread-1] INFO com.heu.test.TestAtomicStampedReference - 116:48:23.792 [Thread-1] DEBUG com.heu.test.TestAtomicStampedReference - change B-&gt;A:true16:48:24.793 [main] INFO com.heu.test.TestAtomicStampedReference - 修改后的版本号 216:48:24.793 [main] INFO com.heu.test.TestAtomicStampedReference - change A-&gt;C:false</code></pre><h3 id="AtomicMarkableReference"><a href="#AtomicMarkableReference" class="headerlink" title="AtomicMarkableReference"></a>AtomicMarkableReference</h3><ul><li><strong>AtomicStampedReference <strong>可以给原子引用加上</strong>版本号</strong>，追踪原子引用整个的变化过程，如：A -&gt; B -&gt; A -&gt;C，通过 AtomicStampedReference 可以知道，引用变量中途被更改了几次。但是有时候，并不关心引用变量更改了几次，只是单纯的关心是否更改过，所以就有了 AtomicMarkableReference 。</li></ul><h2 id="原子数组"><a href="#原子数组" class="headerlink" title="原子数组"></a>原子数组</h2><p>使用原子的方式更新数组里的某个元素：</p><ul><li>AtomicIntegerArray：整形数组原子类</li><li>AtomicLongArray：长整形数组原子类</li><li>AtomicReferenceArray ：引用类型数组原子类</li></ul><p>使用原子数组可以保证元素的线程安全。</p><p>上面三个类提供的方法几乎相同，所以这里以 AtomicIntegerArray 为例子来介绍，代码如下：</p><pre><code>public class TestAtomicIntegerArray &#123;    public static void main(String[] args) &#123;                //不安全的数组        demo(                ()-&gt;new int[10],                (array)-&gt;array.length,                (array, index) -&gt; array[index]++,                array-&gt; System.out.println(Arrays.toString(array))        );                //安全的数组        demo(                ()-&gt;new AtomicIntegerArray(10),                (array) -&gt; array.length(),                (array, index) -&gt; array.getAndIncrement(index),                (array) -&gt; System.out.println(array)        );            &#125;    private static &lt;T&gt; void demo(        Supplier&lt;T&gt; arraySupplier,        Function&lt;T,Integer&gt; lengthFun,        BiConsumer&lt;T,Integer&gt; putConsumer,        Consumer&lt;T&gt; printConsumer) &#123;        ArrayList&lt;Thread&gt; ts = new ArrayList&lt;&gt;();        T array = arraySupplier.get();        int length = lengthFun.apply(array);        for (int i = 0; i &lt; length; i++) &#123;            ts.add(new Thread(()-&gt;&#123;                for (int j = 0; j &lt; 10000; j++) &#123;                    putConsumer.accept(array,j%length);                &#125;            &#125;));        &#125;        ts.forEach(t-&gt;t.start());        ts.forEach(t-&gt;&#123;            try &#123;                t.join();            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;        &#125;);        printConsumer.accept(array);    &#125;&#125;</code></pre><p>输出：</p><pre><code>[9470, 9579, 9616, 9594, 9566, 9633, 9605, 9611, 9892, 9879][10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000]</code></pre><h2 id="字段更新器"><a href="#字段更新器" class="headerlink" title="字段更新器"></a>字段更新器</h2><ul><li>AtomicReferenceFieldUpdater // 域 字段</li><li>AtomicIntegerFieldUpdater</li><li>AtomicLongFieldUpdater</li></ul><p>利用字段更新器，可以针对对象的某个域（Field）进行原子操作，只能配合 volatile 修饰的字段使用，否则会出现异常。</p><pre><code>Exception in thread &quot;main&quot; java.lang.IllegalArgumentException: Must be volatile type</code></pre><pre><code>public class TestFieldUpdater &#123;    private volatile int field;    public static void main(String[] args) &#123;        AtomicIntegerFieldUpdater&lt;TestFieldUpdater&gt; fieldUpdater = AtomicIntegerFieldUpdater.newUpdater(TestFieldUpdater.class, &quot;field&quot;);        TestFieldUpdater updater = new TestFieldUpdater();        fieldUpdater.compareAndSet(updater, 0, 10);        // 修改成功 field = 10        System.out.println(updater.field);        // 修改成功 field = 20        fieldUpdater.compareAndSet(updater, 10, 20);        System.out.println(updater.field);        // 修改失败 field = 20        fieldUpdater.compareAndSet(updater, 10, 30);        System.out.println(updater.field);    &#125;</code></pre><pre><code>10 20 20</code></pre><h2 id="原子累加器"><a href="#原子累加器" class="headerlink" title="原子累加器"></a>原子累加器</h2><h3 id="AtomicLong-Vs-LongAdder"><a href="#AtomicLong-Vs-LongAdder" class="headerlink" title="AtomicLong Vs LongAdder"></a>AtomicLong Vs LongAdder</h3><pre><code>public class TestLongAdder &#123;    public static void main(String[] args) &#123;        for (int i = 0; i &lt; 5; i++) &#123;            demo(()-&gt;new AtomicLong(0),(ref)-&gt;ref.getAndIncrement());        &#125;        for (int i = 0; i &lt; 5; i++) &#123;            demo(()-&gt;new LongAdder(),(ref)-&gt;ref.increment());        &#125;    &#125;    private static &lt;T&gt; void demo(Supplier&lt;T&gt; supplier, Consumer&lt;T&gt; consumer) &#123;        ArrayList&lt;Thread&gt; list = new ArrayList&lt;&gt;();        T adder = supplier.get();        // 4 个线程，每人累加 50 万        for (int i = 0; i &lt; 4; i++) &#123;            list.add(new Thread(() -&gt; &#123;                for (int j = 0; j &lt; 500000; j++) &#123;                    consumer.accept(adder);                &#125;            &#125;));        &#125;        long start = System.nanoTime();        list.forEach(t -&gt; t.start());        list.forEach(t -&gt; &#123;            try &#123;                t.join();            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;        &#125;);        long end = System.nanoTime();        System.out.println(adder + &quot; cost:&quot; + (end - start)/1000_000);    &#125;&#125;</code></pre><p>输出：</p><pre><code>2000000 cost:802000000 cost:762000000 cost:602000000 cost:562000000 cost:522000000 cost:322000000 cost:52000000 cost:82000000 cost:82000000 cost:20</code></pre><p><strong>结论：</strong></p><blockquote><p>执行代码后，发现使用 LongAdder 比 AtomicLong 快 2，3 倍，使用 LongAdder 性能提升的原因很简单，就是在有竞争时，设置多个累加单元 (但不会超过 cpu 的核心数)，Therad-0 累加 Cell [0]，而 Thread-1 累加 Cell [1]… 最后将结果汇总。这样它们在累加时操作的不同的 Cell 变量，因此减少了 CAS 重试失败，从而提高性能。</p></blockquote><h3 id="CAS-锁"><a href="#CAS-锁" class="headerlink" title="CAS 锁"></a>CAS 锁</h3><p><strong>使用 cas 实现一个自旋锁</strong></p><pre><code>public class TestLockCas &#123;    public AtomicInteger state = new AtomicInteger(0); // 如果 state 值为 0 表示没上锁, 1 表示上锁    public void lock() &#123;        while (true) &#123;            if(state.compareAndSet(0, 1)) &#123;                break;            &#125;        &#125;    &#125;    public void unlock() &#123;        log.debug(&quot;unlock...&quot;);        state.set(0);    &#125;    public static void main(String[] args) &#123;        Code_13_LockCas lock = new Code_13_LockCas();        new Thread(() -&gt; &#123;            log.info(&quot;begin...&quot;);            lock.lock();            try &#123;                log.info(&quot;上锁成功&quot;);                TimeUnit.SECONDS.sleep(1);            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125; finally &#123;                lock.unlock();            &#125;        &#125;, &quot;t1&quot;).start();        new Thread(() -&gt; &#123;            log.info(&quot;begin...&quot;);            lock.lock();            try &#123;                log.info(&quot;上锁成功&quot;);                TimeUnit.SECONDS.sleep(1);            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125; finally &#123;                lock.unlock();            &#125;        &#125;, &quot;t2&quot;).start();    &#125;&#125;</code></pre><h2 id="LongAdder-原理"><a href="#LongAdder-原理" class="headerlink" title="LongAdder 原理"></a>LongAdder 原理</h2><p>LongAdder 类有几个关键域，在 public class LongAdder extends Striped64 implements Serializable {}，下面的变量属于 Striped64 被 LongAdder 继承：</p><pre><code>// 累加单元数组, 懒惰初始化transient volatile Cell[] cells;// 基础值, 如果没有竞争, 则用 cas 累加这个域transient volatile long base;// 在 cells 创建或扩容时, 置为 1, 表示加锁transient volatile int cellsBusy; </code></pre><h3 id="原理之伪共享"><a href="#原理之伪共享" class="headerlink" title="原理之伪共享"></a>原理之伪共享</h3><p>其中 Cell 即为累加单元。</p><pre><code>// 防止缓存行伪共享@sun.misc.Contendedstatic final class Cell &#123;    volatile long value;    Cell(long x) &#123; value = x; &#125;    // 最重要的方法, 用 cas 方式进行累加, prev 表示旧值, next 表示新值    final boolean cas(long prev, long next) &#123;        return UNSAFE.compareAndSwapLong(this, valueOffset, prev, next);    &#125;    // 省略不重要代码&#125;</code></pre><p>要想讨论 @sun.misc.Contended 注解的重要意义得从缓存说起，缓存与内存的速度比较：</p><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210608110939298.png"></p><p>因为 CPU 与 内存的速度差异很大，需要靠预读数据至缓存来提升效率。缓存离 cpu 越近速度越快。 而缓存以缓存行为单位，每个缓存行对应着一块内存，一般是 64 byte（8 个 long），缓存的加入会造成数据副本的产生，即同一份数据会缓存在不同核心的缓存行中，CPU 要保证数据的一致性，如果某个 CPU 核心更改了数据，其它 CPU 核心对应的整个缓存行必须失效。</p><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210609205336917.png"></p><p>因为 Cell 是数组形式，在内存中是连续存储的，一个 Cell 为 24 字节（16 字节的对象头和 8 字节的 value），因 此缓存行可以存下 2 个的 Cell 对象。这样问题来了： Core-0 要修改 Cell [0]，Core-1 要修改 Cell [1]，无论谁修改成功，都会导致对方 Core 的缓存行失效，比如 Core-0 中 Cell [0]=6000, Cell [1]=8000 要累加 Cell [0]=6001, Cell [1]=8000 ，这会让 Core-1 的缓存行失效，而 @sun.misc.Contended 就是用来解决这个问题，它的原理是在使用此注解的对象或字段的前后各增加 128 字节大小的 padding，从而让 CPU 将对象预读至缓存时占用不同的缓存行，这样，不会造成对方缓存行的失效。</p><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210609205244398.png"></p><h3 id="add-方法分析"><a href="#add-方法分析" class="headerlink" title="add 方法分析"></a>add 方法分析</h3><p>LongAdder 进行累加操作是调用 increment 方法，它又调用 add 方法。</p><pre><code>public void increment() &#123;        add(1L);    &#125;</code></pre><p><strong>第一步：add 方法分析，流程图如下：</strong></p><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/20210203225824450.png"></p><p>源码如下：</p><pre><code>public void add(long x) &#123;        // as 为累加单元数组, b 为基础值, x 为累加值        Cell[] as; long b, v; int m; Cell a;        // 进入 if 的两个条件        // 1. as 有值, 表示已经发生过竞争, 进入 if        // 2. cas 给 base 累加时失败了, 表示 base 发生了竞争, 进入 if        // 3. 如果 as 没有创建, 然后 cas 累加成功就返回，累加到 base 中 不存在线程竞争的时候用到。        if ((as = cells) != null || !casBase(b = base, b + x)) &#123;            // uncontended 表示 cell 是否有竞争，这里赋值为 true 表示有竞争            boolean uncontended = true;            if (                // as 还没有创建                    as == null || (m = as.length - 1) &lt; 0 ||                            // 当前线程对应的 cell 还没有被创建，a为当线程的cell                            (a = as[getProbe() &amp; m]) == null ||       // 给当前线程的 cell 累加失败 uncontended=false ( a 为当前线程的 cell )                            !(uncontended = a.cas(v = a.value, v + x))            ) &#123;                // 当 cells 为空时，累加操作失败会调用方法，                // 当 cells 不为空，当前线程的 cell 创建了但是累加失败了会调用方法，                // 当 cells 不为空，当前线程 cell 没创建会调用这个方法                // 进入 cell 数组创建、cell 创建的流程                longAccumulate(x, null, uncontended);            &#125;        &#125;    &#125;</code></pre><p><strong>第二步：longAccumulate 方法分析，流程图如下：</strong></p><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210609210026550.png"></p><p>源码如下：</p><pre><code>final void longAccumulate(long x, LongBinaryOperator fn,                              boolean wasUncontended) &#123;        int h;        // 当前线程还没有对应的 cell, 需要随机生成一个 h 值用来将当前线程绑定到 cell        if ((h = getProbe()) == 0) &#123;            // 初始化 probe            ThreadLocalRandom.current();            // h 对应新的 probe 值, 用来对应 cell            h = getProbe();            wasUncontended = true;        &#125;        // collide 为 true 表示需要扩容        boolean collide = false;        for (;;) &#123;            Cell[] as; Cell a; int n; long v;            // 已经有了 cells            if ((as = cells) != null &amp;&amp; (n = as.length) &gt; 0) &#123;                // 但是还没有当前线程对应的 cell                if ((a = as[(n - 1) &amp; h]) == null) &#123;                    // 为 cellsBusy 加锁, 创建 cell, cell 的初始累加值为 x                    // 成功则 break, 否则继续 continue 循环                    if (cellsBusy == 0) &#123;       // Try to attach new Cell                        Cell r = new Cell(x);   // Optimistically create                        if (cellsBusy == 0 &amp;&amp; casCellsBusy()) &#123;                            boolean created = false;                            try &#123;               // Recheck under lock                                Cell[] rs; int m, j;                                if ((rs = cells) != null &amp;&amp;                                    (m = rs.length) &gt; 0 &amp;&amp;                                    // 判断槽位确实是空的                                    rs[j = (m - 1) &amp; h] == null) &#123;                                    rs[j] = r;                                    created = true;                                &#125;                            &#125; finally &#123;                                cellsBusy = 0;                            &#125;                            if (created)                                break;                            continue;           // Slot is now non-empty                        &#125;                &#125;                // 有竞争, 改变线程对应的 cell 来重试 cas                else if (!wasUncontended)                    wasUncontended = true;                    // cas 尝试累加, fn 配合 LongAccumulator 不为 null, 配合 LongAdder 为 null                else if (a.cas(v = a.value, ((fn == null) ? v + x : fn.applyAsLong(v, x))))                    break;                    // 如果 cells 长度已经超过了最大长度, 或者已经扩容, 改变线程对应的 cell 来重试 cas                else if (n &gt;= NCPU || cells != as)                    collide = false;                    // 确保 collide 为 false 进入此分支, 就不会进入下面的 else if 进行扩容了                else if (!collide)                    collide = true;                    // 加锁                else if (cellsBusy == 0 &amp;&amp; casCellsBusy()) &#123;                    // 加锁成功, 扩容                    continue;                &#125;                // 改变线程对应的 cell                h = advanceProbe(h);            &#125;            // 还没有 cells, cells==as是指没有其它线程修改cells，as和cells引用相同的对象，使用casCellsBusy()尝试给 cellsBusy 加锁            else if (cellsBusy == 0 &amp;&amp; cells == as &amp;&amp; casCellsBusy()) &#123;                // 加锁成功, 初始化 cells, 最开始长度为 2, 并填充一个 cell                // 成功则 break;                boolean init = false;                try &#123;                           // Initialize table                    if (cells == as) &#123;                        Cell[] rs = new Cell[2];                        rs[h &amp; 1] = new Cell(x);                        cells = rs;                        init = true;                    &#125;                &#125; finally &#123;                    cellsBusy = 0;                &#125;                if (init)                    break;            &#125;            // 上两种情况失败, 尝试给 base 使用casBase累加            else if (casBase(v = base, ((fn == null) ? v + x : fn.applyAsLong(v, x))))                break;        &#125;    &#125;</code></pre><h3 id="sum-方法分析"><a href="#sum-方法分析" class="headerlink" title="sum 方法分析"></a>sum 方法分析</h3><p>获取最终结果通过 sum 方法，将各个累加单元的值加起来就得到了总的结果：</p><pre><code>public long sum() &#123;        Cell[] as = cells; Cell a;        long sum = base;        if (as != null) &#123;            for (int i = 0; i &lt; as.length; ++i) &#123;                if ((a = as[i]) != null)                    sum += a.value;            &#125;        &#125;        return sum;    &#125;</code></pre><h2 id="Unsafe-方法"><a href="#Unsafe-方法" class="headerlink" title="Unsafe 方法"></a>Unsafe 方法</h2><h3 id="Unsafe-对象的获取"><a href="#Unsafe-对象的获取" class="headerlink" title="Unsafe 对象的获取"></a>Unsafe 对象的获取</h3><p>Unsafe 对象提供了非常底层的操作内存、线程的方法，Unsafe 对象不能直接调用，只能通过反射获得。LockSupport 的 park 方法，CAS 相关的方法底层都是通过 Unsafe 类来实现的。</p><pre><code>public static void main(String[] args) throws NoSuchFieldException, IllegalAccessException &#123;        // Unsafe 使用了单例模式，unsafe 对象是类中的一个私有的变量         Field theUnsafe = Unsafe.class.getDeclaredField(&quot;theUnsafe&quot;);        theUnsafe.setAccessible(true);        Unsafe unsafe = (Unsafe)theUnsafe.get(null);            &#125;</code></pre><h3 id="Unsafe-模拟实现-cas-操作"><a href="#Unsafe-模拟实现-cas-操作" class="headerlink" title="Unsafe 模拟实现 cas 操作"></a>Unsafe 模拟实现 cas 操作</h3><pre><code>public class UnsafeTest &#123;    public static void main(String[] args) throws NoSuchFieldException, IllegalAccessException &#123;        // 创建 unsafe 对象        Field theUnsafe = Unsafe.class.getDeclaredField(&quot;theUnsafe&quot;);        theUnsafe.setAccessible(true);        Unsafe unsafe = (Unsafe)theUnsafe.get(null);        // 拿到偏移量        long idOffset = unsafe.objectFieldOffset(Teacher.class.getDeclaredField(&quot;id&quot;));        long nameOffset = unsafe.objectFieldOffset(Teacher.class.getDeclaredField(&quot;name&quot;));        // 进行 cas 操作        Teacher teacher = new Teacher();        unsafe.compareAndSwapLong(teacher, idOffset, 0, 100);        unsafe.compareAndSwapObject(teacher, nameOffset, null, &quot;lisi&quot;);        System.out.println(teacher);    &#125;&#125;@Dataclass Teacher &#123;    private volatile int id;    private volatile String name;&#125;</code></pre><h3 id="Unsafe-模拟实现原子整数"><a href="#Unsafe-模拟实现原子整数" class="headerlink" title="Unsafe 模拟实现原子整数"></a>Unsafe 模拟实现原子整数</h3><pre><code>public class UnsafeAccessor &#123;    public static void main(String[] args) &#123;        Account.demo(new MyAtomicInteger(10000));    &#125;&#125;class MyAtomicInteger implements Account &#123;    private volatile Integer value;    private static final Unsafe UNSAFE = Unsafe.getUnsafe();    private static final long valueOffset;    static &#123;        try &#123;            valueOffset = UNSAFE.objectFieldOffset                    (AtomicInteger.class.getDeclaredField(&quot;value&quot;));        &#125; catch (Exception ex) &#123; throw new Error(ex); &#125;    &#125;    public MyAtomicInteger(Integer value) &#123;        this.value = value;    &#125;    public Integer get() &#123;        return value;    &#125;    public void decrement(Integer amount) &#123;        while (true) &#123;            Integer preVal = this.value;            Integer nextVal = preVal - amount;            if(UNSAFE.compareAndSwapObject(this, valueOffset, preVal, nextVal)) &#123;                break;            &#125;        &#125;    &#125;    @Override    public Integer getBalance() &#123;        return get();    &#125;    @Override    public void withdraw(Integer amount) &#123;        decrement(amount);    &#125;&#125;</code></pre><h1 id="共享模型之不可变"><a href="#共享模型之不可变" class="headerlink" title="共享模型之不可变"></a>共享模型之不可变</h1><h2 id="日期转换的问题"><a href="#日期转换的问题" class="headerlink" title="日期转换的问题"></a>日期转换的问题</h2><p>下面的代码在运行时，由于 SimpleDateFormat 不是线程安全的，有很大几率出现 java.lang.NumberFormatException 或者出现不正确的日期解析结果。</p><pre><code>SimpleDateFormat sdf = new SimpleDateFormat(&quot;yyyy-MM-dd&quot;);        for (int i = 0; i &lt; 10; i++) &#123;            new Thread(() -&gt; &#123;                try &#123;                    log.debug(&quot;&#123;&#125;&quot;, sdf.parse(&quot;1951-04-21&quot;));                &#125; catch (Exception e) &#123;                    log.error(&quot;&#123;&#125;&quot;, e);                &#125;            &#125;).start();        &#125;</code></pre><p>输出：</p><pre><code>Exception in thread &quot;Thread-3&quot; Exception in thread &quot;Thread-0&quot; java.lang.NumberFormatException: For input string: &quot;1951.&quot;    at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)    at java.base/java.lang.Long.parseLong(Long.java:692)    at java.base/java.lang.Long.parseLong(Long.java:817)    at java.base/java.text.DigitList.getLong(DigitList.java:195)    at java.base/java.text.DecimalFormat.parse(DecimalFormat.java:2123)    at java.base/java.text.SimpleDateFormat.subParse(SimpleDateFormat.java:1933)    at java.base/java.text.SimpleDateFormat.parse(SimpleDateFormat.java:1541)    at java.base/java.text.DateFormat.parse(DateFormat.java:393)    at com.heu.test.TestDate.lambda$main$0(TestDate.java:21)    at java.base/java.lang.Thread.run(Thread.java:834)</code></pre><p>如果一个对象不能够修改其内部状态（属性），那么它就是线程安全的，因为不存在并发修改！这样的对象在 java 中有很多，例如在 Java 8 后，提供了一个新的日期格式化类 DateTimeFormatter。</p><pre><code>DateTimeFormatter dtf = DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd&quot;);        for (int i = 0; i &lt; 10; i++) &#123;            new Thread(() -&gt; &#123;                LocalDate date = dtf.parse(&quot;2018-10-01&quot;, LocalDate::from);                log.debug(&quot;&#123;&#125;&quot;, date);            &#125;).start();        &#125;</code></pre><h2 id="不可变设计"><a href="#不可变设计" class="headerlink" title="不可变设计"></a>不可变设计</h2><p>String 类中不可变的体现：</p><pre><code>public final class String    implements java.io.Serializable, Comparable&lt;String&gt;, CharSequence &#123;    /** The value is used for character storage. */    private final char value[];    /** Cache the hash code for the string */    private int hash; // Default to 0    // ...&#125;</code></pre><h3 id="final-的使用"><a href="#final-的使用" class="headerlink" title="final 的使用"></a>final 的使用</h3><p>发现该类、类中所有属性都是 ﬁnal 的：</p><ul><li>属性用 ﬁnal 修饰保证了该属性是只读的，不能修改。</li><li>类用 ﬁnal 修饰保证了该类中的方法不能被覆盖，防止子类无意间破坏不可变性。</li></ul><h3 id="保护性拷贝"><a href="#保护性拷贝" class="headerlink" title="保护性拷贝"></a>保护性拷贝</h3><p>有同学会说，使用字符串时，也有一些跟修改相关的方法啊，比如 substring 等，那么下面就看一看这些方法是 如何实现的，就以 substring 为例：</p><pre><code>public String substring(int beginIndex, int endIndex) &#123;        if (beginIndex &lt; 0) &#123;            throw new StringIndexOutOfBoundsException(beginIndex);        &#125;        if (endIndex &gt; value.length) &#123;            throw new StringIndexOutOfBoundsException(endIndex);        &#125;        int subLen = endIndex - beginIndex;        if (subLen &lt; 0) &#123;            throw new StringIndexOutOfBoundsException(subLen);        &#125;        // 上面是一些校验，下面才是真正的创建新的String对象        return ((beginIndex == 0) &amp;&amp; (endIndex == value.length)) ? this                : new String(value, beginIndex, subLen);    &#125;</code></pre><p>我们发现其内部是调用 String 的构造方法创建了一个新字符串：</p><pre><code>public String(char value[], int offset, int count) &#123;       if (offset &lt; 0) &#123;           throw new StringIndexOutOfBoundsException(offset);       &#125;       if (count &lt;= 0) &#123;           if (count &lt; 0) &#123;               throw new StringIndexOutOfBoundsException(count);           &#125;           if (offset &lt;= value.length) &#123;               this.value = &quot;&quot;.value;               return;           &#125;       &#125;       // Note: offset or count might be near -1&gt;&gt;&gt;1.       if (offset &gt; value.length - count) &#123;           throw new StringIndexOutOfBoundsException(offset + count);       &#125;       // 上面是一些安全性的校验，下面是给String对象的value赋值，新创建了一个数组来保存String对象的值       this.value = Arrays.copyOfRange(value, offset, offset+count);   &#125;</code></pre><p>构造新字符串对象时，会生成新的 char [] value，对内容进行复制 。这种通过创建副本对象来避免共享的手段称之为保护性拷贝（defensive copy）。</p><h2 id="模式之享元"><a href="#模式之享元" class="headerlink" title="模式之享元"></a>模式之享元</h2><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>享元定义英文名称：Flyweight pattern。当需要重用数量有限的同一类对象时，归类为：Structual patterns。</p><h3 id="体现"><a href="#体现" class="headerlink" title="体现"></a>体现</h3><p><strong>包装类</strong><br>在 JDK 中 Boolean，Byte，Short，Integer，Long，Character 等包装类提供了 valueOf 方法。例如 Long 的 valueOf 会缓存 -128~127 之间的 Long 对象，在这个范围之间会重用对象，大于这个范围，才会新建 Long 对象：</p><pre><code>public static Long valueOf(long l) &#123; final int offset = 128; if (l &gt;= -128 &amp;&amp; l &lt;= 127) &#123; // will cache return LongCache.cache[(int)l + offset]; &#125; return new Long(l);&#125;</code></pre><ul><li>Byte, Short, Long 缓存的范围都是 -128~127。</li><li>Character 缓存的范围是 0~127。</li><li>Integer 的默认范围是 -128~127，最小值不能变，但最大值可以通过调整虚拟机参数 “-Djava.lang.Integer.- - - IntegerCache.high “来改变。</li><li>Boolean 缓存了 TRUE 和 FALSE。</li></ul><h2 id="final-的原理"><a href="#final-的原理" class="headerlink" title="final 的原理"></a>final 的原理</h2><p><strong>设置 final 变量的原理</strong></p><p>理解了 volatile 原理，再对比 final 的实现就比较简单了：</p><pre><code>public class TestFinal &#123;    final int a = 20;&#125;</code></pre><p>字节码：</p><pre><code>0: aload_01: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V4: aload_05: bipush 207: putfield #2 // Field a:I &lt;-- 写屏障10: return</code></pre><blockquote><p>final 变量的赋值操作都必须在定义时或者构造器中进行初始化赋值，并且发现 final 变量的赋值也会通过 putfield 指令来完成，同样在这条指令之后也会加入写屏障，保证在其它线程读到它的值时不会出现为 0 的情况。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 多线程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JMM内存模型 </tag>
            
            <tag> Volatile </tag>
            
            <tag> CAS </tag>
            
            <tag> AtomicReference </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>多线程与高并发 — 线程池</title>
      <link href="/2020/09/09/thread/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E9%AB%98%E5%B9%B6%E5%8F%91%20%E2%80%94%20%E7%BA%BF%E7%A8%8B%E6%B1%A0/"/>
      <url>/2020/09/09/thread/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E9%AB%98%E5%B9%B6%E5%8F%91%20%E2%80%94%20%E7%BA%BF%E7%A8%8B%E6%B1%A0/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="AQS"><a href="#AQS" class="headerlink" title="AQS"></a>AQS</h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>程池<br>线程池介绍<br>池化技术现在已经屡见不鲜了，线程池、数据库连接池、Http 连接池等等都是对这个思想的应用。池化技术的思想主要是为了减少每次获取资源的消耗，提高对资源的利用率。</p><p>线程池提供了一种限制和管理资源（包括执行一个任务）的方式。 每个线程池还维护一些基本统计信息，例如已完成任务的数量。</p><p>使用线程池的好处：</p><p>降低资源消耗：通过重复利用已创建的线程降低线程创建和销毁造成的消耗。<br>提高响应速度：当任务到达时，任务可以不需要等到线程创建就能立即执行。<br>提高线程的可管理性：线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。<br>自定义线程池</p><p>image-20210614101113540</p><p>上图就是一个线程池的实现，先初始化线程池、阻塞队列大小，然后开几个线程通过线程池对象调用方法执行任务，如果任务过多，会添加到阻塞队列中，线程执行完任务再从阻塞队列中取值继续执行。当执行的线程数大于线程池和阻塞队列的大小，我们可以定义拒绝策略，类似 jdk 线程池那样。代码实现如下：</p><p>@Slf4j<br>public class TestThreadPool {<br>    public static void main(String[] args) {<br>        ThreadPool threadPool = new ThreadPool(1,1000,TimeUnit.SECONDS,4,(queue,task)-&gt;{<br>            // 1. 死等<br>           queue.put(task);<br>            // 2) 带超时等待<br>           //queue.offer(task, 1500, TimeUnit.MILLISECONDS);<br>            // 3) 让调用者放弃任务执行<br>           //log.debug(“放弃{}”, task);<br>            // 4) 让调用者抛出异常<br>            //throw new RuntimeException(“任务执行失败 “ + task);<br>            // 5) 让调用者自己执行任务<br>            //task.run();<br>        });</p><pre><code>    for (int i = 0; i &lt; 4; i++) &#123;        int j = i;        threadPool.execute(()-&gt;&#123;            try &#123;                Thread.sleep(1000);            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;            log.debug(&quot;&#123;&#125;&quot;, j);        &#125;);    &#125;&#125;</code></pre><p>}</p><p>//拒绝策略<br>@FunctionalInterface<br>interface RejectPolicy<T> {<br>    void reject(BlockingQueue<T> queue, T task);<br>}</p><p>@Slf4j<br>class ThreadPool{<br>    //任务队列<br>    private BlockingQueue<Runnable> taskQueue;</p><pre><code>//线程集合private HashSet&lt;Worker&gt; workers = new HashSet&lt;&gt;();//核心线程数private int coreSize;//获取任务时的超时时间private long timeout;private TimeUnit timeUnit;//拒绝策略private RejectPolicy&lt;Runnable&gt; rejectPolicy;public ThreadPool(int coreSize, long timeout, TimeUnit timeUnit, int queueCapcity,RejectPolicy&lt;Runnable&gt; rejectPolicy) &#123;    this.coreSize = coreSize;    this.timeout = timeout;    this.timeUnit = timeUnit;    this.taskQueue = new BlockingQueue&lt;&gt;(queueCapcity);    this.rejectPolicy = rejectPolicy;&#125;//执行任务public void execute(Runnable task) &#123;    // 当任务数没有超过 coreSize 时，直接交给 worker 对象执行    // 如果任务数超过 coreSize 时，加入任务队列暂存    synchronized (workers) &#123;        if (workers.size() &lt; coreSize) &#123;            Worker worker = new Worker(task);            log.debug(&quot;新增 worker&#123;&#125;, &#123;&#125;&quot;, worker, task);            workers.add(worker);            worker.start();        &#125; else &#123;            // 1) 死等            // 2) 带超时等待            // 3) 让调用者放弃任务执行            // 4) 让调用者抛出异常            // 5) 让调用者自己执行任务            //taskQueue.put(task);            taskQueue.tryPut(rejectPolicy, task);        &#125;    &#125;&#125;class Worker extends Thread &#123;    private Runnable task;    public Worker(Runnable task) &#123;        this.task = task;    &#125;    @Override    public void run() &#123;        //执行任务        // 1) 当 task 不为空，执行任务        // 2) 当 task 执行完毕，再接着从任务队列获取任务并执行        //while(task != null || (task = taskQueue.take()) != null)        while (task != null || (task = taskQueue.poll(timeout, timeUnit)) != null) &#123;            try &#123;                log.debug(&quot;正在执行...&#123;&#125;&quot;, task);                task.run();            &#125; catch (Exception e) &#123;                e.printStackTrace();            &#125; finally &#123;                task = null;            &#125;        &#125;        synchronized (workers) &#123;            log.debug(&quot;worker 被移除&#123;&#125;&quot;, this);            workers.remove(this);        &#125;    &#125;&#125;</code></pre><p>}</p><p>@Slf4j<br>class BlockingQueue<T> {<br>    //1.任务队列<br>    private Deque<T> queue = new ArrayDeque<T>();</p><pre><code>//2.锁private ReentrantLock lock = new ReentrantLock();//3.生产者条件变量private Condition fullWait = lock.newCondition();//4.消费者条件变量private Condition emptyWait = lock.newCondition();//5.容量private int capcity;public BlockingQueue(int capcity) &#123;    this.capcity = capcity;&#125;//带超时的阻塞获取public T poll(long timeout, TimeUnit unit) &#123;    lock.lock();    try &#123;        // 将 timeout 统一转换为 纳秒        long nanos = unit.toNanos(timeout);        while (queue.isEmpty()) &#123;            // 返回值是剩余时间            if (nanos &lt;= 0) &#123;                return null;            &#125;            try &#123;                nanos=emptyWait.awaitNanos(nanos);            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;        &#125;        T t = queue.removeFirst();        fullWait.signal();        return t;    &#125;finally &#123;        lock.unlock();    &#125;&#125;//阻塞获取public T take() &#123;    lock.lock();    try &#123;        while (queue.isEmpty()) &#123;            try &#123;                emptyWait.wait();            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;        &#125;        T t = queue.removeFirst();        fullWait.signal();        return t;    &#125;finally &#123;        lock.unlock();    &#125;&#125;//阻塞添加public void put(T task) &#123;    lock.lock();    try &#123;        while (queue.size() == capcity) &#123;            try &#123;                fullWait.wait();            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;        &#125;        log.debug(&quot;加入任务队列 &#123;&#125;&quot;, task);        queue.addLast(task);        emptyWait.signal();    &#125;finally &#123;        lock.unlock();    &#125;&#125;//带超时的阻塞添加public boolean offer(T task, long timeout, TimeUnit timeUnit) &#123;    lock.lock();    try &#123;        long nanos = timeUnit.toNanos(timeout);        while (queue.size() == capcity) &#123;            try &#123;                nanos = fullWait.awaitNanos(nanos);            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;        &#125;        log.debug(&quot;加入任务队列 &#123;&#125;&quot;, task);        queue.addLast(task);        emptyWait.signal();        return true;    &#125;finally &#123;        lock.unlock();    &#125;&#125;public int size() &#123;    lock.lock();    try &#123;        return queue.size();    &#125;finally &#123;        lock.unlock();    &#125;&#125;public void tryPut(RejectPolicy&lt;T&gt; rejectPolicy,T task) &#123;    lock.lock();    try &#123;        if (queue.size() == capcity) &#123;            rejectPolicy.reject(this, task);        &#125; else &#123;            log.debug(&quot;加入任务队列 &#123;&#125;&quot;, task);            queue.addLast(task);            emptyWait.signal();        &#125;    &#125;finally &#123;        lock.unlock();    &#125;&#125;</code></pre><p>}<br>ThreadPoolExecutor<br>线程池状态<br>ThreadPoolExecutor 使用 int 的高 3 位来表示线程池状态，低 29 位表示线程数量，ThreadPoolExecutor 类中的线程状态变量如下：</p><p>JAVA<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br> // Integer.SIZE 值为 32<br>private static final int COUNT_BITS = Integer.SIZE - 3;<br> // runState is stored in the high-order bits<br> private static final int RUNNING    = -1 &lt;&lt; COUNT_BITS;<br> private static final int SHUTDOWN   =  0 &lt;&lt; COUNT_BITS;<br> private static final int STOP       =  1 &lt;&lt; COUNT_BITS;<br> private static final int TIDYING    =  2 &lt;&lt; COUNT_BITS;<br> private static final int TERMINATED =  3 &lt;&lt; COUNT_BITS;<br>状态名称    高 3 位的值    描述<br>RUNNING    111    接收新任务，同时处理任务队列中的任务<br>SHUTDOWN    000    不接受新任务，但是处理任务队列中的任务<br>STOP    001    中断正在执行的任务，同时抛弃阻塞队列中的任务<br>TIDYING    010    任务执行完毕，活动线程为 0 时，即将进入终结阶段<br>TERMINATED    011    终结状态<br>线程池状态和线程池中线程的数量由一个原子整型 ctl 来共同表示。使用一个数来表示两个值的主要原因是：可以通过一次 CAS 同时更改两个属性的值。</p><p>JAVA<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>// 原子整数，前 3 位保存了线程池的状态，剩余位保存的是线程数量<br>private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));</p><p>// 并不是所有平台的 int 都是 32 位。<br>// 去掉前三位保存线程状态的位数，剩下的用于保存线程数量<br>// 高3位为0，剩余位数全为1<br>private static final int COUNT_BITS = Integer.SIZE - 3;</p><p>// 2^COUNT_BITS次方，表示可以保存的最大线程数<br>// CAPACITY 的高3位为 0<br>private static final int CAPACITY   = (1 &lt;&lt; COUNT_BITS) - 1;<br>获取线程池状态、线程数量以及合并两个值的操作：</p><p>JAVA<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>/ Packing and unpacking ctl<br>// 获取运行状态<br>// 该操作会让除高3位以外的数全部变为0<br>private static int runStateOf(int c)     { return c &amp; ~CAPACITY; }</p><p>// 获取运行线程数<br>// 该操作会让高3位为0<br>private static int workerCountOf(int c)  { return c &amp; CAPACITY; }</p><p>// 计算ctl新值<br>private static int ctlOf(int rs, int wc) { return rs | wc; }<br>线程池的属性：</p><p>JAVA<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>// 工作线程，内部封装了Thread<br>private final class Worker<br>        extends AbstractQueuedSynchronizer<br>        implements Runnable {<br>    …<br>}</p><p>// 阻塞队列，用于存放来不及被核心线程执行的任务<br>private final BlockingQueue<Runnable> workQueue;</p><p>// 锁<br>private final ReentrantLock mainLock = new ReentrantLock();</p><p>// 用于存放核心线程的容器，只有当持有锁时才能够获取其中的元素（核心线程）<br>private final HashSet<Worker> workers = new HashSet<Worker>();<br>构造方法<br>看一下 ThreadPoolExecutor 类参数最多、最全的有参构造方法：</p><p>JAVA<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>public ThreadPoolExecutor(int corePoolSize,<br>                          int maximumPoolSize,<br>                          long keepAliveTime,<br>                          TimeUnit unit,<br>                          BlockingQueue<Runnable> workQueue,<br>                          ThreadFactory threadFactory,<br>                          RejectedExecutionHandler handler)<br>构造参数解释：</p><p>corePoolSize：核心线程数</p><p>maximumPoolSize：最大线程数</p><p>maximumPoolSize - corePoolSize = 救急线程数<br>keepAliveTime：救急线程空闲时的最大生存时间</p><p>unit：时间单位</p><p>workQueue：阻塞队列（存放任务）</p><p>有界阻塞队列：ArrayBlockingQueue<br>无界阻塞队列：LinkedBlockingQueue<br>最多只有一个同步元素的队列：SynchronousQueue<br>PriorityBlockingQueue：优先队列</p><p>threadFactory：线程工厂（给线程取名字）</p><p>handler：拒绝策略</p><p>工作方式：</p><p>线程池中刚开始没有线程，当一个任务提交给线程池后，线程池会创建一个新线程来执行任务。</p><p>当线程数达到 corePoolSize 没有线程空闲时，这时再加入任务，新加的任务会被加入 workQueue 队列排 队，直到有空闲的线程。</p><p>如果队列选择了有界队列，那么任务超过了队列大小时，会创建 maximumPoolSize - corePoolSize 数目的线程来救急。</p><p>如果线程数达到 maximumPoolSize 仍然有新任务，这时会执行拒绝策略。拒绝策略 jdk 提供了下面的前 4 种实现，其它的著名框架也提供了实现：</p><p>ThreadPoolExecutor.AbortPolicy：让调用者抛出 RejectedExecutionException 异常，这是默认策略。<br>ThreadPoolExecutor.CallerRunsPolicy：让调用者运行任务。<br>ThreadPoolExecutor.DiscardPolicy：放弃本次任务。<br>ThreadPoolExecutor.DiscardOldestPolicy：放弃队列中最早的任务，本任务取而代之。<br>Dubbo 的实现：在抛出 RejectedExecutionException 异常之前会记录日志，并 dump 线程栈信息，方便定位问题。<br>Netty 的实现：创建一个新线程来执行任务。<br>ActiveMQ 的实现：带超时等待（60s）尝试放入队列，类似之前自定义的拒绝策略。<br>PinPoint 的实现，它使用了一个拒绝策略链，会逐一尝试策略链中每种拒绝策略。<br>当高峰过去后，超过 corePoolSize 的救急线程如果一段时间没有任务做，需要结束节省资源，这个时间由 keepAliveTime 和 unit 来控制。</p><p>jdk 线程池的拒绝策略结构图如下：</p><p>在这里插入图片描述</p><p>据这个构造方法，JDK Executors 类中提供了众多工厂方法来创建各种用途的线程池。</p><p>newFixedThreadPool<br>newFixedThreadPool 创建的是固定大小的线程池。实现代码如下：</p><p>JAVA<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>// 创建大小为 2 的固定线程池, 自定义线程名称<br> ExecutorService executorService = Executors.newFixedThreadPool(2, new ThreadFactory() {<br>     private AtomicInteger atomicInteger = new AtomicInteger(1);<br>     @Override<br>     public Thread newThread(Runnable r) {<br>         return new Thread(r, “my_thread_” + atomicInteger.getAndIncrement());<br>     }<br> });<br> // 开 3 个线程, 线程池大小为 2 , 第三个线程执行时, 如果前两个线程任务没执行完, 会加入任务队列.<br> executorService.execute(() -&gt; {<br>     log.info(“1”);<br> });<br> executorService.execute(() -&gt; {<br>     log.info(“2”);<br> });<br> executorService.execute(() -&gt; {<br>     log.info(“3”);<br> });<br>Executors 类 使用 newFixedThreadPool 创建线程的源码如下：</p><p>JAVA<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>public static ExecutorService newFixedThreadPool(int nThreads) {<br>        return new ThreadPoolExecutor(nThreads, nThreads,<br>                                      0L, TimeUnit.MILLISECONDS,<br>                                      new LinkedBlockingQueue<Runnable>());<br>    }<br>    public ThreadPoolExecutor(int corePoolSize,<br>                              int maximumPoolSize,<br>                              long keepAliveTime,<br>                              TimeUnit unit,<br>                              BlockingQueue<Runnable> workQueue) {<br>        this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue,<br>             Executors.defaultThreadFactory(), defaultHandler);<br>    }<br>通过源码可以看到 new ThreadPoolExecutor (xxx) 方法其实是是调用了之前的完整参数的构造方法，创建的是固定的线程数，使用了默认的线程工厂和拒绝策略。</p><p>特点：</p><p>核心线程数 = 最大线程数（没有救急线程被创建），因此也无需超时时间。<br>阻塞队列是无界的（LinkedBlockingQueue），可以放任意数量的任务。<br>适用于任务量已知，相对耗时的任务。<br>newCachedThreadPool</p><pre><code class="bash">ExecutorService executorService = Executors.newCachedThreadPool();    public static ExecutorService newCachedThreadPool() &#123;     return new ThreadPoolExecutor(0, Integer.MAX_VALUE,     60L, TimeUnit.SECONDS,     new SynchronousQueue&lt;Runnable&gt;());    &#125;</code></pre><p>特点：</p><p>核心线程数是 0，最大线程数是 Integer.MAX_VALUE，救急线程的空闲生存时间是 60s，意味着全部都是救急线程（60s 后没有任务就回收），救急线程可以无限创建。<br>队列采用了 SynchronousQueue 实现特点是它没有容量，没有线程来取任务是放不进去的（一手交钱、一手交 货）SynchronousQueue。<br>整个线程池表现为线程数会根据任务量不断增长，没有上限，当任务执行完毕，空闲 1 分钟后释放线程。<br>适合任务数比较密集，但每个任务执行时间较短的情况。<br>示例：</p><pre><code class="bash">SynchronousQueue&lt;Integer&gt; integers = new SynchronousQueue&lt;&gt;();        new Thread(() -&gt; &#123;            try &#123;                log.debug(&quot;putting &#123;&#125; &quot;, 1);                integers.put(1);                log.debug(&quot;&#123;&#125; putted...&quot;, 1);                log.debug(&quot;putting...&#123;&#125; &quot;, 2);                integers.put(2);                log.debug(&quot;&#123;&#125; putted...&quot;, 2);            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;        &#125;,&quot;t1&quot;).start();        Thread.sleep(1000);        new Thread(() -&gt; &#123;            try &#123;                log.debug(&quot;taking &#123;&#125;&quot;,1);                integers.take();            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;        &#125;,&quot;t2&quot;).start();        Thread.sleep(1000);        new Thread(() -&gt; &#123;            try &#123;                log.debug(&quot;taking &#123;&#125;&quot;,2);                integers.take();            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;        &#125;,&quot;t3&quot;).start();</code></pre><p>输出：</p><pre><code class="bash">20:17:15.364 [t1] DEBUG com.heu.test.TestPool2 - putting 1 20:17:16.372 [t2] DEBUG com.heu.test.TestPool2 - taking 120:17:16.373 [t1] DEBUG com.heu.test.TestPool2 - 1 putted...20:17:16.373 [t1] DEBUG com.heu.test.TestPool2 - putting...2 20:17:17.373 [t3] DEBUG com.heu.test.TestPool2 - taking 220:17:17.374 [t1] DEBUG com.heu.test.TestPool2 - 2 putted...</code></pre><p>newSingleThreadExecutor</p><pre><code class="bash">public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1,0L, TimeUnit.MILLISECONDS,new LinkedBlockingQueue&lt;Runnable&gt;()));&#125;</code></pre><p>使用场景：</p><p>希望多个任务排队执行。线程数固定为 1，任务数多于 1 时，会放入无界队列排队。任务执行完毕，这唯一的线程也不会被释放。<br>newSingleThreadExecutor 和 newFixedThreadPool 区别：<br>自己创建一个单线程串行执行任务，如果任务执行失败而终止，那么没有任何补救措施，而 newSingleThreadExecutor 线程池还会新建一个线程，保证池的正常工作。<br>newSingleThreadExecutor () 线程个数始终为 1，不能修改。FinalizableDelegatedExecutorService 应用的是装饰器模式，只对外暴露了 ExecutorService 接口，不能调用 ThreadPoolExecutor 中特有的方法。<br>Executors.newFixedThreadPool (1) 初始时为 1，以后还可以修改。它对外暴露的是 ThreadPoolExecutor 对象，可以强转后调用 setCorePoolSize 等方法进行修改。<br>Executors 返回线程池对象的弊端如下：</p><p>FixedThreadPool 和 SingleThreadExecutor：允许请求的队列长度为 Integer.MAX_VALUE，可能堆积大量的请求，从而导致 OOM。</p><p>CachedThreadPool 和 ScheduledThreadPool：允许创建的线程数量为 Integer.MAX_VALUE ，可能会创建大量线程，从而导致 OOM。</p><p>其实就是使用有界队列，控制线程创建数量。</p><p>此外，除了避免 OOM 的原因之外，不推荐使用 Executors 提供的线程池的原因还有：</p><p>实际使用中需要根据自己机器的性能、业务场景来手动配置线程池的参数比如核心线程数、使用的任务队列、饱和策略等等。<br>我们应该显示地给线程池命名，这样有助于我们定位问题。<br>提交任务</p><pre><code class="bash">// 执行任务void execute(Runnable command);// 提交任务 task，用返回值 Future 获得任务执行结果，Future的原理就是利用之前讲到的保护性暂停模式来接受返回结果的，主线程可以执行 FutureTask.get()方法来等待任务执行完成。&lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task);// 提交 tasks 中所有任务&lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException;// 提交 tasks 中所有任务，带超时时间&lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException;// 提交 tasks 中所有任务，哪个任务先成功执行完毕，返回此任务执行结果，其它任务取消&lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException;// 提交 tasks 中所有任务，哪个任务先成功执行完毕，返回此任务执行结果，其它任务取消，带超时时间&lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;</code></pre><p>关闭线程池<br>shutdown：</p><pre><code class="bash">/*      线程池状态变为 SHUTDOWN    - 不会接收新任务    - 但已提交任务会执行完，包括等待队列里面的    - 此方法不会阻塞调用线程的执行    */    public void shutdown() &#123;        final ReentrantLock mainLock = this.mainLock;        mainLock.lock();        try &#123;            checkShutdownAccess();            // 修改线程池状态            advanceRunState(SHUTDOWN);            // 仅会打断空闲线程            interruptIdleWorkers();            onShutdown(); // 扩展点 ScheduledThreadPoolExecutor        &#125; finally &#123;            mainLock.unlock();        &#125;        // 尝试终结(没有运行的线程可以立刻终结)        tryTerminate();    &#125;        ```shutdownNow：```bash/*线程池状态变为 STOP- 不会接收新任务- 会将队列中的任务返回- 并用 interrupt 的方式中断正在执行的任务*/   public List&lt;Runnable&gt; shutdownNow() &#123;       List&lt;Runnable&gt; tasks;       final ReentrantLock mainLock = this.mainLock;       mainLock.lock();       try &#123;           checkShutdownAccess();           // 修改线程池状态           advanceRunState(STOP);           // 打断所有线程           interruptWorkers();           // 获取队列中剩余任务           tasks = drainQueue();       &#125; finally &#123;           mainLock.unlock();       &#125;       // 尝试终结       tryTerminate();       return tasks;   &#125;</code></pre><p>其它方法：</p><pre><code class="bash">// 不在 RUNNING 状态的线程池，此方法就返回 trueboolean isShutdown();// 线程池状态是否是 TERMINATEDboolean isTerminated();// 调用 shutdown 后，由于调用使线程结束线程的方法是异步的并不会等待所有任务运行结束就返回，因此如果它想在线程池 TERMINATED 后做些其它事情，可以利用此方法等待boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException;任务调度线程池在任务调度线程池功能加入之前，可以使用 java.util.Timer 来实现定时功能，Timer 的优点在于简单易用，但由于所有任务都是由同一个线程来调度，因此所有任务都是串行执行的，同一时间只能有一个任务在执行，前一个任务的延迟或异常都将会影响到之后的任务。</code></pre><p>示例：</p><pre><code class="bash">public static void main(String[] args) &#123;        Timer timer = new Timer();        TimerTask task1 = new TimerTask() &#123;            @Override            public void run() &#123;                log.debug(&quot;task 1&quot;);                try &#123;                    Thread.sleep(2000);                &#125; catch (InterruptedException e) &#123;                    e.printStackTrace();                &#125;            &#125;        &#125;;        TimerTask task2 = new TimerTask() &#123;            @Override            public void run() &#123;                log.debug(&quot;task 2&quot;);            &#125;        &#125;;        // 使用 timer 添加两个任务，希望它们都在 1s 后执行        // 但由于 timer 内只有一个线程来顺序执行队列中的任务，因此『任务1』的延时，影响了『任务2』的执行        timer.schedule(task1,1000);        timer.schedule(task2,1000);    &#125;</code></pre><p>输出：</p><pre><code class="bash">20:40:59.276 [Timer-0] DEBUG com.heu.test.TestTimer - task 120:41:01.296 [Timer-0] DEBUG com.heu.test.TestTimer - task 2</code></pre><p>使用 ScheduledExecutorService 改写：</p><pre><code class="bash">public static void main(String[] args) &#123;        ScheduledExecutorService executorService = Executors.newScheduledThreadPool(2);        executorService.schedule(() -&gt; &#123;            System.out.println(&quot;任务1，执行时间：&quot; + new Date());            try &#123;                Thread.sleep(2000);            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;        &#125;,1000, TimeUnit.MILLISECONDS);        executorService.schedule(() -&gt; &#123;            System.out.println(&quot;任务2，执行时间：&quot; + new Date());        &#125;,1000, TimeUnit.MILLISECONDS);    &#125;    ```输出：```bash任务1，执行时间：Mon Jun 14 20:46:29 CST 2021任务2，执行时间：Mon Jun 14 20:46:29 CST 2021整个线程池表现为：线程数固定，任务数多于线程数时，会放入无界队列排队。任务执行完毕，这些线程也不会被释放，用来执行延迟或反复执行的任务。</code></pre><p>scheduleAtFixedRate 例子：</p><pre><code class="bash">ScheduledExecutorService pool = Executors.newScheduledThreadPool(1);log.debug(&quot;start...&quot;);pool.scheduleAtFixedRate(() -&gt; &#123;     log.debug(&quot;running...&quot;);    sleep(2);&#125;, 1, 1, TimeUnit.SECONDS);</code></pre><p>输出：</p><pre><code class="bash">21:44:30.311 TestTimer [main] - start... 21:44:31.360 TestTimer [pool-1-thread-1] - running... 21:44:33.361 TestTimer [pool-1-thread-1] - running... 21:44:35.362 TestTimer [pool-1-thread-1] - running... 21:44:37.362 TestTimer [pool-1-thread-1] - running...</code></pre><p>输出分析：一开始，延时 1s，接下来，由于任务执行时间 &gt; 间隔时间，间隔被『撑』到了 2s。</p><p>scheduleWithFixedDelay 例子：</p><pre><code class="bash">ScheduledExecutorService pool = Executors.newScheduledThreadPool(1);log.debug(&quot;start...&quot;);pool.scheduleWithFixedDelay(()-&gt; &#123;     log.debug(&quot;running...&quot;);     sleep(2);&#125;, 1, 1, TimeUnit.SECONDS);</code></pre><p>输出：</p><pre><code class="bash">21:40:55.078 TestTimer [main] - start... 21:40:56.140 TestTimer [pool-1-thread-1] - running... 21:40:59.143 TestTimer [pool-1-thread-1] - running... 21:41:02.145 TestTimer [pool-1-thread-1] - running... 21:41:05.147 TestTimer [pool-1-thread-1] - running...</code></pre><p>输出分析：一开始，延时 1s，scheduleWithFixedDelay 的间隔是 上一个任务结束 &lt;-&gt; 延时 &lt;-&gt; 下一个任务开始 所以间隔都是 3s。</p><p>正确处理执行任务异常<br>如果线程池中的线程执行任务时，如果任务抛出了异常，默认是中断执行该任务而不是抛出异常或者打印异常信息。</p><p>方法 1：主动捉异常：</p><pre><code class="bash">ExecutorService pool = Executors.newFixedThreadPool(1);    pool.submit(() -&gt; &#123;         try &#123;             log.debug(&quot;task1&quot;);             int i = 1 / 0;         &#125; catch (Exception e) &#123;             log.error(&quot;error:&quot;, e);         &#125;    &#125;);</code></pre><p>方法 2：使用 Future，错误信息都被封装进 submit 方法的返回方法中。</p><pre><code class="bash">ExecutorService pool = Executors.newFixedThreadPool(1);    Future&lt;Boolean&gt; f = pool.submit(() -&gt; &#123;         log.debug(&quot;task1&quot;);         int i = 1 / 0;         return true;    &#125;);    log.debug(&quot;result:&#123;&#125;&quot;, f.get());</code></pre><p>Tomcat 线程池</p><p>image-20210614205652864</p><p>LimitLatch 用来限流，可以控制最大连接个数，类似 J.U.C 中的 Semaphore 后面再讲。<br>Acceptor 只负责【接收新的 socket 连接】。<br>Poller 只负责监听 socket channel 是否有【可读的 I/O 事件】。<br>一旦可读，封装一个任务对象（socketProcessor），提交给 Executor 线程池处理。<br>Executor 线程池中的工作线程最终负责【处理请求】。<br>Tomcat 线程池扩展了 ThreadPoolExecutor，行为稍有不同，如果总线程数达到 maximumPoolSize，这时不会立刻抛 RejectedExecutionException 异常，而是再次尝试将任务放入队列，如果还失败，才抛出 RejectedExecutionException 异常。</p><p>tomcat 部分源码：</p><pre><code class="bash">public void execute(Runnable command, long timeout, TimeUnit unit) &#123;        submittedCount.incrementAndGet();        try &#123;            super.execute(command);        &#125; catch (RejectedExecutionException rx) &#123;            if (super.getQueue() instanceof TaskQueue) &#123;                final TaskQueue queue = (TaskQueue)super.getQueue();                try &#123;                    // 使任务从新进入阻塞队列                    if (!queue.force(command, timeout, unit)) &#123;                        submittedCount.decrementAndGet();                        throw new RejectedExecutionException(&quot;Queue capacity is full.&quot;);                    &#125;                &#125; catch (InterruptedException x) &#123;                    submittedCount.decrementAndGet();                    Thread.interrupted();                    throw new RejectedExecutionException(x);                &#125;            &#125; else &#123;                submittedCount.decrementAndGet();                throw rx;            &#125;        &#125;    &#125;    public boolean force(Runnable o, long timeout, TimeUnit unit) throws InterruptedException &#123;        if ( parent.isShutdown() )            throw new RejectedExecutionException(                    &quot;Executor not running, can&#39;t force a command into the queue&quot;            );        return super.offer(o,timeout,unit); //forces the item onto the queue, to be used if the task        is rejected    &#125;</code></pre><p>Connector 配置如下：</p><p>在这里插入图片描述<br>Executor 线程池配置如下：</p><p>在这里插入图片描述<br>可以看到该线程池实现的是一个无界的队列，所以说是不是执行任务的线程数大于了核心线程数，都会添加到阻塞队列中，那么救急线程是不是就不会用到呢，其实不是，分析如下图：</p><p>在这里插入图片描述</p><p>如图所示，当添加新的任务时，如果提交的任务大于核心线程数小于最大线程数就创建救急线程，否则就加入任务队列中。</p><p>异步模式之工作线程<br>定义：</p><p>让有限的工作线程（Worker Thread）来轮流异步处理无限多的任务。也可以将其归类为分工模式，它的典型实现就是线程池，也体现了经典设计模式中的享元模式。</p><p>例如：</p><p>海底捞的服务员（线程），轮流处理每位客人的点餐（任务），如果为每位客人都配一名专属的服务员，那 么成本就太高了（对比另一种多线程设计模式：Thread-Per-Message） 注意，不同任务类型应该使用不同的线程池，这样能够避免饥饿，并能提升效率 例如，如果一个餐馆的工人既要招呼客人（任务类型 A），又要到后厨做菜（任务类型 B）显然效率不咋地，分成 服务员（线程池 A）与厨师（线程池 B）更为合理，当然你能想到更细致的分工。</p><p>饥饿：</p><p>固定大小线程池会有饥饿现象，解决方法可以增加线程池的大小，不过不是根本解决方案，还是前面提到的，不同的任务类型，采用不同的线程池。实现代码如下：</p><pre><code class="bash">/** * 异步模式之工作线程 */@Slf4j(topic = &quot;c.Code_07_StarvationTest&quot;)public class Code_07_StarvationTest &#123;    public static List&lt;String&gt; list = new ArrayList&lt;&gt;(Arrays.asList(&quot;宫保鸡丁&quot;, &quot;青椒肉丝&quot;, &quot;千张肉丝&quot;));    public static Random random = new Random();    public static String cooking() &#123;        return list.get(random.nextInt(list.size()));    &#125;    public static void main(String[] args) &#123;        // 演示饥饿现象        //  ExecutorService executorService = Executors.newFixedThreadPool(2);        //  test1(executorService);        // 解决        ExecutorService cookPool = Executors.newFixedThreadPool(1);        ExecutorService waiterPool = Executors.newFixedThreadPool(1);        waiterPool.execute(() -&gt; &#123;            log.info(&quot;处理点餐&quot;);            Future&lt;String&gt; f = cookPool.submit(() -&gt; &#123;                log.info(&quot;做菜&quot;);                return cooking();            &#125;);            try &#123;                log.info(&quot;上菜 &#123;&#125; &quot;, f.get());            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125; catch (ExecutionException e) &#123;                e.printStackTrace();            &#125;        &#125;);        waiterPool.execute(() -&gt; &#123;            log.info(&quot;处理点餐&quot;);            Future&lt;String&gt; f2 = cookPool.submit(() -&gt; &#123;                log.info(&quot;做菜&quot;);                return cooking();            &#125;);            try &#123;                log.info(&quot;上菜 &#123;&#125; &quot;, f2.get());            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125; catch (ExecutionException e) &#123;                e.printStackTrace();            &#125;        &#125;);    &#125;    public static void test1( ExecutorService executorService) &#123;        executorService.execute(() -&gt; &#123;            log.info(&quot;处理点餐&quot;);            Future&lt;String&gt; f = executorService.submit(() -&gt; &#123;                log.info(&quot;做菜&quot;);                return cooking();            &#125;);            try &#123;                log.info(&quot;上菜 &#123;&#125; &quot;, f.get());            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125; catch (ExecutionException e) &#123;                e.printStackTrace();            &#125;        &#125;);        executorService.execute(() -&gt; &#123;            log.info(&quot;处理点餐&quot;);            Future&lt;String&gt; f2 = executorService.submit(() -&gt; &#123;                log.info(&quot;做菜&quot;);                return cooking();            &#125;);            try &#123;                log.info(&quot;上菜 &#123;&#125; &quot;, f2.get());            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125; catch (ExecutionException e) &#123;                e.printStackTrace();            &#125;        &#125;);    &#125;&#125;</code></pre><p>创建多大的线程池合适？</p><p>过小会导致程序不能充分地利用系统资源、容易导致饥饿，过大会导致更多的线程上下文切换，占用更多内存。</p><p>CPU 密集型运算 通常采用 cpu 核数 + 1 能够实现最优的 CPU 利用率，+1 是保证当线程由于页缺失故障（操作系统）或其它原因导致暂停时，额外的这个线程就能顶上去，保证 CPU 时钟周期不被浪费。<br>I/O 密集型运算 CPU 不总是处于繁忙状态，例如，当你执行业务计算时，这时候会使用 CPU 资源，但当你执行 I/O 操作时、远程 RPC 调用时，包括进行数据库操作时，这时候 CPU 就闲下来了，你可以利用多线程提高它的利用率。<br>经验公式如下：<br>线程数 = 核数 * 期望 CPU 利用率 * 总时间 (CPU 计算时间 + 等待时间) / CPU 计算时间。<br>例如 4 核 CPU 计算时间是 50% ，其它等待时间是 50%，期望 cpu 被 100% 利用，套用公式 4 * 100% * 100% / 50% = 8。<br>例如 4 核 CPU 计算时间是 10% ，其它等待时间是 90%，期望 cpu 被 100% 利用，套用公式 4 * 100% * 100% / 10% = 40。<br>应用之定时任务<br>使用 newScheduledThreadPool 中的 scheduleAtFixedRate 这个方法可以执行定时任务。代码如下：</p><pre><code class="bash">public static void main(String[] args) &#123;        // 获取当前时间        LocalDateTime now = LocalDateTime.now();        System.out.println(now);        // 获取每周四晚时间        LocalDateTime time = now.withHour(18).withMinute(0).withSecond(0).withNano(0).with(DayOfWeek.THURSDAY);        if(now.compareTo(time) &gt; 0) &#123;            time = time.plusWeeks(1);        &#125;        long initalDelay = Duration.between(now, time).toMillis();        // 一周的时间        long period = 1000 * 60 * 60 * 24 * 7;        // initalDelay 表示当前时间与周四的时间差, period 一周的间隔时间。        ScheduledExecutorService executorService = Executors.newScheduledThreadPool(1);        // 创建一个定时任务, 每周四 18:00:00 执行。        executorService.scheduleAtFixedRate(() -&gt; &#123;            System.out.println(&quot;running&quot;);        &#125;, initalDelay, period, TimeUnit.MILLISECONDS);    &#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> 多线程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 线程 </tag>
            
            <tag> ThreadPoolExecutor </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>多线程与高并发 — synchronized底层原理</title>
      <link href="/2020/09/05/thread/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E9%AB%98%E5%B9%B6%E5%8F%91%20%E2%80%94%20synchronized%E5%BA%95%E5%B1%82%E5%8E%9F%E7%90%86/"/>
      <url>/2020/09/05/thread/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E9%AB%98%E5%B9%B6%E5%8F%91%20%E2%80%94%20synchronized%E5%BA%95%E5%B1%82%E5%8E%9F%E7%90%86/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="synchronized-原理及进阶"><a href="#synchronized-原理及进阶" class="headerlink" title="synchronized 原理及进阶"></a>synchronized 原理及进阶</h2><h3 id="synchronized-原理"><a href="#synchronized-原理" class="headerlink" title="synchronized 原理"></a>synchronized 原理</h3><pre><code>static final Object lock=new Object();    static int counter = 0;    public static void main(String[] args) &#123;        synchronized (lock) &#123;            counter++;        &#125;    &#125;</code></pre><p><strong>上面代码反编译后的部分字节码：</strong></p><pre><code> 0 getstatic #2 &lt;com/heu/test/Test17.lock&gt; # 取得lock的引用（synchronized开始了） 3 dup     # 复制操作数栈栈顶的值放入栈顶，即复制了一份lock的引用 4 astore_1 # 操作数栈栈顶的值弹出，即将lock的引用存到局部变量表中 5 monitorenter # 将lock对象的Mark Word置为指向Monitor指针 6 getstatic #3 &lt;com/concurrent/test/Test17.counter&gt; 9 iconst_110 iadd11 putstatic #3 &lt;com/concurrent/test/Test17.counter&gt;14 aload_1# 从局部变量表中取得lock的引用，放入操作数栈栈顶15 monitorexit# 将lock对象的Mark Word重置，唤醒EntryList16 goto 24 (+8)# 下面是异常处理指令，可以看到，如果出现异常，也能自动地释放锁19 astore_220 aload_121 monitorexit22 aload_223 athrow24 return</code></pre><p><strong>注意：方法级别的 synchronized 不会在字节码指令中有所体现</strong></p><h3 id="synchronized-原理进阶"><a href="#synchronized-原理进阶" class="headerlink" title="synchronized 原理进阶"></a>synchronized 原理进阶</h3><p>轻量级锁的使用场景是：如果一个对象虽然有多个线程要对它进行加锁，但是加锁的时间是错开的（也就是没有人可以竞争的），那么可以使用轻量级锁来进行优化。轻量级锁对使用者是透明的，即语法仍然是 synchronized，假设有两个方法同步块，利用同一个对象加锁：</p><pre><code>static final Object obj = new Object();public static void method1() &#123;     synchronized( obj ) &#123;         // 同步块 A         method2();     &#125;&#125;public static void method2() &#123;     synchronized( obj ) &#123;         // 同步块 B     &#125;&#125;</code></pre><ol><li>每次指向到 synchronized 代码块时，都会创建锁记录（Lock Record）对象，每个线程都会包括一个锁记录的结构，锁记录内部可以储存对象的 Mark Word 和对象引用 reference</li></ol><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210603204523508.png"></p><ol start="2"><li>让锁记录中的 Object reference 指向对象，并且尝试用 cas (compare and sweep) 替换 Object 对象的 Mark Word ，将 Mark Word 的值存入锁记录中。</li></ol><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/20210130164905217.png"></p><ol start="3"><li>如果 cas 替换成功，那么对象的对象头储存的就是锁记录的地址和状态 00 表示轻量级锁，如下所示：</li></ol><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/20210130165114847.png"></p><ol start="4"><li>如果 cas 失败，有两种情况：</li></ol><ul><li>如果是其它线程已经持有了该 Object 的轻量级锁，那么表示有竞争，首先会进行自旋锁，自旋一定次数后，如果还是失败就进入锁膨胀阶段。</li><li>如果是自己的线程已经执行了 synchronized 进行加锁，那么再添加一条 Lock Record 作为重入的计数。</li></ul><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/20210130165409613.png"></p><ol start="5"><li>当线程退出 synchronized 代码块的时候，如果获取的是取值为 null 的锁记录，表示有重入，这时重置锁记录，表示重入计数减一。</li></ol><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210603205156243.png"></p><ol start="6"><li>当线程退出 synchronized 代码块的时候，如果获取的锁记录取值不为 null，那么使用 cas 将 Mark Word 的值恢复给对象</li></ol><ul><li><p>成功则解锁成功</p></li><li><p>失败，则说明轻量级锁进行了锁膨胀或已经升级为重量级锁，进入重量级锁解锁流程。</p></li></ul><h3 id="锁膨胀"><a href="#锁膨胀" class="headerlink" title="锁膨胀"></a>锁膨胀</h3><p>如果在尝试加轻量级锁的过程中，cas 操作无法成功，这是有一种情况就是其它线程已经为这个对象加上了轻量级锁，这是就要进行锁膨胀，将轻量级锁变成重量级锁。</p><ol><li>当 Thread-1 进行轻量级加锁时，Thread-0 已经对该对象加了轻量级锁：</li></ol><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/20210130174657210.png"></p><ol start="2"><li>这时 Thread-1 加轻量级锁失败，进入锁膨胀流程：</li></ol><ul><li>即为对象申请 Monitor 锁，让 Object 指向重量级锁地址；</li><li>然后自己进入 Monitor 的 EntryList 变成 BLOCKED 状态。</li></ul><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/20210130174858951.png"></p><ol start="3"><li>当 Thread-0 退出 synchronized 同步块时，使用 cas 将 Mark Word 的值恢复给对象头，对象的对象头指向 Monitor，那么会进入重量级锁的解锁过程，即按照 Monitor 的地址找到 Monitor 对象，将 Owner 设置为 null ，唤醒 EntryList 中的 Thread-1 线程。</li></ol><h3 id="自旋优化"><a href="#自旋优化" class="headerlink" title="自旋优化"></a>自旋优化</h3><p>重量级锁竞争的时候，还可以使用自旋来进行优化，如果当前线程自旋成功（即在自旋的时候持锁的线程释放了锁），那么当前线程就可以不用进行上下文切换就获得了锁。</p><ol><li>自旋重试成功的情况：</li></ol><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210603210509276.png"></p><ol start="2"><li>自旋重试失败的情况，自旋了一定次数还是没有等到持锁的线程释放锁：</li></ol><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210603210240902.png"></p><p>自旋会占用 CPU 时间，单核 CPU 自旋就是浪费，多核 CPU 自旋才能发挥优势。在 Java 6 之后自旋锁是自适应的，比如对象刚刚的一次自旋操作成功过，那么认为这次自旋成功的可能性会高，就多自旋几次；反之，就少自旋甚至不自旋，总之，比较智能。Java 7 之后不能控制是否开启自旋功能。</p><h3 id="偏向锁"><a href="#偏向锁" class="headerlink" title="偏向锁"></a>偏向锁</h3><p>在轻量级锁中可以发现，如果同一个线程对同一个对象进行重入锁时，也需要执行 CAS 操作，这是有点耗时滴，那么 Java6 开始引入了偏向锁，只有第一次使用 CAS 时将对象的 Mark Word 头设置为偏向线程 ID，之后这个入锁线程再进行重入锁时，发现线程 ID 是自己的，那么就不用再进行 CAS 了。</p><p><strong>比较轻量级锁与偏向锁：</strong></p><pre><code>static final Object obj = new Object();public static void m1() &#123;    synchronized(obj) &#123;        // 同步块 A        m2();    &#125;&#125;public static void m2() &#123;    synchronized(obj) &#123;        // 同步块 B        m3();    &#125;&#125;public static void m3() &#123;    synchronized(obj) &#123;        // 同步块 C    &#125;&#125;</code></pre><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/20210130181026149.png"></p><p><strong>偏向状态</strong></p><p>对象头格式如下：</p><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/20210130181306490.png"></p><p><strong>一个对象的创建过程</strong></p><ul><li><p>如果开启了偏向锁（默认是开启的），那么对象刚创建之后，Mark Word 最后三位的值是 101，并且它的 Thread，epoch，age 都是 0 ，在加锁的时候进行设置这些的值。</p></li><li><p>偏向锁默认是延迟的，不会在程序启动的时候立刻生效，如果想避免延迟，可以添加虚拟机参数来禁用延迟：</p></li><li><p>XX:BiasedLockingStartupDelay=0</p></li><li><p>注意：处于偏向锁的对象解锁后，线程 id 仍存储于对象头中。</p></li><li><p>测试：</p><pre><code>public static void main(String[] args) throws InterruptedException &#123;      Test1 t = new Test1();      test.parseObjectHeader(getObjectHeader(t))；      synchronized (t)&#123;          test.parseObjectHeader(getObjectHeader(t));      &#125;      test.parseObjectHeader(getObjectHeader(t));  &#125;</code></pre></li></ul><p>​输出结果如下，三次输出的状态码都为 101：</p><pre><code>biasedLockFlag (1bit): 1    LockFlag (2bit): 01biasedLockFlag (1bit): 1    LockFlag (2bit): 01biasedLockFlag (1bit): 1    LockFlag (2bit): 01</code></pre><p>如果没有开启偏向锁，那么对象创建后最后三位的值为 001，这时候它的 hashcode、age 都为 0，hashcode 是第一次用到 hashcode 时才赋值的。在上面测试代码运行时在添加 VM 参数 -XX:-UseBiasedLocking 禁用偏向锁（禁用偏向锁则优先使用轻量级锁），退出 synchronized 状态变回 001：</p><pre><code>biasedLockFlag (1bit): 0    LockFlag (2bit): 01LockFlag (2bit): 00biasedLockFlag (1bit): 0    LockFlag (2bit): 01</code></pre><p><strong>撤销偏向锁 —hashcode 方法</strong></p><p>测试 hashCode：当调用对象的 hashcode 方法的时候就会撤销这个对象的偏向锁，因为使用偏向锁时没有位置存 hashcode 的值了。</p><ol><li>测试代码如下，使用虚拟机参数 -XX:BiasedLockingStartupDelay=0 ，确保最开始使用了偏向锁！但是结果显示程序使用了轻量级锁。</li></ol><pre><code>public static void main(String[] args) throws InterruptedException &#123;    Test1 t = new Test1();    t.hashCode();    test.parseObjectHeader(getObjectHeader(t));       synchronized (t)&#123;        test.parseObjectHeader(getObjectHeader(t));    &#125;    test.parseObjectHeader(getObjectHeader(t));&#125;</code></pre><ol start="2"><li>输出结果</li></ol><pre><code>biasedLockFlag (1bit): 0    LockFlag (2bit): 01LockFlag (2bit): 00biasedLockFlag (1bit): 0    LockFlag (2bit): 01</code></pre><p><strong>撤销偏向锁 — 其它线程使用对象</strong></p><p>这里演示的是偏向锁撤销变成轻量级锁的过程，那么就得满足轻量级锁的使用条件，就是没有线程对同一个对象进行锁竞争，使用 wait 和 notify 来辅助实现</p><ol><li><p>设置虚拟机参数 -XX:BiasedLockingStartupDelay=0 确保程序最开始使用了偏向锁！</p></li><li><p>输出结果，最开始使用的是偏向锁，但是第二个线程尝试获取对象锁时，发现本来对象偏向的是线程一，那么偏向锁就会失效，加的就是轻量级锁</p></li></ol><pre><code>static final Object lock = new Object();    public static void main(String[] args) &#123;        new Thread(() -&gt; &#123;            synchronized (lock) &#123;                log.debug(&quot;获得锁&quot;);                try &#123;//                    Thread.sleep(20000);                    lock.wait(20000);                &#125; catch (InterruptedException e) &#123;                    e.printStackTrace();                &#125;            &#125;        &#125;, &quot;t1&quot;).start();        Sleeper.sleep(1);        synchronized (lock) &#123;            log.debug(&quot;获得锁&quot;);        &#125;    &#125;</code></pre><pre><code>biasedLockFlag (1bit): 1    LockFlag (2bit): 01biasedLockFlag (1bit): 1    LockFlag (2bit): 01biasedLockFlag (1bit): 1    LockFlag (2bit): 01biasedLockFlag (1bit): 1    LockFlag (2bit): 01LockFlag (2bit): 00biasedLockFlag (1bit): 0    LockFlag (2bit): 01</code></pre><p><strong>撤销 — 调用 wait/notify</strong></p><p>会使对象的锁变成重量级锁，因为 wait/notify 方法只有重量级锁才支持。</p><p><strong>批量重偏向</strong></p><ul><li><p>如果对象虽然被多个线程访问，但是线程间不存在竞争，这时偏向 t1 的对象仍有机会重新偏向 t2 (重偏向会重置 Thread ID)。</p></li><li><p>当撤销超过 20 次后（超过阈值），JVM 会觉得是不是偏向错了，这时会在给对象加锁时，重新偏向至加锁线程。</p></li></ul><p><strong>批量撤销</strong></p><p>当撤销偏向锁的阈值超过 40 以后，就会将整个类的对象都改为不可偏向的</p><p><strong>小结</strong></p><p>从 JDK1.6 开始，synchronized 锁的实现发生了很大的变化，JVM 引入了相应的优化手段来提升 synchronized 锁的性能，这种提升涉及到偏向锁、轻量级锁以及重量级锁，从而减少锁竞争带来的用户态与内核态之间的切换，这种锁的优化实际上是通过 java 对象头中的一些标志位去实现的，对于锁的访问与改变，实际上都是与 java 对象头息息相关。</p><p>对象实例在堆中会被划分为三个部分：对象头，实例数据与对齐填充。对象头也是由三块内容来构成：</p><ul><li>Mark Word（记录了对象，锁及垃圾回收的相关信息）</li><li>指向类的指针</li><li>数组长度</li></ul><p>Mark Word 的位信息包括如下组成部分：</p><ul><li>无锁标记（hashcode、分代年龄、偏向锁标志）</li><li>偏向锁标记 （偏向线程 id）</li><li>轻量级锁标记 （锁记录）</li><li>重量级锁标记 （Monitor）</li><li>GC 标记</li></ul><p>对于 synchronized 锁来说，锁的升级主要是通过 Mark Word 中的锁标记位与是否是偏向锁标记为来达成的，synchronized 关键字的对象锁都是先从偏向锁开始，随着锁竞争的不断升级，逐步演化至轻量级锁，最后变成了重量级锁。</p><ol><li>偏向锁：针对一个线程来说的，主要作用是优化同一个线程多次获取一个锁的情况， </li></ol><ul><li><p>当一个线程执行了一个 synchronized 方法的时候，肯定能得到对象的 monitor ，这个方法所在的对象就会在 Mark Work 处设为偏向锁标记，还会有一个字段指向拥有锁的这个线程的线程 ID 。</p></li><li><p>当这个线程再次访问同一个 synchronized 方法的时候，如果按照通常的方法，这个线程还是要尝试获取这个对象的 monitor ，再执行这个 synchronized 方法。</p></li><li><p>但是由于 Mark Word 的存在，当第二个线程再次来访问的时候，就会检查这个对象的 Mark Word 的偏向锁标记，再判断一下这个字段记录的线程 ID 是不是跟第二个线程的 ID 是否相同的。如果相同，就无需再获取 monitor 了，直接进入方法体中。</p></li></ul><ol start="2"><li><p>如果是另一个线程访问这个 synchronized 方法，那么实际情况会如何呢？：偏向锁会被取消掉。</p></li><li><p>轻量级锁：若第一个线程已经获取到了当前对象的锁，这时第二个线程又开始尝试争抢该对象的锁，由于该对象的锁已经被第一个线程获取到，因此它是偏向锁，而第二个线程再争抢时，会发现该对象头中的 Mark Word 已经是偏向锁，但里面储存的线程 ID 并不是自己（是第一个线程），那么它会进行 CAS (Compare and Swap)，从而获取到锁，这里面存在两种情况：</p></li></ol><ul><li><p>获取到锁成功（一共只有两个线程）：那么它会将 Mark Word 中的线程 ID 由第一个线程变成自己 (偏向锁标记位保持不表)，这样该对象依然会保持偏向锁的状态。</p></li><li><p>获取锁失败（一共不止两个线程）：则表示这时可能会有多个线程同时再尝试争抢该对象的锁，那么这是偏向锁就会进行升级，升级为轻量级锁。</p></li></ul><p>4.自旋锁，若自旋失败，那么锁就会转化为重量级锁，在这种情况下，无法获取到锁的线程都会进入到 moniter (即内核态)，自旋最大的特点是避免了线程从用户态进入到内核态。</p>]]></content>
      
      
      <categories>
          
          <category> 多线程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Monitor </tag>
            
            <tag> synchronized </tag>
            
            <tag> wait/notify </tag>
            
            <tag> park/unpark </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>多线程与高并发 — 同步锁</title>
      <link href="/2020/09/03/thread/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E9%AB%98%E5%B9%B6%E5%8F%91%20%E2%80%94%20%E5%90%8C%E6%AD%A5%E9%94%81/"/>
      <url>/2020/09/03/thread/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E9%AB%98%E5%B9%B6%E5%8F%91%20%E2%80%94%20%E5%90%8C%E6%AD%A5%E9%94%81/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="共享模型之管程"><a href="#共享模型之管程" class="headerlink" title="共享模型之管程"></a>共享模型之管程</h1><h2 id="线程共享带来的问题"><a href="#线程共享带来的问题" class="headerlink" title="线程共享带来的问题"></a>线程共享带来的问题</h2><p>线程出现问题的根本原因是因为线程上下文切换，导致线程里的指令没有执行完就切换执行其它线程了。</p><pre><code>public static int count = 0;    public static void main(String[] args) throws InterruptedException &#123;        Thread t1 = new Thread(() -&gt; &#123;            for (int i = 1;i &lt; 5000; i++)&#123;                count++;            &#125;        &#125;);        Thread t2 = new Thread(() -&gt; &#123;            for (int i = 1;i &lt; 5000; i++)&#123;                count--;            &#125;        &#125;);        t1.start();        t2.start();        t1.join();        t2.join();        log.debug(&quot;count的值是&#123;&#125;&quot;,count);    &#125;</code></pre><p>如上代码，当执行 count++ 或者 count– 操作的时候，从字节码分析，实际上是 4 步操作：</p><pre><code>count++; // 操作字节码如下：getstatic i // 获取静态变量i的值iconst_1 // 准备常量1iadd // 自增putstatic i // 将修改后的值存入静态变量icount--; // 操作字节码如下：getstatic i // 获取静态变量i的值iconst_1 // 准备常量1isub // 自减putstatic i // 将修改后的值存入静态变量i</code></pre><p>如果上面代码是单线程按顺序运行的，那么 count 的值不会计算错，执行过程如下图所示：</p><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210603162020219.png"></p><p>但多线程下上面代码可能交错运行，出现负数的情况：</p><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210603162438074.png"></p><p>但多线程下上面代码可能交错运行，出现正数的情况：</p><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210603162738148.png"></p><ol><li>临界区 Critical Section</li></ol><ul><li><p>一个程序运行多个线程本身是没有问题的；</p></li><li><p>问题出在多个线程访问共享资源：</p><ul><li>多个线程读共享资源其实也没有问题；</li><li>在多个线程对共享资源读写操作时发生指令交错，就会出现问题。</li></ul></li><li><p>一段代码块内如果存在对共享资源的多线程读写操作，称这段代码块为临界区。</p></li></ul><p>例如下面代码中的临界区：</p><pre><code>static int counter = 0; static void increment() // 临界区 &#123;       counter++; &#125; static void decrement() // 临界区 &#123;     counter--; &#125;</code></pre><ol start="2"><li>竞态条件 Race Condition</li></ol><p>多个线程在临界区内执行，由于代码的执行序列不同而导致结果无法预测，称之为发生了竞态条件。</p><h2 id="synchronized-解决方案"><a href="#synchronized-解决方案" class="headerlink" title="synchronized 解决方案"></a>synchronized 解决方案</h2><p>为了避免临界区中的竞态条件发生，由多种手段可以达到：</p><ul><li>阻塞式解决方案：synchronized 、Lock</li><li>非阻塞式解决方案：原子变量</li></ul><p>使用 synchronized 来进行解决，即俗称的对象锁，它采用互斥的方式让同一时刻至多只有一个线程持有对象锁，其他线程如果想获取这个锁就会阻塞住，这样就能保证拥有锁的线程可以安全的执行临界区内的代码，不用担心线程上下文切换。</p><blockquote><p>注意：虽然 java 中互斥和同步都可以采用 synchronized 关键字来完成，但它们还是有区别的：</p></blockquote><ul><li>互斥是保证临界区的竞态条件发生，同一时刻只能有一个线程执行临界区代码。</li><li>同步是由于线程执行的先后、顺序不同，需要一个线程等待其它线程运行到某个点。</li></ul><p><strong>synchronized 语法</strong></p><pre><code>synchronized(对象) &#123;    //临界区&#125;</code></pre><p>上面的实例程序使用 synchronized 后如下，计算出的结果是正确！</p><pre><code>static int counter = 0;static final Object room = new Object();public static void main(String[] args) throws InterruptedException &#123;     Thread t1 = new Thread(() -&gt; &#123;         for (int i = 0; i &lt; 5000; i++) &#123;             synchronized (room) &#123;             counter++;            &#125;         &#125;     &#125;, &quot;t1&quot;);     Thread t2 = new Thread(() -&gt; &#123;         for (int i = 0; i &lt; 5000; i++) &#123;             synchronized (room) &#123;             counter--;         &#125;     &#125;     &#125;, &quot;t2&quot;);     t1.start();     t2.start();     t1.join();     t2.join();     log.debug(&quot;&#123;&#125;&quot;,counter);&#125;</code></pre><p>synchronized 实际上利用对象保证了临界区代码的原子性，临界区内的代码在外界看来是不可分割的，不会被线程切换所打断。</p><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210603182210273.png"></p><h2 id="synchronized-加在方法上"><a href="#synchronized-加在方法上" class="headerlink" title="synchronized 加在方法上"></a>synchronized 加在方法上</h2><pre><code>class Test&#123;        public synchronized void test() &#123;        &#125;    &#125;    //等价于锁住对象    class Test&#123;        public void test() &#123;            synchronized(this) &#123;            &#125;        &#125;    &#125;    class Test&#123;        public synchronized static void test() &#123;        &#125;    &#125;   // 等价于锁住类    class Test&#123;        public static void test() &#123;            synchronized(Test.class) &#123;            &#125;        &#125;    &#125;</code></pre><h2 id="所谓的线程八锁"><a href="#所谓的线程八锁" class="headerlink" title="所谓的线程八锁"></a>所谓的线程八锁</h2><p><strong>其实就是考察 synchronized 锁住的是哪个对象。</strong></p><ul><li>情况 1：12 或 21</li></ul><pre><code>class Number&#123;     public synchronized void a() &#123;         log.debug(&quot;1&quot;);     &#125;     public synchronized void b() &#123;         log.debug(&quot;2&quot;);     &#125;&#125;public static void main(String[] args) &#123;     Number n1 = new Number();     new Thread(()-&gt;&#123; n1.a(); &#125;).start();     new Thread(()-&gt;&#123; n1.b(); &#125;).start();&#125;</code></pre><ul><li>情况 2：1s 后 12，或 2 1s 后 1</li></ul><pre><code>class Number&#123;     public synchronized void a() &#123;        sleep(1);         log.debug(&quot;1&quot;);     &#125;     public synchronized void b() &#123;         log.debug(&quot;2&quot;);     &#125;&#125;public static void main(String[] args) &#123;     Number n1 = new Number();     new Thread(()-&gt;&#123; n1.a(); &#125;).start();     new Thread(()-&gt;&#123; n1.b(); &#125;).start();&#125;</code></pre><ul><li>情况 3：3 1s 12 或 2 3 1s 1 或 32 1s 1</li></ul><pre><code>class Number&#123;     public synchronized void a() &#123;        sleep(1);         log.debug(&quot;1&quot;);     &#125;     public synchronized void b() &#123;         log.debug(&quot;2&quot;);     &#125;    public synchronized void c() &#123;         log.debug(&quot;3&quot;);     &#125;&#125;public static void main(String[] args) &#123;     Number n1 = new Number();     new Thread(()-&gt;&#123; n1.a(); &#125;).start();     new Thread(()-&gt;&#123; n1.b(); &#125;).start();    new Thread(()-&gt;&#123; n1.c(); &#125;).start();&#125;</code></pre><ul><li>情况 4：2 1s 后 1</li></ul><pre><code>class Number&#123;     public synchronized void a() &#123;        sleep(1);         log.debug(&quot;1&quot;);     &#125;     public synchronized void b() &#123;         log.debug(&quot;2&quot;);     &#125;&#125;public static void main(String[] args) &#123;     Number n1 = new Number();    Number n2 = new Number();     new Thread(()-&gt;&#123; n1.a(); &#125;).start();     new Thread(()-&gt;&#123; n2.b(); &#125;).start();&#125;</code></pre><ul><li>情况 5：2 1s 后 1</li></ul><pre><code>class Number&#123;     public static synchronized void a() &#123;        sleep(1);         log.debug(&quot;1&quot;);     &#125;     public synchronized void b() &#123;         log.debug(&quot;2&quot;);     &#125;&#125;//对象锁 b方法获得public static void main(String[] args) &#123;     Number n1 = new Number();    Number n2 = new Number();     new Thread(()-&gt;&#123; n1.a(); &#125;).start();     new Thread(()-&gt;&#123; n2.b(); &#125;).start();&#125;</code></pre><p>情况 6：1s 后 12， 或 2 1s 后 1</p><pre><code>class Number&#123;     public static synchronized void a() &#123;        sleep(1);         log.debug(&quot;1&quot;);     &#125;     public static synchronized void b() &#123;         log.debug(&quot;2&quot;);     &#125;&#125;public static void main(String[] args) &#123;     Number n1 = new Number();     new Thread(()-&gt;&#123; n1.a(); &#125;).start();     new Thread(()-&gt;&#123; n1.b(); &#125;).start();&#125;</code></pre><ul><li>情况 7：2 1s 后 1</li></ul><pre><code>class Number&#123;     public static synchronized void a() &#123;        sleep(1);         log.debug(&quot;1&quot;);     &#125;     public synchronized void b() &#123;         log.debug(&quot;2&quot;);     &#125;&#125;//对象锁 b方法获得public static void main(String[] args) &#123;     Number n1 = new Number();    Number n2 = new Number();     new Thread(()-&gt;&#123; n1.a(); &#125;).start();     new Thread(()-&gt;&#123; n2.b(); &#125;).start();&#125;</code></pre><ul><li>情况 8：1s 后 12， 或 2 1s 后 1</li></ul><pre><code>class Number&#123;     public static synchronized void a() &#123;        sleep(1);         log.debug(&quot;1&quot;);     &#125;     public static synchronized void b() &#123;         log.debug(&quot;2&quot;);     &#125;&#125;//对象锁 b方法获得public static void main(String[] args) &#123;     Number n1 = new Number();    Number n2 = new Number();     new Thread(()-&gt;&#123; n1.a(); &#125;).start();     new Thread(()-&gt;&#123; n2.b(); &#125;).start();&#125;</code></pre><h2 id="变量的线程安全分析"><a href="#变量的线程安全分析" class="headerlink" title="变量的线程安全分析"></a>变量的线程安全分析</h2><h3 id="成员变量和静态变量的线程安全分析"><a href="#成员变量和静态变量的线程安全分析" class="headerlink" title="成员变量和静态变量的线程安全分析"></a>成员变量和静态变量的线程安全分析</h3><ul><li><p>如果它们没有共享，则线程安全。</p></li><li><p>如果它们被共享了，根据它们的状态是否能够改变，又分两种情况：</p><ul><li>如果只有读操作，则线程安全；</li><li>如果有读写操作，则这段代码是临界区，需要考虑线程安全。</li></ul></li></ul><h3 id="局部变量线程安全分析"><a href="#局部变量线程安全分析" class="headerlink" title="局部变量线程安全分析"></a>局部变量线程安全分析</h3><p><strong>局部变量是否线程安全？</strong></p><ul><li><p>局部变量是线程安全的。</p></li><li><p>但局部变量引用的对象则未必：</p><ul><li>如果该对象没有逃离方法的作用范围，它是线程安全的；</li><li>如果该对象逃离方法的作用范围，需要考虑线程安全。</li></ul></li></ul><p><strong>线程安全的情况</strong></p><p>局部变量【局部变量被初始化为基本数据类型】是安全的，示例如下：</p><pre><code>public static void test1() &#123;     int i = 10;     i++;&#125;</code></pre><p>每个线程调用 test1 () 方法时，局部变量会在每个线程的栈帧内存中被创建多份，是彼此隔离的，因此不存在共享。</p><p><strong>线程不安全的情况</strong></p><p>如果局部变量引用的对象逃离方法的范围，那么要考虑线程安全的，分析如下代码：</p><pre><code>public class Test &#123;    public static void main(String[] args) &#123;        UnsafeTest unsafeTest = new UnsafeTest();        for(int i = 0; i &lt; 10; i++) &#123;            new Thread(() -&gt; &#123;                unsafeTest.method1();            &#125;, &quot;t&quot; + i).start();        &#125;    &#125;&#125;class UnsafeTest &#123;    List&lt;Integer&gt; list = new ArrayList&lt;&gt;();    public void method1() &#123;        for (int i = 0; i &lt; 200; i++) &#123;            method2();            method3();        &#125;    &#125;    public void method2() &#123;        list.add(1);    &#125;    public void method3() &#123;        list.remove(0);    &#125;&#125;</code></pre><p><strong>不安全原因分析</strong></p><p>无论哪个线程中的 method2 和 method3 引用的都是同一个对象中的 list 成员变量：一个 ArrayList ，在添加一个元素的时候，它可能会有两步来完成：</p><ol><li><p>第一步，在 arrayList [Size] 的位置存放此元素； 第二步增大 Size 的值。</p></li><li><p>在单线程运行的情况下，如果 Size = 0，添加一个元素后，此元素在位置 0，而且 Size=1；而如果是在多线程情下，比如有两个线程，线程 一先将元素存放在位置 0，但是此时发生上下文切换，线程 B 得到运行的机会，线程 B 也向此 ArrayList 添加元素，因为此时 Size 仍等于 0 ，所以线程二也将元素存放在位置 0，然后线程一和线程二都继续运行，都增加 Size 的值。 那好，现在看看 ArrayList 的情况，元素实际上只有一个，存放在位置 0，而 Size 却等于 2。这就是线程不安全了。</p></li></ol><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/20200307215429-139261.png"></p><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/20210129145229674.png"></p><p><strong>解决方法</strong></p><p>可以将 list 修改成局部变量，然后将 list 作为引用传入方法中，因为局部变量是每个线程私有的，不会出现共享问题，那么就不会有上述问题了。修改的代码如下：</p><pre><code>class SafeTest &#123;    public void method1() &#123;         List&lt;Integer&gt; list = new ArrayList&lt;&gt;();        for (int i = 0; i &lt; 200; i++) &#123;            method2(list);            method3(list);        &#125;    &#125;    public void method2(List&lt;Integer&gt; list) &#123;        list.add(1);    &#125;    public void method3(List&lt;Integer&gt; list) &#123;        list.remove(0);    &#125;&#125;</code></pre><p><strong>思考 private 或 final 的重要性</strong></p><p>在上诉代码中，其实存在线程安全的问题，因为 method2，method3 方法都是用 public 声明的，如果一个类继承 SafeTest 类，对 method2，method3 方法进行了重写，比如重写 method3 方法，代码如下：</p><pre><code>class UnsafeSubTest extends UnsafeTest &#123;    @Override    public void method3(List&lt;Integer&gt; list) &#123;        new Thread(() -&gt; &#123;            list.remove(0);        &#125;).start();    &#125;&#125;</code></pre><p>可以看到重写的方法中又使用到了线程，当主线程和重写的 method3 方法的线程同时存在，此时 list 就是这两个线程的共享资源了，就会出现线程安全问题，我们可以用 private 访问修饰符解决此问题，代码实现如下：</p><pre><code>class ThreadSafe &#123;    public final void method1(int loopNumber) &#123;        ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;();        for (int i = 0; i &lt; loopNumber; i++) &#123;            method2(list);            method3(list);        &#125;    &#125;    private void method2(ArrayList&lt;String&gt; list) &#123;        list.add(&quot;1&quot;);    &#125;    private void method3(ArrayList&lt;String&gt; list) &#123;        list.remove(0);    &#125;&#125;class ThreadSafeSubClass extends ThreadSafe&#123;    @Override    public void method3(ArrayList&lt;String&gt; list) &#123;        new Thread(() -&gt; &#123;            list.remove(0);        &#125;).start();    &#125;&#125;</code></pre><h3 id="常见线程安全类"><a href="#常见线程安全类" class="headerlink" title="常见线程安全类"></a>常见线程安全类</h3><ul><li>String</li><li>StringBuﬀer</li><li>Random</li><li>Vector （List 的线程安全实现类）</li><li>Hashtable （Hash 的线程安全实现类）</li><li>java.util.concurrent 包下的类</li></ul><p>这里说它们是线程安全的是指：多个线程调用它们同一个实例的某个方法时，是线程安全的。如：</p><pre><code>Hashtable table = new Hashtable();new Thread(()-&gt;&#123;     table.put(&quot;key1&quot;, &quot;value1&quot;);&#125;).start();new Thread(()-&gt;&#123;     table.put(&quot;key2&quot;, &quot;value2&quot;);&#125;).start();</code></pre><p><strong>线程安全类方法的组合</strong></p><p>但注意它们多个方法的组合不是原子的，看如下代码：</p><pre><code>Hashtable table = new Hashtable();// 线程1，线程2if( table.get(&quot;key&quot;) == null) &#123; table.put(&quot;key&quot;, value);&#125;</code></pre><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/2021012916122421.png"></p><p>如上图所示，当使用方法组合时，出现了线程安全问题，当线程 1 执行完 get (“key”) ，这是一个原子操作没问题，但是在 get (“key”) == null 比较时，如果线程的时间片用完了，线程 2 获取时间片执行了 get (“key”) == null 操作，然后进行 put (“key”, “v2”) 操作，结束后，线程 1 被分配 cpu 时间片继续执行，执行 put 操作就会出现线程安全问题。</p><p><strong>不可变类的线程安全</strong></p><p>String 和 Integer 类都是不可变的类，因为其类内部状态是不可改变的，因此它们的方法都是线程安全的。疑问是 String 有 replace，substring 等方法可以改变值啊，其实调用这些方法返回的已经是一个新创建的对象了！</p><pre><code>public String substring(int beginIndex, int endIndex) &#123;        if (beginIndex &lt; 0) &#123;            throw new StringIndexOutOfBoundsException(beginIndex);        &#125;        if (endIndex &gt; value.length) &#123;            throw new StringIndexOutOfBoundsException(endIndex);        &#125;        int subLen = endIndex - beginIndex;        if (subLen &lt; 0) &#123;            throw new StringIndexOutOfBoundsException(subLen);        &#125;        return ((beginIndex == 0) &amp;&amp; (endIndex == value.length)) ? this                : new String(value, beginIndex, subLen); // 新建一个对象，然后返回，没有修改等操作，是线程安全的。    &#125;</code></pre><p><strong>示例分析 - 是否线程安全</strong></p><p>分析线程是否安全，先对类的成员变量，类变量，局部变量进行考虑，如果变量会在各个线程之间共享，那么就得考虑线程安全问题了，如果变量 A 引用的是线程安全类的实例，并且只调用该线程安全类的一个方法，那么该变量 A 是线程安全的的。</p><blockquote><p>示例一：此类不是线程安全的，MyAspect 切面类只有一个实例，成员变量 start 会被多个线程同时进行读写操作。</p></blockquote><pre><code>@Aspect@Componentpublic class MyAspect &#123;        // 是否安全？        private long start = 0L;        @Before(&quot;execution(* *(..))&quot;)        public void before() &#123;            start = System.nanoTime();        &#125;        @After(&quot;execution(* *(..))&quot;)        public void after() &#123;            long end = System.nanoTime();            System.out.println(&quot;cost time:&quot; + (end-start));        &#125;    &#125;</code></pre><blockquote><p>示例二：MyServlet、UserServiceImpl、UserDaoImpl 类都只有一个实例，UserDaoImpl 类中没有成员变量，update 方法里的变量引用的对象不是线程共享的，所以是线程安全的；UserServiceImpl 类中只有一个线程安全的 UserDaoImpl 类的实例，那么 UserServiceImpl 类也是线程安全的，同理 MyServlet 也是线程安全的。</p></blockquote><pre><code>public class MyServlet extends HttpServlet &#123; // 是否安全     private UserService userService = new UserServiceImpl();     public void doGet(HttpServletRequest request, HttpServletResponse response) &#123;         userService.update(...);     &#125;&#125;public class UserServiceImpl implements UserService &#123;     // 是否安全     private UserDao userDao = new UserDaoImpl();     public void update() &#123;         userDao.update();     &#125;&#125;public class UserDaoImpl implements UserDao &#123;     public void update() &#123;     String sql = &quot;update user set password = ? where username = ?&quot;;     // 是否安全     try (Connection conn = DriverManager.getConnection(&quot;&quot;,&quot;&quot;,&quot;&quot;))&#123;         // ...     &#125; catch (Exception e) &#123;     // ...     &#125;  &#125;&#125;</code></pre><blockquote><p>示例三：跟示例二大体相似，UserDaoImpl 类中有成员变量，那么多个线程可以对成员变量 conn 同时进行操作，故是不安全的。</p></blockquote><pre><code>public class MyServlet extends HttpServlet &#123;    // 是否安全    private UserService userService = new UserServiceImpl();    public void doGet(HttpServletRequest request, HttpServletResponse response) &#123;        userService.update(...);    &#125;&#125;public class UserServiceImpl implements UserService &#123;    // 是否安全    private UserDao userDao = new UserDaoImpl();    public void update() &#123;        userDao.update();    &#125;&#125;public class UserDaoImpl implements UserDao &#123;    // 是否安全    private Connection conn = null;    public void update() throws SQLException &#123;        String sql = &quot;update user set password = ? where username = ?&quot;;        conn = DriverManager.getConnection(&quot;&quot;,&quot;&quot;,&quot;&quot;);        // ...        conn.close();    &#125;&#125;</code></pre><blockquote><p>示例四：跟示例三大体相似，UserServiceImpl 类的 update 方法中 UserDao 是作为局部变量存在的，所以每个线程访问的时候都会新建有一个 UserDao 对象，新建的对象是线程独有的，所以是线程安全的。</p></blockquote><pre><code>public class MyServlet extends HttpServlet &#123;    // 是否安全    private UserService userService = new UserServiceImpl();    public void doGet(HttpServletRequest request, HttpServletResponse response) &#123;        userService.update(...);    &#125;&#125;public class UserServiceImpl implements UserService &#123;    public void update() &#123;        UserDao userDao = new UserDaoImpl();        userDao.update();    &#125;&#125;public class UserDaoImpl implements UserDao &#123;    // 是否安全    private Connection = null;    public void update() throws SQLException &#123;        String sql = &quot;update user set password = ? where username = ?&quot;;        conn = DriverManager.getConnection(&quot;&quot;,&quot;&quot;,&quot;&quot;);        // ...        conn.close();    &#125;&#125;</code></pre><blockquote><p>示例五：</p></blockquote><p>public abstract class Test {<br>    public void bar() {<br>        // 是否安全<br>        SimpleDateFormat sdf = new SimpleDateFormat(“yyyy-MM-dd HH:mm:ss”);<br>        foo(sdf);<br>    }<br>    public abstract foo(SimpleDateFormat sdf);<br>    public static void main(String[] args) {<br>        new Test().bar();<br>    }<br>}<br>其中 foo 的行为是不确定的，可能导致不安全的发生，被称之为外星方法，因为 foo 方法可以被重写，导致线程不安全。在 String 类中就考虑到了这一点，String 类是 final 关键字声明的，子类不能重写它的方法。</p><pre><code>public void foo(SimpleDateFormat sdf) &#123;    String dateStr = &quot;1999-10-11 00:00:00&quot;;    for (int i = 0; i &lt; 20; i++) &#123;        new Thread(() -&gt; &#123;            try &#123;                sdf.parse(dateStr);            &#125; catch (ParseException e) &#123;                e.printStackTrace();            &#125;        &#125;).start();    &#125;&#125;</code></pre><h2 id="案例分析-—-卖票"><a href="#案例分析-—-卖票" class="headerlink" title="案例分析 — 卖票"></a>案例分析 — 卖票</h2><pre><code>import lombok.extern.slf4j.Slf4j;import java.util.ArrayList;import java.util.List;import java.util.Random;import java.util.Vector;public class ExerciseSell &#123;    public static void main(String[] args) throws InterruptedException &#123;        // 模拟多人买票        TicketWindow window = new TicketWindow(1000);        // 所有线程的集合        List&lt;Thread&gt; threadList = new ArrayList&lt;&gt;();        // 卖出的票数统计        List&lt;Integer&gt; amountList = new Vector&lt;&gt;();        for (int i = 0; i &lt; 2000; i++) &#123;            Thread thread = new Thread(() -&gt; &#123;                // 买票                int amount = window.sell(random(5));                // 统计买票数                amountList.add(amount);            &#125;);            threadList.add(thread);            thread.start();        &#125;        for (Thread thread : threadList) &#123;            thread.join();        &#125;        // 统计卖出的票数和剩余票数        log.debug(&quot;余票：&#123;&#125;&quot;,window.getCount());        log.debug(&quot;卖出的票数：&#123;&#125;&quot;, amountList.stream().mapToInt(i-&gt; i).sum());    &#125;    // Random 为线程安全    static Random random = new Random();    // 随机 1~5    public static int random(int amount) &#123;        return random.nextInt(amount) + 1;    &#125;&#125;// 售票窗口class TicketWindow &#123;    private int count;    public TicketWindow(int count) &#123;        this.count = count;    &#125;    // 获取余票数量    public int getCount() &#123;        return count;    &#125;    // 售票    public synchronized int sell(int amount) &#123;        if (this.count &gt;= amount) &#123;            this.count -= amount;            return amount;        &#125; else &#123;            return 0;        &#125;    &#125;&#125;</code></pre><h2 id="Monitor-概念"><a href="#Monitor-概念" class="headerlink" title="Monitor 概念"></a>Monitor 概念</h2><h3 id="Java-对象头"><a href="#Java-对象头" class="headerlink" title="Java 对象头"></a>Java 对象头</h3><p>以 32 位虚拟机为例，普通对象的对象头结构如下，其中的 Klass Word 为指针，指向对应的 Class 对象。</p><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/20200308223951-617147.png"></p><p><strong>数组对象</strong></p><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/20210130134453728.png"></p><p><strong>其中 Mark Word 结构为：</strong></p><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/20210130134641162.png"></p><p>所以一个对象的结构如下：</p><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/20200308224345-655905.png"></p><h3 id="Monitor-原理"><a href="#Monitor-原理" class="headerlink" title="Monitor 原理"></a>Monitor 原理</h3><p>Monitor 被翻译为监视器或者说管程，每个 java 对象都可以关联一个 Monitor，如果使用 synchronized 给对象上锁（重量级），该对象头的 Mark Word 中就被设置为指向 Monitor 对象的指针。</p><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/20210130135025351.png"></p><ul><li><p>刚开始时 Monitor 中的 Owner 为 null；</p></li><li><p>当 Thread-2 执行 synchronized (obj){} 代码时就会将 Monitor 的所有者 Owner 设置为 Thread-2，上锁成功，Monitor 中同一时刻只能有一个 Owner；</p></li><li><p>当 Thread-2 占据锁时，如果线程 Thread-3 ，Thread-4 也来执行 synchronized (obj){} 代码，就会进入 EntryList（阻塞队列） 中变成 BLOCKED（阻塞） 状态；</p></li><li><p>Thread-2 执行完同步代码块的内容，然后唤醒 EntryList 中等待的线程来竞争锁，竞争时是非公平的；</p></li><li><p>图中 WaitSet 中的 Thread-0，Thread-1 是之前获得过锁，但条件不满足进入 WAITING 状态的线程，后面讲 wait-notify 时会分析。</p></li></ul><blockquote><p>注意：synchronized 必须是进入同一个对象的 monitor 才有上述的效果，不加 synchronized 的对象不会关联监视器，不遵从以上规则。</p></blockquote><h2 id="wait-和-notify"><a href="#wait-和-notify" class="headerlink" title="wait 和 notify"></a>wait 和 notify</h2><ul><li><p>obj.wait () 让进入 object 监视器的线程到 waitSet 等待。</p></li><li><p>obj.notify () 在 object 上正在 waitSet 等待的线程中挑一个唤醒。</p></li><li><p>obj.notifyAll () 让 object 上正在 waitSet 等待的线程全部唤醒。</p></li></ul><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/20210130214454663.png"></p><ul><li><p>锁对象调用 wait 方法（obj.wait），就会使当前线程进入 WaitSet 中，变为 WAITING 状态。</p></li><li><p>处于 BLOCKED 和 WAITING 状态的线程都为阻塞状态，CPU 都不会分给他们时间片。但是有所区别：</p><ul><li><p>BLOCKED 状态的线程是在竞争对象时，发现 Monitor 的 Owner 已经是别的线程了，此时就会进入 EntryList 中，并处于 BLOCKED 状态。</p></li><li><p>WAITING 状态的线程是获得了对象的锁，但是自身因为某些原因需要进入阻塞状态时，锁对象调用了 wait 方法而进入了 WaitSet 中，处于 WAITING 状态。</p></li><li><p>BLOCKED 状态的线程会在锁被释放的时候被唤醒，但是处于 WAITING 状态的线程只有被锁对象调用了 notify 方法 (obj.notify/obj.notifyAll)，才会被唤醒。</p></li></ul></li></ul><blockquote><p>注：只有当对象加锁以后，才能调用 wait 和 notify 方法。</p></blockquote><h3 id="Wait-与-Sleep-的区别"><a href="#Wait-与-Sleep-的区别" class="headerlink" title="Wait 与 Sleep 的区别"></a>Wait 与 Sleep 的区别</h3><ul><li><p>Sleep 是 Thread 类的静态方法，Wait 是 Object 的方法，Object 又是所有类的父类，所以所有类都有 Wait 方法。</p></li><li><p>Sleep 在阻塞的时候不会释放锁，而 Wait 在阻塞的时候会释放锁，它们都会释放 CPU 资源。</p></li><li><p>Sleep 不需要与 synchronized 一起使用，而 Wait 需要与 synchronized 一起使用（对象被锁以后才能使用）</p></li><li><p>使用 wait 一般需要搭配 notify 或者 notifyAll 来使用，不然会让线程一直等待。</p></li></ul><h3 id="优雅地使用-wait-notify"><a href="#优雅地使用-wait-notify" class="headerlink" title="优雅地使用 wait/notify"></a>优雅地使用 wait/notify</h3><p><strong>什么时候适合使用 wait？</strong></p><ul><li>当线程不满足某些条件，需要暂停运行时，可以使用 wait 。这样会将对象的锁释放，让其他线程能够继续运行。如果此时使用 sleep，会导致所有线程都进入阻塞，导致所有线程都没法运行，直到当前线程 sleep 结束后，运行完毕，才能得到执行。</li></ul><p><strong>使用 wait/notify 需要注意什么？</strong></p><ul><li>当有多个线程在运行时，对象调用了 wait 方法，此时这些线程都会进入 WaitSet 中等待。如果这时使用了 notify 方法，可能会造成虚假唤醒（唤醒的不是满足条件的等待线程），这时就需要使用 notifyAll 方法。</li></ul><pre><code>synchronized (lock) &#123;    while(//不满足条件，一直等待，避免虚假唤醒) &#123;        lock.wait();    &#125;    //满足条件后再运行&#125;synchronized (lock) &#123;    //唤醒所有等待线程    lock.notifyAll();&#125;</code></pre><p><strong>示例</strong></p><pre><code>@Slf4jpublic class TestWait &#123;    static final Object room = new Object();    static boolean hasCigarette = false;    static boolean hasTakeout = false;    public static void main(String[] args) throws InterruptedException &#123;        new Thread(()-&gt;&#123;            synchronized (room) &#123;                log.debug(&quot;有烟吗？[&#123;&#125;]&quot;,hasCigarette);                if (!hasCigarette) &#123;                    log.debug(&quot;没烟，歇会&quot;);                    try &#123;                        Thread.sleep(2000);                    &#125; catch (InterruptedException e) &#123;                        e.printStackTrace();                    &#125;                &#125;                log.debug(&quot;有烟没？[&#123;&#125;]&quot;,hasCigarette);                if (hasCigarette) &#123;                    log.debug(&quot;可以干活了&quot;);                &#125;            &#125;        &#125;,&quot;t1&quot;).start();        for (int i = 0; i &lt; 5; i++) &#123;            new Thread(() -&gt; &#123;                synchronized (room) &#123;                    log.debug(&quot;可以干活了&quot;);                &#125;            &#125;,&quot;其他人&quot;).start();        &#125;        Thread.sleep(1000);        new Thread(() -&gt; &#123;            hasCigarette = true;            log.debug(&quot;烟来了&quot;);        &#125;,&quot;送烟的&quot;).start();    &#125;&#125;</code></pre><p>输出：</p><pre><code>19:26:21.111 [t1] DEBUG com.heu.test.TestWait - 有烟吗？[false]19:26:21.123 [t1] DEBUG com.heu.test.TestWait - 没烟，歇会19:26:22.116 [送烟的] DEBUG com.heu.test.TestWait - 烟来了19:26:23.134 [t1] DEBUG com.heu.test.TestWait - 有烟没？[true]19:26:23.134 [t1] DEBUG com.heu.test.TestWait - 可以干活了19:26:23.134 [其他人] DEBUG com.heu.test.TestWait - 可以干活了19:26:23.135 [其他人] DEBUG com.heu.test.TestWait - 可以干活了19:26:23.135 [其他人] DEBUG com.heu.test.TestWait - 可以干活了19:26:23.135 [其他人] DEBUG com.heu.test.TestWait - 可以干活了19:26:23.136 [其他人] DEBUG com.heu.test.TestWait - 可以干活了</code></pre><ul><li><p>其它干活的线程，都要一直阻塞，效率太低；</p></li><li><p>t1 线程必须睡足 2s 后才能醒来，就算烟提前送到，也无法立刻醒来；</p></li><li><p>加了 synchronized (room) 后，就好比 t1 线程在里面反锁了门睡觉，烟根本没法送进门，而 main 线程没加 synchronized 就好像 main 线程是翻窗户进来的；</p></li><li><p>解决方法，使用 wait - notify 机制。</p></li></ul><p>思考下面的实现行吗，为什么？</p><pre><code>@Slf4jpublic class TestWait &#123;    static final Object room = new Object();    static boolean hasCigarette = false;    static boolean hasTakeout = false;    public static void main(String[] args) throws InterruptedException &#123;        new Thread(()-&gt;&#123;            synchronized (room) &#123;                log.debug(&quot;有烟吗？[&#123;&#125;]&quot;,hasCigarette);                if (!hasCigarette) &#123;                    log.debug(&quot;没烟，歇会&quot;);                    try &#123;                        room.wait(2000);                    &#125; catch (InterruptedException e) &#123;                        e.printStackTrace();                    &#125;                &#125;                log.debug(&quot;有烟没？[&#123;&#125;]&quot;,hasCigarette);                if (hasCigarette) &#123;                    log.debug(&quot;可以干活了&quot;);                &#125;            &#125;        &#125;,&quot;t1&quot;).start();        for (int i = 0; i &lt; 5; i++) &#123;            new Thread(() -&gt; &#123;                synchronized (room) &#123;                    log.debug(&quot;可以干活了&quot;);                &#125;            &#125;,&quot;其他人&quot;).start();        &#125;        Thread.sleep(1000);        new Thread(() -&gt; &#123;            synchronized (room) &#123;                hasCigarette = true;                log.debug(&quot;烟来了&quot;);                room.notify();            &#125;                   &#125;,&quot;送烟的&quot;).start();    &#125;&#125;</code></pre><p>输出：</p><pre><code>19:33:01.717 [t1] DEBUG com.heu.test.TestWait - 有烟吗？[false]19:33:01.727 [t1] DEBUG com.heu.test.TestWait - 没烟，歇会19:33:01.728 [其他人] DEBUG com.heu.test.TestWait - 可以干活了19:33:01.728 [其他人] DEBUG com.heu.test.TestWait - 可以干活了19:33:01.729 [其他人] DEBUG com.heu.test.TestWait - 可以干活了19:33:01.729 [其他人] DEBUG com.heu.test.TestWait - 可以干活了19:33:01.729 [其他人] DEBUG com.heu.test.TestWait - 可以干活了19:33:02.717 [送烟的] DEBUG com.heu.test.TestWait - 烟来了19:33:02.717 [t1] DEBUG com.heu.test.TestWait - 有烟没？[true]19:33:02.717 [t1] DEBUG com.heu.test.TestWait - 可以干活了</code></pre><ul><li>解决了其它干活的线程阻塞的问题；</li><li>但如果有其它线程也在等待条件呢。</li></ul><p>这样呢？</p><pre><code>new Thread(()-&gt;&#123;    synchronized (room) &#123;        log.debug(&quot;有烟吗？[&#123;&#125;]&quot;,hasCigarette);        if (!hasCigarette) &#123;            log.debug(&quot;没烟，歇会&quot;);            try &#123;                room.wait(2000);            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;        &#125;        log.debug(&quot;有烟没？[&#123;&#125;]&quot;,hasCigarette);        if (hasCigarette) &#123;            log.debug(&quot;可以干活了&quot;);        &#125; else &#123;            log.debug(&quot;没干成活&quot;);        &#125;    &#125;&#125;,&quot;t1&quot;).start();new Thread(() -&gt; &#123;    synchronized (room) &#123;        Thread thread = Thread.currentThread();        log.debug(&quot;外卖送到没？[&#123;&#125;]&quot;,hasTakeout);        if (!hasTakeout) &#123;            log.debug(&quot;没外卖，歇会&quot;);            try &#123;                room.wait();            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;        &#125;        log.debug(&quot;外卖送到没？[&#123;&#125;]&quot;,hasTakeout);        if (hasTakeout) &#123;            log.debug(&quot;可以干活了&quot;);        &#125; else &#123;            log.debug(&quot;没干成活&quot;);        &#125;    &#125;&#125;,&quot;t2&quot;).start();new Thread(() -&gt; &#123;    synchronized (room) &#123;        hasTakeout = true;        log.debug(&quot;外卖来了&quot;);        room.notify();    &#125;&#125;,&quot;送外卖的&quot;).start();</code></pre><p>输出：</p><pre><code>19:44:18.155 [t1] DEBUG com.heu.test.TestWait - 有烟吗？[false]19:44:18.166 [t1] DEBUG com.heu.test.TestWait - 没烟，歇会19:44:18.167 [t2] DEBUG com.heu.test.TestWait - 外卖送到没？[false]19:44:18.167 [t2] DEBUG com.heu.test.TestWait - 没外卖，歇会19:44:19.165 [送外卖的] DEBUG com.heu.test.TestWait - 外卖来了19:44:19.165 [t1] DEBUG com.heu.test.TestWait - 有烟没？[false]19:44:19.166 [t1] DEBUG com.heu.test.TestWait - 没干成活</code></pre><ul><li><p>notify 只能随机唤醒一个 WaitSet 中的线程，这时如果有其它线程也在等待，那么就可能唤醒不了正确的线程，称之为【虚假唤醒】</p></li><li><p>解决方法，改为 notifyAll。</p></li></ul><p>解决办法：</p><pre><code>new Thread(() -&gt; &#123;    synchronized (room) &#123;        hasTakeout = true;        log.debug(&quot;外卖来了&quot;);        room.notifyAll();    &#125;&#125;,&quot;送外卖的&quot;).start();</code></pre><p>输出：</p><pre><code>19:46:23.330 [t1] DEBUG com.heu.test.TestWait - 有烟吗？[false]19:46:23.340 [t1] DEBUG com.heu.test.TestWait - 没烟，歇会19:46:23.340 [t2] DEBUG com.heu.test.TestWait - 外卖送到没？[false]19:46:23.341 [t2] DEBUG com.heu.test.TestWait - 没外卖，歇会19:46:24.338 [送外卖的] DEBUG com.heu.test.TestWait - 外卖来了19:46:24.339 [t1] DEBUG com.heu.test.TestWait - 有烟没？[false]19:46:24.339 [t1] DEBUG com.heu.test.TestWait - 没干成活19:46:24.339 [t2] DEBUG com.heu.test.TestWait - 外卖送到没？[true]19:46:24.340 [t2] DEBUG com.heu.test.TestWait - 可以干活了</code></pre><ul><li><p>用 notifyAll 仅解决某个线程的唤醒问题，但使用 if + wait 判断仅有一次机会，一旦条件不成立，就没有重新判断的机会了。</p></li><li><p>解决方法，用 while + wait，当条件不成立，再次 wait。</p></li></ul><p>将 if 改为 while：</p><pre><code>while (!hasCigarette) &#123;     log.debug(&quot;没烟，先歇会！&quot;);     try &#123;         room.wait();     &#125; catch (InterruptedException e) &#123;         e.printStackTrace();     &#125;&#125;</code></pre><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><ol><li><p>当调用 wait 时，首先需要确保调用了 wait 方法的线程已经持有了对象的锁 (调用 wait 方法的代码片段需要放在 sychronized 块或者时 sychronized 方法中，这样才可以确保线程在调用 wait 方法前已经获取到了对象的锁)。</p></li><li><p>当调用 wait 时，该线程就会释放掉这个对象的锁，然后进入等待状态 (wait set)。</p></li><li><p>当线程调用了 wait 后进入到等待状态时，它就可以等待其他线程调用相同对象的 notify 或者 notifyAll 方法使得自己被唤醒。</p></li><li><p>一旦这个线程被其它线程唤醒之后，该线程就会与其它线程以同开始竞争这个对象的锁 (公平竞争)；只有当该线程获取到对象的锁后，线程才会继续往下执行。</p></li><li><p>当调用对象的 notify 方法时，他会随机唤醒对象等待集合 (wait set) 中的任意一个线程，当某个线程被唤醒后，它就会与其它线程一同竞争对象的锁。</p></li><li><p>当调用对象的 notifyAll 方法时，它会唤醒该对象等待集合 (wait set) 中的所有线程，这些线程被唤醒后，又会开始竞争对象的锁。</p></li><li><p>在某一时刻，只有唯一的一个线程能拥有对象的锁。</p></li></ol><p>同步模式之保护性暂停<br>定义<br>即 Guarded Suspension，用在一个线程等待另一个线程的执行结果。</p><p>有一个结果需要从一个线程传递到另一个线程，让他们关联同一个 GuardedObject。</p><p>如果有结果不断从一个线程到另一个线程那么可以使用消息队列（见生产者 / 消费者）。</p><p>JDK 中，join 、Future 的实现，采用的就是此模式。</p><p>单任务及多任务版 GuardedObject 如下图所示：</p><p>image-20210605200231671</p><p>在这里插入图片描述</p><p>实现<br>一个线程等待另一个线程的执行结果（带超时）</p><p>@Slf4j<br>public class GuardedObjectV2 {<br>    private Object response;<br>    private final Object lock = new Object();</p><pre><code>public Object get(long millis) &#123;    synchronized (lock) &#123;        long begin = System.currentTimeMillis();        long timePassed = 0;        while (response == null) &#123;            long waitTime = millis - timePassed;            log.debug(&quot;waitTime: &#123;&#125;&quot;, waitTime);            if (waitTime &lt;= 0) &#123;                log.debug(&quot;break..&quot;);            &#125;            try &#123;                lock.wait();            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;            timePassed=System.currentTimeMillis()-begin;            log.debug(&quot;timePassed: &#123;&#125;, object is null &#123;&#125;&quot;,                    timePassed, response == null);        &#125;        return response;    &#125;&#125;public void complete(Object response) &#123;    synchronized (lock) &#123;        this.response = response;        log.debug(&quot;notify..&quot;);        lock.notifyAll();    &#125;&#125;</code></pre><p>}</p><p>@Slf4j<br>public class GuardedObjectTest {<br>    public static void main(String[] args) {<br>        GuardedObjectV2 v2 = new GuardedObjectV2();<br>        new Thread(()-&gt;{<br>            try {<br>                Thread.sleep(1000);<br>            } catch (InterruptedException e) {<br>                e.printStackTrace();<br>            }<br>            v2.complete(null);<br>            try {<br>                Thread.sleep(1000);<br>            } catch (InterruptedException e) {<br>                e.printStackTrace();<br>            }<br>            v2.complete(Arrays.asList(“a”, “b”, “c”));<br>        }).start();</p><pre><code>    Object response = v2.get(2500);    if (response != null) &#123;        log.debug(&quot;get response: [&#123;&#125;] lines&quot;, ((List&lt;String&gt;) response).size());    &#125; else &#123;        log.debug(&quot;can&#39;t get response&quot;);    &#125;&#125;</code></pre><p>}</p><p>输出：</p><p>JAVA<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>20:31:46.262 [main] DEBUG com.heu.test.GuardedObjectV2 - waitTime: 2500<br>20:31:47.258 [Thread-0] DEBUG com.heu.test.GuardedObjectV2 - notify..<br>20:31:47.258 [main] DEBUG com.heu.test.GuardedObjectV2 - timePassed: 1002, object is null true<br>20:31:47.258 [main] DEBUG com.heu.test.GuardedObjectV2 - waitTime: 1498<br>20:31:48.272 [Thread-0] DEBUG com.heu.test.GuardedObjectV2 - notify..<br>20:31:48.272 [main] DEBUG com.heu.test.GuardedObjectV2 - timePassed: 2016, object is null false<br>20:31:48.273 [main] DEBUG com.heu.test.GuardedObjectTest - get response: [3] lines<br>多任务版 GuardedObject</p><p>@Slf4j<br>public class Code_23_Test {</p><pre><code>public static void main(String[] args) &#123;    for (int i = 0; i &lt; 3; i++) &#123;        new People().start();    &#125;    try &#123;        Thread.sleep(1000);    &#125; catch (InterruptedException e) &#123;        e.printStackTrace();    &#125;    for(Integer id : Mailboxes.getIds()) &#123;        new Postman(id, &quot;内容 &quot; + id).start();    &#125;&#125;</code></pre><p>}</p><p>@Slf4j(topic = “c.People”)<br>class People extends Thread {</p><pre><code>@Overridepublic void run() &#123;    GuardedObject guardedObject = Mailboxes.createGuardedObject();    log.info(&quot;收信的为 id: &#123;&#125;&quot;, guardedObject.getId());    Object o = guardedObject.get(5000);    log.info(&quot;收到信的 id: &#123;&#125;, 内容: &#123;&#125;&quot;, guardedObject.getId(), o);&#125;</code></pre><p>}</p><p>@Slf4j(topic = “c.Postman”)<br>class Postman extends Thread {</p><pre><code>private int id;private String mail;public Postman(int id, String mail) &#123;    this.id = id;    this.mail = mail;&#125;@Overridepublic void run() &#123;    GuardedObject guardedObject = Mailboxes.getGuardedObject(id);    log.info(&quot;送信的 id: &#123;&#125;, 内容: &#123;&#125;&quot;, id, mail);    guardedObject.complete(mail);&#125;</code></pre><p>}</p><p>class Mailboxes {</p><pre><code>private static int id = 1;private static Map&lt;Integer, GuardedObject&gt; boxes = new Hashtable&lt;&gt;();public static synchronized int generateId() &#123;    return id++;&#125;// 用户会进行投信public static GuardedObject createGuardedObject() &#123;    GuardedObject guardedObject = new GuardedObject(generateId());    boxes.put(guardedObject.getId(), guardedObject);    return guardedObject;&#125;// 派件员会派发信public static GuardedObject getGuardedObject(int id) &#123;    return boxes.remove(id);&#125;public static Set&lt;Integer&gt; getIds() &#123;    return boxes.keySet();&#125;</code></pre><p>}</p><p>class GuardedObject {</p><pre><code>private int id;public GuardedObject(int id) &#123;    this.id = id;&#125;public int getId() &#123;    return this.id;&#125;private Object response;// 优化等待时间public Object get(long timeout) &#123;    synchronized (this) &#123;        long begin = System.currentTimeMillis();        long passTime = 0;        while (response == null) &#123;            long waitTime = timeout - passTime; // 剩余等待时间            if(waitTime &lt;= 0) &#123;                break;            &#125;            try &#123;                this.wait(waitTime);            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;            passTime = System.currentTimeMillis() - begin;        &#125;        return response;    &#125;&#125;public void complete(Object response) &#123;    synchronized (this) &#123;        this.response = response;        this.notify();    &#125;&#125;</code></pre><p>}<br>输出：</p><p>JAVA<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10:35:05.689 c.People [Thread-1] - 开始收信 id:3<br>10:35:05.689 c.People [Thread-2] - 开始收信 id:1<br>10:35:05.689 c.People [Thread-0] - 开始收信 id:2<br>10:35:06.688 c.Postman [Thread-4] - 送信 id:2, 内容:内容2<br>10:35:06.688 c.Postman [Thread-5] - 送信 id:1, 内容:内容1<br>10:35:06.688 c.People [Thread-0] - 收到信 id:2, 内容:内容2<br>10:35:06.688 c.People [Thread-2] - 收到信 id:1, 内容:内容1<br>10:35:06.688 c.Postman [Thread-3] - 送信 id:3, 内容:内容3<br>10:35:06.689 c.People [Thread-1] - 收到信 id:3, 内容:内容3<br>异步模式之生产者 / 消费者<br>定义<br>与前面的保护性暂停中的 GuardObject 不同，不需要产生结果和消费结果的线程一一对应。</p><p>消费队列可以用来平衡生产和消费的线程资源。</p><p>生产者仅负责产生结果数据，不关心数据该如何处理，而消费者专心处理结果数据。</p><p>消息队列是有容量限制的，满时不会再加入数据，空时不会再消耗数据。</p><p>JDK 中各种阻塞队列，采用的就是这种模式。</p><p>“异步 “的意思就是生产者产生消息之后消息没有被立刻消费，而 “同步模式” 中，消息在产生之后被立刻消费了。</p><p>在这里插入图片描述</p><p>实现</p><p>@Slf4j(topic = “c.TestProducerConsumer”)<br>public class TestProducerConsumer {<br>    public static void main(String[] args) {<br>        MessageQueue messageQueue = new MessageQueue(2);<br>        for (int i = 0; i &lt; 4; i++) {<br>            int id = i;<br>            new Thread(() -&gt; {<br>                try {<br>                    log.debug(“download…”);<br>                    List<String> response = Downloader.download();<br>                    log.debug(“try put message({})”, id);<br>                    messageQueue.put(new Message(id, response));<br>                } catch (IOException e) {<br>                    e.printStackTrace();<br>                }<br>            }, “生产者” + i).start();<br>        }</p><pre><code>    new Thread(() -&gt; &#123;        while (true) &#123;            Message message = messageQueue.take();            List&lt;String&gt; response = (List&lt;String&gt;) message.getMessage();            log.debug(&quot;take message(&#123;&#125;): [&#123;&#125;] lines&quot;, message.getId(), response.size());        &#125;    &#125;, &quot;消费者&quot;).start();&#125;</code></pre><p>}</p><p>class Message {<br>    private int id;<br>    private Object message;</p><pre><code>public Message(int id, Object message) &#123;    this.id = id;    this.message = message;&#125;public int getId() &#123;    return id;&#125;public Object getMessage() &#123;    return message;&#125;</code></pre><p>}</p><p>@Slf4j(topic = “c.MessageQueue”)<br>class MessageQueue {<br>    private LinkedList<Message> queue;<br>    private int capacity;</p><pre><code>public MessageQueue(int capacity) &#123;    this.capacity = capacity;    queue = new LinkedList&lt;&gt;();&#125;public Message take() &#123;    synchronized (queue) &#123;        while (queue.isEmpty()) &#123;            log.debug(&quot;没货了, wait&quot;);            try &#123;                queue.wait();            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;        &#125;        Message message = queue.removeFirst();        queue.notifyAll();        return message;    &#125;&#125;public void put(Message message) &#123;    synchronized (queue) &#123;        while (queue.size() == capacity) &#123;            log.debug(&quot;库存已达上限, wait&quot;);            try &#123;                queue.wait();            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;        &#125;        queue.addLast(message);        queue.notifyAll();    &#125;&#125;</code></pre><p>}<br>join 原理<br>调用者轮询检查线程 alive 状态。</p><p>JAVA<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>t1.join();<br>//等价于下面的代码<br>synchronized (t1) {<br>     // 调用者线程进入 t1 的 waitSet 等待, 直到 t1 运行结束<br>     while (t1.isAlive()) {<br>         t1.wait(0);<br>     }<br>}<br>park &amp; unpark<br>基本使用<br>park &amp; unpark 是 LockSupport 线程通信工具类的静态方法。</p><p>JAVA<br>1<br>2<br>3<br>4<br>// 暂停当前线程<br>LockSupport.park();<br>// 恢复某个线程的运行<br>LockSupport.unpark;</p><p>@Slf4j<br>public class TestPark {<br>    public static void main(String[] args) throws InterruptedException {<br>        Thread t1=new Thread(() -&gt; {<br>            log.debug(“start…”);<br>            try {<br>                Thread.sleep(1000);<br>                log.debug(“park…”);<br>                LockSupport.park();<br>                log.debug(“resume..”);<br>            } catch (InterruptedException e) {<br>                e.printStackTrace();<br>            }<br>        },”t1”);<br>        t1.start();<br>        Thread.sleep(2000);<br>        log.debug(“unpark…”);<br>        LockSupport.unpark(t1);<br>    }<br>}<br>输出：</p><p>JAVA<br>1<br>2<br>3<br>4<br>20:54:15.719 [t1] DEBUG com.heu.test.TestPark - start…<br>20:54:16.735 [t1] DEBUG com.heu.test.TestPark - park…<br>20:54:17.723 [main] DEBUG com.heu.test.TestPark - unpark…<br>20:54:17.724 [t1] DEBUG com.heu.test.TestPark - resume..<br>特点<br>与 Object 的 wait &amp; notify 相比：</p><p>wait，notify 和 notifyAll 必须配合 Object Monitor 一起使用，而 park，unpark 不必；</p><p>park &amp; unpark 是以线程为单位来【阻塞】和【唤醒】线程，而 notify 只能随机唤醒一个等待线程，notifyAll 是唤醒所有等待线程，就不那么【精确】；</p><p>park &amp; unpark 可以先 unpark，而 wait &amp; notify 不能先 notify。</p><p>park unpark 原理<br>每个线程都有自己的一个 Parker 对象，由三部分组成 _counter， _cond 和 _mutex。</p><p>打个比喻，线程就像一个旅人，Parker 就像他随身携带的背包，条件变量 _ cond 就好比背包中的帐篷。_counter 就好比背包中的备用干粮（0 为耗尽，1 为充足）；<br>调用 park 就是要看需不需要停下来歇息：<br>如果备用干粮耗尽，那么钻进帐篷歇息；<br>如果备用干粮充足，那么不需停留，继续前进。<br>调用 unpark，就好比令干粮充足：<br>如果这时线程还在帐篷，就唤醒让他继续前进；<br>如果这时线程还在运行，那么下次它调用 park 时，仅是消耗掉备用干粮，不需停留继续前进；<br>因为背包空间有限，多次调用 unpark 仅会补充一份备用干粮。<br>先调用 park 再调用 upark 的过程：</p><p>先调用 park：</p><p>当前线程调用 Unsafe.park () 方法；<br>检查 _counter ，本情况为 0，这时获得 _mutex 互斥锁 (mutex 对象有个等待队列 _cond)；<br>线程进入 _cond 条件变量阻塞；<br>设置 _counter = 0。</p><p>在这里插入图片描述<br>调用 upark：</p><p>调用 Unsafe.unpark (Thread_0) 方法，设置 _counter 为 1；<br>唤醒 _cond 条件变量中的 Thread_0；<br>Thread_0 恢复运行；<br>设置 _counter 为 0。</p><p>在这里插入图片描述<br>先调用 upark 再调用 park 的过程</p><p>调用 Unsafe.unpark (Thread_0) 方法，设置 _counter 为 1；<br>当前线程调用 Unsafe.park () 方法；<br>检查 _counter ，本情况为 1，这时线程无需阻塞，继续运行；<br>设置 _counter 为 0。</p><p>在这里插入图片描述<br>线程状态转换</p><p>在这里插入图片描述<br>NEW –&gt; RUNNABLE：当调用了 t.start () 方法时，由 NEW –&gt; RUNNABLE。</p><p>RUNNABLE &lt;–&gt; WAITING</p><p>当调用了 t 线程用 synchronized (obj) 获取了对象锁后，调用 obj.wait () 方法时，t 线程从 RUNNABLE –&gt; WAITING。<br>调用 obj.notify () ， obj.notifyAll () ， t.interrupt () 时，会在 WaitSet 等待队列中出现锁竞争，非公平竞争。<br>竞争锁成功，t 线程从 WAITING –&gt; RUNNABLE<br>竞争锁失败，t 线程从 WAITING –&gt; BLOCKED<br>RUNNABLE &lt;–&gt; WAITING</p><p>当前线程调用 t.join () 方法时，当前线程从 RUNNABLE –&gt; WAITING，注意是当前线程在 t 线程对象的监视器上等待。<br>t 线程运行结束，或调用了当前线程的 interrupt () 时，当前线程从 WAITING –&gt; RUNNABLE。<br>RUNNABLE &lt;–&gt; WAITING</p><p>当前线程调用 LockSupport.park () 方法会让当前线程从 RUNNABLE –&gt; WAITING。<br>调用 LockSupport.unpark (目标线程) 或调用了线程 的 interrupt () ，会让目标线程从 WAITING –&gt; RUNNABLE。<br>RUNNABLE &lt;–&gt; TIMED_WAITING</p><p>t 线程用 synchronized (obj) 获取了对象锁后，调用 obj.wait (long n) 方法时，t 线程从 RUNNABLE –&gt; TIMED_WAITING。<br>t 线程等待时间超过了 n 毫秒，或调用 obj.notify () ， obj.notifyAll () ， t.interrupt () 时：<br>竞争锁成功，t 线程从 TIMED_WAITING –&gt; RUNNABLE<br>竞争锁失败，t 线程从 TIMED_WAITING –&gt; BLOCKED<br>RUNNABLE &lt;–&gt; TIMED_WAITING</p><p>当前线程调用 t.join (long n) 方法时，当前线程从 RUNNABLE –&gt; TIMED_WAITING。<br>当前线程等待时间超过了 n 毫秒，或 t 线程运行结束，或调用了当前线程的 interrupt () 时，当前线程从 TIMED_WAITING –&gt; RUNNABLE。<br>RUNNABLE &lt;–&gt; TIMED_WAITING</p><p>当前线程调用 Thread.sleep (long n) ，当前线程从 RUNNABLE –&gt; TIMED_WAITING。<br>当前线程等待时间超过了 n 毫秒，当前线程从 TIMED_WAITING –&gt; RUNNABLE。<br>RUNNABLE &lt;–&gt; TIMED_WAITING</p><p>当前线程调用 LockSupport.parkNanos (long nanos) 或 LockSupport.parkUntil (long millis) 时，当前线 程从 RUNNABLE –&gt; TIMED_WAITING。<br>调用 LockSupport.unpark (目标线程) 或调用了线程 的 interrupt () ，或是等待超时，会让目标线程从 TIMED_WAITING–&gt; RUNNABLE。<br>RUNNABLE &lt;–&gt; BLOCKED</p><p>t 线程用 synchronized (obj) 获取了对象锁时如果竞争失败，从 RUNNABLE –&gt; BLOCKED。<br>持 obj 锁线程的同步代码块执行完毕，会唤醒该对象上所有 BLOCKED 的线程重新竞争，如果其中 t 线程竞争成功，从 BLOCKED –&gt; RUNNABLE ，其它失败的线程仍然 BLOCKED。<br>RUNNABLE &lt;–&gt; TERMINATED</p><p>当前线程所有代码运行完毕，进入 TERMINATED。<br>活跃性<br>定义<br>线程因为某些原因，导致代码一直无法执行完毕，这种的现象叫做活跃性。</p><p>死锁<br>有这样的情况：一个线程需要同时获取多把锁，这时就容易发生死锁。如：t1 线程获得 A 对象锁，接下来想获取 B 对象的锁 t2 线程获得 B 对象锁，接下来想获取 A 对象的锁。</p><p>public static void main(String[] args) {<br>        final Object A = new Object();<br>        final Object B = new Object();<br>        new Thread(()-&gt;{<br>            synchronized (A) {<br>                try {<br>                    Thread.sleep(2000);<br>                } catch (InterruptedException e) {<br>                    e.printStackTrace();<br>                }<br>                synchronized (B) {</p><pre><code>            &#125;        &#125;    &#125;).start();    new Thread(()-&gt;&#123;        synchronized (B) &#123;            try &#123;                Thread.sleep(1000);            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;            synchronized (A) &#123;            &#125;        &#125;    &#125;).start();&#125;</code></pre><p>发生死锁的必要条件</p><p>互斥条件：在一段时间内，一种资源只能被一个进程所使用。<br>请求和保持条件：进程已经拥有了至少一种资源，同时又去申请其他资源。因为其他资源被别的进程所使用，该进程进入阻塞状态，并且不释放自己已有的资源。<br>不可抢占条件：进程对已获得的资源在未使用完成前不能被强占，只能在进程使用完后自己释放。<br>循环等待条件：发生死锁时，必然存在一个进程 —— 资源的循环链。<br>定位死锁的方法<br>检测死锁可以使用 jconsole 工具；或者使用 jps 定位进程 id，再用 jstack 根据进程 id 定位死锁。</p><p>哲学家就餐问题</p><p>有五位哲学家，围坐在圆桌旁。他们只做两件事，思考和吃饭，思考一会吃口饭，吃完饭后接着思考。吃饭时要用两根筷子吃，桌上共有 5 根筷子，每位哲学家左右手边各有一根筷子。如果筷子被身边的人拿着，自己就得等待。</p><p>当每个哲学家即线程持有一根筷子时，他们都在等待另一个线程释放锁，因此造成了死锁。这种线程没有按预期结束，执行不下去的情况，归类为【活跃性】问题，除了死锁以外，还有活锁和饥饿者两种情况。</p><p>避免死锁的方法</p><p>在线程使用锁对象时，顺序加锁即可避免死锁。</p><p>在这里插入图片描述<br>活锁<br>活锁出现在两个线程互相改变对方的结束条件，谁也无法结束。</p><p>避免活锁的方法：在线程执行时，中途给予不同的间隔时间即可。</p><p>死锁与活锁的区别：</p><p>死锁是因为线程互相持有对象想要的锁，并且都不释放，最后到时线程阻塞，停止运行的现象。</p><p>活锁是因为线程间修改了对方的结束条件，而导致代码一直在运行，却一直运行不完的现象。</p><p>饥饿<br>某些线程因为优先级太低，导致一直无法获得资源的现象。在使用顺序加锁时，可能会出现饥饿现象。</p><p>ReentrantLock<br>相对于 synchronized 它具备如下特点：</p><p>可中断</p><p>可以设置超时时间</p><p>可以设置为公平锁</p><p>支持多个条件变量</p><p>与 synchronized 一样，都支持可重入。</p><p>基本语法：</p><p>JAVA<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>// 获取锁<br>reentrantLock.lock();<br>try {<br>     // 临界区<br>} finally {<br>     // 释放锁<br>     reentrantLock.unlock();<br>}<br>可重入<br>可重入是指同一个线程如果首次获得了这把锁，那么因为它是这把锁的拥有者，因此有权利再次获取这把锁。<br>如果是不可重入锁，那么第二次获得锁时，自己也会被锁挡住。<br>JAVA<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>26<br>27<br>28<br>29<br>30<br>31<br>32<br>33<br>34<br>35<br>36<br>37<br>38<br>39<br>40<br>@Slf4j<br>public class TestReentrantLock {<br>    static ReentrantLock lock = new ReentrantLock();</p><pre><code>public static void main(String[] args) &#123;    method1();&#125;public static void method1() &#123;    lock.lock();    try &#123;        log.debug(&quot;method1&quot;);        method2();    &#125;finally &#123;        lock.unlock();    &#125;&#125;public static void method2() &#123;    lock.lock();    try &#123;        log.debug(&quot;method2&quot;);        method3();    &#125;finally &#123;        lock.unlock();    &#125;&#125;public static void method3() &#123;    lock.lock();    try &#123;        log.debug(&quot;method3&quot;);    &#125;finally &#123;        lock.unlock();    &#125;&#125;</code></pre><p>}<br>输出：</p><p>JAVA<br>1<br>2<br>3<br>21:49:13.947 [main] DEBUG com.heu.test.TestReentrantLock - method1<br>21:49:13.960 [main] DEBUG com.heu.test.TestReentrantLock - method2<br>21:49:13.960 [main] DEBUG com.heu.test.TestReentrantLock - method3<br>可打断<br>如果某个线程处于阻塞状态，可以调用其 interrupt 方法让其停止阻塞，获得锁失败。简而言之就是：处于阻塞状态的线程，被打断了就不用阻塞了，直接停止运行。</p><p>注意如果是不可中断模式，那么即使使用了 interrupt 也不会让等待中断。</p><p>JAVA<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>26<br>27<br>28<br>29<br>public static void main(String[] args) {<br>        ReentrantLock lock = new ReentrantLock();<br>        Thread t1 = new Thread(() -&gt; {<br>            try {<br>                // 加锁，可打断锁<br>                lock.lockInterruptibly();<br>            } catch (InterruptedException e) {<br>                e.printStackTrace();<br>                // 被打断，返回，不再向下执行<br>                return;<br>            }finally {<br>                // 释放锁<br>                lock.unlock();<br>            }</p><pre><code>    &#125;);    lock.lock();    try &#123;        t1.start();        Thread.sleep(1000);        // 打断        t1.interrupt();    &#125; catch (InterruptedException e) &#123;        e.printStackTrace();    &#125; finally &#123;        lock.unlock();    &#125;&#125;</code></pre><p>18:02:40.520 [main] c.TestInterrupt - 获得了锁<br>18:02:40.524 [t1] c.TestInterrupt - 启动…<br>18:02:41.530 [main] c.TestInterrupt - 执行打断<br>java.lang.InterruptedException<br>     at<br>java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireInterruptibly(AbstractQueuedSynchr<br>onizer.java:898)<br>     at<br>java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireInterruptibly(AbstractQueuedSynchron<br>izer.java:1222)<br>     at java.util.concurrent.locks.ReentrantLock.lockInterruptibly(ReentrantLock.java:335)<br>     at cn.itcast.n4.reentrant.TestInterrupt.lambda$main$0(TestInterrupt.java:17)<br>     at java.lang.Thread.run(Thread.java:748)<br>18:02:41.532 [t1] c.TestInterrupt - 等锁的过程中被打断<br>锁超时<br>使用 lock.tryLock 方法会返回获取锁是否成功。如果成功则返回 true ，反之则返回 false 。<br>tryLock 方法可以指定等待时间，参数为：tryLock (long timeout, TimeUnit unit)，其中 timeout 为最长等待时间，TimeUnit 为时间单位。<br>简而言之就是：获取锁失败了、获取超时了或者被打断了，不再阻塞，直接停止运行。<br>不设置等待时间</p><p>JAVA<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>public static void main(String[] args) {<br>        ReentrantLock lock = new ReentrantLock();<br>        Thread t1 = new Thread(() -&gt; {<br>            // 未设置等待时间，一旦获取失败，直接返回false<br>            if(!lock.tryLock()) {<br>                System.out.println(“获取失败”);<br>                // 获取失败，不再向下执行，返回<br>                return;<br>            }<br>            System.out.println(“得到了锁”);<br>            lock.unlock();<br>        });</p><pre><code>    lock.lock();    try&#123;        t1.start();        Thread.sleep(3000);    &#125; catch (InterruptedException e) &#123;        e.printStackTrace();    &#125; finally &#123;        lock.unlock();    &#125;&#125;</code></pre><p>设置等待时间</p><p>JAVA<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>26<br>27<br>28<br>29<br>30<br>31<br>32<br>33<br>public static void main(String[] args) {<br>        ReentrantLock lock = new ReentrantLock();<br>        Thread t1 = new Thread(() -&gt; {<br>            try {<br>                // 判断获取锁是否成功，最多等待1秒<br>                if(!lock.tryLock(1, TimeUnit.SECONDS)) {<br>                    System.out.println(“获取失败”);<br>                    // 获取失败，不再向下执行，直接返回<br>                    return;<br>                }<br>            } catch (InterruptedException e) {<br>                e.printStackTrace();<br>                // 被打断，不再向下执行，直接返回<br>                return;<br>            }<br>            System.out.println(“得到了锁”);<br>            // 释放锁<br>            lock.unlock();<br>        });</p><pre><code>    lock.lock();    try&#123;        t1.start();        // 打断等待        t1.interrupt();        Thread.sleep(3000);    &#125; catch (InterruptedException e) &#123;        e.printStackTrace();    &#125; finally &#123;        lock.unlock();    &#125;&#125;</code></pre><p>公平锁<br>在线程获取锁失败，进入阻塞队列时，先进入的会在锁被释放后先获得锁。这样的获取方式就是公平的。</p><p>// 默认是不公平锁，需要在创建时指定为公平锁<br>ReentrantLock lock = new ReentrantLock(true);<br>条件变量<br>synchronized 中也有条件变量，就是我们讲原理时那个 waitSet 休息室，当条件不满足时进入 waitSet 等待。ReentrantLock 的条件变量比 synchronized 强大之处在于，它是支持多个条件变量的，这就好比：</p><p>synchronized 是那些不满足条件的线程都在一间休息室等消息。<br>而 ReentrantLock 支持多间休息室，有专门等烟的休息室、专门等早餐的休息室，唤醒时也是按休息室来唤醒.<br>使用要点：</p><p>await 前需要获得锁。<br>await 执行后，会释放锁，进入 conditionObject 等待。<br>await 的线程被唤醒（或打断、或超时）时重新竞争 lock 锁。<br>竞争 lock 锁成功后，从 await 后继续执行。<br>示例：</p><p>JAVA</p><p>public class TestCondition {<br>    static ReentrantLock lock = new ReentrantLock();<br>    static Condition waitCigaretteQueue = lock.newCondition();<br>    static Condition waitbreakfastQueue = lock.newCondition();<br>    static volatile boolean hasCigrette = false;<br>    static volatile boolean hasBreakfast = false;</p><pre><code>public static void main(String[] args) throws InterruptedException &#123;    new Thread(() -&gt; &#123;        lock.lock();        try &#123;            while (!hasCigrette) &#123;                try &#123;                    waitCigaretteQueue.await();                &#125; catch (InterruptedException e) &#123;                    e.printStackTrace();                &#125;            &#125;            log.debug(&quot;等到了它的烟&quot;);        &#125;finally &#123;            lock.unlock();        &#125;    &#125;).start();    new Thread(() -&gt; &#123;        lock.lock();        try &#123;            while (!hasBreakfast) &#123;                try &#123;                    waitbreakfastQueue.await();                &#125; catch (InterruptedException e) &#123;                    e.printStackTrace();                &#125;            &#125;            log.debug(&quot;等到了它的早餐&quot;);        &#125;finally &#123;            lock.unlock();        &#125;    &#125;).start();    Thread.sleep(1000);    sendBreakfast();    Thread.sleep(1000);    sendCigarette();&#125;private static void sendCigarette() &#123;    lock.lock();    try &#123;        log.debug(&quot;送烟来了&quot;);        hasCigrette = true;        waitCigaretteQueue.signal();    &#125;finally &#123;        lock.unlock();    &#125;&#125;private static void  sendBreakfast() &#123;    lock.lock();    try &#123;        log.debug(&quot;送早餐来了&quot;);        hasBreakfast = true;        waitbreakfastQueue.signal();    &#125;finally &#123;        lock.unlock();    &#125;&#125;</code></pre><p>}<br>输出：</p><p>22:13:53.349 [main] DEBUG com.heu.test.TestCondition - 送早餐来了<br>22:13:53.359 [Thread-1] DEBUG com.heu.test.TestCondition - 等到了它的早餐<br>22:13:54.368 [main] DEBUG com.heu.test.TestCondition - 送烟来了<br>22:13:54.368 [Thread-0] DEBUG com.heu.test.TestCondition - 等到了它的烟</p><h1 id="ReentrantLock"><a href="#ReentrantLock" class="headerlink" title="ReentrantLock"></a>ReentrantLock</h1><p><em>相对于 synchronized 它具备如下特点：</em></p><ul><li>可中断</li><li>可以设置超时时间</li><li>可以设置为公平锁</li><li>支持多个条件变量</li></ul><p><strong>与 synchronized 一样，都支持可重入。</strong></p><p><strong>基本语法：</strong></p><pre><code>// 获取锁reentrantLock.lock();try &#123;     // 临界区&#125; finally &#123;     // 释放锁     reentrantLock.unlock();&#125;</code></pre><h2 id="可重入"><a href="#可重入" class="headerlink" title="可重入"></a>可重入</h2><ul><li>可重入是指同一个线程如果首次获得了这把锁，那么因为它是这把锁的拥有者，因此有权利再次获取这把锁。</li><li>如果是不可重入锁，那么第二次获得锁时，自己也会被锁挡住。</li></ul><pre><code>@Slf4jpublic class TestReentrantLock &#123;    static ReentrantLock lock = new ReentrantLock();    public static void main(String[] args) &#123;        method1();    &#125;    public static void method1() &#123;        lock.lock();        try &#123;            log.debug(&quot;method1&quot;);            method2();        &#125;finally &#123;            lock.unlock();        &#125;    &#125;    public static void method2() &#123;        lock.lock();        try &#123;            log.debug(&quot;method2&quot;);            method3();        &#125;finally &#123;            lock.unlock();        &#125;    &#125;    public static void method3() &#123;        lock.lock();        try &#123;            log.debug(&quot;method3&quot;);        &#125;finally &#123;            lock.unlock();        &#125;    &#125;&#125;</code></pre><p>输出：</p><pre><code>21:49:13.947 [main] DEBUG com.heu.test.TestReentrantLock - method121:49:13.960 [main] DEBUG com.heu.test.TestReentrantLock - method221:49:13.960 [main] DEBUG com.heu.test.TestReentrantLock - method3</code></pre><h2 id="可打断"><a href="#可打断" class="headerlink" title="可打断"></a>可打断</h2><ul><li><p>如果某个线程处于阻塞状态，可以调用其 interrupt 方法让其停止阻塞，获得锁失败。简而言之就是：处于阻塞状态的线程，被<br>打断了就不用阻塞了，直接停止运行。</p></li><li><p>注意如果是不可中断模式，那么即使使用了 interrupt 也不会让等待中断。</p></li></ul><pre><code>public static void main(String[] args) &#123;        ReentrantLock lock = new ReentrantLock();        Thread t1 = new Thread(() -&gt; &#123;            try &#123;                // 加锁，可打断锁                lock.lockInterruptibly();            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();                // 被打断，返回，不再向下执行                return;            &#125;finally &#123;                // 释放锁                lock.unlock();            &#125;        &#125;);        lock.lock();        try &#123;            t1.start();            Thread.sleep(1000);            // 打断            t1.interrupt();        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125; finally &#123;            lock.unlock();        &#125;    &#125;</code></pre><p><strong>输出:</strong></p><pre><code>18:02:40.520 [main] c.TestInterrupt - 获得了锁18:02:40.524 [t1] c.TestInterrupt - 启动... 18:02:41.530 [main] c.TestInterrupt - 执行打断java.lang.InterruptedException      at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireInterruptibly(AbstractQueuedSynchronizer.java:898)      at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireInterruptibly(AbstractQueuedSynchronizer.java:1222)      at java.util.concurrent.locks.ReentrantLock.lockInterruptibly(ReentrantLock.java:335)      at cn.itcast.n4.reentrant.TestInterrupt.lambda$main$0(TestInterrupt.java:17)      at java.lang.Thread.run(Thread.java:748) 18:02:41.532 [t1] c.TestInterrupt - 等锁的过程中被打断</code></pre><h2 id="锁超时"><a href="#锁超时" class="headerlink" title="锁超时"></a>锁超时</h2><ul><li><p>使用 lock.tryLock 方法会返回获取锁是否成功。如果成功则返回 true ，反之则返回 false 。</p></li><li><p>tryLock 方法可以指定等待时间，参数为：tryLock (long timeout, TimeUnit unit)，其中 timeout 为最长等待时间，TimeUnit 为时间单位。</p></li><li><p>简而言之就是：获取锁失败了、获取超时了或者被打断了，不再阻塞，直接停止运行。</p></li></ul><p><strong>不设置等待时间</strong></p><pre><code>public static void main(String[] args) &#123;        ReentrantLock lock = new ReentrantLock();        Thread t1 = new Thread(() -&gt; &#123;            // 未设置等待时间，一旦获取失败，直接返回false            if(!lock.tryLock()) &#123;                System.out.println(&quot;获取失败&quot;);                // 获取失败，不再向下执行，返回                return;            &#125;            System.out.println(&quot;得到了锁&quot;);            lock.unlock();        &#125;);        lock.lock();        try&#123;            t1.start();            Thread.sleep(3000);        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125; finally &#123;            lock.unlock();        &#125;    &#125;</code></pre><p><strong>设置等待时间</strong></p><pre><code>public static void main(String[] args) &#123;        ReentrantLock lock = new ReentrantLock();        Thread t1 = new Thread(() -&gt; &#123;            try &#123;                // 判断获取锁是否成功，最多等待1秒                if(!lock.tryLock(1, TimeUnit.SECONDS)) &#123;                    System.out.println(&quot;获取失败&quot;);                    // 获取失败，不再向下执行，直接返回                    return;                &#125;            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();                // 被打断，不再向下执行，直接返回                return;            &#125;            System.out.println(&quot;得到了锁&quot;);            // 释放锁            lock.unlock();        &#125;);        lock.lock();        try&#123;            t1.start();            // 打断等待            t1.interrupt();            Thread.sleep(3000);        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125; finally &#123;            lock.unlock();        &#125;    &#125;</code></pre><h2 id="公平锁"><a href="#公平锁" class="headerlink" title="公平锁"></a>公平锁</h2><p>在线程获取锁失败，进入阻塞队列时，先进入的会在锁被释放后先获得锁。这样的获取方式就是公平的。</p><pre><code>// 默认是不公平锁，需要在创建时指定为公平锁ReentrantLock lock = new ReentrantLock(true);</code></pre><h2 id="条件变量"><a href="#条件变量" class="headerlink" title="条件变量"></a>条件变量</h2><p>synchronized 中也有条件变量，就是我们讲原理时那个 waitSet 休息室，当条件不满足时进入 waitSet 等待。ReentrantLock 的条件变量比 synchronized 强大之处在于，它是支持多个条件变量的，这就好比：</p><ul><li><p>synchronized 是那些不满足条件的线程都在一间休息室等消息。</p></li><li><p>而 ReentrantLock 支持多间休息室，有专门等烟的休息室、专门等早餐的休息室，唤醒时也是按休息室来唤醒.</p></li></ul><p><strong>使用要点：</strong></p><ul><li>await 前需要获得锁。</li><li>await 执行后，会释放锁，进入 conditionObject 等待。</li><li>await 的线程被唤醒（或打断、或超时）时重新竞争 lock 锁。</li><li>竞争 lock 锁成功后，从 await 后继续执行。</li></ul><p>示例：</p><pre><code>public class TestCondition &#123;    static ReentrantLock lock = new ReentrantLock();    static Condition waitCigaretteQueue = lock.newCondition();    static Condition waitbreakfastQueue = lock.newCondition();    static volatile boolean hasCigrette = false;    static volatile boolean hasBreakfast = false;    public static void main(String[] args) throws InterruptedException &#123;        new Thread(() -&gt; &#123;            lock.lock();            try &#123;                while (!hasCigrette) &#123;                    try &#123;                        waitCigaretteQueue.await();                    &#125; catch (InterruptedException e) &#123;                        e.printStackTrace();                    &#125;                &#125;                log.debug(&quot;等到了它的烟&quot;);            &#125;finally &#123;                lock.unlock();            &#125;        &#125;).start();        new Thread(() -&gt; &#123;            lock.lock();            try &#123;                while (!hasBreakfast) &#123;                    try &#123;                        waitbreakfastQueue.await();                    &#125; catch (InterruptedException e) &#123;                        e.printStackTrace();                    &#125;                &#125;                log.debug(&quot;等到了它的早餐&quot;);            &#125;finally &#123;                lock.unlock();            &#125;        &#125;).start();        Thread.sleep(1000);        sendBreakfast();        Thread.sleep(1000);        sendCigarette();    &#125;    private static void sendCigarette() &#123;        lock.lock();        try &#123;            log.debug(&quot;送烟来了&quot;);            hasCigrette = true;            waitCigaretteQueue.signal();        &#125;finally &#123;            lock.unlock();        &#125;    &#125;    private static void  sendBreakfast() &#123;        lock.lock();        try &#123;            log.debug(&quot;送早餐来了&quot;);            hasBreakfast = true;            waitbreakfastQueue.signal();        &#125;finally &#123;            lock.unlock();        &#125;    &#125;&#125;</code></pre><p>输出：</p><pre><code>22:13:53.349 [main] DEBUG com.heu.test.TestCondition - 送早餐来了22:13:53.359 [Thread-1] DEBUG com.heu.test.TestCondition - 等到了它的早餐22:13:54.368 [main] DEBUG com.heu.test.TestCondition - 送烟来了22:13:54.368 [Thread-0] DEBUG com.heu.test.TestCondition - 等到了它的烟</code></pre><p>同步模式之顺序控制<br>线程 1 输出 a 5 次，线程 2 输出 b 5 次，线程 3 输出 c 5 次。现在要求输出 abcabcabcabcabc 怎么实现。</p><p>Wait/Notify 实现</p><p> public static void main(String[] args) {<br>        WaitAndNotify waitAndNotify = new WaitAndNotify(1, 5);</p><pre><code>    new Thread(()-&gt;&#123;        waitAndNotify.run(&quot;a&quot;, 1, 2);    &#125;).start();    new Thread(()-&gt;&#123;        waitAndNotify.run(&quot;b&quot;, 2, 3);    &#125;).start();    new Thread(()-&gt;&#123;        waitAndNotify.run(&quot;c&quot;, 3, 1);    &#125;).start();&#125;</code></pre><p>}</p><p>class WaitAndNotify {<br>    public void run(String str, int flag, int nextFlag) {<br>        for(int i = 0; i &lt; loopNumber; i++) {<br>            synchronized(this) {<br>                while (flag != this.flag) {<br>                    try {<br>                        this.wait();<br>                    } catch (InterruptedException e) {<br>                        e.printStackTrace();<br>                    }<br>                }<br>                System.out.print(str);<br>                // 设置下一个运行的线程标记<br>                this.flag = nextFlag;<br>                // 唤醒所有线程<br>                this.notifyAll();<br>            }<br>        }<br>    }</p><pre><code>private int flag;private int loopNumber;public WaitAndNotify(int flag, int loopNumber) &#123;    this.flag = flag;    this.loopNumber = loopNumber;&#125;</code></pre><p>park/unpary 实现</p><p>public static Thread t1, t2, t3;<br>    public static void main(String[] args) {<br>        ParkAndUnPark obj = new ParkAndUnPark(5);<br>        t1 = new Thread(() -&gt; {<br>            obj.run(“a”, t2);<br>        });</p><pre><code>    t2 = new Thread(() -&gt; &#123;        obj.run(&quot;b&quot;, t3);    &#125;);    t3 = new Thread(() -&gt; &#123;        obj.run(&quot;c&quot;, t1);    &#125;);    t1.start();    t2.start();    t3.start();    LockSupport.unpark(t1);&#125;</code></pre><p>}</p><p>class ParkAndUnPark {<br>    public void run(String str, Thread nextThread) {<br>        for(int i = 0; i &lt; loopNumber; i++) {<br>            LockSupport.park();<br>            System.out.print(str);<br>            LockSupport.unpark(nextThread);<br>        }<br>    }</p><pre><code>private int loopNumber;public ParkAndUnPark(int loopNumber) &#123;    this.loopNumber = loopNumber;&#125;</code></pre><p>await/signal 实现</p><p>public static void main(String[] args) {<br>        AwaitAndSignal lock = new AwaitAndSignal(5);<br>        Condition a = lock.newCondition();<br>        Condition b = lock.newCondition();<br>        Condition c = lock.newCondition();<br>        new Thread(() -&gt; {<br>            lock.run(“a”, a, b);<br>        }).start();</p><pre><code>    new Thread(() -&gt; &#123;        lock.run(&quot;b&quot;, b, c);    &#125;).start();    new Thread(() -&gt; &#123;        lock.run(&quot;c&quot;, c, a);    &#125;).start();    try &#123;        Thread.sleep(1000);    &#125; catch (InterruptedException e) &#123;        e.printStackTrace();    &#125;    lock.lock();    try &#123;        a.signal();    &#125;finally &#123;        lock.unlock();    &#125;&#125;</code></pre><p>}</p><p>class AwaitAndSignal extends ReentrantLock {<br>    public void run(String str, Condition current, Condition nextCondition) {<br>        for(int i = 0; i &lt; loopNumber; i++) {<br>            lock();<br>            try {<br>                current.await();<br>                System.out.print(str);<br>                nextCondition.signal();<br>            } catch (InterruptedException e) {<br>                e.printStackTrace();<br>            } finally {<br>                unlock();<br>            }<br>        }<br>    }</p><pre><code>private int loopNumber;public AwaitAndSignal(int loopNumber) &#123;    this.loopNumber = loopNumber;&#125;</code></pre><p>同步模式之顺序控制<br>线程 1 输出 a 5 次，线程 2 输出 b 5 次，线程 3 输出 c 5 次。现在要求输出 abcabcabcabcabc 怎么实现。</p><p>Wait/Notify 实现</p><p> public static void main(String[] args) {<br>        WaitAndNotify waitAndNotify = new WaitAndNotify(1, 5);</p><pre><code>    new Thread(()-&gt;&#123;        waitAndNotify.run(&quot;a&quot;, 1, 2);    &#125;).start();    new Thread(()-&gt;&#123;        waitAndNotify.run(&quot;b&quot;, 2, 3);    &#125;).start();    new Thread(()-&gt;&#123;        waitAndNotify.run(&quot;c&quot;, 3, 1);    &#125;).start();&#125;</code></pre><p>}</p><p>class WaitAndNotify {<br>    public void run(String str, int flag, int nextFlag) {<br>        for(int i = 0; i &lt; loopNumber; i++) {<br>            synchronized(this) {<br>                while (flag != this.flag) {<br>                    try {<br>                        this.wait();<br>                    } catch (InterruptedException e) {<br>                        e.printStackTrace();<br>                    }<br>                }<br>                System.out.print(str);<br>                // 设置下一个运行的线程标记<br>                this.flag = nextFlag;<br>                // 唤醒所有线程<br>                this.notifyAll();<br>            }<br>        }<br>    }</p><pre><code>private int flag;private int loopNumber;public WaitAndNotify(int flag, int loopNumber) &#123;    this.flag = flag;    this.loopNumber = loopNumber;&#125;</code></pre><p>park/unpary 实现</p><p>public static Thread t1, t2, t3;<br>    public static void main(String[] args) {<br>        ParkAndUnPark obj = new ParkAndUnPark(5);<br>        t1 = new Thread(() -&gt; {<br>            obj.run(“a”, t2);<br>        });</p><pre><code>    t2 = new Thread(() -&gt; &#123;        obj.run(&quot;b&quot;, t3);    &#125;);    t3 = new Thread(() -&gt; &#123;        obj.run(&quot;c&quot;, t1);    &#125;);    t1.start();    t2.start();    t3.start();    LockSupport.unpark(t1);&#125;</code></pre><p>}</p><p>class ParkAndUnPark {<br>    public void run(String str, Thread nextThread) {<br>        for(int i = 0; i &lt; loopNumber; i++) {<br>            LockSupport.park();<br>            System.out.print(str);<br>            LockSupport.unpark(nextThread);<br>        }<br>    }</p><pre><code>private int loopNumber;public ParkAndUnPark(int loopNumber) &#123;    this.loopNumber = loopNumber;&#125;</code></pre><p>await/signal 实现</p><p>public static void main(String[] args) {<br>        AwaitAndSignal lock = new AwaitAndSignal(5);<br>        Condition a = lock.newCondition();<br>        Condition b = lock.newCondition();<br>        Condition c = lock.newCondition();<br>        new Thread(() -&gt; {<br>            lock.run(“a”, a, b);<br>        }).start();</p><pre><code>    new Thread(() -&gt; &#123;        lock.run(&quot;b&quot;, b, c);    &#125;).start();    new Thread(() -&gt; &#123;        lock.run(&quot;c&quot;, c, a);    &#125;).start();    try &#123;        Thread.sleep(1000);    &#125; catch (InterruptedException e) &#123;        e.printStackTrace();    &#125;    lock.lock();    try &#123;        a.signal();    &#125;finally &#123;        lock.unlock();    &#125;&#125;</code></pre><p>}</p><p>class AwaitAndSignal extends ReentrantLock {<br>    public void run(String str, Condition current, Condition nextCondition) {<br>        for(int i = 0; i &lt; loopNumber; i++) {<br>            lock();<br>            try {<br>                current.await();<br>                System.out.print(str);<br>                nextCondition.signal();<br>            } catch (InterruptedException e) {<br>                e.printStackTrace();<br>            } finally {<br>                unlock();<br>            }<br>        }<br>    }</p><pre><code>private int loopNumber;public AwaitAndSignal(int loopNumber) &#123;    this.loopNumber = loopNumber;&#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> 多线程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Monitor </tag>
            
            <tag> synchronized </tag>
            
            <tag> wait/notify </tag>
            
            <tag> park/unpark </tag>
            
            <tag> ReentrantLock </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>多线程与高并发 — 线程基础、方法</title>
      <link href="/2020/08/31/thread/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E9%AB%98%E5%B9%B6%E5%8F%91%20%E2%80%94%20%E7%BA%BF%E7%A8%8B%E5%9F%BA%E7%A1%80%E3%80%81%E6%96%B9%E6%B3%95/"/>
      <url>/2020/08/31/thread/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E9%AB%98%E5%B9%B6%E5%8F%91%20%E2%80%94%20%E7%BA%BF%E7%A8%8B%E5%9F%BA%E7%A1%80%E3%80%81%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>进程与线程<br>进程与线程<br>进程</p><p>程序由指令和数据组成，但这些指令要运行，数据要读写，就必须将指令加载至 CPU，数据加载至内存。在指令运行过程中还需要用到磁盘、网络等设备。进程就是用来加载指令、管理内存、管理 IO 的。<br>当一个程序被运行，从磁盘加载这个程序的代码至内存，这时就开启了一个进程。<br>进程可以视为程序的一个实例。大部分程序可以同时运行多个实例进程（例如记事本、画图、浏览器 等），也有的程序只能启动一个实例进程（例如网易云音乐、360 安全卫士等）<br>线程</p><p>一个进程之内可以分为一到多个线程。<br>一个线程就是一个指令流，将指令流中的一条条指令以一定的顺序交给 CPU 执行 。<br>java 中，线程作为最小调度单位，进程作为资源分配的最小单位。 在 windows 中进程是不活动的，只是作为线程的容器。<br>两者对比</p><p>进程基本上相互独立的，而线程存在于进程内，是进程的一个子集。<br>进程拥有共享的资源，如内存空间等，供其内部的线程共享。<br>进程间通信较为复杂，同一台计算机的进程通信称为 IPC（Inter-process communication），不同计算机之间的进程通信，需要通过网络，并遵守共同的协议，例如 HTTP。<br>线程通信相对简单，因为它们共享进程内的内存，多个线程可以访问同一个共享变量。<br>线程更轻量，线程上下文切换成本一般上要比进程上下文切换低。<br>并行与并发<br>并发</p><p>单核 cpu 下，线程实际还是串行执行的。操作系统中有一个组件叫做任务调度器，将 cpu 的时间片（windows 下时间片最小约为 15 毫秒）分给不同的程序使用，只是由于 cpu 在线程间（时间片很短）的切换非常快，人类感、觉是同时运行的 。总结为一句话就是： 微观串行，宏观并行 。</p><p>img<br>并行</p><p>多核 cpu 下，每个核（core） 都可以调度运行线程，这时候线程可以是并行的，不同的线程同时使用不同的 cpu 在执行。</p><p>img<br>二者对比</p><p>引用 Rob Pike 的一段描述：并发（concurrent）是同一时间应对（dealing with）多件事情的能力，并行（parallel）是同一时间动手做（doing）多件事情的能力。</p><p>家庭主妇做饭、打扫卫生、给孩子喂奶，她一个人轮流交替做这多件事，这时就是并发</p><p>雇了 3 个保姆，一个专做饭、一个专打扫卫生、一个专喂奶，互不干扰，这时是并行</p><p>家庭主妇雇了个保姆，她们一起这些事，这时既有并发，也有并行（这时会产生竞争，例如锅只有一口，一 个人用锅时，另一个人就得等待）</p><p>应用<br>同步和异步的概念</p><p>以调用方的角度讲，如果需要等待结果返回才能继续运行的话就是同步，不需要等待就是异步。</p><p>1）设计</p><p>多线程可以使方法的执行变成异步的，比如说读取磁盘文件时，假设读取操作花费了 5 秒，如果没有线程的调度机制，那么 cpu 只能等 5 秒，啥都不能做。</p><p>结论<br>比如在项目中，视频文件需要转换格式等操作比较费时，这时开一个新线程处理视频转换，避免阻塞主线程。</p><p>tomcat 的异步 servlet 也是类似的目的，让用户线程处理耗时较长的操作，避免阻塞 tomcat 的工作线程</p><p>ui 程序中，开线程进行其他操作，避免阻塞 ui 线程</p><p>总结<br>单核 cpu 下，多线程不能实际提高程序运行效率，只是为了能够在不同的任务之间切换，不同线程轮流使用 cpu ，不至于一个线程总占用 cpu，别的线程没法干活。<br>多核 cpu 可以并行跑多个线程，但能否提高程序运行效率还是要分情况的。<br>有些任务，经过精心设计，将任务拆分，并行执行，当然可以提高程序的运行效率，但不是所有计算任 务都能拆分。</p><p>而也不是所有任务都需要拆分，任务的目的如果不同，谈拆分和效率没啥意义。</p><p>IO 操作不占用 cpu，只是我们一般拷贝文件使用的是【阻塞 IO】，这时相当于线程虽然不用 cpu，但需要一 直等待 IO 结束，没能充分利用线程。所以才有后面的【非阻塞 IO】和【异步 IO】优化。<br>CODE<br>1<br>注：以后的代码示例均在添加 @Slf4j 依赖的情况下执行<br>Java 线程<br>创建和运行线程<br>方法一，直接使用 Thread</p><pre><code class="bash">public static void main(String[] args) &#123;        // 匿名内部类方式创建 Thread        Thread t = new Thread(&quot;t1&quot;) &#123;            @Override            public void run() &#123;                log.debug(&quot;running&quot;);            &#125;        &#125;;                t.start();        log.debug(&quot;running&quot;);    &#125;</code></pre><p>方法二，使用 Runnable 配合 Thread（推荐）</p><p>把【线程】和【任务】（要执行的代码）分开，Thread 代表线程，Runnable 可运行的任务（线程要执行的代码）。</p><pre><code class="bash">public static void main(String[] args) &#123;        // 使用 lambda 表达式，因为 Runnable 接口         // 标注了 @FunctionalInterface 这个注解，表示是一个函数式接口，可以使用 lambda 表达式        Runnable r = () -&gt; log.debug(&quot;running&quot;);        new Thread(r, &quot;t1&quot;).start();    &#125;</code></pre><p>小结</p><p>方法 1 是把线程和任务合并在了一起，方法 2 是把线程和任务分开了。<br>用 Runnable 更容易与线程池等高级 API 配合，用 Runnable 让任务类脱离了 Thread 继承体系，更灵活。<br>通过查看源码可以发现，方法二其实到底还是通过方法一执行的！<br>方法三，FutureTask 配合 Thread</p><p>FutureTask 能够接收 Callable 类型的参数，用来处理有返回结果的情况 ，FutureTask 是 Future 和 Runable 的实现。</p><pre><code class="bash">public static void main(String[] args) throws ExecutionException, InterruptedException &#123;    // 实现多线程的第三种方法可以返回数据    FutureTask futureTask = new FutureTask&lt;&gt;(new Callable&lt;Integer&gt;() &#123;        @Override        public Integer call() throws Exception &#123;            log.debug(&quot;多线程任务&quot;);            Thread.sleep(100);            return 100;        &#125;    &#125;);    // 主线程阻塞，同步等待 task 执行完毕的结果    new Thread(futureTask,&quot;我的名字&quot;).start();    log.debug(&quot;主线程&quot;);    log.debug(&quot;&#123;&#125;&quot;,futureTask.get());&#125;</code></pre><p>Future 就是对于具体的 Runnable 或者 Callable 任务的执行结果进行取消、查询是否完成、获取结果。必要时可以通过 get 方法获取执行结果，该方法会阻塞直到任务返回结果。</p><pre><code class="bash">public interface Future&lt;V&gt; &#123;    boolean cancel(boolean mayInterruptIfRunning);    boolean isCancelled();    boolean isDone();    V get() throws InterruptedException, ExecutionException;    V get(long timeout, TimeUnit unit)        throws InterruptedException, ExecutionException, TimeoutException;&#125;</code></pre><p>Future 提供了三种功能： 　　</p><p>判断任务是否完成； 　　</p><p>能够中断任务； 　　</p><p>能够获取任务执行结果。</p><p>多个线程同时执行</p><p>交替执行<br>谁先谁后，不由我们控制<br>查看进程线程的方法</p><p>windows</p><p>任务管理器可以查看进程和线程数，也可以用来杀死进程。<br>tasklist 查看进程。<br>taskkill 杀死进程。<br>linux</p><p>ps -fe 查看所有进程。<br>ps -fT -p 查看某个进程（PID）的所有线程。<br>kill 杀死进程。<br>top 按大写 H 切换是否显示线程。<br>top -H -p 查看某个进程（PID）的所有线程。<br>java</p><p>jps 命令查看所有 java 进程。<br>jstack 查看某个 java 进程（PID）的所有线程状态。<br>jconsole 来查看某个 java 进程中线程的运行情况（图形界面）。<br>线程运行原理<br>虚拟机栈与栈帧</p><p>虚拟机栈描述的是 java 方法执行的内存模型：每个方法被执行的时候都会同时创建一个栈帧 (stack frame) 用于存储局部变量表、操作数栈、动态链接、方法出口等信息，是属于线程私有的。</p><p>当 java 中使用多线程时，每个线程都会维护它自己的栈帧。<br>每个线程只能有一个活动栈帧，对应着当前正在执行的那个方法。<br>线程上下文切换（Thread Context Switch）</p><p>因为以下一些原因导致 cpu 不再执行当前的线程，转而执行另一个线程的代码：</p><p>线程的 cpu 时间片用完 (每个线程轮流执行，看前面并行的概念)。<br>垃圾回收。<br>有更高优先级的线程需要运行。<br>线程自己调用了 sleep、yield、wait、join、park、synchronized、lock 等方法。<br>当 上下文切换发生时，需要由操作系统保存当前线程的状态，并恢复另一个线程的状态，java 中对应的概念就是程序计数器（Program Counter Register），它的作用是记住下一条 jvm 指令的执行地址，是线程私有的。</p><p>Thread 的常见方法<br>start 与 run<br>调用 start</p><pre><code class="bash">public static void main(String[] args) &#123;        Thread t1 = new Thread(new Runnable() &#123;            @Override            public void run() &#123;                log.info(Thread.currentThread().getName() + &quot; running....&quot;);            &#125;        &#125;, &quot;t1&quot;);        // 测试通过 Thread 类实例 t1 对象直接调用 run 方法        t1.run();        log.info(Thread.currentThread().getName() + &quot; running...&quot;);    &#125;</code></pre><p>输出：</p><pre><code class="bash">14:56:56 [main] c.Code_05_Test - main running....14:56:56 [main] c.Code_05_Test - main running...调用 run</code></pre><p>将上面代码的 thread.start(); 改为 thread.run(); 输出结果如下：</p><pre><code class="bash">14:59:35 [main] c.Code_05_Test - main running...14:59:35 [t1] c.Code_05_Test - t1 running....</code></pre><p>通过打印台的输出，发现结果是不一样的，使用 start 方式，CPU 会为创建的线程分配时间片，线程进入运行状态，然后线程调用 run 方法执行逻辑。而直接使用 run 的方式，虽然会创建了线程，但是它是直接调用方法，而不是像 start 方式那样，这个线程对象会处一直处在新建状态，从结果上也可以看出，run 方法是 main 线程调用，而不是 t1 线程。</p><p>小结</p><p>直接调用 run() 是在主线程中执行了 run()，没有启动新的线程。<br>使用 start() 是启动新的线程，通过新的线程间接执行 run() 方法 中的代码。<br>sleep 与 yield<br>sleep</p><p>调用 sleep 会让当前线程从 Running 进入 Timed Waiting 状态（阻塞）。<br>其它线程可以使用 interrupt 方法打断正在睡眠的线程，那么被打断的线程这时就会抛出 InterruptedException 异常【注意：这里打断的是正在休眠的线程，而不是其它状态的线程】。<br>睡眠结束后的线程未必会立刻得到执行 (需要分配到 cpu 时间片)。<br>建议用 TimeUnit 的 sleep() 代替 Thread 的 sleep() 来获得更好的可读性。<br>yield（礼让）</p><p>调用 yield 会让当前线程从 Running 进入 Runnable 就绪状态，然后调度执行其它线程。<br>具体的实现依赖于操作系统的任务调度器。<br>小结</p><p>yield 使 cpu 调用其它线程，但是 cpu 可能会再分配时间片给该线程；而 sleep 需要等过了休眠时间之后才有可能被分配 cpu 时间片。</p><p>线程优先级</p><p>线程优先级会提示（hint）调度器优先调度该线程，但它仅仅是一个提示，调度器可以忽略它。<br>如果 cpu 比较忙，那么优先级高的线程会获得更多的时间片，但 cpu 闲时，优先级几乎没作用。<br>join<br>join 用于等待某个线程结束。哪个线程内调用 join () 方法，就等待哪个线程结束，然后再去执行其他线程。如在主线程中调用 t1.join ()，则是主线程需要等待 t1 线程结束，才能执行其线程。</p><p>JAVA<br>1<br>2<br>3<br>4<br>5<br>Thread t1 = new Thread();<br>//等待 t1 线程执行结束<br>t1.join();<br>// 最多等待 1000ms,如果 1000ms 内线程执行完毕，则会直接执行下面的语句，不会等够 1000ms<br>t1.join(1000);<br>为什么需要 join？</p><p>下面的代码执行，打印 r 是什么？</p><pre><code class="bash">static int r = 0;public static void main(String[] args) throws InterruptedException &#123;     test1();&#125;private static void test1() throws InterruptedException &#123;     log.debug(&quot;开始&quot;);     Thread t1 = new Thread(() -&gt; &#123;         log.debug(&quot;开始&quot;);         sleep(1);         log.debug(&quot;结束&quot;);         r = 10;     &#125;);     t1.start();     log.debug(&quot;结果为:&#123;&#125;&quot;, r);     log.debug(&quot;结束&quot;);&#125;</code></pre><p>分析：</p><p>因为主线程和线程 t1 是并行执行的，t1 线程需要 1 秒之后才能算出 r=10。</p><p>而主线程一开始就要打印 r 的结果，所以只能打印出 r=0。</p><p>解决方法：要想打印出 r=10，用 join 加在 t1.start () 之后即可。</p><p>注意：</p><p>需要等待结果返回，才能继续运行就是同步。</p><p>不需要等待结果返回，就能继续运行就是异步。</p><p>interrupt()<br>interrupt 打断线程有两种情况，如下：</p><p>如果一个线程在在运行中被打断，打断标记会被置为 true 。<br>如果是打断的是因 sleep、wait、join 方法而被阻塞的线程，会将打断标记置为 false 。<br>isInterrupted () 与 interrupted () 比较</p><p>首先，isInterrupted 是实例方法，interrupted 是静态方法，它们的用处都是查看当前打断的状态，但是 isInterrupted 方法查看线程的时候，不会将打断标记清空，也就是置为 false，interrupted 查看线程打断状态后，会将打断标志置为 false，也就是清空打断标记。</p><p>以 sleep 为例：</p><pre><code class="bash">private static void test1() throws InterruptedException &#123;     Thread t1 = new Thread(()-&gt;&#123;         sleep(1);     &#125;, &quot;t1&quot;);     t1.start();          sleep(0.5);//t2睡眠0.5s     t1.interrupt();     log.debug(&quot; 打断状态: &#123;&#125;&quot;, t1.isInterrupted());&#125;</code></pre><p>输出：</p><pre><code class="bash">java.lang.InterruptedException: sleep interrupted     at java.lang.Thread.sleep(Native Method)     at java.lang.Thread.sleep(Thread.java:340)     at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)     at cn.heu.n2.util.Sleeper.sleep(Sleeper.java:8)     at cn.heu.n4.TestInterrupt.lambda$test1$3(TestInterrupt.java:59)     at java.lang.Thread.run(Thread.java:745)21:18:10.374 [main] TestInterrupt - 打断状态: false</code></pre><p>打断正常运行的线程，不会清空打断状态：</p><pre><code class="bash">private static void test2() throws InterruptedException &#123;     Thread t2 = new Thread(()-&gt;&#123;     while(true) &#123;         Thread current = Thread.currentThread();         boolean interrupted = current.isInterrupted();         if(interrupted) &#123;             log.debug(&quot; 打断状态: &#123;&#125;&quot;, interrupted);             break;        &#125;     &#125;  &#125;, &quot;t2&quot;);  t2.start();  sleep(0.5);//t2睡眠0.5s  t2.interrupt();&#125;</code></pre><p>输出：</p><pre><code class="bash">20:57:37.964 [t2] TestInterrupt - 打断状态: true</code></pre><p>注：打断 park 线程，不会清空打断状态。而如果打断标记已经是 true, 则 park 会失效。</p><p>​ 可以使用 Thread.interrupted () 清除打断状态。</p><p>模式之两阶段终止<br>Two Phase Termination，就是考虑在一个线程 T1 中如何优雅地终止另一个线程 T2，这里的优雅指的是给 T2 一个料理后事的机会（如释放锁）。</p><p>如下所示：线程的 isInterrupted() 方法可以取得线程的打断标记，如果线程在睡眠 sleep 期间被打断，打断标记是不会变的，为 false，但是 sleep 期间被打断会抛出异常，我们据此手动设置打断标记为 true；如果是在程序正常运行期间被打断的，那么打断标记就被自动设置为 true。处理好这两种情况那我们就可以放心地来料理后事啦！</p><p>image-20210603153151665<br>代码实现如下：</p><pre><code class="bash">public class Test &#123;    public static void main(String[] args) throws InterruptedException &#123;        TwoParseTermination twoParseTermination = new TwoParseTermination();        twoParseTermination.start();        Thread.sleep(3500);        twoParseTermination.stop();    &#125;&#125;class TwoParseTermination &#123;    private Thread monitor;    // 启动线程    public void start() &#123;        monitor = new Thread(() -&gt; &#123;            while (true) &#123;                Thread thread = Thread.currentThread();                if(thread.isInterrupted()) &#123; // 调用 isInterrupted 不会清除标记                    log.info(&quot;料理后事 ...&quot;);                    break;                &#125; else &#123;                    try &#123;                        Thread.sleep(1000);                        log.info(&quot;执行监控的功能 ...&quot;);                    &#125; catch (InterruptedException e) &#123;                        log.info(&quot;设置打断标记 ...&quot;);                        thread.interrupt();                        e.printStackTrace();                    &#125;                &#125;            &#125;        &#125;, &quot;monitor&quot;);        monitor.start();    &#125;    // 终止线程    public void stop() &#123;        monitor.interrupt();    &#125;&#125;</code></pre><p>不推荐的方法<br>还有一些不推荐使用的方法，这些方法已过时，容易破坏同步代码块，造成线程死锁。</p><p>stop：停止线程运行。<br>suspend () ：挂起（暂停）线程运行。<br>resume ()：恢复线程运行。<br>主线程与守护线程<br>默认情况下，Java 进程需要等待所有线程都运行结束，才会结束。有一种特殊的线程叫做守护线程，只要其它非守</p><p>护线程运行结束了，即使守护线程的代码没有执行完，也会强制结束。</p><p>注意</p><p>垃圾回收器线程就是一种守护线程</p><p>Tomcat 中的 Acceptor 和 Poller 线程都是守护线程，所以 Tomcat 接收到 shutdown 命令后，不会等待它们处理完当前请求。</p><p>五种状态<br>五种状态的划分主要是从操作系统的层面进行划分的：</p><p>1583507073055<br>【初始状态】仅是在语言层面创建了线程对象，还未与操作系统线程关联。</p><p>【可运行状态】（就绪状态）指该线程已经被创建（与操作系统线程关联），可以由 CPU 调度执行。</p><p>【运行状态】指获取了 CPU 时间片运行中的状态。</p><p>当 CPU 时间片用完，会从【运行状态】转换至【可运行状态】，会导致线程的上下文切换。<br>【阻塞状态】</p><p>如果调用了阻塞 API，如 BIO 读写文件，这时该线程实际不会用到 CPU，会导致线程上下文切换，进入【阻塞状态】；<br>等 BIO 操作完毕，会由操作系统唤醒阻塞的线程，转换至【可运行状态】。<br>与【可运行状态】的区别是：对【阻塞状态】的线程来说只要它们一直不唤醒，调度器就一直不会考虑调度它们。<br>【终止状态】表示线程已经执行完毕，生命周期已经结束，不会再转换为其它状态。</p><p>六种状态<br>这是从 Java API 层面来描述的，根据 Thread.State 枚举，分为六种状态：</p><p>image-20210630120605408<br>【NEW】： 线程刚被创建，但是还没有调用 start () 方法。</p><p>【RUNNABLE】： 当调用了 start () 方法之后，注意，Java API 层面的 RUNNABLE 状态涵盖了 操作系统 层面的【可运行状态】、【运行状态】和【阻塞状态】（由于 BIO 导致的线程阻塞，在 Java 里无法区分，仍然认为是可运行）。</p><p>【BLOCKED】 ， 【WAITING】 ， 【TIMED_WAITING】 都是 Java API 层面对【阻塞状态】的细分，后面会在状态转换一节</p><p>详述。</p><p>【TERMINATED】 当线程代码运行结束。</p>]]></content>
      
      
      <categories>
          
          <category> 多线程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 多线程 </tag>
            
            <tag> 进程 </tag>
            
            <tag> 线程方法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java8新特性</title>
      <link href="/2020/08/26/java/Java8%E6%96%B0%E7%89%B9%E6%80%A7/"/>
      <url>/2020/08/26/java/Java8%E6%96%B0%E7%89%B9%E6%80%A7/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>前言</p><p>前几篇文章，给大家分享了JDK 17中的一些新特性。<br>接下来的内容，我们继续围绕JDK各版本的特性进行讨论学习。<br>之前的文章中提到过，目前有三个版本（8、11、17）是长期维护（LTS）版本；而目前绝大多数企业使用的版本还是JDK8。<br>本期我们一起看一下JDK8有哪些特性。<br>语法</p><p>Lambda表达式</p><p>它们使您能够将功能视为方法参数，或将代码视为数据。Lambda 表达式让您可以更简洁地表达单方法接口（称为函数式接口）的实例。<br>List<String> list = new ArrayList&lt;&gt;(Arrays.asList(“a”,”bb”,”ccc”));<br>list.removeIf(s -&gt; s.length() == 3);<br>System.out.println(list);<br>方法引用(Method references)</p><p>为已有名称的方法提供易于阅读的 lambda 表达式。<br>List<String> list = new ArrayList&lt;&gt;(Arrays.asList(“a”,”bb”,”ccc”));<br>// 方法引用：  谁::做什么<br>list.forEach(System.out::println);<br>默认方法(Default methods)</p><p>允许将新功能添加到接口中，并确保与为这些接口的旧版本编写的代码的兼容性。例如：List接口中的replaceAll方法<br>/*</p><ul><li>……</li><li>@since 1.8</li><li>/<br>default void replaceAll(UnaryOperator<E> operator) {<br>  Objects.requireNonNull(operator);<br>  final ListIterator<E> li = this.listIterator();<br>  while (li.hasNext()) {<pre><code>  li.set(operator.apply(li.next()));</code></pre>  }<br>}<br>重复注解(Repeating Annotations)</li></ul><p>提供了将相同注解类型多次应用于相同声明或类型使用的能力。<br>// 定义注解Schedule<br>// @Repeatable为jdk中的元注解，表示Schedule可以重复使用<br>@Repeatable(Schedules.class)<br>public @interface Schedule {<br>  String dayOfMonth() default “first”;<br>  String dayOfWeek() default “Mon”;<br>  int hour() default 12;<br>}</p><p>// 使用<br>@Schedule(dayOfMonth=”last”)<br>@Schedule(dayOfWeek=”Fri”, hour=”23”)<br>public void doPeriodicCleanup() { … }<br>类型注解(Type Annotations)</p><p>提供了在使用类型的任何地方应用注解的能力，而不仅仅是在声明上。与插件一起使用，此功能可以改进代码的类型检查。<br>在 Java SE 8 发布之前，注解只能应用于声明。从 Java SE 8 版本开始，注解也可以应用于任何类型的使用。例如：<br>类的实例化<br>new @Interned MyObject();<br>类型转换<br>myString = (@NonNull String) str;<br>接口实现<br>class UnmodifiableListimplements @Readonly List&lt;@Readonly T&gt; { … }<br>抛异常<br>void monitorTemperature() throws @Critical TemperatureException { … }<br>示例<br>// 需要使用插件checker framework:  <a href="https://checkerframework.org/">https://checkerframework.org/</a><br>// 也可以自定义插件</p><p>// @NonNull 表示String s不能是null 否则在编译时就会由插件给出错误<br>public static void test(@NonNull String s){<br>    System.out.println(s);<br>}</p><p>public static void main(String[] args) {<br>    test(null);<br>}</p><p>// 编译结果<br>   test(null);<br>             ^<br>  found   : null (NullType)<br>  required: @Initialized @NonNull String<br>改进类型推断(type inference)</p><p>Java 编译器利用目标类型来推断泛型方法调用的类型参数。<br>List<String> stringList = new ArrayList&lt;&gt;();<br>stringList.add(“A”);<br>// addAll(Collection&lt;? extends String&gt;) 目标类型是Collection&lt;? extends String&gt;<br>// Arrays.asList() 返回 List<T><br>// 编译器根据Collection&lt;? extends String&gt;自动推断T为String<br>stringList.addAll(Arrays.asList());</p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> jdk </tag>
            
            <tag> optional </tag>
            
            <tag> stream流 </tag>
            
            <tag> LocalDateTime </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>反射机制</title>
      <link href="/2020/08/20/java/%E5%8F%8D%E5%B0%84%E6%9C%BA%E5%88%B6/"/>
      <url>/2020/08/20/java/%E5%8F%8D%E5%B0%84%E6%9C%BA%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="何为反射？"><a href="#何为反射？" class="headerlink" title="何为反射？"></a>何为反射？</h1><p>反射是动态获取信息以及动态调用对象方法的一种机制。它赋予了我们在运行时分析类以及执行类中方法的能力。通过反射你可以获取任意一个类的所有属性和方法，你还可以调用这些方法和属性。</p><h1 id="反射的应用场景了解么？"><a href="#反射的应用场景了解么？" class="headerlink" title="反射的应用场景了解么？"></a>反射的应用场景了解么？</h1><p>Spring/Spring Boot、MyBatis 等等框架中都大量使用了反射机制。这些框架中也大量使用了动态代理，而动态代理的实现也依赖反射。</p><p>比如下面是通过 JDK 实现动态代理的示例代码，其中就使用了反射类 Method 来调用指定的方法。</p><pre><code class="bash">public class DebugInvocationHandler implements InvocationHandler &#123;    /**     * 代理类中的真实对象     */    private final Object target;    public DebugInvocationHandler(Object target) &#123;        this.target = target;    &#125;    public Object invoke(Object proxy, Method method, Object[] args) throws InvocationTargetException, IllegalAccessException &#123;        System.out.println(&quot;before method &quot; + method.getName());        Object result = method.invoke(target, args);        System.out.println(&quot;after method &quot; + method.getName());        return result;    &#125;&#125;</code></pre><p>另外，像 Java 中的一大利器 注解 的实现也用到了反射。为什么你使用 Spring 的时候 ，一个 @Component 注解就声明了一个类为 Spring Bean 呢？为什么你通过一个 @Value 注解就读取到配置文件中的值呢？究竟是怎么起作用的呢？</p><p>这些都是因为你可以基于反射分析类，然后获取到类 / 属性 / 方法 / 方法的参数上的注解。你获取到注解之后，就可以做进一步的处理。</p><h1 id="谈谈反射机制的优缺点"><a href="#谈谈反射机制的优缺点" class="headerlink" title="谈谈反射机制的优缺点"></a>谈谈反射机制的优缺点</h1><p>优点 ： 可以让咱们的代码更加灵活、为各种框架提供开箱即用的功能提供了便利</p><p>缺点 ：让我们在运行时有了分析操作类的能力，这同样也增加了安全问题。比如可以无视泛型参数的安全检查（泛型参数的安全检查发生在编译时）。另外，反射的性能也要稍差点，不过，对于框架来说实际是影响不大的。</p><h1 id="反射获取-Class-对象的四种方式"><a href="#反射获取-Class-对象的四种方式" class="headerlink" title="反射获取 Class 对象的四种方式"></a>反射获取 Class 对象的四种方式</h1><p>如果我们动态获取到这些信息，我们需要依靠 Class 对象。Class 类对象将一个类的方法、变量等信息告诉运行的程序。Java 提供了四种方式获取 Class 对象：</p><h3 id="1-知道具体类的情况下可以使用："><a href="#1-知道具体类的情况下可以使用：" class="headerlink" title="1. 知道具体类的情况下可以使用："></a>1. 知道具体类的情况下可以使用：</h3><pre><code class="bash">Class alunbarClass = TargetObject.class;</code></pre><h3 id="2-通过-Class-forName-传入类的路径获取："><a href="#2-通过-Class-forName-传入类的路径获取：" class="headerlink" title="2. 通过 Class.forName() 传入类的路径获取："></a>2. 通过 Class.forName() 传入类的路径获取：</h3><pre><code class="bash">Class alunbarClass = TargetObject.class;</code></pre><h3 id="3-通过对象实例-instance-getClass-获取："><a href="#3-通过对象实例-instance-getClass-获取：" class="headerlink" title="3. 通过对象实例 instance.getClass() 获取："></a>3. 通过对象实例 instance.getClass() 获取：</h3><pre><code class="bash">TargetObject o = new TargetObject();Class alunbarClass2 = o.getClass();</code></pre>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 反射 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>神秘的 Java NIO</title>
      <link href="/2020/08/17/io/%E7%A5%9E%E7%A7%98%E7%9A%84%20Java%20NIO/"/>
      <url>/2020/08/17/io/%E7%A5%9E%E7%A7%98%E7%9A%84%20Java%20NIO/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p><strong>从计算机结构的视角来看的话， I/O 描述了计算机系统与外部设备之间通信的过程。</strong></p><p><strong>我们再先从应用程序的角度来解读一下 I/O。</strong></p><p>根据大学里学到的操作系统相关的知识：为了保证操作系统的稳定性和安全性，一个进程的地址空间划分为 <strong>用户空间（User space） 和 内核空间（Kernel space ）</strong> 。像我们平常运行的应用程序都是运行在用户空间，只有内核空间才能进行系统态级别的资源有关的操作，比如文件管理、进程通信、内存管理等等。也就是说，想要进行 IO 操作，一定是要依赖内核空间的能力。并且，用户空间的程序不能直接访问内核空间。</p><p>当想要执行 IO 操作时，由于没有执行这些操作的权限，只能发起系统调用请求操作系统帮忙完成。因此，用户进程想要执行 IO 操作的话，必须通过 系统调用 来间接访问内核空间。</p><p>我们在平常开发过程中接触最多的就是** 磁盘 IO（读写文件） 和 网络 IO（网络请求和响应）。从应用程序的视角来看的话，我们的应用程序对操作系统的内核发起 IO 调用（系统调用），操作系统的内核负责执行具体的 IO 操作。也就是说，我们的应用程序实际上只是发起了 IO 操作的调用而已，具体 IO 的执行是由操作系统的内核来完成的。**</p><p>当应用程序发起 I/O 调用后，会经历两个步骤：</p><ol><li>内核等待 I/O 设备准备好数据；</li><li>内核将数据从内核空间拷贝到用户空间。</li></ol><h2 id="同步、异步、阻塞、非阻塞"><a href="#同步、异步、阻塞、非阻塞" class="headerlink" title="同步、异步、阻塞、非阻塞"></a>同步、异步、阻塞、非阻塞</h2><h3 id="同步与异步"><a href="#同步与异步" class="headerlink" title="同步与异步"></a>同步与异步</h3><ul><li><p>同步就是一个任务的完成需要依赖另外一个任务时，只有等待被依赖的任务完成后，依赖的任务才能算完成，这是一种可靠的任务序列。要么成功都成功，失败都失败，两个任务的状态可以保持一致。</p></li><li><p>而异步是不需要等待被依赖的任务完成，只是通知被依赖的任务要完成什么工作，依赖的任务也立即执行，只要自己完成了整个任务就算完成了。至于被依赖的任务最终是否真正完成，依赖它的任务无法确定，所以它是不可靠的任务序列。我们可以用打电话和发短信来很好的比喻同步与异步操作。</p></li></ul><h3 id="阻塞与非阻塞"><a href="#阻塞与非阻塞" class="headerlink" title="阻塞与非阻塞"></a>阻塞与非阻塞</h3><ul><li><p>阻塞与非阻塞主要是从 CPU 的消耗上来说的，阻塞就是 CPU 停下来等待一个慢的操作完成 CPU 才接着完成其它的事。</p></li><li><p>非阻塞就是在这个慢的操作在执行时 CPU 去干其它别的事，等这个慢的操作完成时，CPU 再接着完成后续的操作。虽然表面上看非阻塞的方式可以明显的提高 CPU 的利用率，但是也带了另外一种后果就是系统的线程切换增加。增加的 CPU 使用时间能不能补偿系统的切换成本需要好好评估。</p></li></ul><h3 id="同-异、阻-非堵塞-组合"><a href="#同-异、阻-非堵塞-组合" class="headerlink" title="同 / 异、阻 / 非堵塞 组合"></a>同 / 异、阻 / 非堵塞 组合</h3><p>|组合方式|性能分析|<br>｜—｜—:|<br>|同步阻塞|最常用的一种用法，使用也是最简单的，但是 I/O 性能一般很差，CPU 大部分在空闲状态。|</p><p>|同步非阻塞|提升 I/O 性能的常用手段，就是将 I/O 的阻塞改成非阻塞方式，尤其在网络 I/O 是长连接，同时传输数据也不是很多的情况下，提升性能非常有效。 这种方式通常能提升 I/O 性能，但是会增加 CPU 消耗，要考虑增加的 I/O 性能能不能补偿 CPU 的消耗，也就是系统的瓶颈是在 I/O 还是在 CPU 上。|</p><p>|异步阻塞|这种方式在分布式数据库中经常用到，例如在网一个分布式数据库中写一条记录，通常会有一份是同步阻塞的记录，而还有两至三份是备份记录会写到其它机器上，这些备份记录通常都是采用异步阻塞的方式写 I/O。异步阻塞对网络 I/O 能够提升效率，尤其像上面这种同时写多份相同数据的情况。|</p><p>|异步非阻塞|这种组合方式用起来比较复杂，只有在一些非常复杂的分布式情况下使用，像集群之间的消息同步机制一般用这种 I/O 组合方式。如 Cassandra 的 Gossip 通信机制就是采用异步非阻塞的方式。它适合同时要传多份相同的数据到集群中不同的机器，同时数据的传输量虽然不大，但是却非常频繁。这种网络 I/O 用这个方式性能能达到最高。|</p><h2 id="Java-IO"><a href="#Java-IO" class="headerlink" title="Java IO"></a>Java IO</h2><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/944365-3a31f3fd3df13c18.jpg" alt="Java IO" title="Java IO"></p><h2 id="NIO-定义"><a href="#NIO-定义" class="headerlink" title="NIO 定义"></a>NIO 定义</h2><ul><li>即 Java New IO。</li><li>是 1 个全新的、 JDK 1.4 后提供的 IO API。</li></ul><h2 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h2><ul><li>提供了与标准 IO 不同的 IO 工作方式。</li><li>可替代 标准 Java IO 的 IO API。<h2 id="新特性"><a href="#新特性" class="headerlink" title="新特性"></a>新特性</h2>对比于 <font color="red">Java IO</font>，<font color="red">NIO</font> 具备的新特性如下：</li></ul><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210709102817810.png" alt="NIO组件" title="NIO组件"></p><h2 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h2><p>1.通过 Channel 注册到 Selector 上的状态来实现一种客户端与服务端的通信。</p><p>2.Channel 中数据的读取是通过 Buffer , 一种非阻塞的读取方式。</p><ol start="3"><li>Selector 多路复用器为单线程模型， 线程的资源开销相对比较小。</li></ol><h2 id="核心组件"><a href="#核心组件" class="headerlink" title="核心组件"></a>核心组件</h2><p>Java NIO 的核心组件 包括：</p><ul><li>通道（Channel）</li><li>缓冲区（Buffer）</li><li>选择器（Selectors）<br>下面将详细介绍：</li></ul><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/944365-93cd55b2ed7cd37c.png" alt="NIO核心组件" title="NIO核心组件"></p><p>Bufer 是一个缓冲区，实际上是一个容器，一个连续数组。Channel 提供从文件、网络读取数据的渠道，但是读写的数据都必须经过 Buffer。</p><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/13449209-300fd48a7251c327.png" alt="Buffer缓冲区" title="Buffer缓冲区"></p><p>Buffer 缓冲区本质上是一块可以写入数据，然后可以从中读取数据的内存。这块内存被包装成 NIO Buffer 对象，并提供了一组方法，用来方便的访问该模块内存。为了理解 Buffer 的工作原理，需要熟悉它的三个属性：capacity、position 和 limit。</p><p>position 和 limit 的含义取决于 Buffer 处在读模式还是写模式。不管 Buffer 处在什么模式，capacity 的含义总是一样的。见下图：</p><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/13449209-d261cbcb9b9ed88f.png" alt="Buffer缓冲区"></p><ul><li><p>capacity：Buffer 作为一个内存块，有固定的大小值，也叫作 “capacity”，只能往其中写入 capacity 个 byte、long、char 等类型。一旦 Buffer 满了，需要将其清空（通过读数据或者清楚数据）才能继续写数据。</p></li><li><p>position：当你写数据到 Buffer 中时，position 表示当前的位置。初始的 position 值为 0，当写入一个字节数据到 Buffer 中后，position 会向前移动到下一个可插入数据的 Buffer 单元。position 最大可为 capacity-1。当读取数据时，也是从某个特定位置读，将 Buffer 从写模式切换到读模式，position 会被重置为 0。当从 Buffer 的 position 处读取一个字节数据后，position 向前移动到下一个可读的位置。</p></li><li><p>limit：在写模式下，Buffer 的 limit 表示你最多能往 Buffer 里写多少数据。 写模式下，limit 等于 Buffer 的 capacity。当切换 Buffer 到读模式时， limit 表示你最多能读到多少数据。因此，当切换 Buffer 到读模式时，limit 会被设置成写模式下的 position 值。换句话说，你能读到之前写入的所有数据（limit 被设置成已写数据的数量，这个值在写模式下就是 position）。</p></li></ul><p><img src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/88ff862764024c3b8567367df11df6ab~tplv-k3u1fbpfcp-watermark.image" alt="IO 多路复用模型"></p><p>IO 多路复用模型中，线程首先发起 select 调用，询问内核数据是否准备就绪，等内核把数据准备好了，用户线程再发起 read 调用。read 调用的过程（数据从内核空间 -&gt; 用户空间）还是阻塞的。</p><blockquote><p>目前支持 IO 多路复用的系统调用，有 select，epoll 等等。select 系统调用，是目前几乎在所有的操作系统上都有支持。</p></blockquote><ul><li>select 调用 ：内核提供的系统调用，它支持一次查询多个系统调用的可用状态。几乎所有的操作系统都支持。</li><li>epoll 调用 ：linux 2.6 内核，属于 select 调用的增强版本，优化了 IO 的执行效率。</li></ul><p><strong>IO 多路复用模型，通过减少无效的系统调用，减少了对 CPU 资源的消耗。</strong></p><h2 id="具体使用"><a href="#具体使用" class="headerlink" title="具体使用"></a>具体使用</h2><h3 id="基于通道-amp-缓冲数据"><a href="#基于通道-amp-缓冲数据" class="headerlink" title="基于通道 &amp; 缓冲数据"></a>基于通道 &amp; 缓冲数据</h3><p>具体步骤如下：</p><pre><code class="bash">// 1. 获取数据源 和 目标传输地的输入输出流（此处以数据源 = 文件为例）FileInputStream fin = new FileInputStream(infile);FileOutputStream fout = new FileOutputStream(outfile);// 2. 获取数据源的输入输出通道FileChannel fcin = fin.getChannel();FileChannel fcout = fout.getChannel();// 3. 创建 缓冲区 对象：Buffer（共有2种方法） // 方法1：使用allocate()静态方法 ByteBuffer buff = ByteBuffer.allocate(256); // 上述方法创建1个容量为256字节的ByteBuffer // 注：若发现创建的缓冲区容量太小，则重新创建一个大小合适的缓冲区// 方法2：通过包装一个已有的数组来创建 // 注：通过包装的方法创建的缓冲区保留了被包装数组内保存的数据 ByteBuffer buff = ByteBuffer.wrap(byteArray); // 额外：若需将1个字符串存入ByteBuffer，则如下 String sendString=&quot;你好,服务器. &quot;; ByteBuffer sendBuff = ByteBuffer.wrap(sendString.getBytes(&quot;UTF-16&quot;));// 4. 从通道读取数据 &amp; 写入到缓冲区// 注：若 以读取到该通道数据的末尾，则返回-1fcin.read(buff);// 5. 传出数据准备：将缓存区的写模式 转换-&gt;&gt; 读模式 调用flip()方法会将position设置为0，并将limit设置为之前的position的值。buff.flip();// 6. 从 Buffer 中读取数据 &amp; 传出数据到通道fcout.write(buff);// 7. 重置缓冲区// 目的：重用现在的缓冲区,即 不必为了每次读写都创建新的缓冲区，在再次读取之前要重置缓冲区// 注：不会改变缓冲区的数据，只是重置缓冲区的主要索引值buff.clear();</code></pre><p>向 Buffer 中写数据：写数据到 Buffer 中有两种方式：</p><ul><li>从 channel 写到 Buffer：</li></ul><pre><code class="bash">int bytes = channel.read(buf); //将channel中的数据读取到buf中</code></pre><ul><li>通过 Buffer 的 put () 方法写到 Buffer：</li></ul><pre><code class="bash">buf.put(byte); //将数据通过put()方法写入到buf中</code></pre><p>从 Buffer 中读数据有两种方式：</p><ul><li>从 Buffer 读取数据到 Channel：</li></ul><pre><code class="bash">int bytes = channel.write(buf); //将buf中的数据读取到channel中</code></pre><ul><li>通过 Buffer 的 get () 方法读取数据：</li></ul><pre><code class="bash">byte bt = buf.get(); //从buf中读取一个byte</code></pre><p>其他方法：</p><ul><li><p>rewind () 方法：Buffer.rewind () 方法将 position 设置为 0，使得可以重读 Buffer 中的所有数据，limit 保持不变。</p></li><li><p>clear () 与 compact () 方法：一旦读完 Buffer 中的数据，需要让 Buffer 准备好再次被写入，可以通过 clear () 或 compact () 方法完成。如果调用的是 clear () 方法，position 将被设置为 0，limit 设置为 capacity 的值，但是 Buffer 并未被清空，只是通过这些标记告诉我们可以从哪里开始往 Buffer 中写入多少数据。如果 Buffer 中还有一些未读的数据，调用 clear () 方法将被” 遗忘 “。compact () 方法将所有未读的数据拷贝到 Buffer 起始处，然后将 position 设置到最后一个未读元素的后面，limit 属性依然设置为 capacity。可以使得 Buffer 中的未读数据还可以在后续中被使用。</p></li><li><p>mark () 与 reset () 方法：通过调用 Buffer.mark () 方法可以标记一个特定的 position，之后可以通过调用 Buffer.reset () 恢复到这个 position 上。</p></li></ul><h3 id="基于选择器（Selecter）"><a href="#基于选择器（Selecter）" class="headerlink" title="基于选择器（Selecter）"></a>基于选择器（Selecter）</h3><pre><code class="bash">// 1. 创建Selector对象   Selector sel = Selector.open();// 2. 向Selector对象绑定通道    // a. 创建可选择通道，并配置为非阻塞模式    ServerSocketChannel server = ServerSocketChannel.open();    server.configureBlocking(false);     // b. 绑定通道到指定端口    ServerSocket socket = server.socket();    InetSocketAddress address = new InetSocketAddress(port);    socket.bind(address);     // c. 向Selector中注册感兴趣的事件    server.register(sel, SelectionKey.OP_ACCEPT);     return sel;// 3. 处理事件try &#123;        while(true) &#123;         // 该调用会阻塞，直到至少有一个事件就绪、准备发生         selector.select();         // 一旦上述方法返回，线程就可以处理这些事件        Set&lt;SelectionKey&gt; keys = selector.selectedKeys();         Iterator&lt;SelectionKey&gt; iter = keys.iterator();         while (iter.hasNext()) &#123;             SelectionKey key = (SelectionKey) iter.next();             iter.remove();             process(key);         &#125;        &#125;    &#125; catch (IOException e) &#123;        e.printStackTrace();   &#125;</code></pre><p>Selector 与 Channel 是相互配合使用的，将 Channel 注册在 Selector 上之后，才可以正确的使用 Selector，但此时 Channel 必须为非阻塞模式。Selector 可以监听 Channel 的四种状态（Connect、Accept、Read、Write），当监听到某一 Channel 的某个状态时，才允许对 Channel 进行相应的操作。</p><ul><li>Connect：某一个客户端连接成功后</li><li>Accept：准备好进行连接</li><li>Read：可读</li><li>Write：可写</li></ul><h3 id="NIO-实现多路复用"><a href="#NIO-实现多路复用" class="headerlink" title="NIO 实现多路复用"></a>NIO 实现多路复用</h3><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/image-20210709111120737.png" alt="NIO 实现多路复用"></p><ul><li><p>首先，通过 Selector.open () 创建一个 Selector，作为类似调度员的角色；</p></li><li><p>然后，创建一个 ServerSocketChannel，并且向 Selector 注册，通过指定 SelectionKey.OP_ACCEPT，告诉调度员，它关注的是新的连接请求；</p></li><li><p>为什么我们要明确配置非阻塞模式呢？这是因为阻塞模式下，注册操作是不允许的，会抛出 IllegalBlockingModeException 异常；</p></li><li><p>Selector 阻塞在 select 操作，当有 Channel 发生接入请求，就会被唤醒。</p></li></ul><blockquote><p>当一个连接创建后，不需要对应一个线程，这个连接会被注册到多路复用器上面，所有的连接只需要一个线程就可以搞定，当这个线程中的多路复用器进行轮询的时候，发现连接上有请求的话，才开启一个线程进行处理，也就是一个请求一个线程模式。</p></blockquote><h2 id="实例讲解"><a href="#实例讲解" class="headerlink" title="实例讲解"></a>实例讲解</h2><ul><li>实例说明：实现文件复制功能</li><li>实现方式：通道 FileChannel、 缓冲区 ByteBuffer</li></ul><pre><code class="bash">import java.io.FileInputStream;import java.io.FileOutputStream;import java.io.IOException;import java.nio.ByteBuffer;import java.nio.channels.FileChannel;public class Test &#123;    public static void main(String[] args) throws IOException &#123;        // 设置输入源 &amp; 输出地 = 文件        String infile = &quot;C:\\copy.sql&quot;;        String outfile = &quot;C:\\copy.txt&quot;;        // 1. 获取数据源 和 目标传输地的输入输出流（此处以数据源 = 文件为例）        FileInputStream fin = new FileInputStream(infile);        FileOutputStream fout = new FileOutputStream(outfile);        // 2. 获取数据源的输入输出通道        FileChannel fcin = fin.getChannel();        FileChannel fcout = fout.getChannel();        // 3. 创建缓冲区对象        ByteBuffer buff = ByteBuffer.allocate(1024);                while (true) &#123;            // 4. 从通道读取数据 &amp; 写入到缓冲区            // 注：若 以读取到该通道数据的末尾，则返回-1              int r = fcin.read(buff);            if (r == -1) &#123;                break;            &#125;            // 5. 传出数据准备：调用flip()方法              buff.flip();                        // 6. 从 Buffer 中读取数据 &amp; 传出数据到通道            fcout.write(buff);                        // 7. 重置缓冲区            buff.clear();                      &#125;        &#125;&#125;</code></pre><p><strong>NIO 的工作流程步骤：</strong></p><ol><li>首先是先创建 ServerSocketChannel 对象，和真正处理业务的线程池；</li><li>然后给刚刚创建的 ServerSocketChannel 对象进行绑定一个对应的端口，然后设置为非阻塞；</li><li>然后创建 Selector 对象并打开，把这 Selector 对象注册到 ServerSocketChannel 中，并设置好监听的事件，监听 SelectionKey.OP_ACCEPT；</li><li>接着就是 Selector 对象进行死循环监听每一个 Channel 通道的事件，循环执行 Selector.select () 方法，轮询就绪的 Channel；</li><li>从 Selector 中获取所有的 SelectorKey（这个就可以看成是不同的事件），如果 SelectorKey 是处于 OP_ACCEPT 状态，说明是新的客户端接入，调用 ServerSocketChannel.accept 接收新的客户端。；</li><li>然后对这个把这个接受的新客户端的 Channel 通道注册到 ServerSocketChannel 上，并且把之前的 OP_ACCEPT 状态改为 SelectionKey.OP_READ 读取事件状态，并且设置为非阻塞的，然后把当前的这个 SelectorKey 给移除掉，说明这个事件完成了；</li><li>如果第 5 步的时候过来的事件不是 OP_ACCEPT 状态，那就是 OP_READ 读取数据的事件状态，然后调用本文章的上面的那个读取数据的机制就可以了。<br>与 Java IO 的区别</li></ol><p><img src="https://cdn.jsdelivr.net/gh/zhangc233/pic@master/img/944365-a155ef4609137f75.png" alt="NIO与IO区别"></p><h2 id="AIO"><a href="#AIO" class="headerlink" title="AIO"></a>AIO</h2><ul><li><p>与 NIO 不同，当进行读写操作时，只须直接调用 API 的 read 或 write 方法即可。这两种方法均为异步的，对于读操作而言，当有流可读取时，操作系统会将可读的流传入 read 方法的缓冲区，并通知应用程序；</p></li><li><p>对于写操作而言，当操作系统将 write 方法传递的流写入完毕时，操作系统主动通知应用程序。 即可以理解为，read/write 方法都是异步的，完成后会主动调用回调函数。 在 JDK1.7 中，这部分内容被称作 NIO.2，主要在 java.nio.channels 包下增加了下面四个异步通道：</p><ul><li>AsynchronousSocketChannel</li><li>AsynchronousServerSocketChannel</li><li>AsynchronousFileChannel</li><li>AsynchronousDatagramChannel</li></ul></li></ul><p>其中的 read/write 方法，会返回一个带回调函数的对象，当执行完读取 / 写入操作后，直接调用回调函数。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><strong>Java 对 BIO、NIO、AIO 的支持：</strong></p><ul><li><p>Java BIO ： 同步并阻塞，服务器实现模式为一个连接一个线程，即客户端有连接请求时服务器端就需要启动一个线程进行处理，如果这个连接不做任何事情会造成不必要的线程开销，当然可以通过线程池机制改善。</p></li><li><p>Java NIO ： 同步非阻塞，服务器实现模式为一个请求一个线程，即客户端发送的连接请求都会注册到多路复用器上，多路复用器轮询到连接有 I/O 请求时才启动一个线程进行处理。</p></li><li><p>Java AIO (NIO.2) ： 异步非阻塞，服务器实现模式为一个有效请求一个线程，客户端的 I/O 请求都是由 OS 先完成了再通知服务器应用去启动线程进行处理。</p></li></ul><p><strong>BIO、NIO、AIO 适用场景分析:</strong></p><ul><li><p>BIO 方式适用于连接数目比较小且固定的架构，这种方式对服务器资源要求比较高，并发局限于应用中，JDK1.4 以前的唯一选择，但程序直观简单易理解。</p></li><li><p>NIO 方式适用于连接数目多且连接比较短（轻操作）的架构，比如聊天服务器，并发局限于应用中，编程比较复杂，JDK1.4 开始支持。</p></li><li><p>AIO 方式使用于连接数目多且连接比较长（重操作）的架构，比如相册服务器，充分调用 OS 参与并发操作，编程比较复杂，JDK7 开始支持。</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> IO </category>
          
      </categories>
      
      
        <tags>
            
            <tag> IO </tag>
            
            <tag> NIO </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ThreadLocal 源码解析</title>
      <link href="/2020/08/11/collection/ThreadLocal%20%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/"/>
      <url>/2020/08/11/collection/ThreadLocal%20%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>ThreadLocal<br>前言</p><p>问题：</p><p>ThreadLocal 的 key 是弱引用，那么在 ThreadLocal.get () 的时候，发生 GC 之后，key 是否为 null？<br>ThreadLocal 中 ThreadLocalMap 的数据结构？<br>ThreadLocalMap 的 Hash 算法？<br>ThreadLocalMap 中 Hash 冲突如何解决？<br>ThreadLocalMap 的扩容机制？<br>ThreadLocalMap 中过期 key 的清理机制？探测式清理和启发式清理流程？<br>ThreadLocalMap.set() 方法实现原理？<br>ThreadLocalMap.get() 方法实现原理？<br>项目中 ThreadLocal 使用情况？遇到的坑？<br>……<br>ThreadLocal 代码演示<br>ThreadLocal 使用示例：</p><p>JAVA<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>public class ThreadLocalTest {<br>    private List<String> messages = Lists.newArrayList();</p><pre><code>public static final ThreadLocal&lt;ThreadLocalTest&gt; holder = ThreadLocal.withInitial(ThreadLocalTest::new);public static void add(String message) &#123;    holder.get().messages.add(message);&#125;public static List&lt;String&gt; clear() &#123;    List&lt;String&gt; messages = holder.get().messages;    holder.remove();    System.out.println(&quot;size: &quot; + holder.get().messages.size());    return messages;&#125;public static void main(String[] args) &#123;    ThreadLocalTest.add(&quot;哈哈&quot;);    System.out.println(holder.get().messages);    ThreadLocalTest.clear();&#125;</code></pre><p>}<br>打印结果：</p><p>CODE<br>1<br>2<br>[哈哈]<br>size: 0<br>ThreadLocal 对象可以提供线程局部变量，每个线程 Thread 拥有一份自己的副本变量，多个线程互不干扰。</p><p>ThreadLocal 的数据结构</p><p>img</p><p>Thread 类有一个类型为 ThreadLocal.ThreadLocalMap 的实例变量 threadLocals，也就是说每个线程有一个自己的 ThreadLocalMap。</p><p>ThreadLocalMap 有自己的独立实现，可以简单地将它的 key 视作 ThreadLocal，value 为代码中放入的值（实际上 key 并不是 ThreadLocal 本身，而是它的一个弱引用）。</p><p>每个线程在往 ThreadLocal 里放值的时候，都会往自己的 ThreadLocalMap 里存，读也是以 ThreadLocal 作为引用，在自己的 map 里找对应的 key，从而实现了线程隔离。</p><p>ThreadLocalMap 有点类似 HashMap 的结构，只是 HashMap 是由数组 + 链表实现的，而 ThreadLocalMap 中并没有链表结构。</p><p>我们还要注意 Entry， 它的 key 是 ThreadLocal&lt;?&gt; k ，继承自 WeakReference， 也就是我们常说的弱引用类型。</p><p>GC 之后 key 是否为 null？<br>Java 的四种引用类型：</p><p>强引用：我们常常 new 出来的对象就是强引用类型，只要强引用存在，垃圾回收器将永远不会回收被引用的对象，哪怕内存不足的时候。<br>软引用：使用 SoftReference 修饰的对象被称为软引用，软引用指向的对象在内存要溢出的时候被回收。<br>弱引用：使用 WeakReference 修饰的对象被称为弱引用，只要发生垃圾回收，若这个对象只被弱引用指向，那么就会被回收。<br>虚引用：虚引用是最弱的引用，在 Java 中使用 PhantomReference 进行定义。虚引用中唯一的作用就是用队列接收对象即将死亡的通知。<br>使用反射的方式来看看 GC 后 ThreadLocal 中的数据情况：</p><pre><code class="bash">public class ThreadLocalDemo &#123;    public static void main(String[] args) throws NoSuchFieldException, IllegalAccessException, InterruptedException &#123;        Thread t = new Thread(()-&gt;test(&quot;abc&quot;,false));        t.start();        t.join();        System.out.println(&quot;--gc后--&quot;);        Thread t2 = new Thread(() -&gt; test(&quot;def&quot;, true));        t2.start();        t2.join();    &#125;    private static void test(String s,boolean isGC)  &#123;        try &#123;            new ThreadLocal&lt;&gt;().set(s);            if (isGC) &#123;                System.gc();            &#125;            Thread t = Thread.currentThread();            Class&lt;? extends Thread&gt; clz = t.getClass();            Field field = clz.getDeclaredField(&quot;threadLocals&quot;);            field.setAccessible(true);            Object ThreadLocalMap = field.get(t);            Class&lt;?&gt; tlmClass = ThreadLocalMap.getClass();            Field tableField = tlmClass.getDeclaredField(&quot;table&quot;);            tableField.setAccessible(true);            Object[] arr = (Object[]) tableField.get(ThreadLocalMap);            for (Object o : arr) &#123;                if (o != null) &#123;                    Class&lt;?&gt; entryClass = o.getClass();                    Field valueField = entryClass.getDeclaredField(&quot;value&quot;);                    Field referenceField = entryClass.getSuperclass().getSuperclass().getDeclaredField(&quot;referent&quot;);                    valueField.setAccessible(true);                    referenceField.setAccessible(true);                    System.out.println(String.format(&quot;弱引用key:%s,值:%s&quot;, referenceField.get(o), valueField.get(o)));                &#125;            &#125;        &#125; catch (Exception e) &#123;            e.printStackTrace();        &#125;    &#125;&#125;</code></pre><p>结果如下：</p><pre><code class="bash">弱引用key:java.lang.ThreadLocal@433619b6,值:abc弱引用key:java.lang.ThreadLocal@418a15e3,值:java.lang.ref.SoftReference@bf97a12--gc后--弱引用key:null,值:def</code></pre><p>img</p><p>如图所示，因为这里创建的 ThreadLocal 并没有指向任何值，也就是没有任何引用：</p><p>JAVA<br>1<br>new ThreadLocal&lt;&gt;().set(s);<br>所以这里在 GC 之后，key 就会被回收，我们看到上面 debug 中的 referent=null, 如果改动一下代码：</p><p>img</p><p>这个问题刚开始看，如果没有过多思考，弱引用，还有垃圾回收，那么肯定会觉得是 null。其实是不对的，因为题目说的是在做 ThreadLocal.get() 操作，证明其实还是有强引用存在的，所以 key 并不为 null，如下图所示，ThreadLocal 的强引用仍然是存在的。</p><p>image.png</p><p>如果我们的强引用不存在的话，那么 key 就会被回收，也就是会出现我们 value 没被回收，key 被回收，导致 value 永远存在，出现内存泄漏。</p><p>ThreadLocal.set() 方法源码详解</p><p>img</p><p>ThreadLocal 中的 set 方法原理如上图所示，很简单，主要是判断 ThreadLocalMap 是否存在，然后使用 ThreadLocal 中的 set 方法进行数据处理。</p><p>代码如下：</p><pre><code class="bash">public void set(T value) &#123;    Thread t = Thread.currentThread();    ThreadLocalMap map = getMap(t);    if (map != null)        map.set(this, value);    else        createMap(t, value);&#125;void createMap(Thread t, T firstValue) &#123;    t.threadLocals = new ThreadLocalMap(this, firstValue);&#125;</code></pre><p>主要的核心逻辑还是在 ThreadLocalMap 中的，一步步往下看，后面还有更详细的剖析。</p><p>ThreadLocalMap Hash 算法<br>既然是 Map 结构，那么 ThreadLocalMap 当然也要实现自己的 hash 算法来解决散列表数组冲突问题。</p><p>JAVA<br>1<br>int i = key.threadLocalHashCode &amp; (len-1);<br>ThreadLocalMap 中 hash 算法很简单，这里 i 就是当前 key 在散列表中对应的数组下标位置。</p><p>这里最关键的就是 threadLocalHashCode 值的计算，ThreadLocal 中有一个属性为 HASH_INCREMENT = 0x61c88647</p><pre><code class="bash">public class ThreadLocal&lt;T&gt; &#123;    private final int threadLocalHashCode = nextHashCode();    private static AtomicInteger nextHashCode = new AtomicInteger();    private static final int HASH_INCREMENT = 0x61c88647;    private static int nextHashCode() &#123;        return nextHashCode.getAndAdd(HASH_INCREMENT);    &#125;    static class ThreadLocalMap &#123;        ThreadLocalMap(ThreadLocal&lt;?&gt; firstKey, Object firstValue) &#123;            table = new Entry[INITIAL_CAPACITY];            int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1);            table[i] = new Entry(firstKey, firstValue);            size = 1;            setThreshold(INITIAL_CAPACITY);        &#125;    &#125;&#125;</code></pre><p>每当创建一个 ThreadLocal 对象，这个 ThreadLocal.nextHashCode 这个值就会增长 0x61c88647 。</p><p>这个值很特殊，它是斐波那契数 也叫 黄金分割数。hash 增量为 这个数字，带来的好处就是 hash 分布非常均匀。</p><p>我们自己可以尝试下：</p><p>img</p><p>可以看到产生的哈希码分布很均匀，这里不去细纠斐波那契具体算法，感兴趣的可以自行查阅相关资料。</p><p>ThreadLocalMap Hash 冲突<br>注明： 下面所有示例图中，绿色块Entry 代表正常数据，灰色块代表 Entry 的 key 值为 null，已被垃圾回收。白色块表示 Entry 为 null。</p><p>虽然 ThreadLocalMap 中使用了黄金分割数来作为 hash 计算因子，大大减少了 Hash 冲突的概率，但是仍然会存在冲突。</p><p>HashMap 中解决冲突的方法是在数组上构造一个链表结构，冲突的数据挂载到链表上，如果链表长度超过一定数量则会转化成红黑树。而 ThreadLocalMap 中并没有链表结构，所以这里不能使用 HashMap 解决冲突的方式了。</p><p>img</p><p>如上图所示，如果我们插入一个 value=27 的数据，通过 hash 计算后应该落入第 4 个槽位中，而槽位 4 已经有了 Entry 数据。</p><p>此时就会线性向后查找，一直找到 Entry 为 null 的槽位才会停止查找，将当前元素放入此槽位中。当然迭代过程中还有其他的情况，比如遇到了 Entry 不为 null 且 key 值相等的情况，还有 Entry 中的 key 值为 null 的情况等等都会有不同的处理，后面会一一详细讲解。</p><p>这里还画了一个 Entry 中的 key 为 null 的数据（Entry=2 的灰色块数据），因为 key 值是弱引用类型，所以会有这种数据存在。在 set 过程中，如果遇到了 key 过期的 Entry 数据，实际上是会进行一轮探测式清理操作的，具体操作方式后面会讲到。</p><p>ThreadLocalMap.set() 详解<br>ThreadLocalMap.set() 原理图解<br>看完了 ThreadLocal hash 算法后，我们再来看 set 是如何实现的。往 ThreadLocalMap 中 set 数据（新增或者更新数据）分为好几种情况，针对不同的情况我们画图来说说明。</p><p>第一种情况： 通过 hash 计算后的槽位对应的 Entry 数据为空：这里直接将数据放到该槽位即可。</p><p>img</p><p>第二种情况： 槽位数据不为空，key 值与当前 ThreadLocal 通过 hash 计算获取的 key 值一致：这里直接更新该槽位的数据。</p><p>img</p><p>第三种情况： 槽位数据不为空，往后遍历过程中，在找到 Entry 为 null 的槽位之前，没有遇到 key 过期的 Entry：</p><p>img</p><p>遍历散列数组，线性往后查找，如果找到 Entry 为 null 的槽位，则将数据放入该槽位中，或者往后遍历过程中，遇到了 key 值相等的数据，直接更新即可。</p><p>第四种情况： 槽位数据不为空，往后遍历过程中，在找到 Entry 为 null 的槽位之前，遇到 key 过期的 Entry，如下图，往后遍历过程中，一到了 index=7 的槽位数据 Entry 的 key=null：</p><p>img</p><p>散列数组下标为 7 位置对应的 Entry 数据 key 为 null，表明此数据 key 值已经被垃圾回收掉了，此时就会执行 replaceStaleEntry() 方法，该方法含义是替换过期数据的逻辑，以 index=7 位起点开始遍历，进行探测式数据清理工作。</p><p>初始化探测式清理过期数据扫描的开始位置：slotToExpunge = staleSlot = 7；</p><p>以当前 staleSlot 开始向前迭代查找，找其他过期的数据，然后更新过期数据起始扫描下标 slotToExpunge。for 循环迭代，直到碰到 Entry 为 null 结束。</p><p>如果找到了过期的数据，继续向前迭代，直到遇到 Entry=null 的槽位才停止迭代，如下图所示，slotToExpunge 被更新为 0：</p><p>img</p><p>以当前节点 (index=7) 向前迭代，检测是否有过期的 Entry 数据，如果有则更新 slotToExpunge 值。碰到 null 则结束探测。以上图为例 slotToExpunge 被更新为 0。</p><p>上面向前迭代的操作是为了更新探测清理过期数据的起始下标 slotToExpunge 的值，这个值在后面会讲解，它是用来判断当前过期槽位 staleSlot 之前是否还有过期元素。</p><p>接着开始以 staleSlot 位置 (index=7) 向后迭代，如果找到了相同 key 值的 Entry 数据：</p><p>img</p><p>从当前节点 staleSlot 向后查找 key 值相等的 Entry 元素，找到后更新 Entry 的值并交换 staleSlot 元素的位置 (staleSlot 位置为过期元素)，更新 Entry 数据，然后开始进行过期 Entry 的清理工作，如下图所示：</p><p>img<br>向后遍历过程中，如果没有找到相同 key 值的 Entry 数据：</p><p>img</p><p>从当前节点 staleSlot 向后查找 key 值相等的 Entry 元素，直到 Entry 为 null 则停止寻找。通过上图可知，此时 table 中没有 key 值相同的 Entry。</p><p>创建新的 Entry，替换 table[stableSlot] 位置：</p><p>img</p><p>替换完成后也是进行过期元素清理工作，清理工作主要是有两个方法：expungeStaleEntry() 和 cleanSomeSlots()，具体细节后面会讲到，请继续往后看。</p><p>ThreadLocalMap.set() 源码详解<br>上面已经用图的方式解析了 set() 实现的原理，其实已经很清晰了，我们接着再看下源码：</p><p>java.lang.ThreadLocal.ThreadLocalMap.set():</p><pre><code class="bash">private void set(ThreadLocal&lt;?&gt; key, Object value) &#123;    Entry[] tab = table;    int len = tab.length;    int i = key.threadLocalHashCode &amp; (len-1);    for (Entry e = tab[i];         e != null;         e = tab[i = nextIndex(i, len)]) &#123;        ThreadLocal&lt;?&gt; k = e.get();        if (k == key) &#123;            e.value = value;            return;        &#125;        if (k == null) &#123;            replaceStaleEntry(key, value, i);            return;        &#125;    &#125;    tab[i] = new Entry(key, value);    int sz = ++size;    if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold)        rehash();&#125;</code></pre><blockquote><p>这里会通过 key 来计算在散列表中的对应位置，然后以当前 key 对应的桶的位置向后查找，找到可以使用的桶。</p></blockquote><pre><code class="bash">Entry[] tab = table;int len = tab.length;int i = key.threadLocalHashCode &amp; (len-1);</code></pre><p>什么情况下桶才是可以使用的呢？</p><p>k = key 说明是替换操作，可以使用；<br>碰到一个过期的桶，执行替换逻辑，占用过期桶；<br>查找过程中，碰到桶中 Entry=null 的情况，直接使用。<br>接着就是执行 for 循环遍历，向后查找，我们先看下 nextIndex()、prevIndex() 方法实现：</p><p>img</p><p>JAVA<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>private static int nextIndex(int i, int len) {<br>    return ((i + 1 &lt; len) ? i + 1 : 0);<br>}</p><p>private static int prevIndex(int i, int len) {<br>    return ((i - 1 &gt;= 0) ? i - 1 : len - 1);<br>}<br>接着看剩下 for 循环中的逻辑：</p><p>遍历当前 key 值对应的桶中 Entry 数据为空，这说明散列数组这里没有数据冲突，跳出 for 循环，直接 set 数据到对应的桶中；<br>如果 key 值对应的桶中 Entry 数据不为空 ：<br>如果 k = key，说明当前 set 操作是一个替换操作，做替换逻辑，直接返回 ；<br>如果 key = null，说明当前桶位置的 Entry 是过期数据，执行 replaceStaleEntry() 方法 (核心方法)，然后返回。<br>for 循环执行完毕，继续往下执行说明向后迭代的过程中遇到了 entry 为 null 的情况 ：<br>在 Entry 为 null 的桶中创建一个新的 Entry 对象 ；<br>执行 ++size 操作。<br>调用 cleanSomeSlots() 做一次启发式清理工作，清理散列数组中 Entry 的 key 过期的数据<br>如果清理工作完成后，未清理到任何数据，且 size 超过了阈值 (数组长度的 2/3)，进行 rehash() 操作 ；<br>rehash() 中会先进行一轮探测式清理，清理过期 key，清理完成后如果 size &gt;= threshold - threshold / 4，就会执行真正的扩容逻辑 (扩容逻辑往后看)。<br>接着重点看下 replaceStaleEntry() 方法，replaceStaleEntry() 方法提供替换过期数据的功能，可以对应上面第四种情况的原理图来再回顾下，具体代码如下：</p><p>java.lang.ThreadLocal.ThreadLocalMap.replaceStaleEntry():</p><pre><code class="bash">private void replaceStaleEntry(ThreadLocal&lt;?&gt; key, Object value,                                       int staleSlot) &#123;    Entry[] tab = table;    int len = tab.length;    Entry e;    int slotToExpunge = staleSlot;    for (int i = prevIndex(staleSlot, len);         (e = tab[i]) != null;         i = prevIndex(i, len))        if (e.get() == null)            slotToExpunge = i;    for (int i = nextIndex(staleSlot, len);         (e = tab[i]) != null;         i = nextIndex(i, len)) &#123;        ThreadLocal&lt;?&gt; k = e.get();        if (k == key) &#123;            e.value = value;            tab[i] = tab[staleSlot];            tab[staleSlot] = e;            if (slotToExpunge == staleSlot)                slotToExpunge = i;            cleanSomeSlots(expungeStaleEntry(slotToExpunge), len);            return;        &#125;        if (k == null &amp;&amp; slotToExpunge == staleSlot)            slotToExpunge = i;    &#125;    tab[staleSlot].value = null;    tab[staleSlot] = new Entry(key, value);    if (slotToExpunge != staleSlot)        cleanSomeSlots(expungeStaleEntry(slotToExpunge), len);&#125;</code></pre><p>//slotToExpunge<code>表示开始探测式清理过期数据的开始下标，默认从当前的</code>staleSlot<code>开始。以当前的</code>staleSlot<code>开始，向前迭代查找，找到没有过期的数据，</code>for<code>循环一直碰到</code>Entry<code>为</code>null<code>才会结束。如果向前找到了过期数据，更新探测清理过期数据的开始下标为 i，即</code>slotToExpunge=i<br>for (int i = prevIndex(staleSlot, len);<br>     (e = tab[i]) != null;<br>     i = prevIndex(i, len)){</p><pre><code>if (e.get() == null)&#123;    slotToExpunge = i;&#125;</code></pre><p>}<br>接着开始从 staleSlot 向后查找，也是碰到 Entry 为 null 的桶结束。 如果迭代过程中，碰到 k == key，这说明这里是替换逻辑，替换新数据并且交换当前 staleSlot 位置。如果 slotToExpunge == staleSlot，这说明 replaceStaleEntry() 一开始向前查找过期数据时并未找到过期的 Entry 数据，接着向后查找过程中也未发现过期数据，修改开始探测式清理过期数据的下标为当前循环的 index，即 slotToExpunge = i。最后调用 cleanSomeSlots(expungeStaleEntry(slotToExpunge), len); 进行启发式过期数据清理。</p><p>JAVA<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>if (k == key) {<br>    e.value = value;</p><pre><code>tab[i] = tab[staleSlot];tab[staleSlot] = e;if (slotToExpunge == staleSlot)    slotToExpunge = i;cleanSomeSlots(expungeStaleEntry(slotToExpunge), len);return;</code></pre><p>}<br>cleanSomeSlots() 和 expungeStaleEntry() 方法后面都会细讲，这两个是和清理相关的方法，一个是过期 key 相关 Entry 的启发式清理 (Heuristically scan)，另一个是过期 key 相关 Entry 的探测式清理。</p><p>如果 k != key 则会接着往下走，k == null 说明当前遍历的 Entry 是一个过期数据，slotToExpunge == staleSlot 说明，一开始的向前查找数据并未找到过期的 Entry。如果条件成立，则更新 slotToExpunge 为当前位置，这个前提是前驱节点扫描时未发现过期数据。</p><p>JAVA<br>1<br>2<br>if (k == null &amp;&amp; slotToExpunge == staleSlot)<br>    slotToExpunge = i;<br>往后迭代的过程中如果没有找到 k == key 的数据，且碰到 Entry 为 null 的数据，则结束当前的迭代操作。此时说明这里是一个添加的逻辑，将新的数据添加到 table[staleSlot] 对应的 slot 中。</p><p>JAVA<br>1<br>2<br>tab[staleSlot].value = null;<br>tab[staleSlot] = new Entry(key, value);<br>最后判断除了 staleSlot 以外，还发现了其他过期的 slot 数据，就要开启清理数据的逻辑：</p><p>JAVA<br>1<br>2<br>if (slotToExpunge != staleSlot)<br>    cleanSomeSlots(expungeStaleEntry(slotToExpunge), len);<br>ThreadLocalMap 过期 key 的探测式清理流程<br>上面提及 ThreadLocalMap 的两种过期 key 数据清理方式：探测式清理和启发式清理。</p><p>我们先讲下探测式清理，也就是 expungeStaleEntry 方法，遍历散列数组，从开始位置向后探测清理过期数据，将过期数据的 Entry 设置为 null，沿途中碰到未过期的数据则将此数据 rehash 后重新在 table 数组中定位，如果定位的位置已经有了数据，则会将未过期的数据放到最靠近此位置的 Entry=null 的桶中，使 rehash 后的 Entry 数据距离正确的桶的位置更近一些。操作逻辑如下：</p><p>img</p><p>如上图，set(27) 经过 hash 计算后应该落到 index=4 的桶中，由于 index=4 桶已经有了数据，所以往后迭代最终数据放入到 index=7 的桶中，放入后一段时间后 index=5 中的 Entry 数据 key 变为了 null。</p><p>img</p><p>如果再有其他数据 set 到 map 中，就会触发探测式清理操作。如上图，执行探测式清理后，index=5 的数据被清理掉，继续往后迭代，到 index=7 的元素时，经过 rehash 后发现该元素正确的 index=4，而此位置已经已经有了数据，往后查找离 index=4 最近的 Entry=null 的节点 (刚被探测式清理掉的数据：index=5)，找到后移动 index= 7 的数据到 index=5 中，此时桶的位置离正确的位置 index=4 更近了。</p><p>经过一轮探测式清理后，key 过期的数据会被清理掉，没过期的数据经过 rehash 重定位后所处的桶位置理论上更接近 i= key.hashCode &amp; (tab.len - 1) 的位置。这种优化会提高整个散列表查询性能。</p><p>接着看下 expungeStaleEntry() 具体流程，我们还是以先原理图后源码讲解的方式来一步步梳理：</p><p>img</p><p>假设 expungeStaleEntry(3) 来调用此方法，如上图所示，我们可以看到 ThreadLocalMap 中 table 的数据情况，接着执行清理操作：</p><p>img</p><p>第一步是清空当前 staleSlot 位置的数据，index=3 位置的 Entry 变成了 null。然后接着往后探测：</p><p>img</p><p>执行完第二步后，index=4 的元素挪到 index=3 的槽位中。继续往后迭代检查，碰到正常数据，计算该数据位置是否偏移，如果被偏移，则重新计算 slot 位置，目的是让正常数据尽可能存放在正确位置或离正确位置更近的位置</p><p>img</p><p>在往后迭代的过程中碰到空的槽位，终止探测，这样一轮探测式清理工作就完成了，接着我们继续看看具体实现源代码：</p><p>JAVA<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>26<br>27<br>28<br>29<br>30<br>31<br>private int expungeStaleEntry(int staleSlot) {<br>    Entry[] tab = table;<br>    int len = tab.length;</p><pre><code>tab[staleSlot].value = null;tab[staleSlot] = null;size--;Entry e;int i;for (i = nextIndex(staleSlot, len);     (e = tab[i]) != null;     i = nextIndex(i, len)) &#123;    ThreadLocal&lt;?&gt; k = e.get();    if (k == null) &#123;        e.value = null;        tab[i] = null;        size--;    &#125; else &#123;        int h = k.threadLocalHashCode &amp; (len - 1);        if (h != i) &#123;            tab[i] = null;            while (tab[h] != null)                h = nextIndex(h, len);            tab[h] = e;        &#125;    &#125;&#125;return i;</code></pre><p>}<br>这里我们还是以 staleSlot=3 来做示例说明，首先是将 tab[staleSlot] 槽位的数据清空，然后设置 size– 接着以 staleSlot 位置往后迭代，如果遇到 k==null 的过期数据，也是清空该槽位数据，然后 size–</p><p>JAVA<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>ThreadLocal&lt;?&gt; k = e.get();</p><p>if (k == null) {<br>    e.value = null;<br>    tab[i] = null;<br>    size–;<br>}<br>如果 key 没有过期，重新计算当前 key 的下标位置是不是当前槽位下标位置，如果不是，那么说明产生了 hash 冲突，此时以新计算出来正确的槽位位置往后迭代，找到最近一个可以存放 entry 的位置。</p><p>JAVA<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>int h = k.threadLocalHashCode &amp; (len - 1);<br>if (h != i) {<br>    tab[i] = null;</p><pre><code>while (tab[h] != null)    h = nextIndex(h, len);tab[h] = e;</code></pre><p>}<br>这里是处理正常的产生 Hash 冲突的数据，经过迭代后，有过 Hash 冲突数据的 Entry 位置会更靠近正确位置，这样的话，查询的时候 效率才会更高。</p><p>ThreadLocalMap 扩容机制<br>在 ThreadLocalMap.set() 方法的最后，如果执行完启发式清理工作后，未清理到任何数据，且当前散列数组中 Entry 的数量已经达到了列表的扩容阈值 (len*2/3)，就开始执行 rehash() 逻辑：</p><p>JAVA<br>1<br>2<br>if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold)<br>    rehash();<br>接着看下 rehash() 具体实现：</p><pre><code class="bash">private void rehash() &#123;    expungeStaleEntries();    if (size &gt;= threshold - threshold / 4)        resize();&#125;private void expungeStaleEntries() &#123;    Entry[] tab = table;    int len = tab.length;    for (int j = 0; j &lt; len; j++) &#123;        Entry e = tab[j];        if (e != null &amp;&amp; e.get() == null)            expungeStaleEntry(j);    &#125;&#125;</code></pre><p>这里首先是会进行探测式清理工作，从 table 的起始位置往后清理，上面有分析清理的详细流程。清理完成之后，table 中可能有一些 key 为 null 的 Entry 数据被清理掉，所以此时通过判断 size &gt;= threshold - threshold / 4 也就是 size &gt;= threshold* 3/4 来决定是否扩容。</p><p>还记得上面进行 rehash() 的阈值是 size &gt;= threshold，所以当面试官套路我们 ThreadLocalMap 扩容机制的时候，一定要说清楚这两个步骤：</p><p>img</p><p>接着看看具体的 resize() 方法，为了方便演示，以 oldTab.len=8 来举例：</p><p>img</p><p>扩容后的 tab 的大小为 oldLen * 2，然后遍历老的散列表，重新计算 hash 位置，然后放到新的 tab 数组中，如果出现 hash 冲突则往后寻找最近的 entry 为 null 的槽位，遍历完成之后，oldTab 中所有的 entry 数据都已经放入到新的 tab 中了。重新计算 tab 下次扩容的阈值，具体代码如下：</p><pre><code class="bash">private void resize() &#123;    Entry[] oldTab = table;    int oldLen = oldTab.length;    int newLen = oldLen * 2;    Entry[] newTab = new Entry[newLen];    int count = 0;    for (int j = 0; j &lt; oldLen; ++j) &#123;        Entry e = oldTab[j];        if (e != null) &#123;            ThreadLocal&lt;?&gt; k = e.get();            if (k == null) &#123;                e.value = null;            &#125; else &#123;                int h = k.threadLocalHashCode &amp; (newLen - 1);                while (newTab[h] != null)                    h = nextIndex(h, newLen);                newTab[h] = e;                count++;            &#125;        &#125;    &#125;    setThreshold(newLen);    size = count;    table = newTab;&#125;</code></pre><p>ThreadLocalMap.get() 详解<br>ThreadLocalMap.get() 图解<br>第一种情况： 通过查找 key 值计算出散列表中 slot 位置，然后该 slot 位置中的 Entry.key 和查找的 key 一致，则直接返回：</p><p>img</p><p>第二种情况： slot 位置中的 Entry.key 和要查找的 key 不一致：</p><p>img</p><p>我们以 get(ThreadLocal1) 为例，通过 hash 计算后，正确的 slot 位置应该是 4，而 index=4 的槽位已经有了数据，且 key 值不等于 ThreadLocal1，所以需要继续往后迭代查找。</p><p>迭代到 index=5 的数据时，此时 Entry.key=null，触发一次探测式数据回收操作，执行 expungeStaleEntry() 方法，执行完后，index 5,8 的数据都会被回收，而 index 6,7 的数据都会前移，此时继续往后迭代，到 index = 6 的时候即找到了 key 值相等的 Entry 数据，如下图所示：</p><p>img</p><p>ThreadLocalMap.get() 源码详解<br>java.lang.ThreadLocal.ThreadLocalMap.getEntry():</p><pre><code class="bash">private Entry getEntry(ThreadLocal&lt;?&gt; key) &#123;    int i = key.threadLocalHashCode &amp; (table.length - 1);    Entry e = table[i];    if (e != null &amp;&amp; e.get() == key)        return e;    else        return getEntryAfterMiss(key, i, e);&#125;private Entry getEntryAfterMiss(ThreadLocal&lt;?&gt; key, int i, Entry e) &#123;    Entry[] tab = table;    int len = tab.length;    while (e != null) &#123;        ThreadLocal&lt;?&gt; k = e.get();        if (k == key)            return e;        if (k == null)            expungeStaleEntry(i);        else            i = nextIndex(i, len);        e = tab[i];    &#125;    return null;&#125;</code></pre><p>ThreadLocalMap 过期 key 的启发式清理流程<br>上面多次提及到 ThreadLocalMap 过期可以的两种清理方式：探测式清理 (expungeStaleEntry ())、启发式清理 (cleanSomeSlots ())。</p><p>探测式清理是以当前 Entry 往后清理，遇到值为 null 则结束清理，属于线性探测清理。</p><p>而启发式清理被作者定义为：Heuristically scan some cells looking for stale entries.</p><p>img</p><p>具体代码如下：</p><pre><code class="bash">private boolean cleanSomeSlots(int i, int n) &#123;    boolean removed = false;    Entry[] tab = table;    int len = tab.length;    do &#123;        i = nextIndex(i, len);        Entry e = tab[i];        if (e != null &amp;&amp; e.get() == null) &#123;            n = len;            removed = true;            i = expungeStaleEntry(i);        &#125;    &#125; while ( (n &gt;&gt;&gt;= 1) != 0);    return removed;&#125;</code></pre><p>InheritableThreadLocal<br>我们使用 ThreadLocal 的时候，在异步场景下是无法给子线程共享父线程中创建的线程副本数据的。</p><p>为了解决这个问题，JDK 中还有一个 InheritableThreadLocal 类，我们来看一个例子：</p><pre><code class="bash">public class InheritableThreadLocalDemo &#123;    public static void main(String[] args) &#123;        ThreadLocal&lt;String&gt; ThreadLocal = new ThreadLocal&lt;&gt;();        ThreadLocal&lt;String&gt; inheritableThreadLocal = new InheritableThreadLocal&lt;&gt;();        ThreadLocal.set(&quot;父类数据:threadLocal&quot;);        inheritableThreadLocal.set(&quot;父类数据:inheritableThreadLocal&quot;);        new Thread(new Runnable() &#123;            @Override            public void run() &#123;                System.out.println(&quot;子线程获取父类ThreadLocal数据：&quot; + ThreadLocal.get());                System.out.println(&quot;子线程获取父类inheritableThreadLocal数据：&quot; + inheritableThreadLocal.get());            &#125;        &#125;).start();    &#125;&#125;</code></pre><p>打印结果：</p><p>JAVA<br>1<br>2<br>子线程获取父类ThreadLocal数据：null<br>子线程获取父类inheritableThreadLocal数据：父类数据:inheritableThreadLocal<br>实现原理是子线程是通过在父线程中通过调用 new Thread() 方法来创建子线程，Thread#init 方法在 Thread 的构造方法中被调用。在 init 方法中拷贝父线程数据到子线程中：</p><pre><code class="bash">private void init(ThreadGroup g, Runnable target, String name,                      long stackSize, AccessControlContext acc,                      boolean inheritThreadLocals) &#123;    if (name == null) &#123;        throw new NullPointerException(&quot;name cannot be null&quot;);    &#125;    if (inheritThreadLocals &amp;&amp; parent.inheritableThreadLocals != null)        this.inheritableThreadLocals =            ThreadLocal.createInheritedMap(parent.inheritableThreadLocals);    this.stackSize = stackSize;    tid = nextThreadID();&#125;</code></pre><p>但 InheritableThreadLocal 仍然有缺陷，一般我们做异步化处理都是使用的线程池，而 InheritableThreadLocal 是在 new Thread 中的 init() 方法给赋值的，而线程池是线程复用的逻辑，所以这里会存在问题。</p><p>ThreadLocal 项目中使用实战<br>ThreadLocal 使用场景<br>我们现在项目中日志记录用的是 ELK+Logstash，最后在 Kibana 中进行展示和检索。现在都是分布式系统统一对外提供服务，项目间调用的关系可以通过 traceId 来关联，但是不同项目之间如何传递 traceId 呢？</p><p>这里我们使用 org.slf4j.MDC 来实现此功能，内部就是通过 ThreadLocal 来实现的，具体实现如下：</p><p>当前端发送请求到服务 A 时， 服务 A 会生成一个类似 UUID 的 traceId 字符串，将此字符串放入当前线程的 ThreadLocal 中，在调用服务 B 的时候，将 traceId 写入到请求的 Header 中，服务 B 在接收请求时会先判断请求的 Header 中是否有 traceId，如果存在则写入自己线程的 ThreadLocal 中。</p><p>img</p><p>图中的 requestId 即为我们各个系统链路关联的 traceId，系统间互相调用，通过这个 requestId 即可找到对应链路，这里还有会有一些其他场景：</p><p>img</p><p>针对于这些场景，我们都可以有相应的解决方案，如下所示</p><p>Feign 远程调用解决方案<br>服务发送请求：</p><pre><code class="bash">@Component@Slf4jpublic class FeignInvokeInterceptor implements RequestInterceptor &#123;    @Override    public void apply(RequestTemplate template) &#123;        String requestId = MDC.get(&quot;requestId&quot;);        if (StringUtils.isNotBlank(requestId)) &#123;            template.header(&quot;requestId&quot;, requestId);        &#125;    &#125;&#125;</code></pre><p>服务接收请求：</p><pre><code class="bash">@Slf4j@Componentpublic class LogInterceptor extends HandlerInterceptorAdapter &#123;    @Override    public void afterCompletion(HttpServletRequest arg0, HttpServletResponse arg1, Object arg2, Exception arg3) &#123;        MDC.remove(&quot;requestId&quot;);    &#125;    @Override    public void postHandle(HttpServletRequest arg0, HttpServletResponse arg1, Object arg2, ModelAndView arg3) &#123;    &#125;    @Override    public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123;        String requestId = request.getHeader(BaseConstant.REQUEST_ID_KEY);        if (StringUtils.isBlank(requestId)) &#123;            requestId = UUID.randomUUID().toString().replace(&quot;-&quot;, &quot;&quot;);        &#125;        MDC.put(&quot;requestId&quot;, requestId);        return true;    &#125;&#125;</code></pre><p>线程池异步调用，requestId 传递<br>因为 MDC 是基于 ThreadLocal 去实现的，异步过程中，子线程并没有办法获取到父线程 ThreadLocal 存储的数据，所以这里可以自定义线程池执行器，修改其中的 run() 方法：</p><pre><code class="bash">public class MyThreadPoolTaskExecutor extends ThreadPoolTaskExecutor &#123;    @Override    public void execute(Runnable runnable) &#123;        Map&lt;String, String&gt; context = MDC.getCopyOfContextMap();        super.execute(() -&gt; run(runnable, context));    &#125;    @Override    private void run(Runnable runnable, Map&lt;String, String&gt; context) &#123;        if (context != null) &#123;            MDC.setContextMap(context);        &#125;        try &#123;            runnable.run();        &#125; finally &#123;            MDC.remove();        &#125;    &#125;&#125;</code></pre><p>使用 MQ 发送消息给第三方系统<br>在 MQ 发送的消息体中自定义属性 requestId，接收方消费消息后，自己解析 requestId 使用即可。</p>]]></content>
      
      
      <categories>
          
          <category> 集合 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ThreadLocalMap </tag>
            
            <tag> set </tag>
            
            <tag> key 过期清理策略 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ConcurrentHashMap 源码分析</title>
      <link href="/2020/07/31/collection/ConcurrentHashMap%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"/>
      <url>/2020/07/31/collection/ConcurrentHashMap%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>]]></content>
      
      
      <categories>
          
          <category> 集合 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 集合 </tag>
            
            <tag> ConcurrentHashMap </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HashMap1.7 与 1.8 源码的区别</title>
      <link href="/2020/07/26/collection/HashMap1.7%20%E4%B8%8E%201.8%20%E6%BA%90%E7%A0%81%E7%9A%84%E5%8C%BA%E5%88%AB/"/>
      <url>/2020/07/26/collection/HashMap1.7%20%E4%B8%8E%201.8%20%E6%BA%90%E7%A0%81%E7%9A%84%E5%8C%BA%E5%88%AB/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>简介<br>类定义<br>JAVA<br>1<br>2<br>3<br>public class HashMap&lt;K,V&gt;<br>         extends AbstractMap&lt;K,V&gt;<br>         implements Map&lt;K,V&gt;, Cloneable, Serializable<br>主要简介</p><p>img</p><p>数据结构：引入了 红黑树</p><p>img</p><p>存储流程</p><p>img</p><p>数组元素 &amp; 链表节点的 实现类<br>HashMap 中的数组元素 &amp; 链表节点采用 Node 类 实现。</p><p>与 JDK 1.7 的对比（Entry 类），仅仅只是换了名字。</p><p>该类的源码分析如下：</p><pre><code class="bash">/**   * Node  = HashMap的内部类，实现了Map.Entry接口，本质是 = 一个映射(键值对)  * 实现了getKey()、getValue()、equals(Object o)和hashCode()等方法  **/    static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123;        final int hash; // 哈希值，HashMap根据该值确定记录的位置        final K key; // key        V value; // value        Node&lt;K,V&gt; next;// 链表下一个节点        // 构造方法        Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123;            this.hash = hash;            this.key = key;            this.value = value;            this.next = next;        &#125;                public final K getKey()        &#123; return key; &#125;   // 返回 与 此项 对应的键        public final V getValue()      &#123; return value; &#125; // 返回 与 此项 对应的值        public final String toString() &#123; return key + &quot;=&quot; + value; &#125;        public final V setValue(V newValue) &#123;            V oldValue = value;            value = newValue;            return oldValue;        &#125;      /**         * hashCode（）         */        public final int hashCode() &#123;            return Objects.hashCode(key) ^ Objects.hashCode(value);        &#125;      /**         * equals（）        * 作用：判断2个Entry是否相等，必须key和value都相等，才返回true          */        public final boolean equals(Object o) &#123;            if (o == this)                return true;            if (o instanceof Map.Entry) &#123;                Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o;                if (Objects.equals(key, e.getKey()) &amp;&amp;                    Objects.equals(value, e.getValue()))                    return true;            &#125;            return false;        &#125;    &#125;</code></pre><h2 id="红黑树节点实现类"><a href="#红黑树节点实现类" class="headerlink" title="红黑树节点实现类"></a>红黑树节点实现类</h2><p>HashMap 中的红黑树节点采用 TreeNode 类 实现：</p><pre><code class="bash">/** * 红黑树节点 实现类：继承自LinkedHashMap.Entry&lt;K,V&gt;类 */ static final class TreeNode&lt;K,V&gt; extends LinkedHashMap.Entry&lt;K,V&gt; &#123;       // 属性 = 父节点、左子树、右子树、删除辅助节点 + 颜色   TreeNode&lt;K,V&gt; parent;     TreeNode&lt;K,V&gt; left;      TreeNode&lt;K,V&gt; right;   TreeNode&lt;K,V&gt; prev;      boolean red;        // 构造函数   TreeNode(int hash, K key, V val, Node&lt;K,V&gt; next) &#123;         super(hash, key, val, next);     &#125;      // 返回当前节点的根节点     final TreeNode&lt;K,V&gt; root() &#123;         for (TreeNode&lt;K,V&gt; r = this, p;;) &#123;             if ((p = r.parent) == null)                 return r;             r = p;         &#125;     &#125; </code></pre><p>具体方法使用<br>主要使用 API（方法、函数）<br>与 JDK 1.7 基本相同。</p><pre><code class="bash">V get(Object key); // 获得指定键的值V put(K key, V value);  // 添加键值对void putAll(Map&lt;? extends K, ? extends V&gt; m);  // 将指定Map中的键值对 复制到 此Map中V remove(Object key);  // 删除该键值对boolean containsKey(Object key); // 判断是否存在该键的键值对；是 则返回trueboolean containsValue(Object value);  // 判断是否存在该值的键值对；是 则返回true Set&lt;K&gt; keySet();  // 单独抽取key序列，将所有key生成一个SetCollection&lt;V&gt; values();  // 单独value序列，将所有value生成一个Collectionvoid clear(); // 清除哈希表中的所有键值对int size();  // 返回哈希表中所有 键值对的数量 = 数组中的键值对 + 链表中的键值对boolean isEmpty(); // 判断HashMap是否为空；size == 0时 表示为 空 </code></pre><p>使用流程<br>与 JDK 1.7 基本相同</p><p>在具体使用时，主要流程是：</p><p>声明 1 个 HashMap 的对象；<br>向 HashMap 添加数据（成对 放入 键 - 值对）；<br>获取 HashMap 的某个数据；<br>获取 HashMap 的全部数据：遍历 HashMap。<br>示例代码：</p><pre><code class="bash">import java.util.Collection;import java.util.HashMap;import java.util.Iterator;import java.util.Map;import java.util.Set;public class HashMapTest &#123;    public static void main(String[] args) &#123;      /**        * 1. 声明1个 HashMap的对象        */        Map&lt;String, Integer&gt; map = new HashMap&lt;String, Integer&gt;();      /**        * 2. 向HashMap添加数据（成对 放入 键 - 值对）        */        map.put(&quot;Android&quot;, 1);        map.put(&quot;Java&quot;, 2);        map.put(&quot;iOS&quot;, 3);        map.put(&quot;数据挖掘&quot;, 4);        map.put(&quot;产品经理&quot;, 5);       /**        * 3. 获取 HashMap 的某个数据        */        System.out.println(&quot;key = 产品经理时的值为：&quot; + map.get(&quot;产品经理&quot;));      /**        * 4. 获取 HashMap 的全部数据：遍历HashMap        * 核心思想：        * 步骤1：获得key-value对（Entry） 或 key 或 value的Set集合        * 步骤2：遍历上述Set集合(使用for循环 、 迭代器（Iterator）均可)        * 方法共有3种：分别针对 key-value对（Entry） 或 key 或 value        */        // 方法1：获得key-value的Set集合 再遍历        System.out.println(&quot;方法1&quot;);        // 1. 获得key-value对（Entry）的Set集合        Set&lt;Map.Entry&lt;String, Integer&gt;&gt; entrySet = map.entrySet();        // 2. 遍历Set集合，从而获取key-value        // 2.1 通过for循环        for(Map.Entry&lt;String, Integer&gt; entry : entrySet)&#123;            System.out.print(entry.getKey());            System.out.println(entry.getValue());        &#125;        System.out.println(&quot;----------&quot;);        // 2.2 通过迭代器：先获得key-value对（Entry）的Iterator，再循环遍历        Iterator iter1 = entrySet.iterator();        while (iter1.hasNext()) &#123;            // 遍历时，需先获取entry，再分别获取key、value            Map.Entry entry = (Map.Entry) iter1.next();            System.out.print((String) entry.getKey());            System.out.println((Integer) entry.getValue());        &#125;        // 方法2：获得key的Set集合 再遍历        System.out.println(&quot;方法2&quot;);        // 1. 获得key的Set集合        Set&lt;String&gt; keySet = map.keySet();        // 2. 遍历Set集合，从而获取key，再获取value        // 2.1 通过for循环        for(String key : keySet)&#123;            System.out.print(key);            System.out.println(map.get(key));        &#125;        System.out.println(&quot;----------&quot;);        // 2.2 通过迭代器：先获得key的Iterator，再循环遍历        Iterator iter2 = keySet.iterator();        String key = null;        while (iter2.hasNext()) &#123;            key = (String)iter2.next();            System.out.print(key);            System.out.println(map.get(key));        &#125;        // 方法3：获得value的Set集合 再遍历        System.out.println(&quot;方法3&quot;);        // 1. 获得value的Set集合        Collection valueSet = map.values();        // 2. 遍历Set集合，从而获取value        // 2.1 获得values 的Iterator        Iterator iter3 = valueSet.iterator();        // 2.2 通过遍历，直接获取value        while (iter3.hasNext()) &#123;            System.out.println(iter3.next());        &#125;    &#125;&#125;</code></pre><p>// 注：对于遍历方式，推荐使用针对 key-value对（Entry）的方式：效率高<br>// 原因：<br>   // 1. 对于 遍历keySet 、valueSet，实质上 = 遍历了2次：1 = 转为 iterator 迭代器遍历、2 = 从 HashMap 中取出 key 的 value 操作（通过 key 值 hashCode 和 equals 索引）<br>   // 2. 对于 遍历 entrySet ，实质 = 遍历了1次 = 获取存储实体Entry（存储了key 和 value ）<br>运行结果：</p><pre><code class="bash">方法1Java2iOS3数据挖掘4Android1产品经理5----------Java2iOS3数据挖掘4Android1产品经理5方法2Java2iOS3数据挖掘4Android1产品经理5----------Java2iOS3数据挖掘4Android1产品经理5方法323415</code></pre><p>HashMap 中的重要参数（变量）</p><pre><code class="bash">/**   * 主要参数 同  JDK 1.7   * 即：容量、加载因子、扩容阈值（要求、范围均相同）  */ // 1. 容量（capacity）： 必须是2的幂 &amp; &lt;最大容量（2的30次方） static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // 默认容量 = 16 = 1&lt;&lt;4 = 00001中的1向左移4位 = 10000 = 十进制的2^4=16 static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; // 最大容量 =  2的30次方（若传入的容量过大，将被最大值替换） // 2. 加载因子(Load factor)：HashMap在其容量自动增加前可达到多满的一种尺度  final float loadFactor; // 实际加载因子 static final float DEFAULT_LOAD_FACTOR = 0.75f; // 默认加载因子 = 0.75 // 3. 扩容阈值（threshold）：当哈希表的大小 ≥ 扩容阈值时，就会扩容哈希表（即扩充HashMap的容量）  // a. 扩容 = 对哈希表进行resize操作（即重建内部数据结构），从而哈希表将具有大约两倍的桶数 // b. 扩容阈值 = 容量 x 加载因子 int threshold; // 4. 其他 transient Node&lt;K,V&gt;[] table;  // 存储数据的Node类型 数组，长度 = 2的幂；数组的每个元素 = 1个单链表 transient int size;// HashMap的大小，即 HashMap中存储的键值对的数量</code></pre><p> /** </p><ul><li>与红黑树相关的参数</li><li>/<br>// 1. 桶的树化阈值：即 链表转成红黑树的阈值，在存储数据时，当链表长度 &gt; 该值时，则将链表转换成红黑树<br>static final int TREEIFY_THRESHOLD = 8;<br>// 2. 桶的链表还原阈值：即 红黑树转为链表的阈值，当在扩容（resize（））时（此时HashMap的数据存储位置会重新计算），在重新计算存储位置后，当原有的红黑树内数量 &lt; 6时，则将 红黑树转换成链表<br>static final int UNTREEIFY_THRESHOLD = 6;<br>// 3. 最小树形化容量阈值：即 当哈希表中的容量 &gt; 该值时，才允许树形化链表 （即 将链表 转换成红黑树）<br>// 否则，若桶内元素太多时，则直接扩容，而不是树形化<br>// 为了避免进行扩容、树形化选择的冲突，这个值不能小于 4 * TREEIFY_THRESHOLD<br>static final int MIN_TREEIFY_CAPACITY = 64;<br>加载因子<br>同 JDK 1.7，但由于其重要性，故此处再次说明。</li></ul><p>img</p><p>总结 数据结构 &amp; 参数方面与 JDK 1.7 的区别：</p><p>img</p><p>源码分析<br>本次的源码分析主要是根据 使用步骤 进行相关函数的详细分析，主要分析内容如下：</p><p>img</p><p>源码中数据结构 &amp; 主要参数</p><p>img</p><p>步骤 1：声明 1 个 HashMap 的对象<br>此处主要分析的构造函数类似 JDK 1.7。</p><p>源码分析：</p><pre><code class="bash">/**  * 函数使用原型  */  Map&lt;String,Integer&gt; map = new HashMap&lt;String,Integer&gt;(); /**   * 源码分析：主要是HashMap的构造函数 = 4个   * 仅贴出关于HashMap构造函数的源码   */public class HashMap&lt;K,V&gt;    extends AbstractMap&lt;K,V&gt;    implements Map&lt;K,V&gt;, Cloneable, Serializable&#123;    // 省略上节阐述的参数      /**     * 构造函数1：默认构造函数（无参）     * 加载因子 &amp; 容量 = 默认 = 0.75、16     */    public HashMap() &#123;        this.loadFactor = DEFAULT_LOAD_FACTOR;    &#125;    /**     * 构造函数2：指定“容量大小”的构造函数     * 加载因子 = 默认 = 0.75 、容量 = 指定大小     */    public HashMap(int initialCapacity) &#123;        // 实际上是调用指定“容量大小”和“加载因子”的构造函数        // 只是在传入的加载因子参数 = 默认加载因子        this(initialCapacity, DEFAULT_LOAD_FACTOR);            &#125;    /**     * 构造函数3：指定“容量大小”和“加载因子”的构造函数     * 加载因子 &amp; 容量 = 自己指定     */    public HashMap(int initialCapacity, float loadFactor) &#123;        // 指定初始容量必须非负，否则报错           if (initialCapacity &lt; 0)             throw new IllegalArgumentException(&quot;Illegal initial capacity: &quot; +                                             initialCapacity);         // HashMap的最大容量只能是MAXIMUM_CAPACITY，哪怕传入的 &gt; 最大容量        if (initialCapacity &gt; MAXIMUM_CAPACITY)            initialCapacity = MAXIMUM_CAPACITY;        // 填充比必须为正          if (loadFactor &lt;= 0 || Float.isNaN(loadFactor))              throw new IllegalArgumentException(&quot;Illegal load factor: &quot; +                                             loadFactor);          // 设置 加载因子        this.loadFactor = loadFactor;        // 设置 扩容阈值        // 注：此处不是真正的阈值，仅仅只是将传入的容量大小转化为：&gt;传入容量大小的最小的2的幂，该阈值后面会重新计算        // 下面会详细讲解 -&gt;&gt; 分析1        this.threshold = tableSizeFor(initialCapacity);     &#125;    /**     * 构造函数4：包含“子Map”的构造函数     * 即 构造出来的HashMap包含传入Map的映射关系     * 加载因子 &amp; 容量 = 默认     */    public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123;        // 设置容量大小 &amp; 加载因子 = 默认        this.loadFactor = DEFAULT_LOAD_FACTOR;         // 将传入的子Map中的全部元素逐个添加到HashMap中        putMapEntries(m, false);     &#125;&#125;   /**     * 分析1：tableSizeFor(initialCapacity)     * 作用：将传入的容量大小转化为：&gt;传入容量大小的最小的2的幂     * 与JDK 1.7对比：类似于JDK 1.7 中 inflateTable()里的 roundUpToPowerOf2(toSize)     */    static final int tableSizeFor(int cap) &#123;     int n = cap - 1;     n |= n &gt;&gt;&gt; 1;     n |= n &gt;&gt;&gt; 2;     n |= n &gt;&gt;&gt; 4;     n |= n &gt;&gt;&gt; 8;     n |= n &gt;&gt;&gt; 16;     return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125;注：（同 JDK 1.7 类似）</code></pre><p>此处仅用于接收初始容量大小（capacity）、加载因子 (Load factor)，但仍无真正初始化哈希表，即初始化存储数组 table。<br>此处先给出结论：真正初始化哈希表（初始化存储数组 table）是在第 1 次添加键值对时，即第 1 次调用 put（）时。下面会详细说明。<br>步骤 2：向 HashMap 添加数据（成对 放入 键 - 值对）<br>在该步骤中，与 JDK 1.7 的差别较大：</p><p>img</p><p>添加数据的流程如下：</p><p>img</p><p>源码分析</p><pre><code class="bash">/**  * 函数使用原型  */  map.put(&quot;Android&quot;, 1);       map.put(&quot;Java&quot;, 2);       map.put(&quot;iOS&quot;, 3);       map.put(&quot;数据挖掘&quot;, 4);       map.put(&quot;产品经理&quot;, 5);  /**    * 源码分析：主要分析HashMap的put函数    */   public V put(K key, V value) &#123;       // 1. 对传入数组的键Key计算Hash值 -&gt;&gt;分析1       // 2. 再调用putVal（）添加数据进去 -&gt;&gt;分析2       return putVal(hash(key), key, value, false, true);   &#125;</code></pre><p>分析 1：hash（key）</p><pre><code class="bash">/**  * 分析1：hash(key)  * 作用：计算传入数据的哈希码（哈希值、Hash值）  * 该函数在JDK 1.7 和 1.8 中的实现不同，但原理一样 = 扰动函数 = 使得根据key生成的哈希码（hash值）分布更加均匀、更具备随机性，避免出现hash值冲突（即指不同key但生成同1个hash值）  * JDK 1.7 做了9次扰动处理 = 4次位运算 + 5次异或运算  * JDK 1.8 简化了扰动函数 = 只做了2次扰动 = 1次位运算 + 1次异或运算  */   // JDK 1.7实现：将 键key 转换成 哈希码（hash值）操作  = 使用hashCode() + 4次位运算 + 5次异或运算（9次扰动）   static final int hash(int h) &#123;     h ^= k.hashCode();      h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12);     return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4);  &#125;   // JDK 1.8实现：将 键key 转换成 哈希码（hash值）操作 = 使用hashCode() + 1次位运算 + 1次异或运算（2次扰动）   // 1. 取hashCode值： h = key.hashCode()    // 2. 高位参与低位的运算：h ^ (h &gt;&gt;&gt; 16)     static final int hash(Object key) &#123;        int h;         return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);         // a. 当key = null时，hash值 = 0，所以HashMap的key 可为null               // 注：对比HashTable，HashTable对key直接hashCode（），若key为null时，会抛出异常，所以HashTable的key不可为null         // b. 当key ≠ null时，则通过先计算出 key的 hashCode()（记为h），然后 对哈希码进行 扰动处理： 按位 异或（^） 哈希码自身右移16位后的二进制  &#125;/**  * 计算存储位置的函数分析：indexFor(hash, table.length)  * 注：该函数仅存在于JDK 1.7 ，JDK 1.8中实际上无该函数（直接用1条语句判断写出），但原理相同  * 为了方便讲解，故提前到此讲解  */  static int indexFor(int h, int length) &#123;         return h &amp; (length-1);        // 将对哈希码扰动处理后的结果 与运算(&amp;) （数组长度-1），最终得到存储在数组table的位置（即数组下标、索引）       &#125;</code></pre><p>计算存放在数组 table 中的位置（即数组下标、索引）的过程：</p><p>此处与 JDK 1.7 的区别在于：hash 值的求解过程中哈希码的二次处理方式（扰动处理）。<br>步骤 1、2 = hash 值的求解过程。</p><p>img</p><p>计算示意图：</p><p>img</p><p>在了解如何计算存放数组 table 中的位置 后，所谓 知其然而需知其所以然，下面讲解为什么要这样计算，即主要解答以下 3 个问题：</p><p>为什么不直接采用经过 hashCode（）处理的哈希码作为存储数组 table 的下标位置？<br>为什么采用 哈希码 与运算 (&amp;) （数组长度 - 1） 计算数组下标？<br>为什么在计算数组下标前，需对哈希码进行二次处理：扰动处理？<br>在回答这 3 个问题前，请大家记住一个核心思想：所有处理的根本目的，都是为了提高存储 key-value 的数组下标位置的随机性 &amp; 分布均匀性，尽量避免出现 hash 值冲突。即：对于不同 key，存储的数组下标位置要尽可能不一样。</p><p>为什么不直接采用经过 hashCode（）处理的哈希码作为存储数组 table 的下标位置？</p><p>结论：容易出现哈希码与数组大小范围不匹配的情况，即计算出来的哈希码可能不在数组大小范围内，从而导致无法匹配存储位置。</p><p>img</p><p>为了解决 “哈希码与数组大小范围不匹配” 的问题，HashMap 给出了解决方案：哈希码与运算（&amp;） （数组长度 - 1），即问题 3。</p><p>为什么采用哈希码与运算 (&amp;) （数组长度 - 1） 计算数组下标？</p><p>结论：根据 HashMap 的容量大小（数组长度），按需取哈希码一定数量的低位作为存储的数组下标位置，从而 解决 “哈希码与数组大小范围不匹配” 的问题。</p><p>img</p><p>为什么在计算数组下标前，需对哈希码进行二次处理：扰动处理？</p><p>结论：加大哈希码低位的随机性，使得分布更均匀，从而提高对应数组存储下标位置的随机性 &amp; 均匀性，最终减少 Hash 冲突。</p><p>img</p><p>分析 2：putVal (hash (key), key, value, false, true)<br>计算完存储位置后，具体该如何存放数据到哈希表中。<br>具体如何扩容，即 扩容机制。<br>由于数据结构中加入了红黑树，所以在存放数据到哈希表中时，需进行多次数据结构的判断：数组、红黑树、链表。</p><p>与 JDK 1.7 的区别： JDK 1.7 只需判断 数组 &amp; 链表。</p><p>img</p><p>源码分析：</p><pre><code class="bash">   /**     * 分析2：putVal(hash(key), key, value, false, true)     */    //onlyIfAbsent：插入的值是否存在，存在就不插了。     final V putVal(int hash, K key, V value, boolean onlyIfAbsent,               boolean evict) &#123;            Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i;        // 1. 若哈希表的数组tab为空，则 通过resize() 创建        // 所以，初始化哈希表的时机 = 第1次调用put函数时，即调用resize() 初始化创建        // 关于resize（）的源码分析将在下面讲解扩容时详细分析，此处先跳过        if ((tab = table) == null || (n = tab.length) == 0)        n = (tab = resize()).length;        // 2. 计算插入存储的数组索引i：根据键值key计算的hash值 得到        // 此处的数组下标计算方式 = i = (n - 1) &amp; hash，同JDK 1.7中的indexFor（），上面已详细描述        // 3. 插入时，需判断是否存在Hash冲突：        // 若不存在（即当前table[i] == null），则直接在该数组位置新建节点，插入完毕        // 否则，代表存在Hash冲突，即当前存储位置已存在节点，则依次往下判断：a. 当前位置的key是否与需插入的key相同、b. 判断需插入的数据结构是否为红黑树 or 链表        if ((p = tab[i = (n - 1) &amp; hash]) == null)        tab[i] = newNode(hash, key, value, null);  // newNode(hash, key, value, null)的源码 = new Node&lt;&gt;(hash, key, value, next)    else &#123;        Node&lt;K,V&gt; e; K k;        // a. 判断 table[i]的元素的key是否与 需插入的key一样，若相同则 直接用新value 覆盖 旧value        // 判断原则：equals（）        if (p.hash == hash &amp;&amp;            ((k = p.key) == key || (key != null &amp;&amp; key.equals(k))))            e = p;        // b. 继续判断：需插入的数据结构是否为红黑树 or 链表        // 若是红黑树，则直接在树中插入 or 更新键值对        else if (p instanceof TreeNode)            e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); -&gt;&gt;分析3        // 若是链表,则在链表中插入 or 更新键值对        // i.  遍历table[i]，判断Key是否已存在：采用equals（） 对比当前遍历节点的key 与 需插入数据的key：若已存在，则直接用新value 覆盖 旧value        // ii. 遍历完毕后仍无发现上述情况，则直接在链表尾部插入数据        // 注：新增节点后，需判断链表长度是否&gt;8（8 = 桶的树化阈值）：若是，则把链表转换为红黑树                else &#123;            for (int binCount = 0; ; ++binCount) &#123;                // 对于ii：若数组的下1个位置，表示已到表尾也没有找到key值相同节点，则新建节点 = 插入节点                // 注：此处是从链表尾插入，与JDK 1.7不同（从链表头插入，即永远都是添加到数组的位置，原来数组位置的数据则往后移）                if ((e = p.next) == null) &#123;                    p.next = newNode(hash, key, value, null);                    // 插入节点后，若链表节点&gt;树阈值，则将链表转换为红黑树                    if (binCount &gt;= TREEIFY_THRESHOLD - 1)                         treeifyBin(tab, hash); // 树化操作                    break;                &#125;                // 对于i                if (e.hash == hash &amp;&amp;                    ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))                    break;                // 更新p指向下一个节点，继续遍历                p = e;            &#125;        &#125;        // 对i情况的后续操作：发现key已存在，直接用新value 覆盖 旧value &amp; 返回旧value        if (e != null) &#123;             V oldValue = e.value;            if (!onlyIfAbsent || oldValue == null)                e.value = value;            afterNodeAccess(e); // 替换旧值时会调用的方法（默认实现为空）            return oldValue;        &#125;    &#125;    ++modCount; //表示散列表结构被修改的次数，替换Node元素的value不计数    // 插入成功后，判断实际存在的键值对数量size &gt; 最大容量threshold    // 若 &gt; ，则进行扩容 -&gt;&gt;分析4（但单独讲解，请直接跳出该代码块）    if (++size &gt; threshold)        resize();    afterNodeInsertion(evict);// 插入成功时会调用的方法（默认实现为空）    return null;&#125;    /**     * 分析3：putTreeVal(this, tab, hash, key, value)     * 作用：向红黑树插入 or 更新数据（键值对）     * 过程：遍历红黑树判断该节点的key是否与需插入的key 相同：     *      a. 若相同，则新value覆盖旧value     *      b. 若不相同，则插入     */     final TreeNode&lt;K,V&gt; putTreeVal(HashMap&lt;K,V&gt; map, Node&lt;K,V&gt;[] tab,                                       int h, K k, V v) &#123;            Class&lt;?&gt; kc = null;            boolean searched = false;            TreeNode&lt;K,V&gt; root = (parent != null) ? root() : this;            for (TreeNode&lt;K,V&gt; p = root;;) &#123;                int dir, ph; K pk;                if ((ph = p.hash) &gt; h)                    dir = -1;                else if (ph &lt; h)                    dir = 1;                else if ((pk = p.key) == k || (k != null &amp;&amp; k.equals(pk)))                    return p;                else if ((kc == null &amp;&amp;                          (kc = comparableClassFor(k)) == null) ||                         (dir = compareComparables(kc, k, pk)) == 0) &#123;                    if (!searched) &#123;                        TreeNode&lt;K,V&gt; q, ch;                        searched = true;                        if (((ch = p.left) != null &amp;&amp;                             (q = ch.find(h, k, kc)) != null) ||                            ((ch = p.right) != null &amp;&amp;                             (q = ch.find(h, k, kc)) != null))                            return q;                    &#125;                    dir = tieBreakOrder(k, pk);                &#125;                TreeNode&lt;K,V&gt; xp = p;                if ((p = (dir &lt;= 0) ? p.left : p.right) == null) &#123;                    Node&lt;K,V&gt; xpn = xp.next;                    TreeNode&lt;K,V&gt; x = map.newTreeNode(h, k, v, xpn);                    if (dir &lt;= 0)                        xp.left = x;                    else                        xp.right = x;                    xp.next = x;                    x.parent = x.prev = xp;                    if (xpn != null)                        ((TreeNode&lt;K,V&gt;)xpn).prev = x;                    moveRootToFront(tab, balanceInsertion(root, x));                    return null;                &#125;            &#125;        &#125;</code></pre><p>put 流程：</p><p>img</p><p>扩容机制（即 resize（）函数方法）<br>扩容流程如下：</p><p>img</p><p>源码分析：</p><pre><code class="bash">   //为什么需要扩容？ 元素太多就会导致查询效率由O(1)-&gt;O(n) 扩容后使得元素更加分散，查询效率更高   //为了解决哈希冲突导致的链化影响查询效率的问题，扩容会缓解该问题    /**     * 分析4：resize（）     * 该函数有2种使用情况：1.初始化哈希表 2.当前数组容量过小，需扩容     */   final Node&lt;K,V&gt;[] resize() &#123;    Node&lt;K,V&gt;[] oldTab = table; // 扩容前的数组（当前数组）    int oldCap = (oldTab == null) ? 0 : oldTab.length; // 扩容前的数组的容量 = 长度    int oldThr = threshold;// 扩容前的数组的阈值    int newCap, newThr = 0;    // 针对情况2：若扩容前的数组容量超过最大值，则不再扩充    if (oldCap &gt; 0) &#123;        if (oldCap &gt;= MAXIMUM_CAPACITY) &#123;            threshold = Integer.MAX_VALUE;            return oldTab;        &#125;        // 针对情况2：若无超过最大值，就扩充为原来的2倍        else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp;                 oldCap &gt;= DEFAULT_INITIAL_CAPACITY)            newThr = oldThr &lt;&lt; 1; // 通过右移扩充2倍    &#125;    // 针对情况1：初始化哈希表（采用指定 or 默认值）    /*oldCap == 0 ，说明hashMap中的散列表是null    *    1. new HashMap(initCap,loadFactor);    *   2. new HashMap(intiCap);    *   3. new HashMap(map);并且这个map有数据         */    else if (oldThr &gt; 0) // initial capacity was placed in threshold        newCap = oldThr;    else &#123;               // zero initial threshold signifies using defaults        newCap = DEFAULT_INITIAL_CAPACITY;        newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);    &#125;    // 计算新的resize上限    if (newThr == 0) &#123;        float ft = (float)newCap * loadFactor;        newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ?                  (int)ft : Integer.MAX_VALUE);    &#125;    threshold = newThr;    @SuppressWarnings(&#123;&quot;rawtypes&quot;,&quot;unchecked&quot;&#125;)        Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap];    table = newTab;    if (oldTab != null) &#123;        // 把每个bucket都移动到新的buckets中        for (int j = 0; j &lt; oldCap; ++j) &#123;            Node&lt;K,V&gt; e;            if ((e = oldTab[j]) != null) &#123;                oldTab[j] = null;                if (e.next == null)                    newTab[e.hash &amp; (newCap - 1)] = e;                else if (e instanceof TreeNode)                    ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap);                //第三种情况：桶位已经形成链表                                        //低位链表：存放扩容之前的数组下标位置，与当期位置的下标位置一致                //高位链表：存放扩容之后的数组下标位置为 当前数组下标位置 + 扩容之后数组的长度                else &#123; // 链表优化重hash的代码块                    Node&lt;K,V&gt; loHead = null, loTail = null;                    Node&lt;K,V&gt; hiHead = null, hiTail = null;                    Node&lt;K,V&gt; next;                    do &#123;                        next = e.next;                        // 原索引                        if ((e.hash &amp; oldCap) == 0) &#123;                            if (loTail == null)                                loHead = e;                            else                                loTail.next = e;                            loTail = e;                        &#125;                        // 原索引 + oldCap                        else &#123;                            if (hiTail == null)                                hiHead = e;                            else                                hiTail.next = e;                            hiTail = e;                        &#125;                    &#125; while ((e = next) != null);                    // 原索引放到bucket里                    if (loTail != null) &#123;                        loTail.next = null;                        newTab[j] = loHead;                    &#125;                    // 原索引+oldCap放到bucket里                    if (hiTail != null) &#123;                        hiTail.next = null;                        newTab[j + oldCap] = hiHead;                    &#125;                &#125;            &#125;        &#125;    &#125;    return newTab;&#125;</code></pre><p>扩容流程（含 与 JDK 1.7 的对比）：</p><p>img</p><p>这里主要是 JDK 1.8 扩容时，数据存储位置重新计算的方式。</p><p>image-20210708221831834</p><p>结论示意图：</p><p>img</p><p>数组位置转换的示意图：</p><p>image-20210708214220642</p><p>JDK 1.8 根据此结论作出的新元素存储位置计算规则非常简单，提高了扩容效率，具体如下图。</p><p>这与 JDK 1.7 在计算新元素的存储位置有很大区别：JDK 1.7 在扩容后，都需按照原来方法重新计算，即<br>hashCode（）-&gt;&gt; 扰动处理 -&gt;&gt;（h &amp; length-1））。</p><p>与 JDK 1.7 的区别：</p><p>img</p><p>步骤 3：从 HashMap 中获取数据<br>假如理解了上述 put（）函数的原理，那么 get（）函数非常好理解，因为二者的过程原理几乎相同。</p><p>get（）函数的流程如下：</p><p>img</p><p>源码分析：</p><p>JAVA<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>26<br>27<br>28<br>29<br>30<br>31<br>32<br>33<br>34<br>35<br>36<br>37<br>38<br>39<br>40<br>41<br>42<br>43<br>44<br>45<br>46<br>47<br>48<br>49<br>50<br>/**</p><ul><li>函数原型</li><li>作用：根据键key，向HashMap获取对应的值</li><li>/<br>map.get(key)；</li></ul><p> /**</p><ul><li>源码分析</li><li>/<br>public V get(Object key) {<br>Node&lt;K,V&gt; e;<br>// 1. 计算需获取数据的hash值<br>// 2. 通过getNode（）获取所查询的数据 -&gt;&gt;分析1<br>// 3. 获取后，判断数据是否为空<br>return (e = getNode(hash(key), key)) == null ? null : e.value;<br>}</li></ul><p>/**</p><ul><li><p>分析1：getNode(hash(key), key))</p></li><li><p>/<br>final Node&lt;K,V&gt; getNode(int hash, Object key) {<br>Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k;</p><p>// 1. 计算存放在数组table中的位置<br>if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp;</p><pre><code>(first = tab[(n - 1) &amp; hash]) != null) &#123;// 4. 通过该函数，依次在数组、红黑树、链表中查找（通过equals（）判断）// a. 先在数组中找，若存在，则直接返回if (first.hash == hash &amp;&amp; // always check first node    ((k = first.key) == key || (key != null &amp;&amp; key.equals(k))))    return first;// b. 若数组中没有，则到红黑树中寻找if ((e = first.next) != null) &#123;    // 在树中get    if (first instanceof TreeNode)        return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key);    // c. 若红黑树中也没有，则通过遍历，到链表中寻找    do &#123;        if (e.hash == hash &amp;&amp;            ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))            return e;    &#125; while ((e = e.next) != null);&#125;</code></pre><p>}<br>return null;<br>}<br>步骤 4：对 HashMap 的其他操作<br>HashMap 除了核心的 put（）、get（）函数，还有以下主要使用的函数方法：</p></li></ul><p>JAVA<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10</p><p>void clear(); // 清除哈希表中的所有键值对<br>int size();  // 返回哈希表中所有 键值对的数量 = 数组中的键值对 + 链表中的键值对<br>boolean isEmpty(); // 判断HashMap是否为空；size == 0时 表示为 空 </p><p>void putAll(Map&lt;? extends K, ? extends V&gt; m);  // 将指定Map中的键值对 复制到 此Map中<br>V remove(Object key);  // 删除该键值对</p><p>boolean containsKey(Object key); // 判断是否存在该键的键值对；是 则返回true<br>boolean containsValue(Object value);  // 判断是否存在该值的键值对；是 则返回true<br>关于上述方法的源码的原理 同 JDK 1.7，此处不作过多描述。<br>总结内容 = 数据结构、主要参数、添加 &amp; 查询数据流程、扩容机制.<br>removeNode()<br>JAVA<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>26<br>27<br>28<br>29<br>30<br>31<br>32<br>33<br>34<br>35<br>36<br>37<br>38<br>39<br>40<br>41<br>42<br>43<br>44<br>45<br>46<br>47<br>48<br>49<br>50<br>51<br>52<br>53<br>54<br>55<br>56<br>57<br>58<br>59<br>60<br>61<br>62<br>63<br>64<br>65<br>66<br>67<br>68<br>final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value,<br>                               boolean matchValue, boolean movable) {<br>        //tab：引用当前hashMap的散列表<br>        //p：当前node元素（桶位中头元素）<br>        //n：表示散列表数组长度<br>        //index:表示寻址结果<br>        Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, index;</p><pre><code>    //说明路由的桶位是有数据的，需要进行查找操作，并且删除    if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp;        (p = tab[index = (n - 1) &amp; hash]) != null) &#123;                    //node：查找到的结果        //e：当前Node的下一个元素        Node&lt;K,V&gt; node = null, e; K k; V v;                //第一种情况：当前桶位中的元素 即为要删除的元素        if (p.hash == hash &amp;&amp;            ((k = p.key) == key || (key != null &amp;&amp; key.equals(k))))            node = p;                            else if ((e = p.next) != null) &#123;            //说明当前桶位不止一个元素，可能是链表，可能是红黑树                        if (p instanceof TreeNode) 判断当前桶位是否升级为红黑树                //第二种情况：红黑树查找操作                node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key);                            else &#123;                //第三种情况：链表                do &#123;                    //循环链表 查找node节点                    if (e.hash == hash &amp;&amp;                        ((k = e.key) == key ||                         (key != null &amp;&amp; key.equals(k)))) &#123;                        node = e;                        break;                    &#125;                    p = e;  //保证e一直往下查找                &#125; while ((e = e.next) != null);一直向下找            &#125;        &#125;                //删除数据        //判断node不为空的话，说明按照key查找到需要删除的数据了        if (node != null &amp;&amp; (!matchValue || (v = node.value) == value ||                             (value != null &amp;&amp; value.equals(v)))) &#123;                        //第一种情况：node是树节点，说明需要进行树节点移除操作                            if (node instanceof TreeNode)                ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable);                        //第二种情况：桶位元素即为查找结果，则将该元素的下一个元素放到桶位中            else if (node == p)                tab[index] = node.next;                                //第三种情况：将当前元素p的下一个元素 设置成 要删除的下一个元素            else                p.next = node.next;            ++modCount;            --size;            afterNodeRemoval(node);            return node;        &#125;    &#125;    return null;&#125;</code></pre><p>clear()<br>JAVA<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>依次将数组中的元素重置为null<br>    public void clear() {<br>        Node&lt;K,V&gt;[] tab;<br>        modCount++;<br>        if ((tab = table) != null &amp;&amp; size &gt; 0) {<br>            size = 0;<br>            for (int i = 0; i &lt; tab.length; ++i)<br>                tab[i] = null;<br>        }<br>    }<br>额外补充：关于 HashMap 的其他问题</p><p>image-20210708221739910<br>哈希表如何解决 Hash 冲突？</p><p>image-20210708221806238</p><p>为什么 HashMap 具备下述特点：键 - 值（key-value）都允许为空、线程不安全、不保证有序、存储位置随时间变化？</p><p>img</p><p>HashMap 线程不安全的其中一个重要原因：多线程下容易出现 resize（）死循环。 本质 = 并发 执行 put（）操作导致触发 扩容行为，从而导致 环形链表，使得在获取数据遍历链表时形成死循环，即 Infinite Loop</p><p>先看扩容的源码分析 resize（）：</p><p>JAVA<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>26<br>27<br>28<br>29<br>30<br>31<br>32<br>33<br>34<br>35<br>36<br>37<br>38<br>39<br>40<br>41<br>42<br>43<br>44<br>45<br>46<br>47<br>48<br>49<br>50<br>51<br>52<br>53<br>54<br>55<br>56<br>57<br>58<br>59<br>60<br>61<br>62<br>63<br>64<br>65<br>66<br>67<br>68<br>/**</p><ul><li><p>源码分析：resize(2 * table.length)</p></li><li><p>作用：当容量不足时（容量 &gt; 阈值），则扩容（扩到2倍）</p></li><li><p>/<br>void resize(int newCapacity) {  </p><p>// 1. 保存旧数组（old table）<br>Entry[] oldTable = table;  </p><p>// 2. 保存旧容量（old capacity ），即数组长度<br>int oldCapacity = oldTable.length; </p><p>// 3. 若旧容量已经是系统默认最大容量了，那么将阈值设置成整型的最大值，退出<br>if (oldCapacity == MAXIMUM_CAPACITY) {  </p><pre><code>threshold = Integer.MAX_VALUE;  return;  </code></pre><p>}  </p><p>// 4. 根据新容量（2倍容量）新建1个数组，即新table<br>Entry[] newTable = new Entry[newCapacity];  </p><p>// 5. （重点分析）将旧数组上的数据（键值对）转移到新table中，从而完成扩容 -&gt;&gt;分析1.1<br>transfer(newTable); </p><p>// 6. 新数组table引用到HashMap的table属性上<br>table = newTable;  </p><p>// 7. 重新设置阈值<br>threshold = (int)(newCapacity * loadFactor);<br>} </p></li></ul><p> /**</p><ul><li><p>分析1.1：transfer(newTable); </p></li><li><p>作用：将旧数组上的数据（键值对）转移到新table中，从而完成扩容</p></li><li><p>过程：按旧链表的正序遍历链表、在新链表的头部依次插入</p></li><li><p>/<br>void transfer(Entry[] newTable) {<br>  // 1. src引用了旧数组<br>  Entry[] src = table; </p><p>  // 2. 获取新数组的大小 = 获取新容量大小<br>  int newCapacity = newTable.length;</p><p>  // 3. 通过遍历 旧数组，将旧数组上的数据（键值对）转移到新数组中<br>  for (int j = 0; j &lt; src.length; j++) { </p><pre><code>  // 3.1 取得旧数组的每个元素    Entry&lt;K,V&gt; e = src[j];             if (e != null) &#123;      // 3.2 释放旧数组的对象引用（for循环后，旧数组不再引用任何对象）      src[j] = null;       do &#123;           // 3.3 遍历 以该数组元素为首 的链表          // 注：转移链表时，因是单链表，故要保存下1个结点，否则转移后链表会断开          Entry&lt;K,V&gt; next = e.next;          // 3.3 重新计算每个元素的存储位置         int i = indexFor(e.hash, newCapacity);          // 3.4 将元素放在数组上：采用单链表的头插入方式 = 在链表头上存放数据 = 将数组位置的原有数据放在后1个指针、将需放入的数据放到数组位置中         // 即 扩容后，可能出现逆序：按旧链表的正序遍历链表、在新链表的头部依次插入         e.next = newTable[i];          newTable[i] = e;           // 访问下1个Entry链上的元素，如此不断循环，直到遍历完该链表上的所有节点         e = next;                  &#125; while (e != null);     // 如此不断循环，直到遍历完数组上的所有数据元素 &#125;</code></pre><p> }<br>}<br>从上面可看出：在扩容 resize（）过程中，在将旧数组上的数据 转移到 新数组上时，转移数据操作 = 按旧链表的正序遍历链表、在新链表的头部依次插入，即在转移数据、扩容后，容易出现链表逆序的情况。</p></li></ul><p>设重新计算存储位置后不变，即扩容前 = 1-&gt;2-&gt;3，扩容后 = 3-&gt;2-&gt;1</p><p>此时若（多线程）并发执行 put（）操作，一旦出现扩容情况，则 容易出现 环形链表，从而在获取数据、遍历链表时 形成死循环（Infinite Loop），即 死锁的状态，具体请看下图：</p><p>img</p><p>img</p><p>image-20210708221933718</p><p>image-20210708222003422</p><p>image-20210708222037780</p><p>由于 JDK 1.8 转移数据操作 = 按旧链表的正序遍历链表、在新链表的尾部依次插入，所以不会出现链表 逆序、倒置的情况，故不容易出现环形链表的情况。</p><p>为什么 HashMap 中 String、Integer 这样的包装类适合作为 key 键？</p><p>img</p><p>HashMap 中的 key 若 Object 类型， 则需实现哪些方法？</p>]]></content>
      
      
      <categories>
          
          <category> 集合 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
            <tag> HashMap </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LinkedList 源码分析</title>
      <link href="/2020/07/20/collection/LinkedList%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"/>
      <url>/2020/07/20/collection/LinkedList%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="LinkedList-源码分析"><a href="#LinkedList-源码分析" class="headerlink" title="LinkedList 源码分析"></a>LinkedList 源码分析</h2><p>linkedList 说明<br>LinkedList 是 List 接口的另一种实现，它的底层是基于双向链表实现的，因此它具有插入删除快而查找修改慢的特点，此外，通过对双向链表的操作还可以实现队列和栈的功能。</p><p>LinkedList 解释说明<br>说明文档解释：</p><p>CODE<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18</p><ul><li>双向链表是实现了List和Deque接口。实现了所有List的操作和允许值为Null。</li><li></li><li>所有的操作执行都与双向链表相似。操作索引将遍历整个链表，至于是从头开始遍历还是从尾部</li><li>开始遍历取决于索引的下标距离哪个比较近。</li><li></li><li>需要注意的是这个方法不是同步的方法，需要同步的应用(ConcurrentLinkedDeque高效的队列),如果多个</li><li>线程同时操作LinkedList实例和至少有一个线程修改list的结构,必须在外部加同步操作。</li><li>关于结构性操作可以看前面的HashMap的介绍。这个同步操作通常是压缩在某些对象头上面。(synchronized就是存储在对象头上面)</li><li></li><li>如果对象头不存在这样的对象，这个列表应该使用{@link Collections#synchronizedList Collections.synchronizedList}工具</li><li>来封装，这个操作最好是在创建List之前完成，防止非同步的操作。</li><li>List list = Collections.synchronizedList(new ArrayList(…));</li><li>但是一般不用这个方法，而是用JUC包下的ConcurrentLinkedDeque更加高效,(因为这个底层采用的是CAS操作)</li><li></li><li>快速失败机制，当一个list被多个线程同时修改的时候会抛出异常。但是不能用来保证线程安全。</li><li>所以在多线程环境下，还是要自己加锁或者采用JUC包下面的方法来保证线程安全，</li><li>而不能依靠fail-fast机制抛出异常，这个方法只是用来检测bug。</li></ul><p>LinkedList 数据结构</p><p>image-20210527093412978<br>节点 Node 主要由三部分组成：pre：前驱引用，ele1：节点信息，next：后驱引用。<br>first 和 last 分别指向头结点和尾结点。<br>源码：</p><p>JAVA<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>private static class Node<E> {<br>        E item;<br>        Node<E> next;<br>        Node<E> prev;</p><pre><code>    Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) &#123;        this.item = element;        this.next = next;        this.prev = prev;    &#125;&#125;</code></pre><p>Node 类是 LinkedList 中的私有内部类，LinkedList 中就是通过 Node 来存储集合中的元素。<br>E ：节点的值。<br>Node next：当前节点的后一个节点的引用（可以理解为指向当前节点的后一个节点的指针）。<br>Node prev：当前节点的前一个节点的引用（可以理解为指向当前节点的前一个节点的指针）。</p><p>image-20210527093919777<br>LinkedList 继承了 AbstractSequentialList 抽象类，在遍历 LinkedList 的时候，官方更推荐使用顺序访问，也就是使用迭代器。因为 LinkedList 底层是通过一个链表来实现的，虽然 LinkedList 也提供了 get（int index）方法，但是底层的实现是：每次调用 get（int index）方法的时候，都需要从链表的头部或者尾部进行遍历，每次的遍历时间复杂度是 O (index)，而相对比 ArrayList 的底层实现，每次遍历的时间复杂度都是 O (1)。所以不推荐通过 get（int index）遍历 LinkedList。<br>至于从链表的头部或者尾部进行遍历，官方对遍历进行了优化：通过判断索引 index 更靠近链表的头部还是尾部来选择遍历的方向，因此这里遍历 LinkedList 推荐使用迭代器。<br>实现了 List 接口。即提供 List 接口中所有方法的实现。<br>实现了 Cloneable 接口，支持克隆（浅克隆），底层实现：LinkedList 节点并没有被克隆，只是通过 Object 的 clone（）方法得到的 Object 对象强制转化为了 LinkedList, 然后把它内部的实例域都置空，然后把被拷贝的 LinkedList 节点中的每一个值都拷贝到 clone 中。（后面有源码解析）<br>实现了 Deque 接口，实现了 Deque 所有的可选的操作。<br>实现了 Serializable 接口。表明它支持序列化。和 ArrayList 一样，底层都提供了两个方法：readObject（ObjectInputStream o）、writeObject（ObjectOutputStream o），用于实现序列化，而在底层只序列化节点的个数和节点的值。<br>注：由于后面源码分析过多，所以直接把总结部分放到这里。</p><p>小结<br>LinkedList 底层是一个双链表，是一个直线型的链表结构。</p><p>LinkedList 内部实现了 6 种主要的辅助方法：它们都是 private 修饰的方法或者没有修饰符，表明这里都只是为 LinkedList 的其他方法提供服务，或者同一个包中的类提供服务。在 LinkedList 内部，绝大部分方法的实现都是依靠这 6 种辅助方法，所以只要把这 6 个辅助方法理解了，LinkedList 的基本操作也就掌握了。</p><p>void linkFirst(E e)</p><p>void linkLast(E e)</p><p>linkBefore(E e, Node succ)</p><p>E unlinkFirst(Node f)</p><p>E unlinkLast(Node l)</p><p>E unlink(Node x)</p><p>LinkedList 源码分析<br>方法字段<br>JAVA<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>public class LinkedList<E><br>    extends AbstractSequentialList<E><br>    implements List<E>, Deque<E>, Cloneable, java.io.Serializable<br>{<br>    //元素个数<br>    transient int size = 0;</p><pre><code>/** * 指向第一个节点 *  */transient Node&lt;E&gt; first;/** * 指向最后一个节点 */transient Node&lt;E&gt; last;....&#125;</code></pre><p>size：用来记录 LinkedList 的元素个数。<br>Node first：用来表示 LinkedList 的头节点。<br>Node last：用来表示 LinkedList 的尾节点。<br>构造方法<br>JAVA<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>//空的构造器<br>public LinkedList() {<br> }</p><p>//包含一个数组的构造函数，链表中的顺序按照集合中的元素顺序进行插入<br>public LinkedList(Collection&lt;? extends E&gt; c) {<br>     this();<br>     addAll(c);//这里调用了addAll(),就是插入所有元素<br> }<br>在传入一个集合进行初始化的时候主要调用了 addAll () 方法，那么这个 addAll () 方法是怎么样添加元素的呢？</p><p>addAll(int index, Collection&lt;? extends E&gt; c)<br>JAVA<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>26<br>27<br>28<br>29<br>30<br>31<br>32<br>33<br>34<br>35<br>36<br>37<br>38<br>39<br>40<br>41<br>42<br>43<br>44<br>45<br>46<br>47<br>48<br>49<br>50<br>51<br>52<br>53<br>54<br>55<br>56<br>57<br>58<br>59<br>60<br>61<br>62<br>63<br>64<br>65<br>66<br>67<br>68<br>69<br>70<br>71</p><p>//通过调用addAll(int index, Collection&lt;? extends E&gt; c) 完成集合的添加。<br> public boolean addAll(Collection&lt;? extends E&gt; c) {<br>        return addAll(size, c);<br>    }</p><p> public boolean addAll(int index, Collection&lt;? extends E&gt; c) {<br>        //几乎所有的涉及到在指定位置添加或者删除或修改操作都需要判断传进来的参数是否合法。<br>        checkPositionIndex(index);</p><pre><code>    //先把集合转化为数组，然后为该数组添加一个新的引用（Objext[] a）。        Object[] a = c.toArray();//为什么要将集合转为数组？？？？？    //存储数组的长度    int numNew = a.length;    //如果待添加的集合为空，直接返回，无需进行后面的步骤。后面都是用来把集合中的元素添加到LinkedList中    if (numNew == 0)        return false;    //Node&lt;E&gt; succ：指代待添加节点的位置。Node&lt;E&gt; pred：指代待添加节点的前一个节点。    //下面的代码是依据新添加的元素的位置分为两个分支：    //1.新添加的元素的位置位于LinkedList最后一个元素的后面。    Node&lt;E&gt; pred, succ;    if (index == size) &#123;//插入的位置刚好在最后位置        //则succ为空        succ = null;        //前驱为last所引用的尾结点        pred = last;    &#125; else &#123;        //寻找插入的节点位置        succ = node(index);        //找到插入节点的前驱        pred = succ.prev;    &#125;    //循环插入每个节点    for (Object o : a) &#123;        @SuppressWarnings(&quot;unchecked&quot;) E e = (E) o;//向下转型        Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, null);//生成一个新节点        //前驱为空，表示在第一个位置插入        if (pred == null)            first = newNode;        //否则在index前面插入新节点        else            pred.next = newNode;        pred = newNode;    &#125;    &#123;    //后继为空    if (succ == null)         last = pred;//在末尾插入    &#125; else &#123;        //否则链接最后的节点        pred.next = succ;        succ.prev = pred;    &#125;    size += numNew;//节点个数增加    modCount++;//结构性修改    return true;&#125;</code></pre><p>//集合转数组<br> public Object[] toArray() {<br>        Object[] result = new Object[size];<br>        int i = 0;<br>        for (Node<E> x = first; x != null; x = x.next)<br>            result[i++] = x.item;<br>        return result;<br>    }<br>中间位置插入元素图解如下：</p><p>找到节点</p><p>image-20210527141853019<br>插入新节点</p><p>image-20210527141952529</p><p>改变指针</p><p>image-20210527142031213</p><p>linkFirst(E e)<br>JAVA<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20</p><p>//在头部插入一个新节点<br>   private void linkFirst(E e) {<br>       //因为需要把插入的该元素设置为头节点，所以需要新建一个变量把原来的头节点存储起来。<br>       final Node<E> f = first;<br>       //然后新建一个节点，保存插入节点的值e，由于插入的节点为头结点，因此前驱为null，而后继则为原来的头结点<br>       final Node<E> newNode = new Node&lt;&gt;(null, e, f);<br>       //将头结点引用指向新节点<br>       first = newNode;<br>       //如果原来的头结点为空，则说明没有头结点，头尾节点均为null<br>       if (f == null)<br>           //将新节点置为尾结点<br>           last = newNode;<br>       else<br>           //否则原来的头结点的前引用指向新节点<br>           f.prev = newNode;<br>       //size和modCount自增<br>       size++;<br>       modCount++0;<br>   }<br>图解如下：</p><p>image-20210527162010829</p><p>linkLast(E e)<br>JAVA<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18</p><p>//在尾部插入一个新节点<br>void linkLast(E e) {<br>        //因为需要把插入的该元素设置为尾节点，所以需要新建一个变量把原来的尾节点存储起来。<br>        final Node<E> l = last;<br>        //然后新建一个节点，保存插入节点的值e，由于插入的节点为尾结点，因此前驱为l，而后继则为null<br>        final Node<E> newNode = new Node&lt;&gt;(l, e, null);<br>        //last引用指向新节点<br>        last = newNode;<br>         //如果原来的尾结点为空，则说明没有尾结点，则尾结点为新节点<br>        if (l == null)<br>            first = newNode;<br>        else<br>            //否则原来尾结点的后引用指向新的尾结点<br>            l.next = newNode;<br>        size++;<br>        modCount++;<br>    }<br>过程与头部插入节点类似。</p><p>linkBefore(E e, Node succ)<br>JAVA<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17</p><p>//在某个节点之前插入一个新节点<br>void linkBefore(E e, Node<E> succ) {<br>        // assert succ != null;<br>        //找到该节点的前一个节点，因为要在succ前面插入一个节点<br>        final Node<E> pred = succ.prev;//<br>        //新节点的前一个节点就是原来succ的前一个节点（pred），后一个节点当然就是succ<br>        final Node<E> newNode = new Node&lt;&gt;(pred, e, succ);<br>        succ.prev = newNode;<br>        //如果pred为空，说明要插入的节点位置为第一个节点<br>        if (pred == null)<br>            first = newNode;<br>        else<br>            //否则pred的下一个节点就是新节点<br>            pred.next = newNode;<br>        size++;<br>        modCount++;<br>unlinkFirst(Node f)<br>JAVA<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>26<br>27<br>28</p><p>//删除LinkedList中第一个节点（该节点不为空,并且返回删除的节点的值）<br>private E unlinkFirst(Node<E> f) {<br>        // assert f == first &amp;&amp; f != null;<br>  //<br>  //（因为我们需要设置f节点的下一个节点为头结点，而且需要把f节点的值设置为空）<br>  //<br>  //接着判断一个它的下一个节点是否为空，如果为空的话，则需要把last设置为空。否则<br>  //的话，需要把next的prev设置为空，因为next现在指代头节点。<br>          //定义一个变量element指向待删除节点的值，<br>        final E element = f.item;<br>        //接着定义一个变量next指向待删除节点的下一个节点。<br>        final Node<E> next = f.next;<br>        //接着把f的值和它的next设置为空，把它的下一个节点设置为头节点。<br>        f.item = null;<br>        f.next = null; // help GC 解开与下一个元素的连接，方便GC回收<br>        first = next;<br>        //如果待删除节点的下一个节点为空，说明LinkedList中就一个元素<br>        if (next == null)<br>        //则需要把last设置为空。<br>            last = null;<br>        else<br>            //断开后一个节点与待删除节点的连接<br>            next.prev = null;<br>        size–;<br>        modCount++;<br>        return element;<br>    }<br>unlinkLast(Node l)<br>JAVA<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18</p><p>//删除LinkedList的最后一个节点。（该节点不为空,并且返回删除节点对应的值）<br>//思路和unlinkFirst（）方法差不多。<br>private E unlinkLast(Node<E> l) {<br>        // assert l == last &amp;&amp; l != null;<br>        final E element = l.item;<br>        final Node<E> prev = l.prev;<br>        l.item = null;<br>        l.prev = null; // help GC<br>        last = prev;<br>        if (prev == null)<br>            first = null;<br>        else<br>            prev.next = null;<br>        size–;<br>        modCount++;<br>        return element;<br>    }<br>unlink(Node x)<br>JAVA<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>26<br>27<br>28<br>29<br>30<br>31<br>32<br>33<br>34<br>35<br>36<br>37<br>38<br>39<br>40</p><p>//删除一个节点（该节点不为空）<br>E unlink(Node<E> x) {<br>        // assert x != null;</p><pre><code>     //创建变量用来存储当前被删除节点的值，后面要把该节点返回    final E element = x.item;     //第二个变量用来存储待删除节点的前一个节点    final Node&lt;E&gt; next = x.next;     //第三个变量用来存储待删除节点的后一个节点    final Node&lt;E&gt; prev = x.prev;         //判断prev     //如果待删除节点的前一个节点为空，表明待删除的节点是头结点    if (prev == null) &#123;        //把待删除节点的后一个节点设置为头结点        first = next;    //如果不为空，就需要把待删除的节点的前、后节点链接起来    &#125; else &#123;        //将待删除节点的前后节点进行连接        prev.next = next;        //断开待删除节点与其前一个节点的联系        x.prev = null;    &#125;     //判断next是否为空    //如果为空则表明待删除节点是尾节点，则需要把待删除节点的前一个节点设置为尾节点。    if (next == null) &#123;        last = prev;    //如果不为空,则把前后节点进行连接    &#125; else &#123;        next.prev = prev;        x.next = null;    &#125;    x.item = null;    size--;    modCount++;    return element;&#125;</code></pre><p>图解如下：</p><p>找到待删除节点的信息以及它的前后节点</p><p>image-20210527204905178</p><p>修改前置指针</p><p>image-20210527205037292</p><p>修改后继指针</p><p>image-20210527205107998</p><p>将待删除节点置空，方便 GC</p><p>image-20210527205148729</p><blockquote><p>node(int index)</p></blockquote><pre><code class="bash">//计算指定索引上的节点（返回Node）Node&lt;E&gt; node(int index) &#123;        // assert isElementIndex(index);        //比较index更靠近链表（LinkedList）的头节点还是尾节点。然后进行遍历，获取相应的节点。        if (index &lt; (size &gt;&gt; 1)) &#123;            Node&lt;E&gt; x = first;            for (int i = 0; i &lt; index; i++)                x = x.next;            return x;        &#125; else &#123;            Node&lt;E&gt; x = last;            for (int i = size - 1; i &gt; index; i--)                x = x.prev;            return x;        &#125;    &#125;</code></pre><blockquote><p>removeFirst()</p></blockquote><pre><code class="bash">//提供给用户使用的删除头结点，并返回删除的值。//直接调用了上面的工具方法unlinkFirst（Node f）public E removeFirst() &#123;        final Node&lt;E&gt; f = first;        if (f == null)            throw new NoSuchElementException();        return unlinkFirst(f);    &#125;</code></pre><blockquote><p>removeLast()</p></blockquote><pre><code class="bash">//删除链表中的最后一个节点，并返回被删除节点的值。//和上面一样调用了unlinkLast（Node last）方法。public E removeLast() &#123;        final Node&lt;E&gt; l = last;        if (l == null)            throw new NoSuchElementException();        return unlinkLast(l);    &#125;</code></pre><blockquote><p>addFirst(E e)、addLast(E e)</p></blockquote><pre><code class="bash">//在LinkedList头部添加一个新的元素、尾部添加一个新元素,都是调用了私有方法。public void addFirst(E e) &#123;        linkFirst(e);    &#125;public void addLast(E e) &#123;        linkLast(e);    &#125;</code></pre><blockquote><p>contains(Object o)</p></blockquote><pre><code class="bash">//判断LinkedList是否包含某一个元素,底层通过调用indexof()。//该方法主要用于计算元素在LinkedList中的位置。//思路：先依据obejct是否为空，分为两种情况，然后通过在每种情况下，从头节点开始遍历LinkedList，判断是否有与object相等的元素，如果有，则返回对应的位置index，如果找不到，则返回-1。public boolean contains(Object o) &#123;        return indexOf(o) != -1;    &#125;public int indexOf(Object o) &#123;        int index = 0;        if (o == null) &#123;            for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123;                if (x.item == null)                    return index;                index++;            &#125;        &#125; else &#123;            for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123;                if (o.equals(x.item))                    return index;                index++;            &#125;        &#125;        return -1;    &#125;</code></pre><blockquote><p>size()</p></blockquote><pre><code class="bash">//计算LinkedList的大小,直接返回实例域size。public int size() &#123;        return size;    &#125;</code></pre><blockquote><p>add(E e)</p></blockquote><pre><code class="bash">//添加一个新元素。直接在最后面添加，调用了linkLast（）方法。public boolean add(E e) &#123;        linkLast(e);        return true;    &#125;</code></pre><blockquote><p>remove(Object o)</p></blockquote><pre><code class="bash">//从LinkedList中删除指定元素。（且只删除第一次出现的指定的元素，如果指定的元素在集合中不存在，则返回false，否则返回true）//该方法也是通过object是否为空分为两种情况去，之后与LinkedList中的每一个元素比较，如果找到了，就删掉，返回true即可。如果找不到，则返回false。</code></pre><pre><code class="bash">public boolean remove(Object o) &#123;        if (o == null) &#123;            for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123;                if (x.item == null) &#123;                    unlink(x);                    return true;                &#125;            &#125;        &#125; else &#123;            for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123;                if (o.equals(x.item)) &#123;                    unlink(x);                    return true;                &#125;            &#125;        &#125;        return false;    &#125;clear()</code></pre><pre><code class="bash">//清空LinkedList中的所有元素//该方法也简单，直接遍历整个LinkedList，然后把每个节点都置空,最后要把头节点和尾节点设置为空，size也设置为空，但是modCount仍然自增public void clear() &#123;        // Clearing all of the links between nodes is &quot;unnecessary&quot;, but:        // - helps a generational GC if the discarded nodes inhabit        //   more than one generation        // - is sure to free memory even if there is a reachable Iterator        for (Node&lt;E&gt; x = first; x != null; ) &#123;            Node&lt;E&gt; next = x.next;            x.item = null;            x.next = null;            x.prev = null;            x = next;        &#125;        first = last = null;        size = 0;        modCount++;    &#125;</code></pre><blockquote><p>get(int index)</p></blockquote><pre><code class="bash">//获取对应index的节点的值。//通过node（）方法返回其值。（node（）方法依据索引的值返回其对应的节点。）public E get(int index) &#123;        checkElementIndex(index);        return node(index).item;    &#125;</code></pre><blockquote><p>set(int index, E element)</p></blockquote><pre><code class="bash">//设置对应index的节点的值。//首先检查一下索引是否合法，然后通过node（）方法求出旧值，然后设置新值。最后把旧值返回回去。public E set(int index, E element) &#123;        checkElementIndex(index);        Node&lt;E&gt; x = node(index);        E oldVal = x.item;        x.item = element;        return oldVal;    &#125;</code></pre><blockquote><p>add(int index, E element)</p></blockquote><pre><code class="bash">//在指定的位置上添加新的元素。//在方法中先判断新添加的元素是否是位于LinkedList的最后，然后则直接调用linkLast（）方法添加即可。否则的话，调用linkBefore（）添加即可。public void add(int index, E element) &#123;        checkPositionIndex(index);        if (index == size)            linkLast(element);        else            linkBefore(element, node(index));    &#125;</code></pre><blockquote><p>remove(int index)</p></blockquote><pre><code class="bash">//移除指定位置上的元素public E remove(int index) &#123;        checkElementIndex(index);        return unlink(node(index));    &#125;</code></pre><blockquote><p>isPositionIndex(int index)</p></blockquote><pre><code class="bash">//判断新添加元素的时候，传进来的index是否合法，而且新添加的元素可能在LinkedList最后一个元素的后面，所以这里允许index&lt;=size。private boolean isPositionIndex(int index) &#123;        return index &gt;= 0 &amp;&amp; index &lt;= size;    &#125;</code></pre><blockquote><p>checkElementIndex(int index)</p></blockquote><pre><code class="bash">//判断参数index是否是元素的索引（如果不是则抛出异常）private void checkElementIndex(int index) &#123;        if (!isElementIndex(index))            throw new IndexOutOfBoundsException(outOfBoundsMsg(index));    &#125;</code></pre><blockquote><p>checkPositionIndex(int index)</p></blockquote><pre><code class="bash">//判断新添加元素的时候，传进来的index是否合法，（调用的是isPositionIndex(index)方法）而且新添加的元素可能在LinkedList最后一个元素的后面，所以这里允许index&lt;=size。如果不合法，则抛出异常。private void checkPositionIndex(int index) &#123;        if (!isPositionIndex(index))            throw new IndexOutOfBoundsException(outOfBoundsMsg(index));    &#125;</code></pre><blockquote><p>lastIndexOf(Object o)</p></blockquote><pre><code class="bash">//在LinkedList中查找object在LinkedList中的位置。（从后向前遍历，只返回第一出线的元素的索引，如果没找到，则返回-1）public int lastIndexOf(Object o) &#123;        int index = size;        if (o == null) &#123;            for (Node&lt;E&gt; x = last; x != null; x = x.prev) &#123;                index--;                if (x.item == null)                    return index;            &#125;        &#125; else &#123;            for (Node&lt;E&gt; x = last; x != null; x = x.prev) &#123;                index--;                if (o.equals(x.item))                    return index;            &#125;        &#125;        return -1;    &#125;</code></pre><p>总结<br>LinkedList 是基于双向链表实现的，不论是增删改查方法还是队列和栈的实现，都可通过操作结点实现。<br>LinkedList 无需提前指定容量，因为基于链表操作，集合的容量随着元素的加入自动增加。<br>LinkedList 删除元素后集合占用的内存自动缩小，无需像 ArrayList 一样调用 trimToSize () 方法。<br>LinkedList 的所有方法没有进行同步，因此它也不是线程安全的，应该避免在多线程环境下使用</p>]]></content>
      
      
      <categories>
          
          <category> 集合 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
            <tag> LinkedList </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ArrayList 源码分析</title>
      <link href="/2020/07/15/collection/ArrayList%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"/>
      <url>/2020/07/15/collection/ArrayList%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="LinkedList-源码分析"><a href="#LinkedList-源码分析" class="headerlink" title="LinkedList 源码分析"></a>LinkedList 源码分析</h2><p>ArrayList 集合底层数据结构<br>ArrayList 是由可调整大小的数组实现的，与数组不同的是：数组一旦初始化长度就不可以发生改变，而 ArrayList 长度可变。</p><p>数组特点：</p><p>增删慢：每次删除元素，都需要更改数组长度、拷贝以及移动元素位置。<br>查询快：由于数组在内存中是一块连续空间，因此可以根据地址 + 索引的方式快速获取对应位置上的元素。<br>ArrayList 继承关系<br>JAVA<br>1<br>2<br>public class ArrayList<E> extends AbstractList<E><br>        implements List<E>, RandomAccess, Cloneable, java.io.Serializable<br>Serializable 标记性接口<br>类的序列化由实现 java.io.Serializable 接口的类启用。 不实现此接口的类将不会使任何状态序列化或反序列化。 可序列化类的所有子类型都是可序列化的。 序列化接口没有方法或字段，仅用于标识可串行化的语义。<br>序列化：将对象的数据写入到文件 (写对象)。</p><p>反序列化：将文件中对象的数据读取出来 (读对象)。</p><p>Serializable 源码：</p><p>JAVA<br>1<br>2<br>public interface Serializable {<br>}<br>Cloneable 标记性接口<br>一个类实现 Cloneable 接口来指示 Object.clone () 方法，该方法对于该类的实例进行字段的复制是合法的。在不实现 Cloneable 接口的实例上调用对象的克隆方法会导致异常 CloneNotSupportedException 被抛出。简言：克隆就是依据已经有的数据，创造一份新的完全一样的数据拷贝。</p><p>Cloneable 源码：</p><p>JAVA<br>1<br>2<br>public interface Cloneable {<br>}<br>克隆的前提条件<br>被克隆对象所在的类必须实现 Cloneable 接口</p><p>必须重写 clone 方法</p><p>clone 源码：</p><pre><code class="bash">public Object clone() &#123;        try &#123;            ArrayList&lt;?&gt; v = (ArrayList&lt;?&gt;) super.clone();            v.elementData = Arrays.copyOf(elementData, size);            v.modCount = 0;            return v;        &#125; catch (CloneNotSupportedException e) &#123;            // this shouldn&#39;t happen, since we are Cloneable            throw new InternalError(e);        &#125;    &#125;</code></pre><h2 id="RandomAccess-标记接口"><a href="#RandomAccess-标记接口" class="headerlink" title="RandomAccess 标记接口"></a>RandomAccess 标记接口</h2><p>此标记接口由 List 实现使用，以表明它们支持快速（通常为恒定时间）随机访问。</p><p>此接口的主要目的是允许通用算法更改其行为，以便在应用于随机访问列表或顺序访问列表时提供良好的性能。</p><p>AbstractList 抽象类<br>该类提供了 List 接口的骨架实现，以最小化实现由” 随机存取” 数据存储 (如阵列) 支持的此接口所需的工作量。对于顺序访问数据 (例如链接列表) ，应该使用 AbstractSequentialist 优先于此类。<br>要实现一个不可修改的列表，程序员只需要扩展这个类并提供 get (int) 和 size () 方法的实现。<br>要实现可修改的列表，程序员必须另外覆盖 set (int, E) 方法 (否则将抛出一个 UnsupportedoperationException)。如果列表是可变大小， 则程序员必须另外覆盖 add (int, E) 和 remove (int) 方法。<br>ArrayList 源码分析<br>构造方法<br>Constructor    Constructor 描述<br>ArrayList()    构造一个初始容量为十的空列表。<br>ArrayList(int initialCapacity)    构造具有指定初始容量的空列表。<br>ArrayList(Collection&lt;? extends E&gt; c)    构造一个包含指定集合的元素的列表，按照它们由集合的迭代器返回 的顺序。<br>在源码分析时首先会将涉及的变量、方法等列出来，之后一块进行详细分析！</p><p>无参构造方法</p><pre><code class="bash">public class ArrayList&lt;E&gt; &#123;    //默认空容量的数组,长度为0    private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;    //集合真正存储数据的容器    Object[] elementData;    //集合的大小    private int size;        //空参构造    public ArrayList() &#123;        //赋值        this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;</code></pre><p>有参构造方法一</p><pre><code class="bash">public class ArrayList&lt;E&gt; &#123;    // 默认初始容量    private static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;;    //指定容量的构造方法    public ArrayList(int initialCapacity) &#123;        //判断容量是否大于0        if (initialCapacity &gt; 0) &#123;            //根据构造方法的参数创建指定长度的数据            this.elementData = new Object[initialCapacity];        &#125; else if (initialCapacity == 0) &#123;            //等于0则将空数组的地址赋值给elementData            this.elementData = EMPTY_ELEMENTDATA;        &#125; else &#123;            //以上两个条件都不满足报错            throw new IllegalArgumentException(&quot;Illegal Capacity: &quot;+                                               initialCapacity);        &#125;    &#125;&#125;</code></pre><p>有参构造方法二</p><pre><code class="bash">public class ArrayList&lt;E&gt; &#123;    //长度为0的空数组    private static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;;    //集合存元素的数组    Object[] elementData;    //集合的长度    private int size;    public ArrayList(Collection&lt;? extends E&gt; c) &#123;        // 将集合构造中的集合对象转成数组,且将数组的地址赋值给elementData        elementData = c.toArray();        // 将elementData的长度赋值给集合长度size,且判断是否不等于 0        if ((size = elementData.length) != 0) &#123;            // 判断elementData 和 Object[] 是否为不一样的类型            if (elementData.getClass() != Object[].class)                //如果不一样,使用Arrays的copyOf方法进行元素的拷贝                elementData = Arrays.copyOf(elementData, size, Object[].class);        &#125; else &#123;            // 就把空数组的地址赋值给集合存元素的数组            this.elementData = EMPTY_ELEMENTDATA;        &#125;    &#125;    //将集合转数组的方法    public Object[] toArray() &#123;        //调用数组工具类的方法        return Arrays.copyOf(elementData, size);    &#125;&#125;//Arrays类class Arrays &#123;    public static &lt;T&gt; T[] copyOf(T[] original, int newLength) &#123;        //再次调用方法进行拷贝        return (T[]) copyOf(original, newLength, original.getClass());    &#125;    public static &lt;T,U&gt; T[] copyOf(U[] original, int newLength, Class&lt;? extends T[]&gt; newType) &#123;        @SuppressWarnings(&quot;unchecked&quot;)        //不管三元运算符的结果如何,都会创建一个新的数组        //新数组的长度一定是和集合的size一样        T[] copy = ((Object)newType == (Object)Object[].class)            ? (T[]) new Object[newLength]            : (T[]) Array.newInstance(newType.getComponentType(), newLength);        //数组的拷贝        System.arraycopy(original, 0, copy, 0,                         Math.min(original.length, newLength));       //返回拷贝元素成功后的数组        return copy;    &#125;&#125;</code></pre><p>添加方法<br>方法名    描述<br>public boolean add(E e)    将指定的元素追加到此列表的末尾。<br>public void add(int index, E element)    在此列表中的指定位置插入指定的元素。<br>public boolean addAll(Collection&lt;? extends E&gt; c)    按指定集合的 Iterator 返回的顺序将指定集合中的所有元素 追加到此列表的末尾。<br>public boolean addAll(int index, Collection&lt;? extends E&gt; c)    将指定集合中的所有元素插入到此列表中，从指定的位置 开始。<br>public boolean add (E e) 添加单个元素：</p><p>JAVA<br>1<br>2<br>3<br>4<br>5<br>6<br>public class ArrayTest {<br>    public static void main(String[] args) {<br>        ArrayList<String> list = new ArrayList&lt;&gt;();<br>        list.add(“程序员”);<br>    }<br>}<br>源码：</p><pre><code class="bash">public class ArrayList&lt;E&gt; &#123;    //长度为0的空数组    private static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;;    //默认容量为空的数组（无参构造调用）    private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;;    //集合真实存元素的数组    Object[] elementData;    //集合的长度    private int size;    //默认的容量    private static final int DEFAULT_CAPACITY = 10;    //将添加的数据传入给 e    public boolean add(E e) &#123;        //调用方法对内部容量进行校验        ensureCapacityInternal(size + 1); //minCapacity=1        elementData[size++] = e;        return true;    &#125;    private void ensureCapacityInternal(int minCapacity) &#123;        //判断集合存数据的数组是否等于空容量的数组（无参构造肯定两者相等）        if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123;            //通过最小容量和默认容量 求出较大值 (用于第一次扩容)            minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity);//minCapacity=10        &#125;        //将if中计算出来的容量传递给下一个方法,继续校验        ensureExplicitCapacity(minCapacity);    &#125;    private void ensureExplicitCapacity(int minCapacity) &#123;        //实际修改集合次数++ (在扩容的过程中没用,主要是用于迭代器中)        modCount++;        //判断最小容量 - 数组长度是否大于 0        if (minCapacity - elementData.length &gt; 0)            //将第一次计算出来的容量传递给 核心扩容方法(grow)            grow(minCapacity);    &#125;    private void grow(int minCapacity) &#123;        //记录数组的实际长度,此时由于木有存储元素,长度为0        int oldCapacity = elementData.length;        // &gt;&gt; : 右移,右移几位就相当于除以2的几次幂        // &lt;&lt; : 左移,左移几位就相当于乘以2的几次幂        //扩容的核心算法: 原容量的1.5倍        int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1);        //判断新容量 - 最小容量 是否小于 0, 如果是第一次调用add方法必然小于0        if (newCapacity - minCapacity &lt; 0)            //还是将最小容量赋值给新容量            newCapacity = minCapacity; //newCapacity=10        //判断新容量-最大数组大小 是否&gt;0,如果条件满足就计算出一个超大容量        if (newCapacity - MAX_ARRAY_SIZE &gt; 0)            newCapacity = hugeCapacity(minCapacity);        // minCapacity is usually close to size, so this is a win:        // 调用数组工具类方法,创建一个新数组,将新数组的地址赋值给elementData        elementData = Arrays.copyOf(elementData, newCapacity);    &#125; &#125;</code></pre><p>public void add (int index, E element) 在指定索引处添加元素 ：</p><pre><code class="bash">public class ArrayTest &#123;    public static void main(String[] args) &#123;        ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;();        list.add(&quot;黑马程序员&quot;);        list.add(&quot;传智播客&quot;);        list.add(&quot;传智大学&quot;);        list.add(1,&quot;长沙校区&quot;);        System.out.println(list);    &#125;&#125;</code></pre><p>源码：</p><pre><code class="bash">public class ArrayList&lt;E&gt; &#123;    //长度为0的空数组    private static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;;    //默认容量为空的数组    private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;;    //集合存元素的数组    Object[] elementData;    //集合的长度    private int size;    //默认的容量    private static final int DEFAULT_CAPACITY = 10;    public void add(int index, E element) &#123;            //添加范围检查            rangeCheckForAdd(index);        //调用方法检验是否要扩容,且让增量++        ensureCapacityInternal(size + 1);  // Increments modCount!!        System.arraycopy(elementData, index, elementData, index + 1,                         size - index);        elementData[index] = element;        size++;    &#125;    private void rangeCheckForAdd(int index) &#123;        //超出指定范围就报错        if (index &gt; size || index &lt; 0)            throw new IndexOutOfBoundsException(outOfBoundsMsg(index));    &#125;       private void ensureCapacityInternal(int minCapacity) &#123;        if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123;            minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity);        &#125;                ensureExplicitCapacity(minCapacity);    &#125;    private void ensureExplicitCapacity(int minCapacity) &#123;       //增量++ (也就是实际修改集合的次数)       modCount++;        //只有容量不够的情况下才会调用 核心扩容的grow方法        //如果再调用 add(index,element) 方法之前已经扩容,那么源码跟踪到此结束       if (minCapacity - elementData.length &gt; 0)           grow(minCapacity);     &#125; &#125;</code></pre><p>image-20210525095343406<br>public boolean addAll (Collection&lt;? extends E&gt; c) 将集合的所有元素一次性添加到集合：</p><pre><code class="bash">public class ArrayTest &#123;    public static void main(String[] args) &#123;        ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;();        list.add(&quot;黑马程序员&quot;);        list.add(&quot;传智播客&quot;);        list.add(&quot;传智大学&quot;);        ArrayList&lt;String&gt; list1 = new ArrayList&lt;&gt;();        list1.addAll(list);    &#125;&#125;</code></pre><p>源码：</p><pre><code class="bash">public class ArrayList&lt;E&gt; &#123;    //长度为0的空数组    private static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;;    //默认容量为空的数组    private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;;    //集合存元素的数组    Object[] elementData;    //集合的长度    private int size;    //默认的容量    private static final int DEFAULT_CAPACITY = 10;    public boolean addAll(Collection&lt;? extends E&gt; c) &#123;        //把有数据的集合转成数组        Object[] a = c.toArray();        //有数据集合长度赋值给numNew        int numNew = a.length;        //调用方法检验是否要扩容,且让增量++        ensureCapacityInternal(size + numNew);  // Increments modCount        //调用方法将a数组的元素拷贝到elementData数组中        System.arraycopy(a, 0, elementData, size, numNew);        //集合的长度+=a数组的长度        size += numNew;        //只要a数组的长度不等于0,即说明添加成功        return numNew != 0;    &#125; &#125;</code></pre><p> //结论:底层使用了System.arraycopy方法进行了拷贝<br>public boolean addAll (int index, Collection&lt;? extends E&gt; c) 在指定的索引位置添加集合：</p><pre><code class="bash">public class ArrayTest &#123;    public static void main(String[] args) &#123;        ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;();        list.add(&quot;黑马程序员&quot;);        list.add(&quot;传智播客&quot;);        list.add(&quot;传智大学&quot;);        ArrayList&lt;String&gt; list1 = new ArrayList&lt;&gt;();        list.add(&quot;酷丁鱼&quot;);        list.add(&quot;博学谷&quot;)        list1.addAll(l1,ist);    &#125;&#125;</code></pre><p>源码：</p><pre><code class="bash">public class ArrayList&lt;E&gt; &#123;    //长度为0的空数组    private static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;;    //默认容量为空的数组    private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;;    //集合存元素的数组    Object[] elementData;    //集合的长度    private int size;    //默认的容量    private static final int DEFAULT_CAPACITY = 10;     public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123;        //校验索引        rangeCheckForAdd(index);        //将数据源转成数组        Object[] a = c.toArray();        //记录数据源的长度 3        int numNew = a.length;        //目的就是为了给集合存储数据的数组进行扩容        ensureCapacityInternal(size + numNew);        //numMoved: 要移动元素的个数 --&gt; 1个        //numMoved: 集合list1的长度-调用addAll的第一个参数 (索引1)        int numMoved = size - index;        //判断需要移动的个数是否大于0        if (numMoved &gt; 0)            //先使用System中的方法arraycopy将需要移动的数据进行移动            System.arraycopy(elementData, index, elementData, index + numNew, numMoved);        //将数据源(list)中的所有数据添加到list1中（中间空的位置中）        System.arraycopy(a, 0, elementData, index, numNew);        size += numNew;        return numNew != 0;    &#125;    private void rangeCheckForAdd(int index) &#123;        if (index &gt; size || index &lt; 0)            throw new IndexOutOfBoundsException(outOfBoundsMsg(index));    &#125; &#125;public final class System &#123;      /*参数:            src - 源数组。            srcPos - 源数组中的起始位置。            dest - 目标数组。            destPos - 目的地数据中的起始位置。            length - 要复制的数组元素的数量。 */    public static void arraycopy(Object src,int srcPos,Object dest,int destPos,int length)&#125;</code></pre><blockquote><p>如何计算元素移动的位置 &amp; 数量：</p></blockquote><pre><code class="bash">public class ArrayCopyMethodTest &#123;    public static void main(String[] args) &#123;        String[] a = &#123;&quot;黑马程序员&quot;,&quot;传智播客&quot;,&quot;传智大学&quot;&#125;;        String[] arr = &#123;&quot;酷丁鱼&quot;,&quot;博学谷&quot;,null,null,null,null,null,null,null,null&#125;;          //获取数据源的长度 3        int numNew = a.length;                //numMoved = 集合真实长度 - 要存的索引位置        //要移动元素的个数为:1        int numMoved = 2 - 1;                //判断是否需要移动元素        if (numMoved &gt; 0)            //src - 源数组。            //srcPos - 源数组中的起始位置。            //dest - 目标数组。            //destPos - 目的地数据中的起始位置。            //length - 要复制的数组元素的数量            System.arraycopy(arr, 1, arr, 4,                    numMoved);        System.out.println(Arrays.toString(arr));    &#125;&#125;</code></pre><p>输出：</p><pre><code class="bash">[酷丁鱼, 博学谷, null, null, 博学谷, null, null, null, null, null]</code></pre><p>删除方法<br>public E remove (int index) 根据索引删除元素：</p><pre><code class="bash">public class Test01 &#123;    public static void main(String[] args) &#123;        ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;();        list.add(&quot;山东大李逵&quot;);        list.add(&quot;天魁星宋江&quot;);        list.add(&quot;天罡星卢俊义&quot;);        list.add(&quot;西门大人&quot;);     //根据索引删除元素     String value = list.remove(3);     System.out.println(&quot;删除的元素为: &quot;+value);     System.out.println(&quot;集合的元素: &quot;+list);  &#125;&#125;</code></pre><p>输出：</p><pre><code class="bash">删除的元素为: 西门大人集合的元素: [山东大李逵, 天魁星宋江, 天罡星卢俊义]</code></pre><p>源码：</p><pre><code class="bash">public class ArrayList&lt;E&gt; &#123;    public E remove(int index) &#123;        //范围校验        rangeCheck(index);        //增量++        modCount++;        //将index对应的元素赋值给 oldValue        E oldValue = elementData(index);        //计算集合需要移动元素个数        int numMoved = size - index - 1;        //如果需要移动元素个数大于0,就使用arrayCopy方法进行拷贝        //注意:数据源和数据目的都ntData        if (numMoved &gt; 0)            System.arraycopy(elementData, index+1, elementData, index,            numMoved);        //将源集合最后一个元素置为null,尽早让垃圾回收机制对其进行回收        elementData[--size] = null;        //返回被删除的元素        return oldValue;    &#125;&#125;</code></pre><blockquote><p>public boolean remove (Object o) 根据元素删除元素：</p></blockquote><pre><code class="bash">public class Test01 &#123;    public static void main(String[] args) &#123;    ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;();    list.add(&quot;山东大李逵&quot;);    list.add(&quot;天魁星宋江&quot;);    list.add(&quot;西门大人&quot;);    list.add(&quot;天罡星卢俊义&quot;);    //根据索引删除元素效果    boolean flag = list.remove(&quot;西门大人&quot;);    System.out.println(&quot;是否删除成功: &quot;+flag);    System.out.println(&quot;集合的元素: &quot;+list);    &#125;&#125;</code></pre><p>输出：</p><pre><code class="bash">是否删除成功: true集合的元素: [山东大李逵, 天魁星宋江, 天罡星卢俊义]</code></pre><p>源码：</p><pre><code class="bash">public class ArrayList&lt;E&gt; &#123;    public boolean remove(Object o) &#123;        //判断要删除的元素是否为null        if (o == null) &#123;            //遍历集合            for (int index = 0; index &lt; size; index++)                //判断集合的元素是否为null                if (elementData[index] == null) &#123;                    //如果相等,调用fastRemove方法快速删除                    fastRemove(index);                    return true;                &#125;        &#125; else &#123;            //遍历集合            for (int index = 0; index &lt; size; index++)                //用o对象的equals方法和集合每一个元素进行比较                if (o.equals(elementData[index])) &#123;                    //如果相等,调用fastRemove方法快速删除                    fastRemove(index);                    return true;                &#125;            &#125;         //如果集合没有o该元素,那么就会返回false        return false;    &#125;     private void fastRemove(int index) &#123;3.5 修改方法        //增量++        modCount++;        //计算集合需要移动元素的个数        int numMoved = size - index - 1;                    //如果需要移动的个数大于0,调用arrayCopy方法进行拷贝        if (numMoved &gt; 0)            System.arraycopy(elementData, index+1, elementData, index,numMoved);        //将集合最后一个元素置为null,尽早被释放                    elementData[--size] = null;    &#125;&#125;</code></pre><p>修改方法<br>public E set (int index, E element) 根据索引修改集合元素源码：</p><pre><code class="bash">public class ArrayList&lt;E&gt; &#123;    public E set(int index, E element) &#123;        //校验索引        rangeCheck(index);        //根据索引取出元素 --&gt; 被替换的元素        E oldValue = elementData(index);        //把element存入到elementData数组中        elementData[index] = element;        //返回被替换的元素        return oldValue;    &#125;    private void rangeCheck(int index) &#123;        if (index &gt;= size)            throw new IndexOutOfBoundsException(outOfBoundsMsg(index));    &#125; &#125;</code></pre><p>获取方法<br>public E get (int index) 根据索引获取元素源码：</p><pre><code class="bash">public class ArrayList&lt;E&gt; &#123;    public E get(int index) &#123;        //校验索引        rangeCheck(index);        //根据索引获取数组(集合)中的元素        return elementData(index);    &#125;    private void rangeCheck(int index) &#123;        if (index &gt;= size)            throw new IndexOutOfBoundsException(outOfBoundsMsg(index));    &#125; &#125;</code></pre><p>转换方法<br>ArrayList 中的 toString 方法继承于它的爷爷类 AbstractCollection，继承关系如下：</p><p>image-20210525144352412</p><p>public String toString () 把集合所有数据转换成字符串源码：</p><pre><code class="bash">public class ArrayList&lt;E&gt; &#123;    //长度为0的空数组    private static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;;    //默认容量为空的数组    private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;;    //集合存元素的数组    Object[] elementData;    //集合的长度    private int size;    //默认的容量    private static final int DEFAULT_CAPACITY = 10; &#125; //ArrayList集合的亲爷爷类 public abstract class AbstractCollection&lt;E&gt; &#123;    public String toString() &#123;        //获取迭代器        Iterator&lt;E&gt; it = iterator();        //判断迭代器是否有元素        if (! it.hasNext())            return &quot;[]&quot;;        //创建StringBuilder        StringBuilder sb = new StringBuilder();        //先追加了&#39;[&#39;        sb.append(&#39;[&#39;);        //无限循环        for (;;) &#123;            //调用迭代器的next方法取出元素,且将光标向下移动            E e = it.next();            //三元判断            sb.append(e == this ? &quot;(this Collection)&quot; : e);//拼接元素            if (! it.hasNext())                //没有元素,在缓冲区的最后追加&#39;]&#39;,且把整个缓冲区的数据转成字符串                //然后再结束该方法                return sb.append(&#39;]&#39;).toString();            //有元素,就直接追加            sb.append(&#39;,&#39;).append(&#39; &#39;);        &#125;    &#125; &#125;</code></pre><p>迭代器<br>public Iterator iterator () 普通迭代器源码：</p><pre><code class="bash">public class ArrayList&lt;E&gt; &#123;    //长度为0的空数组    private static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;;    //默认容量为空的数组    private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;;    //集合存元素的数组    Object[] elementData;    //集合的长度    private int size;    //默认的容量    private static final int DEFAULT_CAPACITY = 10;    //获取迭代器的方法    public Iterator&lt;E&gt; iterator() &#123;        //创建了一个对象        return new Itr();    &#125;    //ArrayList集合的内部类 --&gt; 迭代器的源码    private class Itr implements Iterator&lt;E&gt; &#123;        int cursor;       // 光标,默认值就是0,用来指向元素的位置        int lastRet = -1; // 记录-1        // 将集合实际修改次数赋值给预期修改次数，用来判断并发安全性        int expectedModCount = modCount;        //判断集合是否有元素        public boolean hasNext() &#123;            //即光标不等于size时，证明集合还有元素没有遍历完，而光标等于size时，说明元素遍历完毕。            return cursor != size;        &#125;        //遍历元素        public E next() &#123;            checkForComodification();            //光标（0）赋值给i            int i = cursor; //i=0            //判断,如果大于集合的size就说明没有元素了            if (i &gt;= size)                throw new NoSuchElementException();            //把集合存储数据数组的地址赋值给该方法的局部变量            Object[] elementData = ArrayList.this.elementData;            //进行判断,如果条件满足就会产生并发修改异常            if (i &gt;= elementData.length)                throw new ConcurrentModificationException();            //光标自增            cursor = i + 1;            //从数组中取出元素且返回            return (E) elementData[lastRet = i];        &#125;        //校验预期修改集合次数是否和实际修改集合次数一样        final void checkForComodification() &#123;            if (modCount != expectedModCount)                throw new ConcurrentModificationException();        &#125;    &#125; &#125;</code></pre><p>案例：已知集合：List list = new ArrayList (); 里面有三个元素：”hello”、”Java”、”PHP”，使用迭代器遍历集合看有没有”PHP” 这个元素，如果有，就使用集合对象删除该元素：</p><pre><code class="bash">public class Test01 &#123;    public static void main(String[] args) &#123;        //创建集合对象        List&lt;String&gt; list = new ArrayList&lt;String&gt;();        //添加元素        list.add(&quot;hello&quot;);        list.add(&quot;Java&quot;);        list.add(&quot;PHP&quot;);        //获取迭代器        Iterator&lt;String&gt; it = list.iterator();        //遍历集合        while (it.hasNext()) &#123;            String s = it.next();            if(s.equals(&quot;PHP&quot;)) &#123;                list.remove(&quot;PHP&quot;);            &#125;        &#125;    &#125;&#125;</code></pre><p>控制台结果：并发修改异常：</p><pre><code class="bash">Exception in thread &quot;main&quot; java.util.ConcurrentModificationException atjava.util.ArrayList$Itr.checkForComodification(ArrayList.java:901) atjava.util.ArrayList$Itr.next(ArrayList.java:851) at cn.heu.method.Test01.main(Test01.java:24)</code></pre><p>源码：</p><pre><code class="bash">public class ArrayList&lt;E&gt; &#123;    public Iterator&lt;E&gt; iterator() &#123;        return new Itr();    &#125;     //ArrayList内部类    //一定要注意观察 Itr 类中的几个成员变量    private class Itr implements Iterator&lt;E&gt; &#123;        int cursor; // 下一个要返回元素的索引        int lastRet = -1; // 最后一个返回元素的索引        //将实际修改集合次数 赋值 给预期修改次数        //在迭代的过程中,只要实际修改次数和预期修改次数不一致就会产生并发修改异常        //由于expectedModCount是Itr的成员变量,那么只会被赋值一次!!!        //同时由于集合调用了三次add方法,那么实际修改集合次数就是 3,因此    expectedModCount的值也是 3        int expectedModCount = modCount;        //判断集合元素为后面是否还有元素        public boolean hasNext() &#123;            return cursor != size;        &#125;                        //获取元素的方法        public E next() &#123;            //每次获取元素,会先调用该方法校验 预期修改次数是否 == 实际修改次数            checkForComodification();            //把下一个元素的索引赋值给i            int i = cursor;            //判断是否有元素            if (i &gt;= size)                throw new NoSuchElementException();            //将集合底层存储数据的数组赋值给迭代器的局部变量 elementData            Object[] elementData = ArrayList.this.elementData;            //再次判断,如果下一个元素的索引大于集合底层存储元素的长度 并发修改异常            if (i &gt;= elementData.length)                throw new ConcurrentModificationException();            //每次成功获取到元素,下一个元素的索引都是当前索引+1            cursor = i + 1;            //返回元素            return (E) elementData[lastRet = i];        &#125;         final void checkForComodification() &#123;            //如果预期修改次数 和 实际修改次数不相等 就产生并发修改异常            if (modCount != expectedModCount)                throw new ConcurrentModificationException();        &#125;    &#125;            //集合的remove方法    public boolean remove(Object o) &#123;        if (o == null) &#123;            for (int index = 0; index &lt; size; index++)                if (elementData[index] == null) &#123;                    fastRemove(index);                    return true;                &#125;                &#125; else &#123;                    for (int index = 0; index &lt; size; index++)                        if (o.equals(elementData[index])) &#123;                            fastRemove(index);                            return true;                        &#125;                &#125;                 return false;            &#125;                 //快速删除方法    private void fastRemove(int index) &#123;        //最最最关键的一个操作,集合实际修改次数++,那么这个时候由原来的3变成4        //but迭代器的预期修改次数还是3!!!        modCount++;        int numMoved = size - index - 1;        if (numMoved &gt; 0)            System.arraycopy(elementData, index+1, elementData, index, numMoved);        //还有一个很关键的操作,集合的长度也发生了改变        elementData[--size] = null;    &#125;&#125;</code></pre><p>案例二：已知集合：List list = new ArrayList (); 里面有三个元素：”hello”、”PHP”、”JavaSE”，使用迭代器遍历集合看有没有”PHP” 这个元素，如果有，就使用集合对象删除该元素：</p><pre><code class="bash">public class Test01 &#123;    public static void main(String[] args) &#123;        //创建集合对象        List&lt;String&gt; list = new ArrayList&lt;String&gt;();        //添加元素        list.add(&quot;hello&quot;);        list.add(&quot;PHP&quot;);        list.add(&quot;Java&quot;);        //获取迭代器        Iterator&lt;String&gt; it = list.iterator();        //遍历集合        while (it.hasNext()) &#123;            String s = it.next();            if(s.equals(&quot;PHP&quot;)) &#123;                list.remove(&quot;PHP&quot;);            &#125;        &#125;    &#125;&#125;</code></pre><p>输出：</p><pre><code class="bash">[hello,Java]</code></pre><p>问题：使用迭代器遍历集合的时候，集合自身修改了长度，但是却没有产生并发修改异常！为什么？</p><p>image-20210526092755956</p><p>default void remove () 迭代器中的 remove 方法，删除集合中的元素：</p><pre><code class="bash">public class ArrayList&lt;E&gt; &#123;    public Iterator&lt;E&gt; iterator() &#123;        return new Itr();    &#125;     //ArrayList内部类    //一定要注意观察 Itr 类中的几个成员变量    private class Itr implements Iterator&lt;E&gt; &#123;        int cursor; // 下一个要返回元素的索引        int lastRet = -1; // 最后一个返回元素的索引        //将实际修改集合次数 赋值 给预期修改次数        //在迭代的过程中,只要实际修改次数和预期修改次数不一致就会产生并发修改异常        //由于expectedModCount是Itr的成员变量,那么只会被赋值一次!!!        //同时由于集合调用了三次add方法,那么实际修改集合次数就是 3,因此    expectedModCount的值也是 3        int expectedModCount = modCount;        //判断集合元素为后面是否还有元素        public boolean hasNext() &#123;            return cursor != size;        &#125;                        //迭代器删除元素方法        public void remove() &#123;            //判断最后返回元素的索引是否小于0,满足条件就产生 非法状态异常            if (lastRet &lt; 0)                throw new IllegalStateException();            //校验是否会产生并发修改异常,第一次调用不会,因为与其修改次数和实际修改次数一致            checkForComodification();            try &#123;                //真正删除集合元素的方法,调用方法为ArrayList的方法remove,且将0作为参数进行传递                ArrayList.this.remove(lastRet);                //将lastRet赋值给cursor                cursor = lastRet;                //再次等于-1                lastRet = -1;                //再次将集合实际修改次数赋值给预期修改次数,那么这个时候不管集合自身是否删除成功                //那么实际修改次数和预期修改次数又一致了,所以并不会产生并发修改异常                expectedModCount = modCount;            &#125; catch (IndexOutOfBoundsException ex) &#123;                    throw new ConcurrentModificationException();            &#125;        &#125;                final void checkForComodification() &#123;            //如果预期修改次数 和 实际修改次数不相等 就产生并发修改异常            if (modCount != expectedModCount)                throw new ConcurrentModificationException();        &#125;    &#125;</code></pre><p>结论：</p><p>迭代器 remove 方法底层调用的还是集合自身的 remove 方法删除元素；<br>之所以不会产生并发修改异常，其原因是因为在迭代器的 remove 方法中会再次将集合实际修改次数赋值给预期修改次数 。<br>清空方法<br>public void clear () 清空集合所有数据源码：</p><pre><code class="bash">public class ArrayList&lt;E&gt; &#123;    public void clear() &#123;        //实际修改集合次数++        modCount++;        //遍历集合,将集合每一个索引对应位置上的元素都置为null,尽早让其释放        for (int i = 0; i &lt; size; i++)            elementData[i] = null;        //集合长度更改为0        size = 0;    &#125;&#125;</code></pre><p>包含方法<br>public boolean contains (Object o) 判断集合是否包含指定元素源码：</p><pre><code class="bash">public class ArrayList&lt;E&gt; &#123;    //源码contains方法    public boolean contains(Object o) &#123;        //调用indexOf方法进行查找        return indexOf(o) &gt;= 0;    &#125;        public int indexOf(Object o) &#123;        //如果元素是null,也进行遍历操作        //因为集合中有可能够会存储null        if (o == null) &#123;            for (int i = 0; i &lt; size; i++)                if (elementData[i]==null)                    return i;        &#125; else &#123;            for (int i = 0; i &lt; size; i++)                if (o.equals(elementData[i]))                    return i;        &#125;                 //如果没有走if,也没有走else,那么就说明o该元素在集合中不存在        return -1;    &#125;&#125;</code></pre><p>判断集合是否为空<br>源码分析：</p><pre><code class="bash">public class ArrayList&lt;E&gt; &#123;    public boolean isEmpty() &#123;        return size == 0;    &#125;&#125;</code></pre><p>面试题<br>ArrayList 是如何扩容的？<br>见上面的构造方法，简单说就是：第一次扩容 10，以后每次都是原容量的 1.5 倍。</p><p>ArrayList 频繁扩容导致添加性能急剧下降，如何处理？<br>解决方法：直接指定一个大容量的集合。但这种优化方式只针对特定的场景，如果添加的元素是少量的、未知的，不推荐使用 。</p><p>ArrayList 插入或删除元素一定比 LinkedList 慢么？<br>根据索引删除 ：ArrayList 和 LinkedList 对比 ：</p><pre><code class="bash">public class Test02 &#123;    public static void main(String[] args) &#123;        //创建ArrayList集合对象        ArrayList&lt;String&gt; arrayList = new ArrayList&lt;String&gt;();        //添加500W个元素        for (int i = 0; i &lt; 5000000; i++) &#123;            arrayList.add(i+&quot;小黑&quot;);        &#125;        //获取开始时间        long startTime = System.currentTimeMillis();        //根据索引删除ArrayList集合元素        //删除索引5000对应的元素        String value = arrayList.remove(50000);        System.out.println(value);        //获取结束时间        long endTime = System.currentTimeMillis();        System.out.println(&quot;ArrayList集合删除元素的时间: &quot;+(endTime-startTime));        //创建LinkedList集合对象        LinkedList&lt;String&gt; linkedList = new LinkedList&lt;String&gt;();        //添加500W个元素        for (int i = 0; i &lt; 5000000; i++) &#123;            linkedList.add(i+&quot;小黑&quot;);        &#125;        //获取开始时间        startTime = System.currentTimeMillis();        //根据索引删除LinkedList集合元素        //删除索引5000对应的元素        value = arrayList.remove(50000);        System.out.println(value);        endTime = System.currentTimeMillis();        System.out.println(&quot;LinkedList集合删除元素的时间: &quot;+(endTime-startTime));    &#125;&#125;</code></pre><p>输出：</p><pre><code class="bash">50000小黑ArrayList集合删除元素的时间: 1050001小黑LinkedList集合删除元素的时间: 44</code></pre><p>源码分析：</p><p>ArrayList 根据索引删除元素源码：</p><pre><code class="bash">public class ArrayList&lt;E&gt; &#123;    public E remove(int index) &#123;        //范围校验        rangeCheck(index);        //增量++        modCount++;        //将index对应的元素赋值给 oldValue        E oldValue = elementData(index);        //计算集合需要移动元素个数        int numMoved = size - index - 1;        //如果需要移动元素个数大于0,就使用arrayCopy方法进行拷贝        //注意:数据源和数据目的都ntData        if (numMoved &gt; 0)            System.arraycopy(elementData, index+1, elementData, index,            numMoved);        //将源集合最后一个元素置为null,尽早让垃圾回收机制对其进行回收        elementData[--size] = null;        //返回被删除的元素        return oldValue;    &#125;&#125;</code></pre><blockquote><p>LinkedList 根据索引删除元素源码：</p></blockquote><pre><code class="bash">public class LinkedList&lt;E&gt; &#123;    //LinkedList集合删除的方法    public E remove(int index) &#123;        //调用方法校验元素的索引        checkElementIndex(index);        //先调用node(index)方法,找到需要删除的索引        //再调用unlink方法解开链条        return unlink(node(index));    &#125;    //校验索引是否在合法范围之内,不在就报错    private void checkElementIndex(int index) &#123;        if (!isElementIndex(index))            throw new IndexOutOfBoundsException(outOfBoundsMsg(index));    &#125;    //校验    private boolean isElementIndex(int index) &#123;        return index &gt;= 0 &amp;&amp; index &lt; size;    &#125;    //获取要删除的元素    Node&lt;E&gt; node(int index) &#123;        //不管索引是多少,在源码底层都会对整个链表上的元素进行折半的动作        //如果要删除元素的索引小于集合长度的一半,那么就从头节点一个个的往后找        //如果要删除元素的索引大于集合长度的一半,那么就从尾节点一个个的往后找        //(注:这个查找的效率相对于ArrayList集合来说较低)        if (index &lt; (size &gt;&gt; 1)) &#123;            Node&lt;E&gt; x = first;            //从头节点开始往后找            for (int i = 0; i &lt; index; i++)                //获取下一个节点                x = x.next;            //返回找到的节点            return x;        &#125; else &#123;            Node&lt;E&gt; x = last;            //从最后一个位置往前找            for (int i = size - 1; i &gt; index; i--)                //获取前一个节点                x = x.prev;            //返回找到的节点            return x;        &#125;    &#125;    //解开链表,让前后节点相互记录地址    E unlink(Node&lt;E&gt; x) &#123;        //获取要删除的元素        final E element = x.item;        //获取被删除节点下一个节点的地址        final Node&lt;E&gt; next = x.next;        //获取被删除节点下一个节点的地址        final Node&lt;E&gt; prev = x.prev;        //如果被删除节点的上一个节点为null,就让被删除节点的下一个节点成为首节点        if (prev == null) &#123;            first = next;        &#125; else &#123;            //否则,被删除元素上一个节点的 下一个节点 变成 被删除元素的下一个节点            prev.next = next;            //被删除元素的上一个节点置为null,即断开删除元素与上一个元素的链条            x.prev = null;        &#125;        //如果被删除元素的下一个节点为null,最后一个节点就等于被删除元素的上一个节点        if (next == null) &#123;            last = prev;        &#125; else &#123;            //否则,被删除节点的下一个节点 等于被删除节点的前一个节点            next.prev = prev;            //被删除元素的下一个节点置为null,即断开删除元素与后面元素的链条            x.next = null;        &#125;        //被删除元素的内容置为null        x.item = null;        //集合长度--        size--;        //实际修改集合的次数自增        modCount++;        //返回被删除的元素        return element;    &#125;&#125;</code></pre><p>结论：</p><p>数组删除元素确实要比链表慢，慢在需要创建新数组，还有比较麻烦的数据拷贝，但是在 ArrayList 底层不是每次操作元素都需要扩容，因此在这个方面相对于链表来说数组的性能更好。</p><p>LinkedList 删除元素之所以效率并不高，其原理在于底层先需要对整个集合进行折半的动作，然后又需要对集合进行遍历一次，这些操作导致效率变低 。</p><p>根据元素删除：ArrayList 和 LinkedList 对比：</p><pre><code class="bash">public class ArrayTest &#123;    public static void main(String[] args) &#123;        //创建ArrayList集合对象        ArrayList&lt;String&gt; arrayList = new ArrayList&lt;String&gt;();        //添加500W个元素        for (int i = 0; i &lt; 5000000; i++) &#123;            arrayList.add(i+&quot;XXX&quot;);        &#125; //获取开始时间        long startTime = System.currentTimeMillis();        //根据元素删除ArrayList集合元素        //删除元素为 &quot;5000XXX&quot;        boolean b = arrayList.remove(&quot;5000XXX&quot;);        System.out.println(&quot;删除的状态: &quot;+b);        //获取结束时间        long endTime = System.currentTimeMillis();        System.out.println(&quot;ArrayList集合删除元素的时间: &quot;+(endTime-startTime));        //创建LinkedList集合对象        LinkedList&lt;String&gt; linkedList = new LinkedList&lt;String&gt;();        //添加500W个元素        for (int i = 0; i &lt; 5000000; i++) &#123;            linkedList.add(i+&quot;XXX&quot;);        &#125;        //获取开始时间        startTime = System.currentTimeMillis();        //根据元素删除LinkedList集合元素        //删除元素为 &quot;5000XXX&quot;        b = linkedList.remove(&quot;5000XXX&quot;);        System.out.println(&quot;删除的状态: &quot;+b);        endTime = System.currentTimeMillis();        System.out.println(&quot;LinkedList集合删除元素的时间: &quot;+(endTime-startTime));    &#125;&#125;</code></pre><p>输出：</p><pre><code class="bash">删除的状态: trueArrayList集合删除元素的时间: 10删除的状态: trueLinkedList集合删除元素的时间: 5</code></pre><p>ArrayList 根据元素删除元素的源码见上面解析！</p><p>LinkedList 根据元素删除元素 ：</p><pre><code class="bash">public class LinkedList&lt;E&gt; &#123;    public boolean remove(Object o) &#123;        //判断要删除的元素是否为null        //不管是否为null都从第一个元素开始,从头部往后找        //找到之后,调用unlink方法进行解绑,更改节点和节点之间记录的地址        if (o == null) &#123;            for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123;                if (x.item == null) &#123;                    unlink(x);                    return true;                &#125;            &#125;        &#125; else &#123;            for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123;                if (o.equals(x.item)) &#123;                    unlink(x);                    return true;                &#125;            &#125;        &#125;        return false;    &#125;        E unlink(Node&lt;E&gt; x) &#123;        // assert x != null;        final E element = x.item;        final Node&lt;E&gt; next = x.next;        final Node&lt;E&gt; prev = x.prev;        if (prev == null) &#123;            first = next;        &#125; else &#123;            prev.next = next;            x.prev = null;        &#125;        if (next == null) &#123;            last = prev;        &#125; else &#123;            next.prev = prev;            x.next = null;        &#125;        x.item = null;        size--;        modCount++;        return element;    &#125;&#125;</code></pre><h2 id="ArrayList-是线程安全的么？"><a href="#ArrayList-是线程安全的么？" class="headerlink" title="ArrayList 是线程安全的么？"></a>ArrayList 是线程安全的么？</h2><p>ArrayList 不是线程安全的。</p><h2 id="需要线程安全怎么办？"><a href="#需要线程安全怎么办？" class="headerlink" title="需要线程安全怎么办？"></a>需要线程安全怎么办？</h2><p>使用 Collections.synchronizedList (list)<br>使用 Vector</p><h2 id="如何复制某个-ArrayList-到另一个-ArrayList-中去？"><a href="#如何复制某个-ArrayList-到另一个-ArrayList-中去？" class="headerlink" title="如何复制某个 ArrayList 到另一个 ArrayList 中去？"></a>如何复制某个 ArrayList 到另一个 ArrayList 中去？</h2><p>使用 clone () 方法<br>使用 ArrayList 构造方法<br>使用 addAll 方法</p><h2 id="已知成员变量集合存储-N-多用户名称，在多线程的环境下，使用迭代器在读取集合数据的同时如何保证还可以正常的写入数据到集合？"><a href="#已知成员变量集合存储-N-多用户名称，在多线程的环境下，使用迭代器在读取集合数据的同时如何保证还可以正常的写入数据到集合？" class="headerlink" title="已知成员变量集合存储 N 多用户名称，在多线程的环境下，使用迭代器在读取集合数据的同时如何保证还可以正常的写入数据到集合？"></a>已知成员变量集合存储 N 多用户名称，在多线程的环境下，使用迭代器在读取集合数据的同时如何保证还可以正常的写入数据到集合？</h2><p>使用读写分离集合（CopyOnWriteArrayList ）</p><pre><code class="bash">class CollectionThread implements Runnable&#123;    //private static ArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;();    private static CopyOnWriteArrayList&lt;String&gt; list = new CopyOnWriteArrayList&lt;String&gt;();    static&#123;        list.add(&quot;Jack&quot;);        list.add(&quot;Lucy&quot;);        list.add(&quot;Jimmy&quot;);    &#125;    @Override    public void run() &#123;        for (String value : list) &#123;            System.out.println(value);            //在读取数据的同时又向集合写入数据            list.add(&quot;coco&quot;);        &#125;    &#125;&#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> 集合 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
            <tag> ArrayList </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java 集合</title>
      <link href="/2020/07/10/collection/Java%20%E9%9B%86%E5%90%88/"/>
      <url>/2020/07/10/collection/Java%20%E9%9B%86%E5%90%88/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>java 集合及特点<br>java 中常见的数据结构，主要分为 Collection 和 Map 两种主要接口，程序中的数据结构是继承这些接口的数据结构类。</p><p>Collection 接口：</p><p>List 接口继承：ArrayList、 Vector、 LinkedList 等实现；</p><p>Set 接口继承：HashSet、LinkedHashSet、TreeSet 等实现。</p><p>​</p><p>Map 接口： HashMap、SortedMap 继承，LinkedHashMap、TreeMap 等实现。</p><p>几个常用的类及其特点：</p><p>ArrayList</p><p>数据结构：ArrayList 底层使用的是 Object 数组；<br>存储结构：物理存储单元上连续的存储结构；<br>线程是否安全：线程不安全的；ArrayList 是非同步的，方法没有加锁；<br>特点：方便查找，但是新增和删除操作的时候，是要有移动位置的操作，所以 ArrayList 适用于存储，查询操作比较频繁的数据存储。<br>LinkedList</p><p>数据结构：LinkedList 底层使用的是双向循环链表数据结构；<br>存储方式：物理存储单元上非连续、非顺序的存储结构；<br>线程是否安全：线程不安全的；<br>特点：存储每一个元素消耗的空间要比 ArrayList 大，并且由于它的存储结构，导致他的查询不是很方便，需要去遍历每一个节点，然后查找该节点后继节点，不适合存储需要大量查询操作的数据存储，但插入比 ArrayList 方便，不需要进行换位操作，只需要改变指针前驱和后继，增删操作很快，不耗费多余资源 。<br>List 总结</p><p>所有的 List 中只能容纳单个不同类型的对象组成的表，而不是 Key－Value 键值对。例如：[tom,1,c]<br>所有的 List 中可以有相同的元素，例如 Vector 中可以有 [tom,koo,too,koo]<br>所有的 List 中可以有 null 元素，例如 [tom,null,1]<br>基于 Array 的 List（Vector，ArrayList）适合查询，而 LinkedList 适合添加，删除操作<br>Vector</p><p>数据结构：Vector 底层使用的是 Object 数组；<br>存储结构：物理存储单元上连续的存储结构；<br>线程是否安全：Vector 是线程安全的，Vector 类的方法都是有锁的；<br>特点：Vector 是线程安全的，可以由多个线程访问一个 Vector 对象。但当一个线程访问的话，保证线程安全会消耗一定的资源，因此一个线程访问就无需考虑是否线程安全的问题，建议使用 ArrayList。<br>TreeSet</p><p>数据结构：底层数据结构是二叉树；<br>线程是否安全：不保证线程安全的；<br>特点：有序的，并且没有重复元素。可以指定一个顺序，排序后按升序排列元素 。<br>HashSet</p><p>数据结构：链表和红黑树（jdk1.8 以后）；<br>线程是否安全：不保证线程安全的；<br>特点：元素没有顺序 (因为底层用的是 HashMap，HashMap 本身中的元素度没有顺序)、元素不能重复，不可随机访问包含的元素 ，只能用 Iterator 实现单向遍历，多次迭代访问，元素的顺序可能不同 。<br>Set 总结</p><p>Set 实现的基础是 Map（HashMap）；<br>Set 中的元素是不能重复的，如果使用 add (Object obj) 方法添加已经存在的对象，则会覆盖前面的对象。<br>HashMap</p><p>数据结构：链表和红黑树（jdk1.8 以后）；<br>线程是否安全：非线程安全；<br>特点：Null 可以做主键，但只能有一个，可以有多个 Value 为 Null；适用于在 Map 中插入、删除和定位元素。<br>TreeMap</p><p>数据结构：树；<br>线程是否安全：非线程安全；<br>特点：有序的，适用于按自然顺序或自定义顺序遍历键（key）。<br>LinkedHashMap</p><p>数据结构：HashMap+LinkedList；<br>线程是否安全：非线程安全；<br>特点：有序、Key 和 Value 都允许空、Key 重复会覆盖、Value 允许重复。<br>java 中，什么查询最快？</p><p>根据数组下标，查找数组的元素，是 java 中天下第一快的操作！</p><p>数组和 ArrayList 的区别:</p><p>数组可以存储数据类型一致的一组数据，没有提供操作算法，使用数组需要自行编写算法，使用数组编码的专用算法，<br>性能最佳！而 ArrayList 也可以存储一组数据，其内部也是数组，还提供操作算法，使用方便。通用算法好处是使用方便，<br>算法是经过检验的，非常可靠。但是如果期望高性能，使用数组，如期望高开发效率，使用 Arraylist。<br>Vector、ArrayList 和 LinkedList 使用</p><p>大多数情况下，从性能上来说 ArrayList 最好，但是当集合内的元素需要频繁插入、删除时 LinkedList 会有比较好的表现，但是它们三个性能都比不上数组。所以：</p><p>如果能用数组的时候 (元素类型固定，数组长度固定)，请尽量使用数组来代替 List；<br>如果没有频繁的删除插入操作，又不用考虑多线程问题，优先选择 ArrayList；<br>如果在多线程条件下使用，可以考虑 Vector；<br>如果需要频繁地删除插入，LinkedList 就有了用武之地；<br>如果你什么都不知道，用 ArrayList 没错。</p>]]></content>
      
      
      <categories>
          
          <category> 集合 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 集合 </tag>
            
            <tag> java </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
